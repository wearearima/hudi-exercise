<doc id="6361" url="https://en.wikipedia.org/wiki?curid=6361" title="Cassiopeia">
Cassiopeia

Cassiopeia ( ) or Cassiopea may refer to:

</doc>
<doc id="6362" url="https://en.wikipedia.org/wiki?curid=6362" title="Cetus">
Cetus

Cetus () is a constellation. (The) Cetus was a sea monster in Greek mythology as both Perseus and Heracles needed to slay, sometimes in English called 'the whale'. Cetus is in the region of the sky that contains other water-related constellations: Aquarius, Pisces and Eridanus. 
Cetus is not among the 12 true zodiac constellations in the J2000 epoch, nor classical 12-part zodiac. The ecliptic passes less than 0.25° from one of its corners. Thus the moon and planets will enter Cetus (occulting any stars as a foreground object) in 50% of their successive orbits briefly and the southern part of the sun appears in Cetus for about one day each year. Many asteroids in belts have longer phases occulting the north-western part of Cetus, that bulk with a slightly greater inclination to the ecliptic than the moon and planets.
As seen from Mars, the ecliptic (apparent plane of the sun and also the average plane of the planets which is almost the same) passes into Cetus - the centre of the 
sun is a foreground object in Cetus for around six days shortly after the northern summer solstice. Mars's orbit is tilted by 1.85° with respect to Earth's - Mars has relatively great 'inclination', that is, is marginally inclined away from the ecliptic.
Mira ("wonderful", named by Bayer: Omicron Ceti, a star of the neck of the asterism) was the first variable star to be discovered and the prototype of its class, Mira variables. Over a period of 332 days, it reaches a maximum apparent magnitude of 3 - visible to the naked eye - and dips to a minimum magnitude of 10, invisible to the unaided eye. Its seeming appearance and disappearance gave it its name. Mira pulsates with a minimum size of 400 solar diameters and a maximum size of 500 solar diameters. 420 light-years from Earth, it was discovered by David Fabricius in 1596.
α Ceti, traditionally called Menkar ("the nose"), is a red-hued giant star of magnitude 2.5, 220 light-years from Earth. It is a wide double star; the secondary is 93 Ceti, a blue-white hued star of magnitude 5.6, 440 light-years away. β Ceti, also called Deneb Kaitos and Diphda is the brightest star in Cetus. It is an orange-hued giant star of magnitude 2.0, 96 light-years from Earth. The traditional name "Deneb Kaitos" means "the whale's tail". γ Ceti, Kaffaljidhma ("head of the whale") is a very close double star. The primary is a yellow-hued star of magnitude 3.5, 82 light-years from Earth, and the secondary is a blue-hued star of magnitude 6.6. Tau Ceti is noted for being the nearest Sun-like star at a distance of 11.9 light-years. It is a yellow-hued main-sequence star of magnitude 3.5.
AA Ceti is a triple star system; the brightest member has a magnitude of 6.2. The primary and secondary are separated by 8.4 arcseconds at an angle of 304 degrees. The tertiary is not visible in telescopes. AA Ceti is an eclipsing variable star; the tertiary star passes in front of the primary and causes the system's apparent magnitude to decrease by 0.5 magnitudes. UV Ceti is an unusual binary variable star. 8.7 light-years from Earth, the system consists of two red dwarfs. Both of magnitude 13. One of the stars is a flare star, which are prone to sudden, random outbursts that last several minutes; these increase the pair's apparent brightness significantly - as high as magnitude 7.
Cetus lies far from the galactic plane, so that many distant galaxies are visible, unobscured by dust from the Milky Way. Of these, the brightest is Messier 77 (NGC 1068), a 9th magnitude spiral galaxy near Delta Ceti. It appears face-on and has a clearly visible nucleus of magnitude 10. About 50 million light-years from Earth, M77 is also a Seyfert galaxy and thus a bright object in the radio spectrum. Recently, the galactic cluster JKCS 041 was confirmed to be the most distant cluster of galaxies yet discovered.
The massive cD galaxy Holmberg 15A is also found in Cetus. As is spiral galaxy NGC 1042 and ultra-diffuse galaxy NGC 1052-DF2. 
IC 1613 (Caldwell 51) is an irregular dwarf galaxy near the star 26 Ceti and is a member of the Local Group.
NGC 246 (Caldwell 56), also called the Cetus Ring, is a planetary nebula with a magnitude of 8.0, 1600 light-years from Earth. Among some amateur astronomers, NGC 246 has garnered the nickname "Pac-Man Nebula" because of the arrangement of its central stars and the surrounding star field.
Cetus may have originally been associated with a whale, which would have had mythic status amongst Mesopotamian cultures. It is often now called the Whale, though it is most strongly associated with Cetus the sea-monster, who was slain by Perseus as he saved the princess Andromeda from Poseidon's wrath. Cetus is located in a region of the sky called "The Sea" because many water-associated constellations are placed there, including Eridanus, Pisces, Piscis Austrinus, Capricornus, and Aquarius.
Cetus has been depicted in many ways throughout its history. In the 17th century, Cetus was depicted as a "dragon fish" by Johann Bayer. Both Willem Blaeu and Andreas Cellarius depicted Cetus as a whale-like creature in the same century. However, Cetus has also been variously depicted with animal heads attached to a piscine body.
In Chinese astronomy, the stars of Cetus are found among two areas: the Black Tortoise of the North (北方玄武, "Běi Fāng Xuán Wǔ") and the White Tiger of the West (西方白虎, "Xī Fāng Bái Hǔ").
The Tukano and Kobeua people of the Amazon used the stars of Cetus to create a jaguar, representing the god of hurricanes and other violent storms. Lambda, Mu, Xi, Nu, Gamma, and Alpha Ceti represented its head; Omicron, Zeta, and Chi Ceti represented its body; Eta Eri, Tau Cet, and Upsilon Cet marked its legs and feet; and Theta, Eta, and Beta Ceti delineated its tail.
In Hawaii, the constellation was called "Na Kuhi", and Mira (Omicron Ceti) may have been called "Kane".
USS Cetus (AK-77) was a United States Navy Crater class cargo ship named after the constellation.
"Cetus" is the title of a ragtime piano composition by Tom Brier on the album "Constellations".

</doc>
<doc id="6363" url="https://en.wikipedia.org/wiki?curid=6363" title="Carina (constellation)">
Carina (constellation)

Carina ( (U.S.) (Brit.)) is a constellation in the southern sky. Its name is Latin for the hull or keel of a ship, and it was the southern foundation of the larger constellation of Argo Navis (the ship "Argo") until it was divided into three pieces, the other two being Puppis (the poop deck), and Vela (the sails of the ship).
Carina was once a part of Argo Navis, the great ship of Jason and the Argonauts who searched for the Golden Fleece. The constellation of Argo was introduced in ancient Greece. However, due to the massive size of Argo Navis and the sheer number of stars that required separate designation, Nicolas Louis de Lacaille divided Argo into three sections in 1763, including Carina (the hull or keel). In the 19th century, these three became established as separate constellations, and were formally included in the list of 88 modern IAU constellations in 1930. Lacaille kept a single set of Greek letters for the whole of Argo, and separate sets of Latin letter designations for each of the three sections. Therefore, Carina has the α, β and ε, Vela has γ and δ, Puppis has ζ, and so on.
Carina contains Canopus, a white-hued supergiant that is the second brightest star in the night sky at magnitude −0.72. Alpha Carinae, as Canopus is formally designated, is 313 light-years from Earth. Its traditional name comes from the mythological Canopus, who was a navigator for Menelaus, king of Sparta.
There are several other stars above magnitude 3 in Carina. Beta Carinae, traditionally called Miaplacidus, is a blue-white hued star of magnitude 1.7, 111 light-years from Earth. Epsilon Carinae is an orange-hued giant star similarly bright to Miaplacidus at magnitude 1.9; it is 630 light-years from Earth. Another fairly bright star is the blue-white hued Theta Carinae; it is a magnitude 2.7 star 440 light-years from Earth. Theta Carinae is also the most prominent member of the cluster IC 2602. Iota Carinae is a white-hued supergiant star of magnitude 2.2, 690 light-years from Earth.
Eta Carinae is the most prominent variable star in Carina; with a mass of approximately 100 solar masses and 4 million times as bright as the Sun. It was first discovered to be unusual in 1677, when its magnitude suddenly rose to 4, attracting the attention of Edmond Halley. Eta Carinae is inside NGC 3372, commonly called the Carina Nebula. It had a long outburst in 1827, when it brightened to magnitude 1, only fading to magnitude 1.5 in 1828. Its most prominent outburst made Eta Carinae the equal of Sirius; it brightened to magnitude −1.5 in 1843. In the decades following 1843 it appeared relatively placid, having a magnitude between 6.5 and 7.9. However, in 1998, it brightened again, though only to magnitude 5.0, a far less drastic outburst. Eta Carinae is a binary star, with a companion that has a period of 5.5 years; the two stars are surrounded by the Homunculus Nebula, which is composed of gas that was ejected in 1843.
There are several less prominent variable stars in Carina. l Carinae is a Cepheid variable noted for its brightness; it is the brightest Cepheid that is variable to the unaided eye. It is a yellow-hued supergiant star with a minimum magnitude of 4.2 and a maximum magnitude of 3.3; it has a period of 35.5 days.
Two bright Mira variable stars are in Carina: R Carinae and S Carinae; both stars are red giants. R Carinae has a minimum magnitude of 10.0 and a maximum magnitude of 4.0. Its period is 309 days and it is 416 light-years from Earth. S Carinae is similar, with a minimum magnitude of 10.0 and a maximum magnitude of 5.0. However, S Carinae has a shorter period – 150 days, though it is much more distant at 1300 light-years from Earth.
Carina is home to several double stars and binary stars. Upsilon Carinae is a binary star with two blue-white hued giant components, 1600 light-years from Earth. The primary is of magnitude 3.0 and the secondary is of magnitude 6.0; the two components are distinguishable in a small amateur telescope.
Two asterisms are prominent in Carina. One is known as the 'Diamond Cross', which is larger than the Southern Cross (but fainter), and, from the perspective of the southern hemisphere viewer, upside down, the long axes of the two crosses being close to parallel. Another asterism in the constellation is the False Cross, often mistaken for the Southern Cross, which is an asterism in Crux. The False Cross consists of two stars in Carina, Iota Carinae and Epsilon Carinae, and two stars in Vela, Kappa Velorum and Delta Velorum.
Carina is known for its namesake nebula, NGC 3372, discovered by French astronomer Nicolas Louis de Lacaille in 1751, which contains several nebulae. The Carina Nebula overall is an extended emission nebula approximately 8,000 light-years away and 300 light-years wide that includes vast star-forming regions. It has an overall magnitude of 8.0 and an apparent diameter of over 2 degrees. Its central region is called the Keyhole, or the Keyhole Nebula. This was described in 1847 by John Herschel, and likened to a keyhole by Emma Converse in 1873. The Keyhole is about seven light-years wide and is composed mostly of ionized hydrogen, with two major star-forming regions. The Homunculus Nebula is a planetary nebula visible to the naked eye that is being ejected by the erratic luminous blue variable star Eta Carinae, the most massive visible star known. Eta Carinae is so massive that it has reached the theoretical upper limit for the mass of a star and is therefore unstable. It is known for its outbursts; in 1840 it briefly became one of the brightest stars in the sky due to a particularly massive outburst, which largely created the Homunculus Nebula. Because of this instability and history of outbursts, Eta Carinae is considered a prime supernova candidate for the next several hundred thousand years because it has reached the end of its estimated million-year life span.
NGC 2516 is an open cluster that is both quite large (approximately half a degree square) and bright, visible to the unaided eye. It is located 1100 light-years from Earth and has approximately 80 stars, the brightest of which is a red giant star of magnitude 5.2. NGC 3114 is another open cluster approximately of the same size, though it is more distant at 3000 light-years from Earth. It is more loose and dim than NGC 2516, as its brightest stars are only 6th magnitude. The most prominent open cluster in Carina is IC 2602, also called the "Southern Pleiades". It contains Theta Carinae, along with several other stars visible to the unaided eye. In total, the cluster possesses approximately 60 stars. The Southern Pleiades is particularly large for an open cluster, with a diameter of approximately one degree. Like IC 2602, NGC 3532 is visible to the unaided eye and is of comparable size. It possesses approximately 150 stars that are arranged in an unusual shape, approximating an ellipse with a dark central area. Several prominent orange giants are among the cluster's bright stars, of the 7th magnitude. Superimposed on the cluster is Chi Carinae, a yellow-white hued star of magnitude 3.9, far more distant than NGC 3532.
Carina also contains the naked-eye globular cluster NGC 2808. Epsilon Carinae and Upsilon Carinae are double stars visible in small telescopes.
One noted galaxy cluster is 1E 0657-56, the Bullet Cluster. At a distance of 4 billion light years (redshift 0.296), this galaxy cluster is named for the shock wave seen in the intracluster medium, which resembles the shock wave of a supersonic bullet. The bow shock visible is thought to be due to the smaller galaxy cluster moving through the intracluster medium at a relative speed of 3000–4000 kilometers per second to the larger cluster. Because this gravitational interaction has been ongoing for hundreds of millions of years, the smaller cluster is being destroyed and will eventually merge with the larger cluster.
Carina contains the radiant of the Eta Carinids meteor shower, which peaks around January 21 each year.
From China (especially northern China), the stars of Carina can barely be seen. The star Canopus (the south polar star in Chinese astronomy) was located by Chinese astronomers in the Vermilion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"). The rest of the stars were first classified by Xu Guanggi during the Ming Dynasty, based on the knowledge acquired from western star charts, and placed among The Southern Asterisms (近南極星區, "Jìnnánjíxīngōu").
Polynesian peoples had no name for the constellation in particular, though they had many names for Canopus. 
The Māori name "Ariki" ("High-born"), . and the Hawaiian "Ke Alii-o-kona-i-ka-lewa", "The Chief of the southern expanse". both attest to the star's prominence in the southern sky, while the Māori "Atutahi", "First-light" or "Single-light", and the Tuamotu "Te Tau-rari" and "Marere-te-tavahi", "He-who-stands-alone". refer to the star's solitary nature.
It was also called "Kapae-poto", ("Short horizon"), because it rarely sets from the vantage point of New Zealand; and "Kauanga" ("Solitary"), when it was the last star visible before sunrise.
Carina is in the southern sky quite near the south celestial pole, making it never set (circumpolar) for most of the southern hemisphere. Due to precession of Earth's axis, by the year 4700 the south celestial pole will be in Carina. Three bright stars in Carina will come within 1 degree of the southern celestial pole and take turns as the southern pole star: Omega Carinae (mag 3.29) in 5600, Upsilon Carinae (mag 2.97) in 6700, and Iota Carinae (mag 2.21) in 7900. About 13860, the bright Canopus (-0.7) will have a greater declination than -82°.
 was a United States Navy Crater class cargo ship named after the constellation.

</doc>
<doc id="6364" url="https://en.wikipedia.org/wiki?curid=6364" title="Camelopardalis">
Camelopardalis

Camelopardalis is a large but faint constellation of the northern sky representing a giraffe. The constellation was introduced in 1612 or 1613 by Petrus Plancius. Some older astronomy books give Camelopardalus or Camelopardus as alternative forms of the name, but the version recognized by the International Astronomical Union matches the genitive form, seen suffixed to most of its key stars.
First attested in English in 1785, the word "camelopardalis" comes from Latin, and it is the romanization of the Greek "καμηλοπάρδαλις" meaning "giraffe", from "κάμηλος" ("kamēlos"), "camel" + "πάρδαλις" ("pardalis"), "spotted", because it has a long neck like a camel and spots.
Although Camelopardalis is the 18th largest constellation, it is not a particularly bright constellation, as the brightest stars are only of fourth magnitude. In fact, it only contains four stars below (brighter than) magnitude 5.0.
Other variable stars are U Camelopardalis, VZ Camelopardalis, and Mira variables T Camelopardalis, X Camelopardalis, and R Camelopardalis. RU Camelopardalis is one of the brighter Type II Cepheids visible in the night sky.
In 2011 a supernova was discovered in the constellation.
Camelopardalis is in the part of the celestial sphere facing away from the galactic plane. Accordingly, many distant galaxies are visible within its borders. 
The annual May meteor shower Camelopardalids from comet 209P/LINEAR have a radiant in Camelopardalis.
The space probe "Voyager 1" is moving in the direction of this constellation, though it will not be nearing any of the stars in this constellation for many thousands of years, by which time its power source will be long dead.
Camelopardalis is not one of Ptolemy's 48 constellations in the "Almagest". It was created by Petrus Plancius in 1613. It first appeared in a globe designed by him and produced by Pieter van den Keere. One year later, Jakob Bartsch featured it in his atlas. Johannes Hevelius depicted this constellation in his works which were so influential that it was referred to as Camelopardali Hevelii or abbreviated as Camelopard. Hevel.
Part of the constellation was hived off to form the constellation Sciurus Volans, the Flying Squirrel, by William Croswell in 1810. However this was not taken up by later cartographers.
In Chinese astronomy, the stars of Camelopardalis are located within a group of circumpolar stars called the Purple Forbidden Enclosure (紫微垣 "Zǐ Wēi Yuán").

</doc>
<doc id="6365" url="https://en.wikipedia.org/wiki?curid=6365" title="Convention of Kanagawa">
Convention of Kanagawa

On March 31, 1854, the or became the first treaty between the United States and the Tokugawa shogunate.
Signed under threat of force, it effectively meant the end of Japan's 220-year-old policy of national seclusion ("sakoku") by opening the ports of Shimoda and Hakodate to American vessels. It also ensured the safety of American castaways and established the position of an American consul in Japan. The treaty also precipitated the signing of similar treaties establishing diplomatic relations with other Western powers.
Since the beginning of the seventeenth century, the Tokugawa shogunate pursued a policy of isolating the country from outside influences. Foreign trade was maintained only with the Dutch and the Chinese and was conducted exclusively at Nagasaki under a strict government monopoly. This policy had two main objectives. One was the fear that trade with western powers and the spread of Christianity would serve as a pretext for the invasion of Japan by imperialist forces, as had been the case with most of the nations of Asia. The second objective was fear that foreign trade and the wealth developed would lead to the rise of a "daimyō" powerful enough to overthrow the ruling Tokugawa clan.
By the early nineteenth century, this policy of isolation was increasingly under challenge. In 1844, King William II of the Netherlands sent a letter urging Japan to end the isolation policy on its own before change would be forced from the outside. In 1846, an official American expedition led by Commodore James Biddle arrived in Japan asking for ports to be opened for trade, but was sent away.
In 1853, United States Navy Commodore Matthew C. Perry was sent with a fleet of warships by US president Millard Fillmore to force the opening of Japanese ports to American trade, through the use of gunboat diplomacy if necessary. The growing commerce between America and China, the presence of American whalers in waters offshore Japan, and the increasing monopolization of potential coaling stations by the British and French in Asia were all contributing factors. The Americans were also driven by concepts of Manifest Destiny and the desire to impose the benefits of western civilization on what they perceived as backward Asian nations. For the Japanese standpoint, increasing contacts with foreign warships and the increasing disparity between western military technology and the Japanese feudal armies created growing concern. The Japanese had been keeping abreast of world events via information gathered from Dutch traders in Dejima and had been forewarned by the Dutch of Perry's voyage. There was considerable internal debate in Japan on how best to meet this potential threat to Japan's economic and political sovereignty in light of events occurring in China with the Opium Wars.
Perry arrived with four warships at Uraga, at the mouth of Edo Bay on July 8, 1853. After refusing Japanese demands that he proceed to Nagasaki, which was the designated port for foreign contact, and after threatening to continue directly on to Edo, the nation's capital, and to burn it to the ground if necessary, he was allowed to land at nearby Kurihama on July 14 and to deliver his letter.
Despite years of debate on the isolation policy, Perry's letter created great controversy within the highest levels of the Tokugawa shogunate. The "shōgun" himself, Tokugawa Ieyoshi, died days after Perry's departure, and was succeeded by his sickly young son, Tokugawa Iesada, leaving effective administration in the hands of the Council of Elders ("rōjū") led by Abe Masahiro. Abe felt that it was currently impossible for Japan to resist the American demands by military force, and yet was reluctant to take any action on his own authority for such an unprecedented situation. Attempting to legitimize any decision taken, Abe polled all of the "daimyō" for their opinions. This was the first time that the Tokugawa shogunate had allowed its decision-making to be a matter of public debate, and had the unforeseen consequence of portraying the shogunate as weak and indecisive. The results of the poll also failed to provide Abe with an answer as, of the 61 known responses, 19 were in favor of accepting the American demands and 19 were equally opposed. Of the remainder, 14 gave vague responses expressing concern of possible war, 7 suggested making temporary concessions and two advised that they would simply go along with whatever was decided.
Perry returned again on February 13, 1854, with an even larger force of eight warships and made it clear that he would not be leaving until a treaty was signed. Negotiations began on March 8 and proceeded for around one month. The Japanese side gave in to almost all of Perry's demands, with the exception of a commercial agreement modeled after previous American treaties with China, which Perry agreed to defer to a later time. The main controversy centered on the selection of the ports to open, with Perry adamantly rejecting Nagasaki. The treaty, written in English, Dutch, Chinese and Japanese, was signed on March 31, 1854 at what is now known as Kaikō Hiroba (Port Opening Square) Yokohama, a site adjacent to the current Yokohama Archives of History.
The "Japan–US Treaty of Peace and Amity" has twelve articles: 
The final article, Article Twelve, stipulated that the terms of the treaty were to be ratified by the President of the United States and the "August Sovereign of Japan" within 18 months. At the time, "shōgun" Tokugawa Iesada was the de facto ruler of Japan; for the Emperor to interact in any way with foreigners was out of the question. Perry concluded the treaty with representatives of the shogun, led by plenipotentiary and the text was endorsed subsequently, albeit reluctantly, by Emperor Kōmei.
The treaty was ratified on February 21, 1855.
In the short term, the US was content with the agreement since Perry had achieved his primary objective of breaking Japan's "sakoku" policy and setting the grounds for protection of American citizens and an eventual commercial agreement. On the other hand, the Japanese were forced into this trade, and many saw it as a sign of weakness. The Tokugawa shogunate could point out that the treaty was not actually signed by the Shogun, or indeed any of his "rōjū", and that it had at least temporarily averted the possibility of immediate military confrontation.
Externally, the treaty led to the United States-Japan Treaty of Amity and Commerce, the "Harris Treaty" of 1858, which allowed the establishment of foreign concessions, extraterritoriality for foreigners, and minimal import taxes for foreign goods. The Japanese chafed under the "unequal treaty system" which characterized Asian and western relations during this period. The Kanagawa treaty was also followed by similar agreements with the United Kingdom (Anglo-Japanese Friendship Treaty, October 1854), the Russians (Treaty of Shimoda, February 7, 1855), and the French (Treaty of Amity and Commerce between France and Japan, October 9, 1858).
Internally, the treaty had far-reaching consequences. Decisions to suspend previous restrictions on military activities led to re-armament by many domains and further weakened the position of the Shogun. Debate over foreign policy and popular outrage over perceived appeasement to the foreign powers was a catalyst for the "sonnō jōi" movement and a shift in political power from Edo back to the Imperial Court in Kyoto. The opposition of Emperor Kōmei to the treaties further lent support to the "tōbaku" (overthrow the Shogunate) movement, and eventually to the Meiji Restoration.
The Convention was negotiated and then signed in a purpose-built house in Yokohama, Japan, the site of which is now the Yokohama Archives of History.

</doc>
<doc id="6366" url="https://en.wikipedia.org/wiki?curid=6366" title="Canis Major">
Canis Major

Canis Major is a constellation in the southern celestial hemisphere. In the second century, it was included in Ptolemy's 48 constellations, and is counted among the 88 modern constellations. Its name is Latin for "greater dog" in contrast to Canis Minor, the "lesser dog"; both figures are commonly represented as following the constellation of Orion the hunter through the sky. The Milky Way passes through Canis Major and several open clusters lie within its borders, most notably M41.
Canis Major contains Sirius, the brightest star in the night sky, known as the "dog star". It is bright because of its proximity to the Solar System. In contrast, the other bright stars of the constellation are stars of great distance and high luminosity. At magnitude 1.5, Epsilon Canis Majoris (Adhara) is the second-brightest star of the constellation and the brightest source of extreme ultraviolet radiation in the night sky. Next in brightness are the yellow-white supergiant Delta (Wezen) at 1.8, the blue-white giant Beta (Mirzam) at 2.0, blue-white supergiants Eta (Aludra) at 2.4 and Omicron at 3.0, and white spectroscopic binary Zeta (Furud), also at 3.0. The red hypergiant VY Canis Majoris is one of the largest stars known, while the neutron star RX J0720.4-3125 has a radius of a mere 5 km.
In ancient Mesopotamia, Sirius, named KAK.SI.DI by the Babylonians, was seen as an arrow aiming towards Orion, while the southern stars of Canis Major and a part of Puppis were viewed as a bow, named BAN in the "Three Stars Each" tablets, dating to around 1100 BC. In the later compendium of Babylonian astronomy and astrology titled "MUL.APIN", the arrow, Sirius, was also linked with the warrior Ninurta, and the bow with Ishtar, daughter of Enlil. Ninurta was linked to the later deity Marduk, who was said to have slain the ocean goddess Tiamat with a great bow, and worshipped as the principal deity in Babylon. The Ancient Greeks replaced the bow and arrow depiction with that of a dog.
In Greek Mythology, Canis Major represented the dog Laelaps, a gift from Zeus to Europa; or sometimes the hound of Procris, Diana's nymph; or the one given by Aurora to Cephalus, so famed for its speed that Zeus elevated it to the sky. It was also considered to represent one of Orion's hunting dogs, pursuing Lepus the Hare or helping Orion fight Taurus the Bull; and is referred to in this way by Aratos, Homer and Hesiod. The ancient Greeks refer only to one dog, but by Roman times, Canis Minor appears as Orion's second dog. Alternative names include Canis Sequens and Canis Alter. Canis Syrius was the name used in the 1521 "Alfonsine tables".
The Roman myth refers to Canis Major as "Custos Europae", the dog guarding Europa but failing to prevent her abduction by Jupiter in the form of a bull, and as "Janitor Lethaeus", "the watchdog". In medieval Arab astronomy, the constellation became "al-Kalb al-Akbar", "the Greater Dog", transcribed as "Alcheleb Alachbar" by 17th century writer Edmund Chilmead. Islamic scholar Abū Rayḥān al-Bīrūnī referred to Orion as "Kalb al-Jabbār", "the Dog of the Giant". Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called "Merzem", includes the stars of Canis Major and Canis Minor and is the herald of two weeks of hot weather.
In Chinese astronomy, the modern constellation of Canis Major is located in the Vermilion Bird (), where the stars were classified in several separate asterisms of stars. The Military Market () was a circular pattern of stars containing Nu, Beta, Xi and Xi, and some stars from Lepus. The Wild Cockerel () was at the centre of the Military Market, although it is uncertain which stars depicted what. Schlegel reported that the stars Omicron and Pi Canis Majoris might have been them, while Beta or Nu have also been proposed. Sirius was ' (), the Celestial Wolf, denoting invasion and plunder. Southeast of the Wolf was the asterism ' (), the celestial Bow and Arrow, which was interpreted as containing Delta, Epsilon, Eta and Kappa Canis Majoris and Delta Velorum. Alternatively, the arrow was depicted by Omicron and Eta and aiming at Sirius (the Wolf), while the bow comprised Kappa, Epsilon, Sigma, Delta and 164 Canis Majoris, and Pi and Omicron Puppis.
Both the Māori people and the people of the Tuamotus recognized the figure of Canis Major as a distinct entity, though it was sometimes absorbed into other constellations. ', also called ' and ', ("The Assembly of " or "The Assembly of Sirius") was a Māori constellation that included both Canis Minor and Canis Major, along with some surrounding stars. Related was ', also called ', the Mirror of , formed from an undefined group of stars in Canis Major. They called Sirius ' and ', corresponding to two of the names for the constellation, though ' was a name applied to other stars in various Māori groups and other Polynesian cosmologies. The Tuamotu people called Canis Major "", "the abiding assemblage of ".
The Tharumba people of the Shoalhaven River saw three stars of Canis Major as ' (Bat) and his two wives ' (Mrs Brown Snake) and ' (Mrs Black Snake); bored of following their husband around, the women try to bury him while he is hunting a wombat down its hole. He spears them and all three are placed in the sky as the constellation '. To the Boorong people of Victoria, Sigma Canis Majoris was ' (which has become the official name of this star), and its flanking stars Delta and Epsilon were his two wives. The moon (', "native cat") sought to lure the further wife (Epsilon) away, but assaulted him and he has been wandering the sky ever since.
Canis Major is a constellation in the Southern Hemisphere's summer (or northern hemisphere's winter) sky, bordered by Monoceros (which lies between it and Canis Minor) to the north, Puppis to the east and southeast, Columba to the southwest, and Lepus to the west. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "CMa". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a quadrilateral; in the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −11.03° and −33.25°. Covering 380 square degrees or 0.921% of the sky, it ranks 43rd of the 88 currently-recognized constellations in size.
Canis Major is a prominent constellation because of its many bright stars. These include Sirius (Alpha Canis Majoris), the brightest star in the night sky, as well as three other stars above magnitude 2.0. Furthermore, two other stars are thought to have previously outshone all others in the night sky—Adhara (Epsilon Canis Majoris) shone at −3.99 around 4.7 million years ago, and Mirzam (Beta Canis Majoris) peaked at −3.65 around 4.42 million years ago. Another, NR Canis Majoris, will be brightest at magnitude −0.88 in about 2.87 million years' time.
The German cartographer Johann Bayer used the Greek letters Alpha through Omicron to label the most prominent stars in the constellation, including three adjacent stars as Nu and two further pairs as Xi and Omicron, while subsequent observers designated further stars in the southern parts of the constellation that were hard to discern from Central Europe. Bayer's countryman Johann Elert Bode later added Sigma, Tau and Omega; the French astronomer Nicolas Louis de Lacaille added lettered stars a to k (though none are in use today). John Flamsteed numbered 31 stars, with 3 Canis Majoris being placed by Lacaille into Columba as Delta Columbae (Flamsteed had not recognised Columba as a distinct constellation). He also labelled two stars—his 10 and 13 Canis Majoris—as Kappa and Kappa respectively, but subsequent cartographers such as Francis Baily and John Bevis dropped the fainter former star, leaving Kappa as the sole Kappa. Flamsteed's listing of Nu, Nu, Nu, Xi, Xi, Omicron and Omicron have all remained in use.
Sirius is the brightest star in the night sky at apparent magnitude −1.46 and one of the closest stars to Earth at a distance of 8.6 light-years. Its name comes from the Greek word for "scorching" or "searing". Sirius is also a binary star; its companion Sirius B is a white dwarf with a magnitude of 8.4–10,000 times fainter than Sirius A to observers on Earth. The two orbit each other every 50 years. Their closest approach last occurred in 1993 and they will be at their greatest separation between 2020 and 2025. Sirius was the basis for the ancient Egyptian calendar. The star marked the Great Dog's mouth on Bayer's star atlas.
Flanking Sirius are Beta and Gamma Canis Majoris. Also called Mirzam or Murzim, Beta is a blue-white Beta Cephei variable star of magnitude 2.0, which varies by a few hundredths of a magnitude over a period of six hours. Mirzam is 500 light-years from Earth, and its traditional name means "the announcer", referring to its position as the "announcer" of Sirius, as it rises a few minutes before Sirius does. Gamma, also known as Muliphein, is a fainter star of magnitude 4.12, in reality a blue-white bright giant of spectral type B8IIe located 441 light-years from earth. Iota Canis Majoris, lying between Sirius and Gamma, is another star that has been classified as a Beta Cephei variable, varying from magnitude 4.36 to 4.40 over a period of 1.92 hours. It is a remote blue-white supergiant star of spectral type B3Ib, around 46,000 times as luminous as the sun and, at 2500 light-years distant, 300 times further away than Sirius.
Epsilon, Omicron, Delta, and Eta Canis Majoris were called "Al Adzari" "the virgins" in medieval Arabic tradition. Marking the dog's right thigh on Bayer's atlas is Epsilon Canis Majoris, also known as Adhara. At magnitude 1.5, it is the second-brightest star in Canis Major and the 23rd-brightest star in the sky. It is a blue-white supergiant of spectral type B2Iab, around 404 light-years from Earth. This star is one of the brightest known extreme ultraviolet sources in the sky. It is a binary star; the secondary is of magnitude 7.4. Its traditional name means "the virgins", having been transferred from the group of stars to Epsilon alone. Nearby is Delta Canis Majoris, also called Wezen. It is a yellow-white supergiant of spectral type F8Iab and magnitude 1.84, around 1605 light-years from Earth. With a traditional name meaning "the weight", Wezen is 17 times as massive and 50,000 times as luminous as the Sun. If located in the centre of the Solar System, it would extend out to Earth as its diameter is 200 times that of the Sun. Only around 10 million years old, Wezen has stopped fusing hydrogen in its core. Its outer envelope is beginning to expand and cool, and in the next 100,000 years it will become a red supergiant as its core fuses heavier and heavier elements. Once it has a core of iron, it will collapse and explode as a supernova. Nestled between Adhara and Wezen lies Sigma Canis Majoris, known as Unurgunite to the Boorong and Wotjobaluk people, a red supergiant of spectral type K7Ib that varies irregularly between magnitudes 3.43 and 3.51.
Also called Aludra, Eta Canis Majoris is a blue-white supergiant of spectral type B5Ia with a luminosity 176,000 times and diameter around 80 times that of the Sun. Classified as an Alpha Cygni type variable star, Aludra varies in brightness from magnitude 2.38 to 2.48 over a period of 4.7 days. It is located 1120 light-years away. To the west of Adhara lies 3.0-magnitude Zeta Canis Majoris or Furud, around 362 light-years distant from Earth. It is a spectroscopic binary, whose components orbit each other every 1.85 years, the combined spectrum indicating a main star of spectral type B2.5V.
Between these stars and Sirius lie Omicron, Omicron, and Pi Canis Majoris. Omicron is a massive supergiant star about 21 times as massive as the Sun. Only 7 million years old, it has exhausted the supply of hydrogen at its core and is now processing helium. It is an Alpha Cygni variable that undergoes periodic non-radial pulsations, which cause its brightness to cycle from magnitude 2.93 to 3.08 over a 24.44-day interval. Omicron is an orange K-type supergiant of spectral type K2.5Iab that is an irregular variable star, varying between apparent magnitudes 3.78 and 3.99. Around 18 times as massive as the Sun, it shines with 65,000 times its luminosity.
North of Sirius lie Theta and Mu Canis Majoris, Theta being the most northerly star with a Bayer designation in the constellation. Around 8 billion years old, it is an orange giant of spectral type K4III that is around as massive as the Sun but has expanded to 30 times the Sun's diameter. Mu is a multiple star system located around 1244 light-years distant, its components discernible in a small telescope as a 5.3-magnitude yellow-hued and 7.1-magnitude bluish star. The brighter star is a giant of spectral type K2III, while the companion is a main sequence star of spectral type B9.5V. Nu Canis Majoris is a yellow-hued giant star of magnitude 5.7, 278 light-years away; it is at the threshold of naked-eye visibility. It has a companion of magnitude 8.1.
At the southern limits of the constellation lie Kappa and Lambda Canis Majoris. Although of similar spectra and nearby each other as viewed from Earth, they are unrelated. Kappa is a Gamma Cassiopeiae variable of spectral type B2Vne, which brightened by 50% between 1963 and 1978, from magnitude 3.96 or so to 3.52. It is around 659 light-years distant. Lambda is a blue-white B-type main sequence dwarf with an apparent magnitude of 4.48 located around 423 light-years from Earth. It is 3.7 times as wide as and 5.5 times as massive as the Sun, and shines with 940 times its luminosity.
Canis Major is also home to many variable stars. EZ Canis Majoris is a Wolf–Rayet star of spectral type WN4 that varies between magnitudes 6.71 and 6.95 over a period of 3.766 days; the cause of its variability is unknown but thought to be related to its stellar wind and rotation. VY Canis Majoris is a remote red hypergiant located approximately 3,800 light-years away from Earth. It is one of largest stars known (sometimes described as the largest known) and is also one of most luminous with a radius varying from 1,420 to 2,200 times the Sun's radius, and a luminosity around 300,000 times greater than the Sun. Its current mass is about 17 ± 8 solar masses, having shed material from an initial mass of 25–32 solar masses. VY CMa is also surrounded by a red reflection nebula that has been made by the material expelled by the strong stellar winds of its central star. W Canis Majoris is a type of red giant known as a carbon star—a semiregular variable, it ranges between magnitudes 6.27 and 7.09 over a period of 160 days. A cool star, it has a surface temperature of around 2,900 K and a radius 234 times that of the Sun, its distance estimated at 1,444–1,450 light-years from Earth. At the other extreme in size is RX J0720.4-3125, a neutron star with a radius of around 5 km. Exceedingly faint, it has an apparent magnitude of 26.6. Its spectrum and temperature appear to be mysteriously changing over several years. The nature of the changes are unclear, but it is possible they were caused by an event such as the star's absorption of an accretion disc.
Tau Canis Majoris is a Beta Lyrae-type eclipsing multiple star system that varies from magnitude 4.32 to 4.37 over 1.28 days. Its four main component stars are hot O-type stars, with a combined mass 80 times that of the Sun and shining with 500,000 times its luminosity, but little is known of their individual properties. A fifth component, a magnitude 10 star, lies at a distance of . The system is only 5 million years old. UW Canis Majoris is another Beta Lyrae-type star 3000 light-years from Earth; it is an eclipsing binary that ranges in magnitude from a minimum of 5.3 to a maximum of 4.8. It has a period of 4.4 days; its components are two massive hot blue stars, one a blue supergiant of spectral type O7.5–8 Iab, while its companion is a slightly cooler, less evolved and less luminous supergiant of spectral type O9.7Ib. The stars are 200,000 and 63,000 times as luminous as the Sun. However the fainter star is the more massive at 19 solar masses to the primary's 16. R Canis Majoris is another eclipsing binary that varies from magnitude 5.7 to 6.34 over 1.13 days, with a third star orbiting these two every 93 years. The shortness of the orbital period and the low ratio between the two main components make this an unusual Algol-type system.
Seven star systems have been found to have planets. Nu Canis Majoris is an ageing orange giant of spectral type K1III of apparent magnitude 3.91 located around 64 light-years distant. Around 1.5 times as massive and 11 times as luminous as the Sun, it is orbited over a period of 763 days by a planet 2.6 times as massive as Jupiter. HD 47536 is likewise an ageing orange giant found to have a planetary system—echoing the fate of the Solar System in a few billion years as the Sun ages and becomes a giant. Conversely, HD 45364 is a star 107 light-years distant that is a little smaller and cooler than the Sun, of spectral type G8V, which has two planets discovered in 2008. With orbital periods of 228 and 342 days, the planets have a 3:2 orbital resonance, which helps stabilise the system. HD 47186 is another sunlike star with two planets; the inner—HD 47186 b—takes four days to complete an orbit and has been classified as a Hot Neptune, while the outer—HD 47186 c—has an eccentric 3.7-year period orbit and has a similar mass to Saturn. HD 43197 is a sunlike star around 183 light-years distant that has a Jupiter-size planet with an eccentric orbit.
Z Canis Majoris is a star system a mere 300,000 years old composed of two pre-main-sequence stars—a FU Orionis star and a Herbig Ae/Be star, which has brightened episodically by two magnitudes to magnitude 8 in 1987, 2000, 2004 and 2008. The more massive Herbig Ae/Be star is enveloped in an irregular roughly spherical cocoon of dust that has an inner diameter of and outer diameter of . The cocoon has a hole in it through which light shines that covers an angle of 5 to 10 degrees of its circumference. Both stars are surrounded by a large envelope of in-falling material left over from the original cloud that formed the system. Both stars are emitting jets of material, that of the Herbig Ae/Be star being much larger—11.7 light-years long. Meanwhile, FS Canis Majoris is another star with infra-red emissions indicating a compact shell of dust, but it appears to be a main-sequence star that has absorbed material from a companion. These stars are thought to be significant contributors to interstellar dust.
The band of the Milky Way goes through Canis Major, with only patchy obscurement by interstellar dust clouds. It is bright in the northeastern corner of the constellation, as well as in a triangular area between Adhara, Wezen and Aludra, with many stars visible in binoculars. Canis Major boasts several open clusters. The only Messier object is M41 (NGC 2287), an open cluster with a combined visual magnitude of 4.5, around 2300 light-years from Earth. Located 4 degrees south of Sirius, it contains contrasting blue, yellow and orange stars and covers an area the apparent size of the full moon—in reality around 25 light-years in diameter. Its most luminous stars have already evolved into giants. The brightest is a 6.3-magnitude star of spectral type K3. Located in the field is 12 Canis Majoris, though this star is only 670 light-years distant. NGC 2360, known as Caroline's Cluster after its discoverer Caroline Herschel, is an open cluster located 3.5 degrees west of Muliphein and has a combined apparent magnitude of 7.2. Around 15 light-years in diameter, it is located 3700 light-years away from Earth, and has been dated to around 2.2 billion years old. NGC 2362 is a small, compact open cluster, 5200 light-years from Earth. It contains about 60 stars, of which Tau Canis Majoris is the brightest member. Located around 3 degrees northeast of Wezen, it covers an area around 12 light-years in diameter, though the stars appear huddled around Tau when seen through binoculars. It is a very young open cluster as its member stars are only a few million years old. Lying 2 degrees southwest of NGC 2362 is NGC 2354 a fainter open cluster of magnitude 6.5, with around 15 member stars visible with binoculars. Located around 30' northeast of NGC 2360, NGC 2359 (Thor's Helmet or the Duck Nebula) is a relatively bright emission nebula in Canis Major, with an approximate magnitude of 10, which is 10,000 light-years from Earth. The nebula is shaped by HD 56925, an unstable Wolf–Rayet star embedded within it.
In 2003, an overdensity of stars in the region was announced to be the Canis Major Dwarf, the closest satellite galaxy to Earth. However, there remains debate over whether it represents a disrupted dwarf galaxy or in fact a variation in the thin and thick disk and spiral arm populations of the Milky Way. Investigation of the area yielded only ten RR Lyrae variables—consistent with the Milky Way's halo and thick disk populations rather than a separate dwarf spheroidal galaxy. On the other hand, a globular cluster in Puppis, NGC 2298—which appears to be part of the Canis Major dwarf system—is extremely metal-poor, suggesting it did not arise from the Milky Way's thick disk, and instead is of extragalactic origin.
NGC 2207 and IC 2163 are a pair of face-on interacting spiral galaxies located 125 million light-years from Earth. About 40 million years ago, the two galaxies had a close encounter and are now moving farther apart; nevertheless, the smaller IC 2163 will eventually be incorporated into NGC 2207. As the interaction continues, gas and dust will be perturbed, sparking extensive star formation in both galaxies. Supernovae have been observed in NGC 2207 in 1975 (type Ia SN 1975a), 1999 (the type Ib SN 1999ec), 2003 (type 1b supernova SN 2003H), and 2013 (type II supernova SN 2013ai). Located 16 million light-years distant, ESO 489-056 is an irregular dwarf- and low-surface-brightness galaxy that has one of the lowest metallicities known.

</doc>
<doc id="6367" url="https://en.wikipedia.org/wiki?curid=6367" title="Canis Minor">
Canis Minor

Canis Minor is a small constellation in the northern celestial hemisphere. In the second century, it was included as an asterism, or pattern, of two stars in Ptolemy's 48 constellations, and it is counted among the 88 modern constellations. Its name is Latin for "lesser dog", in contrast to Canis Major, the "greater dog"; both figures are commonly represented as following the constellation of Orion the hunter.
Canis Minor contains only two stars brighter than the fourth magnitude, Procyon (Alpha Canis Minoris), with a magnitude of 0.34, and Gomeisa (Beta Canis Minoris), with a magnitude of 2.9. The constellation's dimmer stars were noted by Johann Bayer, who named eight stars including Alpha and Beta, and John Flamsteed, who numbered fourteen. Procyon is the seventh-brightest star in the night sky, as well as one of the closest. A yellow-white main sequence star, it has a white dwarf companion. Gomeisa is a blue-white main sequence star. Luyten's Star is a ninth-magnitude red dwarf and the Solar System's next closest stellar neighbour in the constellation after Procyon. The fourth-magnitude HD 66141, which has evolved into an orange giant towards the end of its life cycle, was discovered to have a planet in 2012. There are two faint deep-sky objects within the constellation's borders. The 11 Canis-Minorids are a meteor shower that can be seen in early December.
Though strongly associated with the Classical Greek uranographic tradition, Canis Minor originates from ancient Mesopotamia. Procyon and Gomeisa were called "MASH.TAB.BA" or "twins" in the "Three Stars Each" tablets, dating to around 1100 BC. In the later "MUL.APIN", this name was also applied to the pairs of Pi and Pi Orionis and Zeta and Xi Orionis. The meaning of "MASH.TAB.BA" evolved as well, becoming the twin deities Lulal and Latarak, who are on the opposite side of the sky from "Papsukal", the True Shepherd of Heaven in Babylonian mythology. Canis Minor was also given the name "DAR.LUGAL", its position defined as "the star which stands behind it [Orion]", in the "MUL.APIN"; the constellation represents a rooster. This name may have also referred to the constellation Lepus. "DAR.LUGAL" was also denoted "DAR.MUŠEN" and "DAR.LUGAL.MUŠEN" in Babylonia. Canis Minor was then called "tarlugallu" in Akkadian astronomy.
Canis Minor was one of the original 48 constellations formulated by Ptolemy in his second-century Almagest, in which it was defined as a specific pattern (asterism) of stars; Ptolemy identified only two stars and hence no depiction was possible. The Ancient Greeks called the constellation προκυων/"Procyon", "coming before the dog", transliterated into Latin as "Antecanis", "Praecanis", or variations thereof, by Cicero and others. Roman writers also appended the descriptors "parvus", "minor" or "minusculus" ("small" or "lesser", for its faintness), "septentrionalis" ("northerly", for its position in relation to Canis Major), "primus" (rising "first") or "sinister" (rising to the "left") to its name "Canis". 
In Greek mythology, Canis Minor was sometimes connected with the Teumessian Fox, a beast turned into stone with its hunter, Laelaps, by Zeus, who placed them in heaven as Canis Major (Laelaps) and Canis Minor (Teumessian Fox). Eratosthenes accompanied the Little Dog with Orion, while Hyginus linked the constellation with Maera, a dog owned by Icarius of Athens. On discovering the latter's death, the dog and Icarius' daughter Erigone took their lives and all three were placed in the sky—Erigone as Virgo and Icarius as Boötes. As a reward for his faithfulness, the dog was placed along the "banks" of the Milky Way, which the ancients believed to be a heavenly river, where he would never suffer from thirst.
The medieval Arabic astronomers maintained the depiction of Canis Minor ("al-Kalb al-Asghar" in Arabic) as a dog; in his Book of the Fixed Stars, Abd al-Rahman al-Sufi included a diagram of the constellation with a canine figure superimposed. There was one slight difference between the Ptolemaic vision of Canis Minor and the Arabic; al-Sufi claims Mirzam, now assigned to Orion, as part of both Canis Minor—the collar of the dog—and its modern home. The Arabic names for both Procyon and Gomeisa alluded to their proximity and resemblance to Sirius, though they were not direct translations of the Greek; Procyon was called "ash-Shi'ra ash-Shamiya", the "Syrian Sirius" and Gomeisa was called "ash-Shira al-Ghamisa", the Sirius with bleary eyes. Among the Merazig of Tunisia, shepherds note six constellations that mark the passage of the dry, hot season. One of them, called "Merzem", includes the stars of Canis Minor and Canis Major and is the herald of two weeks of hot weather.
The ancient Egyptians thought of this constellation as Anubis, the jackal god.
Alternative names have been proposed: Johann Bayer in the early 17th century termed the constellation "Fovea" "The Pit", and "Morus" "Sycamine Tree". Seventeenth-century German poet and author Philippus Caesius linked it to the dog of Tobias from the Apocrypha. Richard A. Proctor gave the constellation the name "Felis" "the Cat" in 1870 (contrasting with Canis Major, which he had abbreviated to "Canis" "the Dog"), explaining that he sought to shorten the constellation names to make them more manageable on celestial charts. Occasionally, Canis Minor is confused with Canis Major and given the name "Canis Orionis" ("Orion's Dog").
In Chinese astronomy, the stars corresponding to Canis Minor lie in the Vermilion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"). Procyon, Gomeisa and Eta Canis Minoris form an asterism known as Nánhé, the Southern River. With its counterpart, the Northern River Beihe (Castor and Pollux), Nánhé was also associated with a gate or sentry. Along with Zeta and 8 Cancri, 6 Canis Minoris and 11 Canis Minoris formed the asterism "Shuiwei", which literally means "water level". Combined with additional stars in Gemini, Shuiwei represented an official who managed floodwaters or a marker of the water level. Neighboring Korea recognized four stars in Canis Minor as part of a different constellation, "the position of the water". This constellation was located in the Red Bird, the southern portion of the sky.
Polynesian peoples often did not recognize Canis Minor as a constellation, but they saw Procyon as significant and often named it; in the Tuamotu Archipelago it was known as "Hiro", meaning "twist as a thread of coconut fiber", and "Kopu-nui-o-Hiro" ("great paunch of Hiro"), which was either a name for the modern figure of Canis Minor or an alternative name for Procyon. Other names included "Vena" (after a goddess), on Mangaia and "Puanga-hori" (false "Puanga", the name for Rigel), in New Zealand. In the Society Islands, Procyon was called "Ana-tahua-vahine-o-toa-te-manava", literally "Aster the priestess of brave heart", figuratively the "pillar for elocution". The Wardaman people of the Northern Territory in Australia gave Procyon and Gomeisa the names "Magum" and "Gurumana", describing them as humans who were transformed into gum trees in the dreamtime. Although their skin had turned to bark, they were able to speak with a human voice by rustling their leaves.
The Aztec calendar was related to their cosmology. The stars of Canis Minor were incorporated along with some stars of Orion and Gemini into an asterism associated with the day called "Water".
Lying directly south of Gemini's bright stars Castor and Pollux, Canis Minor is a small constellation bordered by Monoceros to the south, Gemini to the north, Cancer to the northeast, and Hydra to the east. It does not border Canis Major; Monoceros is in between the two. Covering 183 square degrees, Canis Minor ranks seventy-first of the 88 constellations in size. It appears prominently in the southern sky during the Northern Hemisphere's winter. The constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of 14 sides. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between and . Most visible in the evening sky from January to March, Canis Minor is most prominent at 10 PM during mid-February. It is then seen earlier in the evening until July, when it is only visible after sunset before setting itself, and rising in the morning sky before dawn. The constellation's three-letter abbreviation, as adopted by the International Astronomical Union in 1922, is "CMi".
Canis Minor contains only two stars brighter than fourth magnitude. At magnitude 0.34, Procyon, or Alpha Canis Minoris, is the seventh-brightest star in the night sky, as well as one of the closest. Its name means "before the dog" or "preceding the dog" in Greek, as it rises an hour before the "Dog Star", Sirius, of Canis Major. It is a binary star system, consisting of a yellow-white main sequence star of spectral type F5 IV-V, named Procyon A, and a faint white dwarf companion of spectral type DA, named Procyon B. Procyon B, which orbits the more massive star every 41 years, is of magnitude 10.7. Procyon A is 1.4 times the Sun's mass, while its smaller companion is 0.6 times as massive as the Sun. The system is from Earth, the shortest distance to a northern-hemisphere star of the first magnitude. Gomeisa, or Beta Canis Minoris, with a magnitude of 2.89, is the second-brightest star in Canis Minor. Lying from the Solar System, it is a blue-white main sequence star of spectral class B8 Ve. Although fainter to Earth observers, it is much brighter than Procyon, and is 250 times as luminous and three times as massive as the Sun. Although its variations are slight, Gomeisa is classified as a shell star (Gamma Cassiopeiae variable), with a maximum magnitude of 2.84 and a minimum magnitude of 2.92. It is surrounded by a disk of gas which it heats and causes to emit radiation.
Johann Bayer used the Greek letters Alpha to Eta to label the most prominent eight stars in the constellation, designating two stars as Delta (named Delta and Delta). John Flamsteed numbered fourteen stars, discerning a third star he named Delta; his star 12 Canis Minoris was not found subsequently. In Bayer's 1603 work "Uranometria", Procyon is located on the dog's belly, and Gomeisa on its neck. Gamma, Epsilon and Eta Canis Minoris lie nearby, marking the dog's neck, crown and chest respectively. Although it has an apparent magnitude of 4.34, Gamma Canis Minoris is an orange K-type giant of spectral class K3-III C, which lies away. Its colour is obvious when seen through binoculars. It is a multiple system, consisting of the spectroscopic binary Gamma A and three optical companions, Gamma B, magnitude 13; Gamma C, magnitude 12; and Gamma D, magnitude 10. The two components of Gamma A orbit each other every 389.2 days, with an eccentric orbit that takes their separation between 2.3 and 1.4 astronomical units (AU). Epsilon Canis Minoris is a yellow bright giant of spectral class G6.5IIb of magnitude of 4.99. It lies from Earth, with 13 times the diameter and 750 times the luminosity of the Sun. Eta Canis Minoris is a giant of spectral class F0III of magnitude 5.24, which has a yellowish hue when viewed through binoculars as well as a faint companion of magnitude 11.1. Located 4 arcseconds from the primary, the companion star is actually around 440 AU from the main star and takes around 5000 years to orbit it.
Near Procyon, three stars share the name Delta Canis Minoris. Delta is a yellow-white F-type giant of magnitude 5.25 located around from Earth. About 360 times as luminous and 3.75 times as massive as the Sun, it is expanding and cooling as it ages, having spent much of its life as a main sequence star of spectrum B6V. Also known as 8 Canis Minoris, Delta is an F-type main-sequence star of spectral type F2V and magnitude 5.59 which is distant. The last of the trio, Delta (also known as 9 Canis Minoris), is a white main sequence star of spectral type A0Vnn and magnitude 5.83 which is distant. These stars mark the paws of the Lesser Dog's left hind leg, while magnitude 5.13 Zeta marks the right. A blue-white bright giant of spectral type B8II, Zeta lies around away from the Solar System.
Lying 222 ± 7 light-years away with an apparent magnitude of 4.39, HD 66141 is 6.8 billion years old and has evolved into an orange giant of spectral type K2III with a diameter around 22 times that of the Sun, and weighing 1.1 solar masses. It is 174 times as luminous as the Sun, with an absolute magnitude of −0.15. HD 66141 was mistakenly named 13 Puppis, as its celestial coordinates were recorded incorrectly when catalogued and hence mistakenly thought to be in the constellation of Puppis; Bode gave it the name Lambda Canis Minoris, which is now obsolete. The orange giant is orbited by a planet, HD 66141b, which was detected in 2012 by measuring the star's radial velocity. The planet has a mass around 6 times that of Jupiter and a period of 480 days.
A red giant of spectral type M4III, BC Canis Minoris lies around distant from the Solar System. It is a semiregular variable star that varies between a maximum magnitude of 6.14 and minimum magnitude of 6.42. Periods of 27.7, 143.3 and 208.3 days have been recorded in its pulsations. AZ, AD and BI Canis Minoris are Delta Scuti variables—short period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. AZ is of spectral type A5IV, and ranges between magnitudes 6.44 and 6.51 over a period of 2.3 hours. AD has a spectral type of F2III, and has a maximum magnitude of 9.21 and minimum of 9.51, with a period of approximately 2.95 hours. BI is of spectral type F2 with an apparent magnitude varying around 9.19 and a period of approximately 2.91 hours.
At least three red giants are Mira variables in Canis Minor. S Canis Minoris, of spectral type M7e, is the brightest, ranging from magnitude 6.6 to 13.2 over a period of 332.94 days. V Canis Minoris ranges from magnitude 7.4 to 15.1 over a period of 366.1 days. Similar in magnitude is R Canis Minoris, which has a maximum of 7.3, but a significantly brighter minimum of 11.6. An S-type star, it has a period of 337.8 days.
YZ Canis Minoris is a red dwarf of spectral type M4.5V and magnitude 11.2, roughly three times the size of Jupiter and from Earth. It is a flare star, emitting unpredictable outbursts of energy for mere minutes, which might be much more powerful analogues of solar flares. Luyten's Star (GJ 273) is a red dwarf star of spectral type M3.5V and close neighbour of the Solar System. Its visual magnitude of 9.9 renders it too faint to be seen with the naked eye, even though it is only away. Fainter still is PSS 544-7, an eighteenth-magnitude red dwarf around 20 percent the mass of the Sun, located from Earth. First noticed in 1991, it is thought to be a cannonball star, shot out of a star cluster and now moving rapidly through space directly away from the galactic disc.
The WZ Sagittae-type dwarf nova DY Canis Minoris (also known as VSX J074727.6+065050) flared up to magnitude 11.4 over January and February 2008 before dropping eight magnitudes to around 19.5 over approximately 80 days. It is a remote binary star system where a white dwarf and low mass star orbit each other close enough for the former star to draw material off the latter and form an accretion disc. This material builds up until it erupts dramatically.
The Milky Way passes through much of Canis Minor, yet it has few deep-sky objects. William Herschel recorded four objects in his 1786 work "Catalogue of Nebulae and Clusters of Stars", including two he mistakenly believed were star clusters. NGC 2459 is a group of five thirteenth- and fourteenth-magnitude stars that appear to lie close together in the sky but are not related. A similar situation has occurred with NGC 2394, also in Canis Minor. This is a collection of fifteen unrelated stars of ninth-magnitude and fainter.
Herschel also observed three faint galaxies, two of which are interacting with each other. NGC 2508 is a lenticular galaxy of thirteenth-magnitude, estimated at 205 million light-years (63 million parsecs) distance with a diameter of 80 thousand light-years (25 thousand parsecs). Named as a single object by Herschel, NGC 2402 is actually a pair of near-adjacent galaxies that appear to be interacting with each other. Only of fourteenth- and fifteenth-magnitudes respectively, the elliptical and spiral galaxy are thought to be approximately 245 million light-years distant, and each measure 55,000 light-years in diameter.
The 11 Canis-Minorids, also called the Beta Canis Minorids, are a meteor shower that arise near the fifth-magnitude star 11 Canis Minoris and were discovered in 1964 by Keith Hindley, who investigated their trajectory and proposed a common origin with the comet D/1917 F1 Mellish. However, this conclusion has been refuted subsequently as the number of orbits analysed was low and their trajectories too disparate to confirm a link. They last from 4 to 15 December, peaking over 10 and 11 December.

</doc>
<doc id="6371" url="https://en.wikipedia.org/wiki?curid=6371" title="Centaurus">
Centaurus

Centaurus is a bright constellation in the southern sky. One of the largest constellations, Centaurus was included among the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. In Greek mythology, Centaurus represents a centaur; a creature that is half human, half horse (another constellation named after a centaur is one from the zodiac: Sagittarius). Notable stars include Alpha Centauri, the nearest star system to the Solar System, its neighbour in the sky Beta Centauri, and V766 Centauri, one of the largest stars yet discovered. The constellation also contains Omega Centauri, the brightest globular cluster as visible from Earth and the largest identified in the Milky Way, possibly a remnant of a dwarf galaxy.
Centaurus contains several very bright stars. Its alpha and beta stars are used as "pointer stars" to help observers find the constellation Crux. Centaurus has 281 stars above magnitude 6.5, meaning that they are visible to the unaided eye, the most of any constellation. Alpha Centauri, the closest star system to the Sun, has a high proper motion; it will be a mere half-degree from Beta Centauri in approximately 4000 years.
Alpha Centauri is a triple star system, a binary around which orbits Proxima Centauri, currently the nearest star to the Sun. Traditionally called Rigil Kentaurus or Toliman, meaning "foot of the centaur", the system has an overall magnitude of −0.28 and is 4.4 light-years from Earth. The primary and secondary are both yellow-hued stars; the first is of magnitude −0.01 and the second: 1.35. Proxima, the tertiary star, is a red dwarf of magnitude 11.0; it appears almost 2 degrees away from the close pairing of Alpha and has a period of approximately one million years. Also a flare star, Proxima has minutes-long outbursts where it brightens by over a magnitude. The Alpha couple revolve in 80-year periodicity and will next appear closest as seen from Earth's telescopes in 2037 and 2038, together as they appear to the naked eye they present the third-brightest "star" in the night sky.
One other first magnitude star Beta Centauri is in the constellation in a position beyond Proxima and toward the narrow axis of Crux, thus with Alpha forming a far-south limb of the constellation. Also called Hadar and Agena, it is a double star; the primary is a blue-hued giant star of magnitude 0.6, 525 light-years from Earth. The secondary is of magnitude 4.0 and has a modest separation, appearing only under intense magnification due to its distance.
The northerly star Theta Centauri, officially named Menkent, is an orange giant star of magnitude 2.06. It is the only bright star of Centaurus that is easily visible from mid-northern latitudes.
The next bright object is Gamma Centauri, a binary star which appears to the naked eye at magnitude 2.2. The primary and secondary are both blue-white hued stars of magnitude 2.9; their period is 84 years.
Centaurus also has many dimmer double stars and binary stars. 3 Centauri is a double star with a blue-white hued primary of magnitude 4.5 and a secondary of magnitude 6.0. The primary is 344 light-years away.
Centaurus is home to many variable stars. R Centauri is a Mira variable star with a minimum magnitude of 11.8 and a maximum magnitude of 5.3; it is about 1,250 light-years from Earth and has a period of 18 months. V810 Centauri is a semiregular variable.
BPM 37093 is a white dwarf star whose carbon atoms are thought to have formed a crystalline structure. Since diamond also consists of carbon arranged in a crystalline lattice (though of a different configuration), scientists have nicknamed this star "Lucy" after the Beatles song ""Lucy in the Sky with Diamonds"."
PDS 70, (V1032 Centauri) a low mass T Tauri star is found in the constellation Centauras. In July 2018 astronomers captured the first conclusive image of a protoplanetary disk containing a nascent exoplanet, named PDS 70b.
ω Centauri (NGC 5139), despite being listed as the constellation's "omega" star, is in fact a naked-eye globular cluster, 17,000 light-years away with a diameter of 150 light-years. It is the largest and brightest globular cluster in the Milky Way; at ten times the size of the next-largest cluster, it has a magnitude of 3.7. It is also the most luminous globular cluster in the Milky Way, at over one million solar luminosities. Omega Centauri is classified as a Shapley class VIII cluster, which means that its center is loosely concentrated. It is also the only globular cluster to be designated with a Bayer letter; the globular cluster 47 Tucanae is the only one designated with a Flamsteed number. It contains several million stars, most of which are yellow dwarf stars, but also possesses red giants and blue-white stars; the stars have an average age of 12 billion years. This has prompted suspicion that Omega Centauri was the core of a dwarf galaxy that had been absorbed by the Milky Way. Omega Centauri was determined to be nonstellar in 1677 by the English astronomer Edmond Halley, though it was visible as a star to the ancients. Its status as a globular cluster was determined by James Dunlop in 1827. To the unaided eye, Omega Centauri appears fuzzy and is obviously non-circular; it is approximately half a degree in diameter, the same size as the full Moon.
Centaurus is also home to open clusters. NGC 3766 is an open cluster 6,300 light-years from Earth that is visible to the unaided eye. It contains approximately 100 stars, the brightest of which are 7th magnitude. NGC 5460 is another naked-eye open cluster, 2,300 light-years from Earth, that has an overall magnitude of 6 and contains approximately 40 stars.
There is one bright planetary nebula in Centaurus, NGC 3918, also known as the Blue Planetary. It has an overall magnitude of 8.0 and a central star of magnitude 11.0; it is 2600 light-years from Earth. The Blue Planetary was discovered by John Herschel and named for its color's similarity to Uranus, though the nebula is apparently three times larger than the planet.
Centaurus is rich in galaxies as well. NGC 4622 is a face-on spiral galaxy located 200 million light-years from Earth (redshift 0.0146). Its spiral arms wind in both directions, which makes it nearly impossible for astronomers to determine the rotation of the galaxy. Astronomers theorize that a collision with a smaller companion galaxy near the core of the main galaxy could have led to the unusual spiral structure. NGC 5253, a peculiar irregular galaxy, is located near the border with Hydra and M83, with which it likely had a close gravitational interaction 1–2 billion years ago. This may have sparked the galaxy's high rate of star formation, which continues today and contributes to its high surface brightness. NGC 5253 includes a large nebula and at least 12 large star clusters. In the eyepiece, it is a small galaxy of magnitude 10 with dimensions of 5 arcminutes by 2 arcminutes and a bright nucleus. NGC 4945 is a spiral galaxy seen edge-on from Earth, 13 million light-years away. It is visible with any amateur telescope, as well as binoculars under good conditions; it has been described as "shaped like a candle flame", being long and thin (16' by 3'). In the eyepiece of a large telescope, its southeastern dust lane becomes visible. Another galaxy is NGC 5102, found by star-hopping from Iota Centauri. In the eyepiece, it appears as an elliptical object 9 arcminutes by 2.5 arcminutes tilted on a southwest-northeast axis.
One of the closest active galaxies to Earth is the Centaurus A galaxy, NGC 5128, at 11 million light-years away (redshift 0.00183). It has a supermassive black hole at its core, which expels massive jets of matter that emit radio waves due to synchrotron radiation. Astronomers posit that its dust lanes, not common in elliptical galaxies, are due to a previous merger with another galaxy, probably a spiral galaxy. NGC 5128 appears in the optical spectrum as a fairly large elliptical galaxy with a prominent dust lane. Its overall magnitude is 7.0 and it has been seen under perfect conditions with the naked eye, making it one of the most distant objects visible to the unaided observer. In equatorial and southern latitudes, it is easily found by star hopping from Omega Centauri. In small telescopes, the dust lane is not visible; it begins to appear with about 4 inches of aperture under good conditions. In large amateur instruments, above about 12 inches in aperture, the dust lane's west-northwest to east-southeast direction is easily discerned. Another dim dust lane on the east side of the 12-arcminute-by-15-arcminute galaxy is also visible. ESO 270-17, also called the Fourcade-Figueroa Object, is a low-surface brightness object believed to be the remnants of a galaxy; it does not have a core and is very difficult to observe with an amateur telescope. It measures 7 arcminutes by 1 arcminute. It likely originated as a spiral galaxy and underwent a catastrophic gravitational interaction with Centaurus A around 500 million years ago, stopping its rotation and destroying its structure.
NGC 4650A is a polar-ring galaxy 136 million light-years from Earth (redshift 0.01). It has a central core made of older stars that resembles an elliptical galaxy, and an outer ring of young stars that orbits around the core. The plane of the outer ring is distorted, which suggests that NGC 4650A is the result of a galaxy collision about a billion years ago. This galaxy has also been cited in studies of dark matter, because the stars in the outer ring orbit too quickly for their collective mass. This suggests that the galaxy is surrounded by a dark matter halo, which provides the necessary mass.
One of the closest galaxy clusters to Earth is the Centaurus Cluster at 160 million light-years away, having redshift 0.0114. It has a cooler, denser central region of gas and a hotter, more diffuse outer region. The intracluster medium in the Centaurus Cluster has a high concentration of metals (elements heavier than helium) due to a large number of supernovae. This cluster also possesses a plume of gas whose origin is unknown.
While Centaurus now has a high southern latitude, at the dawn of civilization it was an equatorial constellation. Precession has been slowly shifting it southward for millennia, and it is now close to its maximal southern declination. In a little over 7000 years it will be at maximum visibility for those in the northern hemisphere, visible at times in the year up to quite a high northern latitude.
The figure of Centaurus can be traced back to a Babylonian constellation known as the Bison-man (MUL.GUD.ALIM). This being was depicted in two major forms: firstly, as a 4-legged bison with a human head, and secondly, as a being with a man's head and torso attached to the rear legs and tail of a bull or bison. It has been closely associated with the Sun god Utu-Shamash from very early times.
The Greeks depicted the constellation as a centaur and gave it its current name. It was mentioned by Eudoxus in the 4th century BC and Aratus in the 3rd century BC. In the 2nd century AD, Claudius Ptolemy catalogued 37 stars in Centaurus, including Alpha Centauri. Large as it is now, in earlier times it was even larger, as the constellation Lupus was treated as an asterism within Centaurus, portrayed in illustrations as an unspecified animal either in the centaur's grasp or impaled on its spear. The Southern Cross, which is now regarded as a separate constellation, was treated by the ancients as a mere asterism formed of the stars composing the centaur's legs. Additionally, what is now the minor constellation Circinus was treated as undefined stars under the centaur's front hooves.
According to the Roman poet Ovid ("Fasti" v.379), the constellation honors the centaur Chiron, who was tutor to many of the earlier Greek heroes including Heracles (Hercules), Theseus, and Jason, the leader of the Argonauts. It is not to be confused with the more warlike centaur represented by the zodiacal constellation Sagittarius. The legend associated with Chiron says that he was accidentally poisoned with an arrow shot by Hercules, and was subsequently placed in the heavens.
In Chinese astronomy, the stars of Centaurus are found in three areas: the Azure Dragon of the East (東方青龍, "Dōng Fāng Qīng Lóng"), the Vermillion Bird of the South (南方朱雀, "Nán Fāng Zhū Què"), and the Southern Asterisms (近南極星區, "Jìnnánjíxīngōu"). Not all of the stars of Centaurus can be seen from China, and the unseen stars were classified among the Southern Asterisms by Xu Guangqi, based on his study of western star charts. However, most of the brightest stars of Centaurus, including α Centauri, θ Centauri (or Menkent), ε Centauri and η Centauri, can be seen in the Chinese sky.
Some Polynesian peoples considered the stars of Centaurus to be a constellation as well. On Pukapuka, Centaurus had two names: "Na Mata-o-te-tokolua" and "Na Lua-mata-o-Wua-ma-Velo". In Tonga, the constellation was called by four names: "O-nga-tangata", "Tautanga-ufi", "Mamangi-Halahu", and "Mau-kuo-mau". Alpha and Beta Centauri were not named specifically by the people of Pukapuka or Tonga, but they were named by the people of Hawaii and the Tuamotus. In Hawaii, the name for Alpha Centauri was either "Melemele" or "Ka Maile-hope" and the name for Beta Centauri was either "Polapola" or "Ka Maile-mua". In the Tuamotu islands, Alpha was called "Na Kuhi" and Beta was called "Tere".
The Pointer (α Centauri and β Centauri) is one of the asterisms used by Bugis sailors for navigation, called "bintoéng balué", meaning "the widowed-before-marriage". It is also called "bintoéng sallatang" meaning "southern star" 
Two United States Navy ships, and , were named after Centaurus, the constellation.

</doc>
<doc id="6372" url="https://en.wikipedia.org/wiki?curid=6372" title="Wikipedia:Complete list of encyclopedia topics (obsolete)">
Wikipedia:Complete list of encyclopedia topics (obsolete)

This page has been rendered obsolete (indeed, harmful) by updates to Wikipedia software and the growth of Wikipedia in general.
See also the most basic encyclopedia article topics or for an alternative method of finding subject areas to work on.
Please do not delete this page, under any circumstances - it, along with associated talk and subpages (and, more critically, their histories), contain important documentation of the early days of Wikipedia - documentation which will (someday) be very important to historians. See the for more.

</doc>
<doc id="6378" url="https://en.wikipedia.org/wiki?curid=6378" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/6">
Wikipedia:Complete list of encyclopedia topics (obsolete)/6

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6379" url="https://en.wikipedia.org/wiki?curid=6379" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/7">
Wikipedia:Complete list of encyclopedia topics (obsolete)/7

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6380" url="https://en.wikipedia.org/wiki?curid=6380" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/8">
Wikipedia:Complete list of encyclopedia topics (obsolete)/8

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6381" url="https://en.wikipedia.org/wiki?curid=6381" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/9">
Wikipedia:Complete list of encyclopedia topics (obsolete)/9

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6382" url="https://en.wikipedia.org/wiki?curid=6382" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/Z">
Wikipedia:Complete list of encyclopedia topics (obsolete)/Z

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6383" url="https://en.wikipedia.org/wiki?curid=6383" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/Y">
Wikipedia:Complete list of encyclopedia topics (obsolete)/Y

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6384" url="https://en.wikipedia.org/wiki?curid=6384" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/X">
Wikipedia:Complete list of encyclopedia topics (obsolete)/X

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6385" url="https://en.wikipedia.org/wiki?curid=6385" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/W">
Wikipedia:Complete list of encyclopedia topics (obsolete)/W

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6386" url="https://en.wikipedia.org/wiki?curid=6386" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/V">
Wikipedia:Complete list of encyclopedia topics (obsolete)/V

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6387" url="https://en.wikipedia.org/wiki?curid=6387" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/U">
Wikipedia:Complete list of encyclopedia topics (obsolete)/U

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6388" url="https://en.wikipedia.org/wiki?curid=6388" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/T">
Wikipedia:Complete list of encyclopedia topics (obsolete)/T

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6389" url="https://en.wikipedia.org/wiki?curid=6389" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/S">
Wikipedia:Complete list of encyclopedia topics (obsolete)/S

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6390" url="https://en.wikipedia.org/wiki?curid=6390" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/R">
Wikipedia:Complete list of encyclopedia topics (obsolete)/R

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6391" url="https://en.wikipedia.org/wiki?curid=6391" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/Q">
Wikipedia:Complete list of encyclopedia topics (obsolete)/Q

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6392" url="https://en.wikipedia.org/wiki?curid=6392" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/P">
Wikipedia:Complete list of encyclopedia topics (obsolete)/P

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6393" url="https://en.wikipedia.org/wiki?curid=6393" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/O">
Wikipedia:Complete list of encyclopedia topics (obsolete)/O

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6394" url="https://en.wikipedia.org/wiki?curid=6394" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/N">
Wikipedia:Complete list of encyclopedia topics (obsolete)/N

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6395" url="https://en.wikipedia.org/wiki?curid=6395" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/M">
Wikipedia:Complete list of encyclopedia topics (obsolete)/M

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6396" url="https://en.wikipedia.org/wiki?curid=6396" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/L">
Wikipedia:Complete list of encyclopedia topics (obsolete)/L

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6397" url="https://en.wikipedia.org/wiki?curid=6397" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/K">
Wikipedia:Complete list of encyclopedia topics (obsolete)/K

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6398" url="https://en.wikipedia.org/wiki?curid=6398" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/J">
Wikipedia:Complete list of encyclopedia topics (obsolete)/J

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6399" url="https://en.wikipedia.org/wiki?curid=6399" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/I">
Wikipedia:Complete list of encyclopedia topics (obsolete)/I

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6400" url="https://en.wikipedia.org/wiki?curid=6400" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/H">
Wikipedia:Complete list of encyclopedia topics (obsolete)/H

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6401" url="https://en.wikipedia.org/wiki?curid=6401" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/G">
Wikipedia:Complete list of encyclopedia topics (obsolete)/G

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6402" url="https://en.wikipedia.org/wiki?curid=6402" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/F">
Wikipedia:Complete list of encyclopedia topics (obsolete)/F

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6403" url="https://en.wikipedia.org/wiki?curid=6403" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/E">
Wikipedia:Complete list of encyclopedia topics (obsolete)/E

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6404" url="https://en.wikipedia.org/wiki?curid=6404" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/D">
Wikipedia:Complete list of encyclopedia topics (obsolete)/D

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6405" url="https://en.wikipedia.org/wiki?curid=6405" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/C">
Wikipedia:Complete list of encyclopedia topics (obsolete)/C

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6406" url="https://en.wikipedia.org/wiki?curid=6406" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/B">
Wikipedia:Complete list of encyclopedia topics (obsolete)/B

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6407" url="https://en.wikipedia.org/wiki?curid=6407" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/A">
Wikipedia:Complete list of encyclopedia topics (obsolete)/A

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6410" url="https://en.wikipedia.org/wiki?curid=6410" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/0">
Wikipedia:Complete list of encyclopedia topics (obsolete)/0

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6411" url="https://en.wikipedia.org/wiki?curid=6411" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/S2">
Wikipedia:Complete list of encyclopedia topics (obsolete)/S2

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6412" url="https://en.wikipedia.org/wiki?curid=6412" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/A2">
Wikipedia:Complete list of encyclopedia topics (obsolete)/A2

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6413" url="https://en.wikipedia.org/wiki?curid=6413" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/B2">
Wikipedia:Complete list of encyclopedia topics (obsolete)/B2

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6414" url="https://en.wikipedia.org/wiki?curid=6414" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/C2">
Wikipedia:Complete list of encyclopedia topics (obsolete)/C2

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6415" url="https://en.wikipedia.org/wiki?curid=6415" title="Wikipedia:Complete list of encyclopedia topics (obsolete)/basic vocabulary">
Wikipedia:Complete list of encyclopedia topics (obsolete)/basic vocabulary

This (now-obsolete) page contains (in its history) important documentation of the early stages of Wikipedia. Please do not delete.
Please consult the "Page history" link for the actual old content - to prevent this obsolete page from showing up in "What links here" lists, the old revision is not kept as the current content.

</doc>
<doc id="6416" url="https://en.wikipedia.org/wiki?curid=6416" title="Impact crater">
Impact crater

An impact crater is an approximately circular depression in the surface of a planet, moon, or other solid body in the Solar System or elsewhere, formed by the hypervelocity impact of a smaller body. In contrast to volcanic craters, which result from explosion or internal collapse, impact craters typically have raised rims and floors that are lower in elevation than the surrounding terrain. Impact craters range from small, simple, bowl-shaped depressions to large, complex, multi-ringed impact basins. Meteor Crater is a well-known example of a small impact crater on Earth.
Impact craters are the dominant geographic features on many solid Solar System objects including the Moon, Mercury, Callisto, Ganymede and most small moons and asteroids. On other planets and moons that experience more active surface geological processes, such as Earth, Venus, Mars, Europa, Io and Titan, visible impact craters are less common because they become eroded, buried or transformed by tectonics over time. Where such processes have destroyed most of the original crater topography, the terms impact structure or astrobleme are more commonly used. In early literature, before the significance of impact cratering was widely recognised, the terms cryptoexplosion or cryptovolcanic structure were often used to describe what are now recognised as impact-related features on Earth.
The cratering records of very old surfaces, such as Mercury, the Moon, and the southern highlands of Mars, record a period of intense early bombardment in the inner Solar System around 3.9 billion years ago. The rate of crater production on Earth has since been considerably lower, but it is appreciable nonetheless; Earth experiences from one to three impacts large enough to produce a crater about once every million years on average. This indicates that there should be far more relatively young craters on the planet than have been discovered so far. The cratering rate in the inner solar system fluctuates as a consequence of collisions in the asteroid belt that create a family of fragments that are often sent cascading into the inner solar system. Formed in a collision 80 million years ago, the Baptistina family of asteroids is thought to have caused a large spike in the impact rate. Note that the rate of impact cratering in the outer Solar System could be different from the inner Solar System.
Although Earth's active surface processes quickly destroy the impact record, about 190 terrestrial impact craters have been identified. These range in diameter from a few tens of meters up to about , and they range in age from recent times (e.g. the Sikhote-Alin craters in Russia whose creation was witnessed in 1947) to more than two billion years, though most are less than 500 million years old because geological processes tend to obliterate older craters. They are also selectively found in the stable interior regions of continents. Few undersea craters have been discovered because of the difficulty of surveying the sea floor, the rapid rate of change of the ocean bottom, and the subduction of the ocean floor into Earth's interior by processes of plate tectonics.
Impact craters are not to be confused with landforms that may appear similar, including calderas, sinkholes, glacial cirques, ring dikes, salt domes, and others.
Daniel M. Barringer, a mining engineer, was convinced already in 1903 that the crater he owned, Meteor Crater, was of cosmic origin. Yet most geologists at the time assumed it formed as the result of a volcanic steam eruption.
In the 1920s, the American geologist Walter H. Bucher studied a number of sites now recognized as impact craters in the United States. He concluded they had been created by some great explosive event, but believed that this force was probably volcanic in origin. However, in 1936, the geologists John D. Boon and Claude C. Albritton Jr. revisited Bucher's studies and concluded that the craters that he studied were probably formed by impacts.
Grove Karl Gilbert suggested in 1893 that the Moon's craters were formed by large asteroid impacts. Ralph Baldwin in 1949 wrote that the Moon's craters were mostly of impact origin. Around 1960, Gene Shoemaker revived the idea. According to David H. Levy, Gene "saw the craters on the Moon as logical impact sites that were formed not gradually, in eons, but explosively, in seconds." For his Ph.D. degree at Princeton (1960), under the guidance of Harry Hammond Hess, Shoemaker studied the impact dynamics of Barringer Meteor Crater. Shoemaker noted Meteor Crater had the same form and structure as two explosion craters created from atomic bomb tests at the Nevada Test Site, notably Jangle U in 1951 and Teapot Ess in 1955. In 1960, Edward C. T. Chao and Shoemaker identified coesite (a form of silicon dioxide) at Meteor Crater, proving the crater was formed from an impact generating extremely high temperatures and pressures. They followed this discovery with the identification of coesite within suevite at Nördlinger Ries, proving its impact origin.
Armed with the knowledge of shock-metamorphic features, Carlyle S. Beals and colleagues at the Dominion Astrophysical Observatory in Victoria, British Columbia, Canada and Wolf von Engelhardt of the University of Tübingen in Germany began a methodical search for impact craters. By 1970, they had tentatively identified more than 50. Although their work was controversial, the American Apollo Moon landings, which were in progress at the time, provided supportive evidence by recognizing the rate of impact cratering on the Moon. Because the processes of erosion on the Moon are minimal, craters persist. Since the Earth could be expected to have roughly the same cratering rate as the Moon, it became clear that the Earth had suffered far more impacts than could be seen by counting evident craters.
Impact cratering involves high velocity collisions between solid objects, typically much greater than the speed of sound in those objects. Such hyper-velocity impacts produce physical effects such as melting and vaporization that do not occur in familiar sub-sonic collisions. On Earth, ignoring the slowing effects of travel through the atmosphere, the lowest impact velocity with an object from space is equal to the gravitational escape velocity of about 11 km/s. The fastest impacts occur at about 72 km/s in the "worst case" scenario in which an object in a retrograde near-parabolic orbit hits Earth. The median impact velocity on Earth is about 20 km/s.
However, the slowing effects of travel through the atmosphere rapidly decelerate any potential impactor, especially in the lowest 12 kilometres where 90% of the earth's atmospheric mass lies. Meteorites of up to 7,000 kg lose all their cosmic velocity due to atmospheric drag at a certain altitude (retardation point), and start to accelerate again due to Earth's gravity until the body reaches its terminal velocity of 0.09 to 0.16 km/s. The larger the meteoroid (i.e. asteroids and comets) the more of its initial cosmic velocity it preserves. While an object of 9,000 kg maintains about 6% of its original velocity, one of 900,000 kg already preserves about 70%. Extremely large bodies (about 100,000 tonnes) are not slowed by the atmosphere at all, and impact with their initial cosmic velocity if no prior disintegration occurs.
Impacts at these high speeds produce shock waves in solid materials, and both impactor and the material impacted are rapidly compressed to high density. Following initial compression, the high-density, over-compressed region rapidly depressurizes, exploding violently, to set in train the sequence of events that produces the impact crater. Impact-crater formation is therefore more closely analogous to cratering by high explosives than by mechanical displacement. Indeed, the energy density of some material involved in the formation of impact craters is many times higher than that generated by high explosives. Since craters are caused by explosions, they are nearly always circular – only very low-angle impacts cause significantly elliptical craters.
This describes impacts on solid surfaces. Impacts on porous surfaces, such as that of Hyperion, may produce internal compression without ejecta, punching a hole in the surface without filling in nearby craters. This may explain the 'sponge-like' appearance of that moon.
It is convenient to divide the impact process conceptually into three distinct stages: (1) initial contact and compression, (2) excavation, (3) modification and collapse. In practice, there is overlap between the three processes with, for example, the excavation of the crater continuing in some regions while modification and collapse is already underway in others.
In the absence of atmosphere, the impact process begins when the impactor first touches the target surface. This contact accelerates the target and decelerates the impactor. Because the impactor is moving so rapidly, the rear of the object moves a significant distance during the short-but-finite time taken for the deceleration to propagate across the impactor. As a result, the impactor is compressed, its density rises, and the pressure within it increases dramatically. Peak pressures in large impacts exceed 1 TPa to reach values more usually found deep in the interiors of planets, or generated artificially in nuclear explosions.
In physical terms, a shock wave originates from the point of contact. As this shock wave expands, it decelerates and compresses the impactor, and it accelerates and compresses the target. Stress levels within the shock wave far exceed the strength of solid materials; consequently, both the impactor and the target close to the impact site are irreversibly damaged. Many crystalline minerals can be transformed into higher-density phases by shock waves; for example, the common mineral quartz can be transformed into the higher-pressure forms coesite and stishovite. Many other shock-related changes take place within both impactor and target as the shock wave passes through, and some of these changes can be used as diagnostic tools to determine whether particular geological features were produced by impact cratering.
As the shock wave decays, the shocked region decompresses towards more usual pressures and densities. The damage produced by the shock wave raises the temperature of the material. In all but the smallest impacts this increase in temperature is sufficient to melt the impactor, and in larger impacts to vaporize most of it and to melt large volumes of the target. As well as being heated, the target near the impact is accelerated by the shock wave, and it continues moving away from the impact behind the decaying shock wave.
Contact, compression, decompression, and the passage of the shock wave all occur within a few tenths of a second for a large impact. The subsequent excavation of the crater occurs more slowly, and during this stage the flow of material is largely subsonic. During excavation, the crater grows as the accelerated target material moves away from the point of impact. The target's motion is initially downwards and outwards, but it becomes outwards and upwards. The flow initially produces an approximately hemispherical cavity that continues to grow, eventually producing a paraboloid (bowl-shaped) crater in which the centre has been pushed down, a significant volume of material has been ejected, and a topographically elevated crater rim has been pushed up. When this cavity has reached its maximum size, it is called the transient cavity.
The depth of the transient cavity is typically a quarter to a third of its diameter. Ejecta thrown out of the crater do not include material excavated from the full depth of the transient cavity; typically the depth of maximum excavation is only about a third of the total depth. As a result, about one third of the volume of the transient crater is formed by the ejection of material, and the remaining two thirds is formed by the displacement of material downwards, outwards and upwards, to form the elevated rim. For impacts into highly porous materials, a significant crater volume may also be formed by the permanent compaction of the pore space. Such compaction craters may be important on many asteroids, comets and small moons.
In large impacts, as well as material displaced and ejected to form the crater, significant volumes of target material may be melted and vaporized together with the original impactor. Some of this impact melt rock may be ejected, but most of it remains within the transient crater, initially forming a layer of impact melt coating the interior of the transient cavity. In contrast, the hot dense vaporized material expands rapidly out of the growing cavity, carrying some solid and molten material within it as it does so. As this hot vapor cloud expands, it rises and cools much like the archetypal mushroom cloud generated by large nuclear explosions. In large impacts, the expanding vapor cloud may rise to many times the scale height of the atmosphere, effectively expanding into free space.
Most material ejected from the crater is deposited within a few crater radii, but a small fraction may travel large distances at high velocity, and in large impacts it may exceed escape velocity and leave the impacted planet or moon entirely. The majority of the fastest material is ejected from close to the center of impact, and the slowest material is ejected close to the rim at low velocities to form an overturned coherent flap of ejecta immediately outside the rim. As ejecta escapes from the growing crater, it forms an expanding curtain in the shape of an inverted cone. The trajectory of individual particles within the curtain is thought to be largely ballistic.
Small volumes of un-melted and relatively un-shocked material may be spalled at very high relative velocities from the surface of the target and from the rear of the impactor. Spalling provides a potential mechanism whereby material may be ejected into inter-planetary space largely undamaged, and whereby small volumes of the impactor may be preserved undamaged even in large impacts. Small volumes of high-speed material may also be generated early in the impact by jetting. This occurs when two surfaces converge rapidly and obliquely at a small angle, and high-temperature highly shocked material is expelled from the convergence zone with velocities that may be several times larger than the impact velocity.
In most circumstances, the transient cavity is not stable and collapses under gravity. In small craters, less than about 4 km diameter on Earth, there is some limited collapse of the crater rim coupled with debris sliding down the crater walls and drainage of impact melts into the deeper cavity. The resultant structure is called a simple crater, and it remains bowl-shaped and superficially similar to the transient crater. In simple craters, the original excavation cavity is overlain by a lens of collapse breccia, ejecta and melt rock, and a portion of the central crater floor may sometimes be flat.
Above a certain threshold size, which varies with planetary gravity, the collapse and modification of the transient cavity is much more extensive, and the resulting structure is called a complex crater. The collapse of the transient cavity is driven by gravity, and involves both the uplift of the central region and the inward collapse of the rim. The central uplift is not the result of "elastic rebound", which is a process in which a material with elastic strength attempts to return to its original geometry; rather the collapse is a process in which a material with little or no strength attempts to return to a state of gravitational equilibrium.
Complex craters have uplifted centers, and they have typically broad flat shallow crater floors, and terraced walls. At the largest sizes, one or more exterior or interior rings may appear, and the structure may be labeled an "impact basin" rather than an impact crater. Complex-crater morphology on rocky planets appears to follow a regular sequence with increasing size: small complex craters with a central topographic peak are called "central peak craters", for example Tycho; intermediate-sized craters, in which the central peak is replaced by a ring of peaks, are called "peak-ring craters", for example Schrödinger; and the largest craters contain multiple concentric topographic rings, and are called "multi-ringed basins", for example Orientale. On icy (as opposed to rocky) bodies, other morphological forms appear that may have central pits rather than central peaks, and at the largest sizes may contain many concentric rings. Valhalla on Callisto is an example of this type.
Non-explosive volcanic craters can usually be distinguished from impact craters by their irregular shape and the association of volcanic flows and other volcanic materials. Impact craters produce melted rocks as well, but usually in smaller volumes with different characteristics.
The distinctive mark of an impact crater is the presence of rock that has undergone shock-metamorphic effects, such as shatter cones, melted rocks, and crystal deformations. The problem is that these materials tend to be deeply buried, at least for simple craters. They tend to be revealed in the uplifted center of a complex crater, however.
Impacts produce distinctive shock-metamorphic effects that allow impact sites to be distinctively identified. Such shock-metamorphic effects can include:
On Earth impact craters have resulted in useful minerals. Some of the ores produced from impact related effects on Earth include ores of iron, uranium, gold, copper, and nickel. It is estimated that the value of materials mined from impact structures is five billion dollars/year just for North America. 
The eventual usefulness of impact craters depends on several factors especially the nature of the materials that were impacted and when the materials were affected. In some cases the deposits were already in place and the impact brought them to the surface. These are called “progenetic economic deposits.” Others were created during the actual impact. The great energy involved caused melting. Useful minerals formed as a result of this energy are classified as “syngenetic deposits.” The third type, called “epigenetic deposits,” is caused by the creation of a basin from the impact.
Many of the minerals that our modern lives depend on are associated with impacts in the past. The Vredeford Dome in the center of the Witwatersrand Basin is the largest goldfield in the world which has supplied about 40% of all the gold ever mined in an impact structure (though the gold did not come from the bolide). The asteroid that struck the region was wide. The Sudbury Basin was caused by an impacting body over in diameter. This basin is famous for its deposits of nickel, copper, and Platinum Group Elements. An impact was involved in making the Carswell structure in Saskatchewan, Canada; it contains uranium deposits.
Hydrocarbons are common around impact structures. Fifty percent of impact structures in North America in hydrocarbon-bearing sedimentary basins contain oil/gas fields.
Because of the many missions studying Mars since the 1960s, there is good coverage of its surface which contains large numbers of craters. Many of the craters on Mars differ from those on the Moon and other moons since Mars contains ice under the ground, especially in the higher latitudes. Some of the types of craters that have special shapes due to impact into ice-rich ground are pedestal craters, rampart craters, expanded craters, and LARLE craters.
On Earth, the recognition of impact craters is a branch of geology, and is related to planetary geology in the study of other worlds. Out of many proposed craters, relatively few are confirmed. The following twenty are a sample of articles of confirmed and well-documented impact sites.
See the Earth Impact Database, a website concerned with 190 () scientifically-confirmed impact craters on Earth.
There are approximately twelve more impact craters/basins larger than 300 km on the Moon, five on Mercury, and four on Mars. Large basins, some unnamed but mostly smaller than 300 km, can also be found on Saturn's moons Dione, Rhea and Iapetus.

</doc>
<doc id="6417" url="https://en.wikipedia.org/wiki?curid=6417" title="Corvus (disambiguation)">
Corvus (disambiguation)

Corvus is a genus of birds including species commonly known as crows, ravens, rooks and jackdaws.
Corvus may also refer to:

</doc>
<doc id="6420" url="https://en.wikipedia.org/wiki?curid=6420" title="Corona Borealis">
Corona Borealis

Corona Borealis is a small constellation in the Northern Celestial Hemisphere. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and remains one of the 88 modern constellations. Its brightest stars form a semicircular arc. Its Latin name, inspired by its shape, means "northern crown". In classical mythology Corona Borealis generally represented the crown given by the god Dionysus to the Cretan princess Ariadne and set by him in the heavens. Other cultures likened the pattern to a circle of elders, an eagle's nest, a bear's den, or even a smokehole. Ptolemy also listed a southern counterpart, Corona Australis, with a similar pattern.
The brightest star is the magnitude 2.2 Alpha Coronae Borealis. The yellow supergiant R Coronae Borealis is the prototype of a rare class of giant stars—the R Coronae Borealis variables—that are extremely hydrogen deficient, and thought to result from the merger of two white dwarfs. T Coronae Borealis, also known as the Blaze Star, is another unusual type of variable star known as a recurrent nova. Normally of magnitude 10, it last flared up to magnitude 2 in 1946. ADS 9731 and Sigma Coronae Borealis are multiple star systems with six and five components respectively. Five star systems have been found to have Jupiter-sized exoplanets. Abell 2065 is a highly concentrated galaxy cluster one billion light-years from the Solar System containing more than 400 members, and is itself part of the larger Corona Borealis Supercluster.
Covering 179 square degrees and hence 0.433% of the sky, Corona Borealis ranks 73rd of the 88 modern constellations by area. Its position in the Northern Celestial Hemisphere means that the whole constellation is visible to observers north of 50°S. It is bordered by Boötes to the north and west, Serpens Caput to the south, and Hercules to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "CrB". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of eight segments ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 39.71° and 25.54°. It has a counterpart—Corona Australis—in the Southern Celestial Hemisphere.
The seven stars that make up the constellation's distinctive crown-shaped pattern are all 4th-magnitude stars except for the brightest of them, Alpha Coronae Borealis. The other six stars are Theta, Beta, Gamma, Delta, Epsilon and Iota Coronae Borealis. The German cartographer Johann Bayer gave twenty stars in Corona Borealis Bayer designations from Alpha to Upsilon in his 1603 star atlas "Uranometria". Zeta Coronae Borealis was noted to be a double star by later astronomers and its components designated Zeta and Zeta. John Flamsteed did likewise with Nu Coronae Borealis; classed by Bayer as a single star, it was noted to be two close stars by Flamsteed. He named them 20 and 21 Coronae Borealis in his catalogue, alongside the designations Nu and Nu respectively. Chinese astronomers deemed nine stars to make up the asterism, adding Pi and Rho Coronae Borealis. Within the constellation's borders, there are 37 stars brighter than or equal to apparent magnitude 6.5.
Alpha Coronae Borealis (officially named Alphecca by the IAU, but sometimes also known as Gemma) appears as a blue-white star of magnitude 2.2. In fact, it is an Algol-type eclipsing binary that varies by 0.1 magnitude with a period of 17.4 days. The primary is a white main-sequence star of spectral type A0V that is 2.91 times the mass of the Sun () and 57 times as luminous (), and is surrounded by a debris disk out to a radius of around 60 astronomical units (AU). The secondary companion is a yellow main-sequence star of spectral type G5V that is a little smaller (0.9 times) the diameter of the Sun. Lying 75±0.5 light-years from Earth, Alphecca is believed to be a member of the Ursa Major Moving Group of stars that have a common motion through space.
Located 112±3 light-years away, Beta Coronae Borealis or Nusakan is a spectroscopic binary system whose two components are separated by 10 AU and orbit each other every 10.5 years. The brighter component is a rapidly oscillating Ap star, pulsating with a period of 16.2 minutes. Of spectral type A5V with a surface temperature of around 7980 K, it has around , 2.6 solar radii (), and . The smaller star is of spectral type F2V with a surface temperature of around 6750 K, and has around , , and between 4 and . Near Nusakan is Theta Coronae Borealis, a binary system that shines with a combined magnitude of 4.13 located 380±20 light-years distant. The brighter component, Theta Coronae Borealis A, is a blue-white star that spins extremely rapidly—at a rate of around 393 km per second. A Be star, it is surrounded by a debris disk.
Flanking Alpha to the east is Gamma Coronae Borealis, yet another binary star system, whose components orbit each other every 92.94 years and are roughly as far apart from each other as the Sun and Neptune. The brighter component has been classed as a Delta Scuti variable star, though this view is not universal. The components are main sequence stars of spectral types B9V and A3V. Located 170±2 light-years away, 4.06-magnitude Delta Coronae Borealis is a yellow giant star of spectral type G3.5III that is around and has swollen to . It has a surface temperature of 5180 K. For most of its existence, Delta Coronae Borealis was a blue-white main-sequence star of spectral type B before it ran out of hydrogen fuel in its core. Its luminosity and spectrum suggest it has just crossed the Hertzsprung gap, having finished burning core hydrogen and just begun burning hydrogen in a shell that surrounds the core.
Zeta Coronae Borealis is a double star with two blue-white components 6.3 arcseconds apart that can be readily separated at 100x magnification. The primary is of magnitude 5.1 and the secondary is of magnitude 6.0. Nu Coronae Borealis is an optical double, whose components are a similar distance from Earth but have different radial velocities, hence are assumed to be unrelated. The primary, Nu Coronae Borealis, is a red giant of spectral type M2III and magnitude 5.2, lying 640±30 light-years distant, and the secondary, Nu Coronae Borealis, is an orange-hued giant star of spectral type K5III and magnitude 5.4, estimated to be 590±30 light-years away. Sigma Coronae Borealis, on the other hand, is a true multiple star system divisible by small amateur telescopes. It is actually a complex system composed of two stars around as massive as the Sun that orbit each other every 1.14 days, orbited by a third Sun-like star every 726 years. The fourth and fifth components are a binary red dwarf system that is 14,000 AU distant from the other three stars. ADS 9731 is an even rarer multiple system in the constellation, composed of six stars, two of which are spectroscopic binaries.
Corona Borealis is home to two remarkable variable stars. T Coronae Borealis is a cataclysmic variable star also known as the Blaze Star. Normally placid around magnitude 10—it has a minimum of 10.2 and maximum of 9.9—it brightens to magnitude 2 in a period of hours, caused by a nuclear chain reaction and the subsequent explosion. T Coronae Borealis is one of a handful of stars called recurrent novae, which include T Pyxidis and U Scorpii. An outburst of T Coronae Borealis was first recorded in 1866; its second recorded outburst was in February 1946. T Coronae Borealis is a binary star with a red-hued giant primary and a white dwarf secondary, the two stars orbiting each other over a period of approximately 8 months. R Coronae Borealis is a yellow-hued variable supergiant star, over 7000 light-years from Earth, and prototype of a class of stars known as R Coronae Borealis variables. Normally of magnitude 6, its brightness periodically drops as low as magnitude 15 and then slowly increases over the next several months. These declines in magnitude come about as dust that has been ejected from the star obscures it. Direct imaging with the Hubble Space Telescope shows extensive dust clouds out to a radius of around 2000 AU from the star, corresponding with a stream of fine dust (composed of grains 5 nm in diameter) associated with the star's stellar wind and coarser dust (composed of grains with a diameter of around 0.14 µm) ejected periodically.
There are several other variables of reasonable brightness for amateur astronomer to observe, including three Mira-type long period variables: S Coronae Borealis ranges between magnitudes 5.8 and 14.1 over a period of 360 days. Located around 1946 light-years distant, it shines with a luminosity 16,643 times that of the Sun and has a surface temperature of 3033 K. One of the reddest stars in the sky, V Coronae Borealis is a cool star with a surface temperature of 2877 K that shines with a luminosity 102,831 times that of the Sun and is a remote 8810 light-years distant from Earth. Varying between magnitudes 6.9 and 12.6 over a period of 357 days, it is located near the junction of the border of Corona Borealis with Hercules and Bootes. Located 1.5° northeast of Tau Coronae Borealis, W Coronae Borealis ranges between magnitudes 7.8 and 14.3 over a period of 238 days. Another red giant, RR Coronae Borealis is a M3-type semiregular variable star that varies between magnitudes 7.3 and 8.2 over 60.8 days. RS Coronae Borealis is yet another semiregular variable red giant, which ranges between magnitudes 8.7 to 11.6 over 332 days. It is unusual in that it is a red star with a high proper motion (greater than 50 milliarcseconds a year). Meanwhile, U Coronae Borealis is an Algol-type eclipsing binary star system whose magnitude varies between 7.66 and 8.79 over a period of 3.45 days
TY Coronae Borealis is a pulsating white dwarf (of ZZ Ceti) type, which is around 70% as massive as the Sun, yet has only 1.1% of its diameter. Discovered in 1990, UW Coronae Borealis is a low-mass X-ray binary system composed of a star less massive than the Sun and a neutron star surrounded by an accretion disk that draws material from the companion star. It varies in brightness in an unusually complex manner: the two stars orbit each other every 111 minutes, yet there is another cycle of 112.6 minutes, which corresponds to the orbit of the disk around the degenerate star. The beat period of 5.5 days indicates the time the accretion disk—which is asymmetrical—takes to precess around the star.
Extrasolar planets have been confirmed in five star systems, four of which were found by the radial velocity method. The spectrum of Epsilon Coronae Borealis was analysed for seven years from 2005 to 2012, revealing a planet around 6.7 times as massive as Jupiter () orbiting every 418 days at an average distance of around 1.3 AU. Epsilon itself is a orange giant of spectral type K2III that has swollen to and . Kappa Coronae Borealis is a spectral type K1IV orange subgiant nearly twice as massive as the Sun; around it lie a dust debris disk, and one planet with a period of 3.4 years. This planet's mass is estimated at . The dimensions of the debris disk indicate it is likely there is a second substellar companion. Omicron Coronae Borealis is a K-type clump giant with one confirmed planet with a mass of that orbits every 187 days—one of the two least massive planets known around clump giants. HD 145457 is an orange giant of spectral type K0III found to have one planet of . Discovered by the Doppler method in 2010, it takes 176 days to complete an orbit. XO-1 is a magnitude 11 yellow main-sequence star located approximately light-years away, of spectral type G1V with a mass and radius similar to the Sun. In 2006 the hot Jupiter exoplanet XO-1b was discovered orbiting XO-1 by the transit method using the XO Telescope. Roughly the size of Jupiter, it completes an orbit around its star every three days.
The discovery of a Jupiter-sized planetary companion was announced in 1997 via analysis of the radial velocity of Rho Coronae Borealis, a yellow main sequence star and Solar analog of spectral type G0V, around 57 light-years distant from Earth. More accurate measurement of data from the Hipparcos satellite subsequently showed it instead to be a low-mass star somewhere between 100 and 200 times the mass of Jupiter. Possible stable planetary orbits in the habitable zone were calculated for the binary star Eta Coronae Borealis, which is composed of two stars—yellow main sequence stars of spectral type G1V and G3V respectively—similar in mass and spectrum to the Sun. No planet has been found, but a brown dwarf companion about 63 times as massive as Jupiter with a spectral type of L8 was discovered at a distance of 3640 AU from the pair in 2001.
Corona Borealis contains few galaxies observable with amateur telescopes. NGC 6085 and 6086 are a faint spiral and elliptical galaxy respectively close enough to each other to be seen in the same visual field through a telescope. Abell 2142 is a huge (six million light-year diameter), X-ray luminous galaxy cluster that is the result of an ongoing merger between two galaxy clusters. It has a redshift of 0.0909 (meaning it is moving away from us at 27,250 km/s) and a visual magnitude of 16.0. It is about 1.2 billion light-years away. Another galaxy cluster in the constellation, RX J1532.9+3021, is approximately 3.9 billion light-years from Earth. At the cluster's center is a large elliptical galaxy containing one of the most massive and most powerful supermassive black holes yet discovered. Abell 2065 is a highly concentrated galaxy cluster containing more than 400 members, the brightest of which are 16th magnitude; the cluster is more than one billion light-years from Earth. On a larger scale still, Abell 2065, along with Abell 2061, Abell 2067, Abell 2079, Abell 2089, and Abell 2092, make up the Corona Borealis Supercluster. Another galaxy cluster, Abell 2162, is a member of the Hercules Superclusters.
In Greek mythology, Corona Borealis was linked to the legend of Theseus and the minotaur. It was generally considered to represent a crown given by Dionysus to Ariadne, the daughter of Minos of Crete, after she had been abandoned by the Athenian prince Theseus. When she wore the crown at her marriage to Dionysus, he placed it in the heavens to commemorate their wedding. An alternate version has the besotted Dionysus give the crown to Ariadne, who in turn gives it to Theseus after he arrives in Crete to kill the minotaur that the Cretans have demanded tribute from Athens to feed. The hero uses the crown's light to escape the labyrinth after disposing of the creature, and Dionysus later sets it in the heavens. The Latin author Hyginus linked it to a crown or wreath worn by Bacchus (Dionysus) to disguise his appearance when first approaching Mount Olympus and revealing himself to the gods, having been previously hidden as yet another child of Jupiter's trysts with a mortal, in this case Semele. Corona Borealis was one of the 48 constellations mentioned in the "Almagest" of classical astronomer Ptolemy.
In Welsh mythology, it was called Caer Arianrhod, "the Castle of the Silver Circle", and was the heavenly abode of the Lady Arianrhod. To the ancient Balts, Corona Borealis was known as "Darželis", the "flower garden".
The Arabs called the constellation Alphecca (a name later given to Alpha Coronae Borealis), which means "separated" or "broken up" ( '), a reference to the resemblance of the stars of Corona Borealis to a loose string of jewels. This was also interpreted as a broken dish. Among the Bedouins, the constellation was known as ' (), or "the dish/bowl of the poor people".
The Skidi people of Native Americans saw the stars of Corona Borealis representing a council of stars whose chief was Polaris. The constellation also symbolised the smokehole over a fireplace, which conveyed their messages to the gods, as well as how chiefs should come together to consider matters of importance. The Shawnee people saw the stars as the "Heavenly Sisters", who descended from the sky every night to dance on earth. Alphecca signifies the youngest and most comely sister, who was seized by a hunter who transformed into a field mouse to get close to her. They married though she later returned to the sky, with her heartbroken husband and son following later. The Mi'kmaq of eastern Canada saw Corona Borealis as "Mskegwǒm", the den of the celestial bear (Alpha, Beta, Gamma and Delta Ursae Majoris).
Polynesian peoples often recognized Corona Borealis; the people of the Tuamotus named it "Na Kaua-ki-tokerau" and probably "Te Hetu". The constellation was likely called "Kaua-mea" in Hawaii, "Rangawhenua" in New Zealand, and "Te Wale-o-Awitu" in the Cook Islands atoll of Pukapuka. Its name in Tonga was uncertain; it was either called "Ao-o-Uvea" or "Kau-kupenga".
In Australian Aboriginal astronomy, the constellation is called "womera" ("the boomerang") due to the shape of the stars. The Wailwun people of northwestern New South Wales saw Corona Borealis as "mullion wollai" "eagle's nest", with Altair and Vega—each called "mullion"—the pair of eagles accompanying it. The Wardaman people of northern Australia held the constellation to be a gathering point for Men's Law, Women's Law and Law of both sexes come together and consider matters of existence.
Corona Borealis was renamed Corona Firmiana in honour of the Archbishop of Salzburg in the 1730 Atlas "Mercurii Philosophicii Firmamentum Firminianum Descriptionem" by Corbinianus Thomas, but this was not taken up by subsequent cartographers. The constellation was featured as a main plot ingredient in the short story "Hypnos" by H. P. Lovecraft, published in 1923; it is the object of fear of one of the protagonists in the short story. Finnish band Cadacross released an album titled "Corona Borealis" in 2002.

</doc>
<doc id="6421" url="https://en.wikipedia.org/wiki?curid=6421" title="Cygnus (constellation)">
Cygnus (constellation)

Cygnus is a northern constellation lying on the plane of the Milky Way, deriving its name from the Latinized Greek word for swan. Cygnus is one of the most recognizable constellations of the northern summer and autumn, and it features a prominent asterism known as the Northern Cross (in contrast to the Southern Cross). Cygnus was among the 48 constellations listed by the 2nd century astronomer Ptolemy, and it remains one of the 88 modern constellations.
Cygnus contains Deneb (ذنب, translit. "ḏanab," tail)which is one of the brightest stars in the night sky and is the most distant first-magnitude star as its "tail star" and one corner of the Summer Triangle. It also has some notable X-ray sources and the giant stellar association of Cygnus OB2. Cygnus is also known as the Northern Cross. One of the stars of this association, NML Cygni, is one of the largest stars currently known. The constellation is also home to Cygnus X-1, a distant X-ray binary containing a supergiant and unseen massive companion that was the first object widely held to be a black hole. Many star systems in Cygnus have known planets as a result of the Kepler Mission observing one patch of the sky, an area around Cygnus. 
Most of the east has part of the Hercules–Corona Borealis Great Wall in the deep sky, a giant galaxy filament that is the largest known structure in the observable universe, covering most of the northern sky.
"See also: Cygnus in Chinese astronomy"
In Hinduism, the period of time (or Muhurta) between 4:24 AM to 5:12 AM is called the Brahmamuhurtha, which means "the moment of the Universe"; the star system in correlation is the Cygnus constellation. This is believed to be a highly auspicious time to meditate, do any task, or start the day.
In Polynesia, Cygnus was often recognized as a separate constellation. In Tonga it was called "Tuula-lupe", and in the Tuamotus it was called "Fanui-tai". In New Zealand it was called "Mara-tea", in the Society Islands it was called "Pirae-tea" or "Taurua-i-te-haapa-raa-manu", and in the Tuamotus it was called "Fanui-raro". Beta Cygni was named in New Zealand; it was likely called "Whetu-kaupo". Gamma Cygni was called "Fanui-runga" in the Tuamotus.
Deneb was also often a given name, in the Islamic world of astronomy. The name "Deneb" comes from the Arabic name "dhaneb", meaning "tail", from the phrase "Dhanab ad-Dajājah", which means “the tail of the hen”.
In Greek mythology, Cygnus has been identified with several different legendary swans. Zeus disguised himself as a swan to seduce Leda, Spartan king Tyndareus's wife, who gave birth to the Gemini, Helen of Troy, and Clytemnestra; Orpheus was transformed into a swan after his murder, and was said to have been placed in the sky next to his lyre (Lyra); and the King Cygnus was transformed into a swan.
The Greeks also associated this constellation with the tragic story of Phaethon, the son of Helios the sun god, who demanded to ride his father's sun chariot for a day. Phaethon, however, was unable to control the reins, forcing Zeus to destroy the chariot (and Phaethon) with a thunderbolt, causing it to plummet to the earth into the river Eridanus. According to the myth, Phaethon's close friend or lover, Cygnus, grieved bitterly and spent many days diving into the river to collect Phaethon's bones to give him a proper burial. The gods were so touched by Cygnus's devotion that they turned him into a swan and placed him among the stars.
In Ovid's "Metamorphoses", there are three people named Cygnus, all of whom are transformed into swans. Alongside Cygnus, noted above, he mentions a boy from Tempe who commits suicide when Phyllius refuses to give him a tamed bull that he demands, but is transformed into a swan and flies away. He also mentions a son of Neptune who is an invulnerable warrior in the Trojan War who is eventually defeated by Achilles, but Neptune saves him by transforming him into a swan.
Together with other avian constellations near the summer solstice, Vultur cadens and Aquila, Cygnus may be a significant part of the origin of the myth of the Stymphalian Birds, one of The Twelve Labours of Hercules.
A very large constellation, Cygnus is bordered by Cepheus to the north and east, Draco to the north and west, Lyra to the west, Vulpecula to the south, Pegasus to the southeast and Lacerta to the east. The three-letter abbreviation for the constellation, as adopted by the IAU in 1922, is "Cyg". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined as a polygon of 28 segments. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between 27.73° and 61.36°. Covering 804 square degrees and around 1.9% of the night sky, Cygnus ranks 16th of the 88 constellations in size.
Cygnus culminates at midnight on 29 June, and is most visible in the evening from the early summer to mid-autumn in the Northern Hemisphere.
Normally, Cygnus is depicted with Delta and Epsilon Cygni as its wings. Deneb, the brightest in the constellation is at its tail, and Albireo as the tip of its beak.
There are several asterisms in Cygnus. In the 17th-century German celestial cartographer Johann Bayer's star atlas the "Uranometria", Alpha, Beta and Gamma Cygni form the pole of a cross, while Delta and Epsilon form the cross beam. The nova P Cygni was then considered to be the body of Christ.
Bayer catalogued many stars in the constellation, giving them the Bayer designations from Alpha to Omega and then using lowercase Roman letters to g. John Flamsteed added the Roman letters h, i, k, l and m (these stars were considered "informes" by Bayer as they lay outside the asterism of Cygnus), but were dropped by Francis Baily.
There are several bright stars in Cygnus. Alpha Cygni, called Deneb, is the brightest star in Cygnus. It is a white supergiant star of spectral type A2Iae that varies between magnitudes 1.21 and 1.29, one of the largest and most luminous A-class stars known. It is located about 3200 light-years away. Its traditional name means "tail" and refers to its position in the constellation. Albireo, designated Beta Cygni, is a celebrated binary star among amateur astronomers for its contrasting hues. The primary is an orange-hued giant star of magnitude 3.1 and the secondary is a blue-green hued star of magnitude 5.1. The system is 380 light-years away and is visible in large binoculars and all amateur telescopes. Gamma Cygni, traditionally named Sadr, is a yellow-tinged supergiant star of magnitude 2.2, 1500 light-years away. Its traditional name means "breast" and refers to its position in the constellation. Delta Cygni (the proper name is Fawaris) is another bright binary star in Cygnus, 171 light-years with a period of 800 years. The primary is a blue-white hued giant star of magnitude 2.9, and the secondary is a star of magnitude 6.6. The two components are visible in a medium-sized amateur telescope. The fifth star in Cygnus above magnitude 3 is Aljanah, designated Epsilon Cygni. It is an orange-hued giant star of magnitude 2.5, 72 light-years from Earth.
There are several other dimmer double and binary stars in Cygnus. Mu Cygni is a binary star with an optical tertiary component. The binary system has a period of 790 years and is 73 light-years from Earth. The primary and secondary, both white stars, are of magnitude 4.8 and 6.2, respectively. The unrelated tertiary component is of magnitude 6.9. Though the tertiary component is visible in binoculars, the primary and secondary currently require a medium-sized amateur telescope to split, as they will through the year 2020. The two stars will be closest between 2043 and 2050, when they will require a telescope with larger aperture to split. The stars 30 and 31 Cygni form a contrasting double star similar to the brighter Albireo. The two are visible in binoculars. The primary, 31 Cygni, is an orange-hued star of magnitude 3.8, 1400 light-years from Earth. The secondary, 30 Cygni, appears blue-green. It is of spectral type A5IIIn and magnitude 4.83, and is around 610 light-years from Earth. 31 Cygni itself is a binary star; the tertiary component is a blue star of magnitude 7.0. Psi Cygni is a binary star visible in small amateur telescopes, with two white components. The primary is of magnitude 5.0 and the secondary is of magnitude 7.5. 61 Cygni is a binary star visible in large binoculars or a small amateur telescope. It is 11.4 light-years from Earth and has a period of 750 years. Both components are orange-hued dwarf (main sequence) stars; the primary is of magnitude 5.2 and the secondary is of magnitude 6.1. 61 Cygni is significant because Friedrich Wilhelm Bessel determined its parallax in 1838, the first star to have a known parallax.
Located near Eta Cygni is the X-ray source Cygnus X-1, which is now thought to be caused by a black hole accreting matter in a binary star system. This was the first x-ray source widely believed to be a black hole.
Cygnus also contains several other noteworthy X-ray sources. Cygnus X-3 is a microquasar containing a Wolf–Rayet star in orbit around a very compact object, with a period of only 4.8 hours. The system is one of the most intrinsically luminous X-ray sources observed. The system undergoes periodic outbursts of unknown nature, and during one such outburst, the system was found to be emitting muons, likely caused by neutrinos. While the compact object is thought to be a neutron star or possibly a black hole, it is possible that the object is instead a more exotic stellar remnant, possibly the first discovered quark star, hypothesized due to its production of cosmic rays that cannot be explained if the object is a normal neutron star. The system also emits cosmic rays and gamma rays, and has helped shed insight on to the formation of such rays. Cygnus X-2 is another X-ray binary, containing an A-type giant in orbit around a neutron star with a 9.8 day period. The system is interesting due to the rather small mass of the companion star, as most millisecond pulsars have much more massive companions. Another black hole in Cygnus is V404 Cygni, which consists of a K-type star orbiting around a black hole of around 12 solar masses. The black hole, similar to that of Cygnus X-3, has been hypothesized to be a quark star. 4U 2129+ 47 is another X-ray binary containing a neutron star which undergoes outbursts, as is EXO 2030+ 375.
Cygnus is also home to several variable stars. SS Cygni is a dwarf nova which undergoes outbursts every 7–8 days. The system's total magnitude varies from 12th magnitude at its dimmest to 8th magnitude at its brightest. The two objects in the system are incredibly close together, with an orbital period of less than 0.28 days. Chi Cygni is a red giant and the second-brightest Mira variable star at its maximum. It ranges between magnitudes 3.3 and 14.2, and spectral types S6,2e to S10,4e (MSe) over a period of 408 days; it has a diameter of 300 solar diameters and is 350 light-years from Earth. P Cygni is a luminous blue variable that brightened suddenly to 3rd magnitude in 1600 AD. Since 1715, the star has been of 5th magnitude, despite being more than 5000 light-years from Earth. The star's spectrum is unusual in that it contains very strong emission lines resulting from surrounding nebulosity. W Cygni is a semi-regular variable red giant star, 618 light-years from Earth.It has a maximum magnitude of 5.10 and a minimum magnitude 6.83; its period of 131 days. It is a red giant ranging between spectral types M4e-M6e(Tc:)III, NML Cygni is a red hypergiant semi-regular variable star located at 5,300 light-years away from Earth. It is one of largest stars currently known in the galaxy with a radius exceeding 1,000 solar radii. Its magnitude is around 16.6, its period is about 940 days.
Cygnus contains the binary star system KIC 9832227. It is predicted that the two stars will coalesce in about 2022, briefly forming a new naked-eye object.
Cygnus is one of the constellations that the Kepler satellite surveyed in its search for extrasolar planets, and as a result, there are about a hundred stars in Cygnus with known planets, the most of any constellation. One of the most notable systems is the Kepler-11 system, containing six transiting planets, all within a plane of approximately one degree. With a spectral type of G6V, the star is somewhat cooler than the Sun. The planets are very close to the star; all but the last planet are closer to Kepler-11 than Mercury is to the Sun, and all the planets are more massive than Earth. The naked-eye star 16 Cygni, a triple star approximately 70 light-years from Earth composed two Sun-like stars and a red dwarf, contains a planet orbiting one of the sun-like stars, found due to variations in the star's radial velocity. Gliese 777, another naked-eye multiple star system containing a yellow star and a red dwarf, also contains a planet. The planet is somewhat similar to Jupiter, but with slightly more mass and a more eccentric orbit. The Kepler-22 system is also notable, in that its extrasolar planet is believed to be the first "Earth-twin" planet ever discovered.
There is an abundance of deep-sky objects, with many open clusters, nebulae of various types and supernova remnants found in Cygnus due to its position on the Milky Way. Some open clusters can be difficult to make out from a rich background of stars.
M39 (NGC 7092) is an open cluster 950 light-years from Earth that is visible to the unaided eye under dark skies. It is loose, with about 30 stars arranged over a wide area; their conformation appears triangular. The brightest stars of M39 are of the 7th magnitude. Another open cluster in Cygnus is NGC 6910, also called the Rocking Horse Cluster, possessing 16 stars with a diameter of 5 arcminutes visible in a small amateur instrument; it is of magnitude 7.4. The brightest of these are two gold-hued stars, which represent the bottom of the toy it is named for. A larger amateur instrument reveals 8 more stars, nebulosity to the east and west of the cluster, and a diameter of 9 arcminutes. The nebulosity in this region is part of the Gamma Cygni Nebula. The other stars, approximately 3700 light-years from Earth, are mostly blue-white and very hot.
Other open clusters in Cygnus include Dolidze 9, Collinder 421, Dolidze 11, and Berkeley 90. Dolidze 9, 2800 light-years from Earth and relatively young at 20 million light-years old, is a faint open cluster with up to 22 stars visible in small and medium-sized amateur telescopes. Nebulosity is visible to the north and east of the cluster, which is 7 arcminutes in diameter. The brightest star appears in the eastern part of the cluster and is of the 7th magnitude; another bright star has a yellow hue. Dolidze 11 is an open cluster 400 million years old, farthest away of the three at 3700 light-years. More than 10 stars are visible in an amateur instrument in this cluster, of similar size to Dolidze 9 at 7 arcminutes in diameter, whose brightest star is of magnitude 7.5. It, too, has nebulosity in the east. Collinder 421 is a particularly old open cluster at an age of approximately 1 billion years; it is of magnitude 10.1. 3100 light-years from Earth, more than 30 stars are visible in a diameter of 8 arcseconds. The prominent star in the north of the cluster has a golden color, whereas the stars in the south of the cluster appear orange. Collinder 421 appears to be embedded in nebulosity, which extends past the cluster's borders to its west. Berkeley 90 is a smaller open cluster, with a diameter of 5 arcminutes. More than 16 members appear in an amateur telescope.
NGC 6826, the Blinking Planetary Nebula, is a planetary nebula with a magnitude of 8.5, 3200 light-years from Earth. It appears to "blink" in the eyepiece of a telescope because its central star is unusually bright (10th magnitude). When an observer focuses on the star, the nebula appears to fade away. Less than one degree from the Blinking Planetary is the double star 16 Cygni.
The North America Nebula (NGC 7000) is one of the most well-known nebulae in Cygnus, because it is visible to the unaided eye under dark skies, as a bright patch in the Milky Way. However, its characteristic shape is only visible in long-exposure photographs – it is difficult to observe in telescopes because of its low surface brightness. It has low surface brightness because it is so large; at its widest, the North America Nebula is 2 degrees across. Illuminated by a hot embedded star of magnitude 6, NGC 7000 is 1500 light-years from Earth.
To the south of Epsilon Cygni is the Veil Nebula (NGC 6960, 6962, 6979, 6992, and 6995), a 5,000-year-old supernova remnant covering approximately 3 degrees of the sky - it is over 50 light-years long. Because of its appearance, it is also called the Cygnus Loop. The Loop is only visible in long-exposure astrophotographs. However, the brightest portion, NGC 6992, is faintly visible in binoculars, and a dimmer portion, NGC 6960, is visible in wide-angle telescopes.
The DR 6 cluster is also nicknamed the "Galactic Ghoul" because of the nebula's resemblance to a human face;
The Northern Coalsack Nebula, also called the Cygnus Rift, is a dark nebula located in the Cygnus Milky Way.
The Gamma Cygni Nebula (IC 1318) includes both bright and dark nebulae in an area of over 4 degrees. DWB 87 is another of the many bright emission nebulae in Cygnus, 7.8 by 4.3 arcminutes. It is in the Gamma Cygni area. Two other emission nebulae include Sharpless 2-112 and Sharpless 2-115. When viewed in an amateur telescope, Sharpless 2–112 appears to be in a teardrop shape. More of the nebula's eastern portion is visible with an O III (doubly ionized oxygen) filter. There is an orange star of magnitude 10 nearby and a star of magnitude 9 near the nebula's northwest edge. Further to the northwest, there is a dark rift and another bright patch. The whole nebula measures 15 arcminutes in diameter. Sharpless 2–115 is another emission nebula with a complex pattern of light and dark patches. Two pairs of stars appear in the nebula; it is larger near the southwestern pair. The open cluster Berkeley 90 is embedded in this large nebula, which measures 30 by 20 arcminutes.
Also of note is the Crescent Nebula (NGC 6888), located between Gamma and Eta Cygni, which was formed by the Wolf–Rayet star HD 192163.
In recent years, amateur astronomers have made some notable Cygnus discoveries. The "Soap bubble nebula" (PN G75.5+1.7), near the Crescent nebula, was discovered on a digital image by Dave Jurasevich in 2007. In 2011, Austrian amateur Matthias Kronberger discovered a planetary nebula (Kronberger 61, now nicknamed "The Soccer Ball") on old survey photos, confirmed recently in images by the Gemini Observatory; both of these are likely too faint to be detected by eye in a small amateur scope.
But a much more obscure and relatively 'tiny' object—one which is readily seen in dark skies by amateur telescopes, under good conditions—is the newly discovered nebula (likely reflection type) associated with the star 4 Cygni (HD 183056): an approximately fan-shaped glowing region of several arcminutes' diameter, to the south and west of the fifth-magnitude star. It was first discovered visually near San Jose, California and publicly reported by amateur astronomer Stephen Waldee in 2007, and was confirmed photographically by Al Howard in 2010. California amateur astronomer Dana Patchick also says he detected it on the Palomar Observatory survey photos in 2005 but had not published it for others to confirm and analyze at the time of Waldee's first official notices and later 2010 paper.
Cygnus X is the largest star-forming region in the Solar neighborhood and includes not only some of the brightest and most massive stars known (such as Cygnus OB2-12), but also Cygnus OB2, a massive stellar association classified by some authors as a young globular cluster.
More supernovae have been seen in the Fireworks Galaxy (NGC 6946) than in any other galaxy.
Cygnus A is the first radio galaxy discovered; at a distance of 730 million light-years from Earth, it is the closest powerful radio galaxy. In the visible spectrum, it appears as an elliptical galaxy in a small cluster. It is classified as an active galaxy because the supermassive black hole at its nucleus is accreting matter, which produces two jets of matter from the poles. The jets' interaction with the interstellar medium creates radio lobes, one source of radio emissions.
Cygnus is also the apparent source of the WIMP-wind due to the orientation of the solar system's rotation through the galactic halo.

</doc>
<doc id="6422" url="https://en.wikipedia.org/wiki?curid=6422" title="Communion">
Communion

Communion may refer to:

</doc>
<doc id="6423" url="https://en.wikipedia.org/wiki?curid=6423" title="Calorie">
Calorie

The calorie is a unit of energy widely used in nutrition.
For historical reasons, two main definitions of calorie are in wide use. The small calorie or gram calorie (usually denoted cal) is the amount of heat energy needed to raise the temperature of one "gram" of water by one degree Celsius (or one kelvin). The large calorie, food calorie, or kilocalorie (Cal, calorie or kcal) is the amount of heat needed to cause the same increase in one "kilogram" of water. Thus, 1 kilocalorie (kcal) = 1000 calories (cal). By convention in food science, the large calorie is commonly called Calorie (with a capital C by some authors to distinguish from the smaller unit). In most countries, labels of industrialized food products are required to indicate the nutritional energy value in (kilo or large) calories per serving or per weight.
Calorie relates directly to the metric system, and therefore to the SI system. It is regarded as obsolete within the scientific community, since the adoption of the SI system, but is still in some use. The SI unit of energy is the joule, with symbol "J": one calorie (small) is defined as exactly 4.184 J; one kilocalorie (large) is 4184 J.
The calorie was first introduced by Nicolas Clément, as a unit of heat energy, in lectures during the years 1819–1824. This was the "large" calorie, viz. modern kilocalorie. 
The term entered French and English dictionaries between 1841 and 1867. It comes .
The "small" calorie (modern calorie) was introduced by Pierre Antoine Favre (Chemist) and Johann T. Silbermann (Physicist) in 1852. 
In 1879, Marcellin Berthelot distinguished between gram-calorie (modern calorie) and kilogram-calorie (modern kilocalorie). Berthelot also introduced the convention of capitalizing the kilogram-calorie, as "Calorie".
The use of the kilogram-calorie (kcal) for nutrition was introduced to the American public by Wilbur Olin Atwater, a professor at Wesleyan University, in 1887.
The modern calorie (cal) was first recognized as a unit of the cm-g-s system (cgs) in 1896,
alongside the already-existing cgs unit of energy, the erg (first suggested by Clausius in 1864, under the name "ergon", and officially adopted in 1882).
Already in 1928 there were serious complaints about the possible confusion arising from the two main definitions of the calorie and whether the notion of using the capital letter to distinguish them was sound.
Use of the calorie was officially deprecated by the ninth General Conference on Weights and Measures, in 1948.
The alternate spelling "calory" is archaic.
The modern (small) calorie is defined as the amount of energy needed to increase the temperature of 1 gram of water by 1 °C (or 1 K, which is the same increment).
The definition depends on the atmospheric pressure and the starting temperature. Accordingly, several different precise definitions of the calorie have been used.
The two definitions most common in older literature appear to be the "15 °C calorie" and the "thermochemical calorie". Until 1948, the latter was defined as 4.1833 international joules; the current standard of 4.184 J was chosen to have the new thermochemical calorie represent the same quantity of energy as before.
The calorie was first defined specifically to measure energy in the form of heat, especially in experimental calorimetry.
In a nutritional context, the kilojoule (kJ) is the SI unit of food energy, although the "calorie" is commonly used. The word "calorie" is commonly used with the number of kilocalories (kcal) of nutritional energy measured.
In the United States, most nutritionists prefer the unit kilocalorie to the unit kilojoules, whereas most physiologists prefer to use kilojoules. In the majority of other countries, nutritionists prefer the kilojoule to the kilocalorie. US food labelling laws require the use of kilocalories (under the name of "Calories"); kilojoules are permitted to be included on food labels alongside kilocalories, but most food labels do not do so. In Australia, kilojoules are officially preferred over kilocalories, but kilocalories retain some degree of popular use. Australian and New Zealand food labelling laws require the use of kilojoules; kilocalories are allowed to be included on labels in addition to kilojoules, but are not required. EU food labelling laws require both kilojoules and kilocalories on all nutritional labels, with the kilojoules listed first.
To facilitate comparison, specific energy or energy density figures are often quoted as "calories per serving" or "kcal per 100 g". A nutritional requirement or consumption is often expressed in calories or kilocalories per day. 
Food nutrients as fat (lipids) contains 9 kilocalories per gram (kcal/g), while carbohydrate (sugar) or protein contains approximately 4 kcal/g. Alcohol in food contains 7 kcal/g.. Food nutrients are also often quoted "per 100 g".
In other scientific contexts, the term "calorie" almost always refers to the small calorie. Even though it is not an SI unit, it is still used in chemistry. For example, the energy released in a chemical reaction per mole of reagent is occasionally expressed in kilocalories per mole. Typically, this use was largely due to the ease with which it could be calculated in laboratory reactions, especially in aqueous solution: a volume of reagent dissolved in water forming a solution, with concentration expressed in moles per litre (1 litre weighing 1 kilogram), will induce a temperature change in degrees Celsius in the total volume of water solvent, and these quantities (volume, molar concentration and temperature change) can then be used to calculate energy per mole. It is also occasionally used to specify energy quantities that relate to reaction energy, such as enthalpy of formation and the size of activation barriers. However, its use is being superseded by the SI unit, the joule, and multiples thereof such as the kilojoule.
In the past, a bomb calorimeter was used to determine the energy content of food by burning a sample and measuring a temperature change in the surrounding water. Today, this method is not commonly used in the United States and has been replaced by calculating the energy content indirectly from adding up the energy provided by energy-containing nutrients of food (such as protein, carbohydrates, and fats). The fibre content is also subtracted to account for the fact that fibre is not digested by the body.

</doc>
<doc id="6424" url="https://en.wikipedia.org/wiki?curid=6424" title="Corona Australis">
Corona Australis

Corona Australis is a constellation in the Southern Celestial Hemisphere. Its Latin name means "southern crown", and it is the southern counterpart of Corona Borealis, the northern crown. It is one of the 48 constellations listed by the 2nd-century astronomer Ptolemy, and it remains one of the 88 modern constellations. The Ancient Greeks saw Corona Australis as a wreath rather than a crown and associated it with Sagittarius or Centaurus. Other cultures have likened the pattern to a turtle, ostrich nest, a tent, or even a hut belonging to a rock hyrax.
Although fainter than its northern counterpart, the oval- or horseshoe-shaped pattern of its brighter stars renders it distinctive. Alpha and Beta Coronae Australis are the two brightest stars with an apparent magnitude of around 4.1. Epsilon Coronae Australis is the brightest example of a W Ursae Majoris variable in the southern sky. Lying alongside the Milky Way, Corona Australis contains one of the closest star-forming regions to the Solar System—a dusty dark nebula known as the Corona Australis Molecular Cloud, lying about 430 light years away. Within it are stars at the earliest stages of their lifespan. The variable stars R and TY Coronae Australis light up parts of the nebula, which varies in brightness accordingly.
The name of the constellation was entered as "Corona Australis" when the International Astronomical Union (IAU) established the 88 modern constellations in 1922.
In 1932, the name was instead recorded as "Corona Austrina" when the IAU's commission on notation approved a list of four-letter abbreviations for the constellations.
The four-letter abbreviations were repealed in 1955. The IAU presently uses "Corona Australis" exclusively.
Corona Australis is a small constellation bordered by Sagittarius to the north, Scorpius to the west, Telescopium to the south, and Ara to the southwest. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "CrA". The official constellation boundaries, as set by Eugène Delporte in 1930, are defined by a polygon of four segments ("illustrated in infobox"). In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between −36.77° and −45.52°. Covering 128 square degrees, Corona Australis culminates at midnight around the 30th of June and ranks 80th in area. Only visible at latitudes south of 53° north, Corona Australis cannot be seen from the British Isles as it lies too far south, but it can be seen from southern Europe and readily from the southern United States.
While not a bright constellation, Corona Australis is nonetheless distinctive due to its easily identifiable pattern of stars, which has been described as horseshoe- or oval-shaped. Though it has no stars brighter than 4th magnitude, it still has 21 stars visible to the unaided eye (brighter than magnitude 5.5). Nicolas Louis de Lacaille used the Greek letters Alpha through to Lambda to label the most prominent eleven stars in the constellation, designating two stars as Eta and omitting Iota altogether. Mu Coronae Australis, a yellow star of spectral type G5.5III and apparent magnitude 5.21, was labelled by Johann Elert Bode and retained by Benjamin Gould, who deemed it bright enough to warrant naming.
The only star in the constellation to have received a name is Alfecca Meridiana or Alpha CrA. The name combines the Arabic name of the constellation with the Latin for "southern". In Arabic, "Alfecca" means "break", and refers to the shape of both Corona Australis and Corona Borealis. Also called simply "Meridiana", it is a white main sequence star located 125 light years away from Earth, with an apparent magnitude of 4.10 and spectral type A2Va. A rapidly rotating star, it spins at almost 200 km per second at its equator, making a complete revolution in around 14 hours. Like the star Vega, it has excess infrared radiation, which indicates it may be ringed by a disk of dust. It is currently a main-sequence star, but will eventually evolve into a white dwarf; currently, it has a luminosity 31 times greater, and a radius and mass of 2.3 times that of the Sun. Beta Coronae Australis is an orange giant 474 light years from Earth. Its spectral type is K0II, and it is of apparent magnitude 4.11. Since its formation, it has evolved from a B-type star to a K-type star. Its luminosity class places it as a bright giant; its luminosity is 730 times that of the Sun, designating it one of the highest-luminosity K0-type stars visible to the naked eye. 100 million years old, it has a radius of 43 solar radii () and a mass of between 4.5 and 5 solar masses (). Alpha and Beta are so similar as to be indistinguishable in brightness to the naked eye.
Some of the more prominent double stars include Gamma Coronae Australis—a pair of yellowish white stars 58 light years away from Earth, which orbit each other every 122 years. Widening since 1990, the two stars can be seen as separate with a 100 mm aperture telescope; they are separated by 1.3 arcseconds at an angle of 61 degrees. They have a combined visual magnitude of 4.2; each component is an F8V dwarf star with a magnitude of 5.01. Epsilon Coronae Australis is an eclipsing binary belonging to a class of stars known as W Ursae Majoris variables. These star systems are known as contact binaries as the component stars are so close together they touch. Varying by a quarter of a magnitude around an average apparent magnitude of 4.83 every seven hours, the star system lies 98 light years away. Its spectral type is F4VFe-0.8+. At the southern end of the crown asterism are the stars Eta¹ and Eta² Coronae Australis, which form an optical double. Of magnitude 5.1 and 5.5, they are separable with the naked eye and are both white. Kappa Coronae Australis is an easily resolved optical double—the components are of apparent magnitudes 6.3 and 5.6 and are about 1000 and 150 light years away respectively. They appear at an angle of 359 degrees, separated by 21.6 arcseconds. Kappa² is actually the brighter of the pair and is more bluish white, with a spectral type of B9V, while Kappa¹ is of spectral type A0III. Lying 202 light years away, Lambda Coronae Australis is a double splittable in small telescopes. The primary is a white star of spectral type A2Vn and magnitude of 5.1, while the companion star has a magnitude of 9.7. The two components are separated by 29.2 arcseconds at an angle of 214 degrees.
Zeta Coronae Australis is a rapidly rotating main sequence star with an apparent magnitude of 4.8, 221.7 light years from Earth. The star has blurred lines in its hydrogen spectrum due to its rotation. Its spectral type is B9V. Theta Coronae Australis lies further to the west, a yellow giant of spectral type G8III and apparent magnitude 4.62. Corona Australis harbours RX J1856.5-3754, an isolated neutron star that is thought to lie 140 (±40) parsecs, or 460 (±130) light years, away, with a diameter of 14 km. It was once suspected to be a strange star, but this has been discounted.
In the north of the constellation is the Corona Australis Molecular Cloud, a dark molecular cloud with many embedded reflection nebulae, including NGC 6729, NGC 6726–7, and IC 4812. A star-forming region of around , it contains Herbig–Haro objects (protostars) and some very young stars. About 430 light years (130 parsecs) away, it is one of the closest star-forming regions to the Solar System. The related NGC 6726 and 6727, along with unrelated NGC 6729, were first recorded by Johann Friedrich Julius Schmidt in 1865. The Coronet cluster, about 554 light years (170 parsecs) away at the edge of the Gould Belt, is also used in studying star and protoplanetary disk formation.
R Coronae Australis is an irregular variable star ranging from magnitudes 9.7 to 13.9. Blue-white, it is of spectral type B5IIIpe. A very young star, it is still accumulating interstellar material. It is obscured by, and illuminates, the surrounding nebula, NGC 6729, which brightens and darkens with it. The nebula is often compared to a comet for its appearance in a telescope, as its length is five times its width. S Coronae Australis is a G-class dwarf in the same field as R and is a T Tauri star. Nearby, another young variable star, TY Coronae Australis, illuminates another nebula: reflection nebula NGC 6726–7. TY Coronae Australis ranges irregularly between magnitudes 8.7 and 12.4, and the brightness of the nebula varies with it. Blue-white, it is of spectral type B8e. The largest young stars in the region, R, S, T, TY and VV Coronae Australis, are all ejecting jets of material which cause surrounding dust and gas to coalesce and form Herbig–Haro objects, many of which have been identified nearby. Lying adjacent to the nebulosity is the globular cluster known as NGC 6723, which is actually in the neighbouring constellation of Sagittarius and is much much further away.
Near Epsilon and Gamma Coronae Australis is Bernes 157, a dark nebula and star forming region. It is a large nebula, 55 by 18 arcminutes, that possesses several stars around magnitude 13. These stars have been dimmed by up to 8 magnitudes by its dust clouds.
IC 1297 is a planetary nebula of apparent magnitude 10.7, which appears as a green-hued roundish object in higher-powered amateur instruments. The nebula surrounds the variable star RU Coronae Australis, which has an average apparent magnitude of 12.9 and is a WC class Wolf–Rayet star. IC 1297 is small, at only 7 arcseconds in diameter; it has been described as "a square with rounded edges" in the eyepiece, elongated in the north-south direction. Descriptions of its color encompass blue, blue-tinged green, and green-tinged blue.
Corona Australis' location near the Milky Way means that galaxies are uncommonly seen. NGC 6768 is a magnitude 11.2 object 35′ south of IC 1297. It is made up of two galaxies merging, one of which is an elongated elliptical galaxy of classification E4 and the other a lenticular galaxy of classification S0. IC 4808 is a galaxy of apparent magnitude 12.9 located on the border of Corona Australis with the neighbouring constellation of Telescopium and 3.9 degrees west-southwest of Beta Sagittarii. However, amateur telescopes will only show a suggestion of its spiral structure. It is 1.9 arcminutes by 0.8 arcminutes. The central area of the galaxy does appear brighter in an amateur instrument, which shows it to be tilted northeast-southwest.
Southeast of Theta and southwest of Eta lies the open cluster ESO 281-SC24, which is composed of the yellow 9th magnitude star GSC 7914 178 1 and five 10th to 11th magnitude stars. Halfway between Theta Coronae Australis and Theta Scorpii is the dense globular cluster NGC 6541. Described as between magnitude 6.3 and magnitude 6.6, it is visible in binoculars and small telescopes. Around 22000 light years away, it is around 100 light years in diameter. It is estimated to be around 14 billion years old. NGC 6541 appears 13.1 arcminutes in diameter and is somewhat resolvable in large amateur instruments; a 12-inch telescope reveals approximately 100 stars but the core remains unresolved.
The Corona Australids are a meteor shower that takes place between 14 and 18 March each year, peaking around 16 March. This meteor shower does not have a high peak hourly rate. In 1953 and 1956, observers noted a maximum of 6 meteors per hour and 4 meteors per hour respectively; in 1955 the shower was "barely resolved". However, in 1992, astronomers detected a peak rate of 45 meteors per hour. The Corona Australids' rate varies from year to year. At only six days, the shower's duration is particularly short, and its meteoroids are small; the stream is devoid of large meteoroids. The Corona Australids were first seen with the unaided eye in 1935 and first observed with radar in 1955. Corona Australid meteors have an entry velocity of 45 kilometers per second. In 2006, a shower originating near Beta Coronae Australis was designated as the Beta Coronae Australids. They appear in May, the same month as a nearby shower known as the May Microscopids, but the two showers have different trajectories and are unlikely to be related.
Corona Australis may have been recorded by ancient Mesopotamians in the MUL.APIN, as a constellation called MA.GUR ("The Bark"). However, this constellation, adjacent to SUHUR.MASH ("The Goat-Fish", modern Capricornus), may instead have been modern Epsilon Sagittarii. As a part of the southern sky, MA.GUR was one of the fifteen "stars of Ea".
In the 3rd century BC, the Greek didactic poet Aratus wrote of, but did not name the constellation, instead calling the two crowns Στεφάνοι ("Stephanoi"). The Greek astronomer Ptolemy described the constellation in the 2nd century AD, though with the inclusion of Alpha Telescopii, since transferred to Telescopium. Ascribing 13 stars to the constellation, he named it Στεφάνος νοτιος (), "Southern Wreath", while other authors associated it with either Sagittarius (having fallen off his head) or Centaurus; with the former, it was called "Corona Sagittarii". Similarly, the Romans called Corona Australis the "Golden Crown of Sagittarius". It was known as "Parvum Coelum" ("Canopy", "Little Sky") in the 5th century. The 18th-century French astronomer Jérôme Lalande gave it the names "Sertum Australe" ("Southern Garland") and "Orbiculus Capitis", while German poet and author Philippus Caesius called it "Corolla" ("Little Crown") or "Spira Australis" ("Southern Coil"), and linked it with the Crown of Eternal Life from the New Testament. Seventeenth-century celestial cartographer Julius Schiller linked it to the Diadem of Solomon. Sometimes, Corona Australis was not the wreath of Sagittarius but arrows held in his hand.
Corona Australis has been associated with the myth of Bacchus and Stimula. Jupiter had impregnated Stimula, causing Juno to become jealous. Juno convinced Stimula to ask Jupiter to appear in his full splendor, which the mortal woman could not handle, causing her to burn. After Bacchus, Stimula's unborn child, became an adult and the god of wine, he honored his deceased mother by placing a wreath in the sky.
In Chinese astronomy, the stars of Corona Australis are located within the Black Tortoise of the North (北方玄武, "Běi Fāng Xuán Wǔ"). The constellation itself was known as "ti'en pieh" ("Heavenly Turtle") and during the Western Zhou period, marked the beginning of winter. However, precession over time has meant that the "Heavenly River" (Milky Way) became the more accurate marker to the ancient Chinese and hence supplanted the turtle in this role. Arabic names for Corona Australis include "Al Ķubbah" "the Tortoise", "Al Ĥibā" "the Tent" or "Al Udḥā al Na'ām" "the Ostrich Nest". It was later given the name "Al Iklīl al Janūbiyyah", which the European authors Chilmead, Riccioli and Caesius transliterated as Alachil Elgenubi, Elkleil Elgenubi and Aladil Algenubi respectively.
The ǀXam speaking San people of South Africa knew the constellation as "≠nabbe ta !nu" "house of branches"—owned originally by the Dassie (rock hyrax), and the star pattern depicting people sitting in a semicircle around a fire.
The indigenous Boorong people of northwestern Victoria saw it as "Won", a boomerang thrown by "Totyarguil" (Altair). The Aranda people of Central Australia saw Corona Australis as a coolamon carrying a baby, which was accidentally dropped to earth by a group of sky-women dancing in the Milky Way. The impact of the coolamon created Gosses Bluff crater, 175 km west of Alice Springs. The Torres Strait Islanders saw Corona Australis as part of a larger constellation encompassing part of Sagittarius and the tip of Scorpius's tail; the Pleiades and Orion were also associated. This constellation was Tagai's canoe, crewed by the Pleiades, called the "Usiam", and Orion, called the "Seg". The myth of Tagai says that he was in charge of this canoe, but his crewmen consumed all of the supplies onboard without asking permission. Enraged, Tagai bound the Usiam with a rope and tied them to the side of the boat, then threw them overboard. Scorpius's tail represents a suckerfish, while Eta Sagittarii and Theta Coronae Australis mark the bottom of the canoe. On the island of Futuna, the figure of Corona Australis was called "Tanuma" and in the Tuamotus, it was called "Na Kaua-ki-Tonga".
"SIMBAD"

</doc>
<doc id="6426" url="https://en.wikipedia.org/wiki?curid=6426" title="Corcovado">
Corcovado

Corcovado (), which means "hunchback" in Portuguese, is a mountain in central Rio de Janeiro, Brazil. It is a 710-metre (2,329 ft) granite peak located in the Tijuca Forest, a national park.
Corcovado hill lies just west of the city center but is wholly within the city limits and visible from great distances. It is known worldwide for the 38-metre (125 ft) statue of Jesus atop its peak, entitled "Cristo Redentor" or "Christ the Redeemer".
The peak and statue can be accessed via a narrow road, by the 3.8 kilometre (2.4 mi) Corcovado Rack Railway, which was opened in 1884 and refurbished in 1980, or by the walking trail on the south side of the mountain that starts from Parque Lage. The railway uses three electrically powered trains, with a passenger capacity of 540 passengers per hour. The rail trip takes approximately 20 minutes and departs every 20 minutes. Due to its limited passenger capacity, the wait to board at the entry station can take several hours. The year-round schedule is 8:30 to 18:30.
From the train terminus and road, the observation deck at the foot of the statue is reached by 223 steps, or by elevators and escalators. Among the most popular year-round tourist attractions in Rio, the Corcovado railway, access roads, and statue platform are commonly crowded.
The most popular attraction of Corcovado mountain is the statue and viewing platform at its peak, drawing over 300,000 visitors per year. From the peak's platform the panoramic view includes downtown Rio, Sugarloaf Mountain, the Lagoa Rodrigo de Freitas (lake), Copacabana and Ipanema beaches, Estádio do Maracanã (Maracanã Stadium), and several of Rio's favelas. Cloud cover is common in Rio and the view from the platform is often obscured. Sunny days are recommended for optimal viewing.
Notable past visitors to the mountain peak include Pope Pius XII, Pope John Paul II, Alberto Santos-Dumont, Albert Einstein, Diana, Princess of Wales, and General Sherman, among others. An additional attraction of the mountain is rock climbing. The south face had 54 climbing routes in 1992. The easiest way starts from Park Lage.
The Corcovado is also a symbol of the Brazilian culture.
The peak of Corcovado is a big granite dome, which describes a generally vertical rocky formation. It is claimed to be the highest such formation in Brazil, the second highest being Pedra Agulha, situated near to the town of Pancas in Espírito Santo.

</doc>
<doc id="6427" url="https://en.wikipedia.org/wiki?curid=6427" title="Cheddar, Somerset">
Cheddar, Somerset

Cheddar is a large village and civil parish in the Sedgemoor district of the English county of Somerset. It is situated on the southern edge of the Mendip Hills, north-west of Wells. The civil parish includes the hamlets of Nyland and Bradley Cross. The parish had a population of 5,755 in 2011 and an acreage of as of 1961.
Cheddar Gorge, on the northern edge of the village, is the largest gorge in the United Kingdom and includes several show caves, including Gough's Cave. The gorge has been a centre of human settlement since Neolithic times including a Saxon palace. It has a temperate climate and provides a unique geological and biological environment that has been recognised by the designation of several Sites of Special Scientific Interest. It is also the site of several limestone quarries. The village gave its name to Cheddar cheese and has been a centre for strawberry growing. The crop was formerly transported on the Cheddar Valley rail line, which closed in the late 1960s but is now a cycle path. The village is now a major tourist destination with several cultural and community facilities, including the Cheddar Show Caves Museum.
The village supports a variety of community groups including religious, sporting and cultural organisations. Several of these are based on the site of The Kings of Wessex Academy, which is the largest educational establishment.
The name Cheddar comes from the Old English word "ceodor", meaning deep dark cavity or pouch.
There is evidence of occupation from the Neolithic period in Cheddar. Britain's oldest complete human skeleton, Cheddar Man, estimated to be 9,000 years old, was found in Cheddar Gorge in 1903. Older remains from the Upper Late Palaeolithic era (12,000–13,000 years ago) have been found. There is some evidence of a Bronze Age field system at the Batts Combe quarry site. There is also evidence of Bronze Age barrows at the mound in the Longwood valley, which if man-made it is likely to be a field system. The remains of a Roman villa have been excavated in the grounds of the current vicarage.
The village of Cheddar had been important during the Roman and Saxon eras. There was a royal palace at Cheddar during the Saxon period, which was used on three occasions in the 10th century to host the Witenagemot. The ruins of the palace were excavated in the 1960s. They are located on the grounds of The Kings of Wessex Academy, together with a 14th century chapel dedicated to St. Columbanus. Roman remains have also been uncovered at the site. Cheddar was listed in the Domesday Book of 1086 as "Ceder", meaning "Shear Water", from the Old English "scear" and Old Welsh "dŵr". An alternative spelling in earlier documents, common through the 1850s is "Chedder". As early as 1130 AD, the Cheddar Gorge was recognised as one of the "Four wonders of England". Historically, Cheddar's source of wealth was farming and cheese making for which it was famous as early as 1170 AD. The parish was part of the Winterstoke Hundred.
The manor of Cheddar was deforested in 1337 and Bishop Ralph was granted a licence by the King to create a hunting forest.
As early as 1527 there are records of watermills on the river. In the 17th and 18th centuries, there were several watermills which ground corn and made paper, with 13 mills on the Yeo at the peak, declining to seven by 1791 and just three by 1915.
In the Victorian era it also became a centre for the production of clothing. The last mill, used as a shirt factory, closed in the early 1950s. William Wilberforce saw the poor conditions of the locals when he visited Cheddar in 1789. He inspired Hannah More in her work to improve the conditions of the Mendip miners and agricultural workers. In 1801, of common land were enclosed under the Inclosure Acts.
Tourism of the Cheddar gorge and caves began with the opening of the Cheddar Valley Railway in 1869.
Cheddar, its surrounding villages and specifically the gorge has been subject to flooding. In the Chew Stoke flood of 1968 the flow of water washed large boulders down the gorge, washed away cars, and damaged the cafe and the entrance to Gough's Cave.
Cheddar is recognised as a village. The adjacent settlement of Axbridge, although only about a third the population of Cheddar, is a town. This apparently illogical situation is explained by the relative importance of the two places in historic times. While Axbridge grew in importance as a centre for cloth manufacturing in the Tudor period and gained a charter from King John, Cheddar remained a more dispersed mining and dairy-farming village. Its population grew with the arrival of the railways in the Victorian era and the advent of tourism.
The parish council, which has 15 members who are elected for four years, is responsible for local issues, including setting an annual precept (local rate) to cover the council's operating costs and producing annual accounts for public scrutiny. The parish council evaluates local planning applications and works with the police, district council officers, and neighbourhood watch groups on matters of crime, security, and traffic. The parish council's role also includes initiating projects for the maintenance and repair of parish facilities, as well as consulting with the district council on the maintenance, repair, and improvement of highways, drainage, footpaths, public transport, and street cleaning. Conservation matters (including trees and listed buildings) and environmental issues are also the responsibility of the council.
The village is in the 'Cheddar and Shipham' electoral ward. After including Shipham the total population of the ward taken at the 2011 census is 6,842.
The village falls within the non-metropolitan district of Sedgemoor, which was formed on 1 April 1974 under the Local Government Act 1972. It was previously part of Axbridge Rural District. Sedgemoor is responsible for local planning and building control, local roads, council housing, environmental health, markets and fairs, refuse collection and recycling, cemeteries and crematoria, leisure services, parks, and tourism. Somerset County Council is responsible for running the largest and most expensive local services such as education, social services, the library, roads, public transport, trading standards, waste disposal and strategic planning, although fire, police and ambulance services are provided jointly with other authorities through the Devon and Somerset Fire and Rescue Service, Avon and Somerset Constabulary and the South Western Ambulance Service.
It is also part of the Wells county constituency represented in the House of Commons of the Parliament of the United Kingdom. It elects one Member of Parliament (MP) by the first past the post system of election, and is part of the South West England constituency of the European Parliament which elects six MEPs using the d'Hondt method of party-list proportional representation.
Cheddar is twinned with Felsberg, Germany and Vernouillet, France, and it has an active programme of exchange visits. Initially, Cheddar twinned with Felsberg in 1984. In 2000, Cheddar twinned with Vernouillet, which had also been twinned with Felsberg. Cheddar also has a friendship link with Ocho Rios in Saint Ann Parish, Jamaica.
The area is underlain by Black Rock slate, Burrington Oolite and Clifton Down Limestone of the Carboniferous Limestone Series, which contain ooliths and fossil debris on top of Old Red Sandstone, and by Dolomitic Conglomerate of the Keuper. Evidence for Variscan orogeny is seen in the sheared rock and cleaved shales. In many places weathering of these strata has resulted in the formation of immature calcareous soils.
Cheddar Gorge, which is located on the edge of the village, is the largest gorge in the United Kingdom.
The gorge is the site of the Cheddar Caves, where Cheddar Man was found in 1903. Older remains from the Upper Late Palaeolithic era (12,000–13,000 years ago) have been found. The caves, produced by the activity of an underground river, contain stalactites and stalagmites. Gough's Cave, which was discovered in 1903, leads around into the rock-face, and contains a variety of large rock chambers and formations. Cox's Cave, discovered in 1837, is smaller but contains many intricate formations. A further cave houses a children's entertainment walk known as the "Crystal Quest".
Cheddar Gorge, including Cox's Cave, Gough's Cave and other attractions, has become a tourist destination, attracting about 500,000 visitors per year.
In a 2005 poll of "Radio Times" readers, following its appearance on the 2005 television programme "Seven Natural Wonders", Cheddar Gorge was named as the second greatest natural wonder in Britain, surpassed only by the Dan yr Ogof caves.
There are several large and unique Sites of Special Scientific Interest (SSSI) around the village.
Cheddar Reservoir is a near-circular artificial reservoir operated by Bristol Water. Dating from the 1930s, it has a capacity of 135 million gallons (614,000 cubic metres). The reservoir is supplied with water taken from the Cheddar Yeo, which rises in Gough's Cave in Cheddar Gorge and is a tributary of the River Axe. The inlet grate for the water pipe that is used to transport the water can be seen next to the sensory garden in Cheddar Gorge. It has been designated as a Site of Special Scientific Interest (SSSI) due to its wintering waterfowl populations.
Cheddar Wood and the smaller Macall's Wood form a biological Site of Special Scientific Interest from what remains of the wood of the Bishops of Bath and Wells in the 13th century and of King Edmund the Magnificent's wood in the 10th. During the 19th century, its lower fringes were grubbed out to make strawberry fields. Most of these have been allowed to revert to woodland. The wood was coppiced until 1917. This site compromises a wide range of habitats which include ancient and secondary semi-natural broadleaved woodland, unimproved neutral grassland, and a complex mosaic of calcareous grassland and acidic dry dwarf-shrub heath. Cheddar Wood is one of only a few English stations for starved wood-sedge ("Carex depauperata"). Purple gromwell ("Lithospermum purpurocaeruleum"), a nationally rare plant, also grows in the wood. Butterflies include silver-washed fritillary ("Argynnis paphia"), dark green fritillary ("Argynnis aglaja"), pearl-bordered fritillary ("Boloria euphrosyne"), holly blue ("Celastrina argiolus") and brown argus ("Aricia agestis"). The slug "Arion fasciatus", which has a restricted distribution in the south of England, and the soldier beetle "Cantharis fusca" also occur.
By far the largest of the SSSIs is called Cheddar Complex and covers of the gorge, caves and the surrounding area. It is important because of both biological and geological features. It includes four SSSIs, formerly known as Cheddar Gorge SSSI, August Hole/Longwood Swallet SSSI, GB Cavern Charterhouse SSSI and Charterhouse on-Mendip SSSI. It is partly owned by the National Trust who acquired it in 1910 and partly managed by the Somerset Wildlife Trust.
Close to the village and gorge are Batts Combe quarry and Callow Rock quarry, two of the active Quarries of the Mendip Hills where limestone is still extracted. Operating since the early 20th century, Batts Combe is owned and operated by Hanson Aggregates. The output in 2005 was around 4,000 tonnes of limestone per day, one third of which was supplied to an on-site lime kiln, which closed in 2009; the remainder was sold as coated or dusted aggregates. The limestone at this site is close to 99 percent carbonate of calcium and magnesium (dolomite).
The Chelmscombe Quarry finished its work as a limestone quarry in the 1950s and was then used by the Central Electricity Generating Board as a tower testing station. During the 1970s and 1980s it was also used to test the ability of containers of radioactive material to withstand impacts and other accidents.
Along with the rest of South West England, Cheddar has a temperate climate which is generally wetter and milder than the rest of the country. The annual mean temperature is approximately . Seasonal temperature variation is less extreme than most of the United Kingdom because of the adjacent sea, which moderates temperature. The summer months of July and August are the warmest with mean daily maxima of approximately . In winter mean minimum temperatures of or are common. In the summer the Azores high-pressure system affects the south-west of England. Convective cloud sometimes forms inland, reducing the number of hours of sunshine; annual sunshine rates are slightly less than the regional average of 1,600 hours. In December 1998 there were 20 days without sun recorded at Yeovilton. Most the rainfall in the south-west is caused by Atlantic depressions or by convection. Most of the rainfall in autumn and winter is caused by the Atlantic depressions, which are most active during those seasons. In summer, a large proportion of the rainfall is caused by sun heating the ground leading to convection and to showers and thunderstorms. Average rainfall is around . About 8–15 days of snowfall per year is typical. November to March have the highest mean wind speeds, and June to August have the lightest winds. The predominant wind direction is from the south-west.
The parish has a population in 2011 of 5,093, with a mean age of 43 years. Residents lived in 2,209 households. The vast majority of households (2,183) gave their ethnic status at the 2001 census as white.
The village gave its name to Cheddar cheese, which is the most popular type of cheese in the United Kingdom. The cheese is now made and consumed worldwide, and only one producer remains in the village.
Since the 1880s, Cheddar's other main produce has been the strawberry,
which is grown on the south-facing lower slopes of the Mendip hills. As a consequence of its use for transporting strawberries to market, the since-closed Cheddar Valley line became known as "The Strawberry Line" after it opened in 1869.
The line ran from Yatton to Wells. When the rest of the line was closed and all passenger services ceased, the section of the line between Cheddar and Yatton remained open for goods traffic. It provided a fast link with the main markets for the strawberries in Birmingham and London, but finally closed in 1964, becoming part of the Cheddar Valley Railway Nature Reserve.
Cheddar Ales is a small brewery based in the village, producing beer for local public houses. Tourism is a significant source of employment. Around 15 percent of employment in Sedgemoor is provided by tourism, but within Cheddar it is estimated to employ as many as 1,000 people.
The village also has a youth hostel, and a number of camping and caravan sites.
Cheddar has a number of active service clubs including Cheddar Vale Lions Club, Mendip Rotary and Mendip Inner Wheel Club. The clubs raise money for projects in the local community and hold annual events such as a fireworks display, duck races in the Gorge, a dragon boat race on the reservoir and concerts on the grounds of the nearby St Michael's Cheshire Home.
Several notable people have been born or lived in Cheddar. Musician Jack Bessant, the bass guitarist with the band Reef grew up on his parents' strawberry farm, and Matt Goss and Luke Goss, former members of Bros, lived in Cheddar for nine months as children. Trina Gulliver, eight-time World Professional Darts Champion, currently lives in Cheddar. Forex trader Dan Legg was born in Cheddar. The comedian Richard Herring grew up in Cheddar. His 2008 Edinburgh Festival Fringe show, "The Headmaster's Son" is based on his time at The Kings of Wessex School, where his father Keith was the headmaster. The final performance of this show was held at the school in November 2009. He also visited the school in March 2010 to perform his show "Hitler Moustache". In May 2013, a community radio station called Pulse was launched.
The market cross in Bath Street dates from the 15th century, with the shelter having been rebuilt in 1834. It has a central octagonal pier, a socket raised on four steps, a hexagonal shelter with six arched four-centred openings, shallow two-stage buttresses at each angle, and an embattled parapet. The shaft is crowned by an abacus with figures in niches, probably from the late 19th century, although the cross is now missing. It was rebuilt by Thomas, Marquess of Bath. It is a Scheduled Ancient Monument (Somerset County No 21) and Grade II* listed building.
In January 2000, the cross was seriously damaged in a traffic accident. By 2002, the cross had been rebuilt and the area around it was redesigned to protect and enhance its appearance.
The cross was badly damaged again in March 2012, when a taxi crashed into it late at night demolishing two sides.
Repair work, which included the addition of wooden-clad steel posts to protect against future crashes, was completed in November 2012 at a cost of £60,000.
Hannah More, a philanthropist and educator, founded a school in the village in the late 18th century for the children of miners. Her first school was located in a 17th-century house. Now named "Hannah More's Cottage", the Grade II-listed building is used by the local community as a meeting place.
The village is situated on the A371 road which runs from Wincanton, to Weston-super-Mare. It is approximately from the route of the M5 motorway with around a drive to junction 21 or 22.
It was on the Cheddar Valley line, a railway line that was opened in 1869 and closed in 1963. It became known as The Strawberry Line because of the large volume of locally-grown strawberries that it carried. It ran from Yatton railway station through to Wells (Tucker Street) railway station and joined the East Somerset Railway to make a through route via Shepton Mallet (High Street) railway station to Witham. Sections of the now-disused railway have been opened as the Strawberry Line Trail, which currently runs from Yatton to Cheddar. The Cheddar Valley line survived until the "Beeching Axe". Towards the end of its life there were so few passengers that diesel railcars were sometimes used. The Cheddar branch closed to passengers on 9 September 1963 and to goods in 1964. The line closed in the 1960s, when it became part of the Cheddar Valley Railway Nature Reserve, and part of the National Cycle Network route 26. The cycle route also intersects with the West Mendip Way and various other footpaths.
The first school in Cheddar was set up by Hannah More during the 18th Century, however now Cheddar has three schools belonging to the Cheddar Valley Group of Schools, twelve schools that provide Cheddar Valley's three-tier education system. Cheddar First School has ten classes for children between 4 and 9 years. Fairlands Middle School, a middle school categorised as a middle-deemed-secondary school, has 510 pupils between 9 and 13. Fairlands takes children moving up from Cheddar First School as well as other first schools in the Cheddar Valley. The Kings of Wessex Academy, a coeducational comprehensive school, has been rated as "good" by Ofsted. It has 1,176 students aged 13 to 18, including 333 in the sixth form. Kings is a faith school linked to the Church of England. It was awarded the specialist status of Technology College in 2001, enabling it to develop its Information Technology (IT) facilities and improve courses in science, mathematics and design technology. In 2007 it became a foundation school, giving it more control over its own finances. The academy owns and runs a sports centre and swimming pool, Kings Fitness & Leisure, with facilities that are used by students as well as residents. It has since November 2016 been a part of the Wessex Learning Trust which incorporates eight academies from the surrounding area.
The Church of St Andrew dates from the 14th century. It was restored in 1873 by William Butterfield. It is a Grade I listed building and contains some 15th-century stained glass and an altar table of 1631. The chest tomb in the chancel is believed to contain the remains of Sir Thomas Cheddar and is dated 1442. The tower, which rises to , contains a bell dating from 1759 made by Thomas Bilbie of the Bilbie family.
There are also churches for Roman Catholic, Methodist and other denominations, including Cheddar Valley Community Church, who not only meet at The Kings of Wessex School on Sunday, but also have their own site on Tweentown for meeting during the week. The Baptist chapel was built in 1831.
Kings Fitness & Leisure, situated on the grounds of The Kings of Wessex School, provides a venue for various sports and includes a 20-metre swimming pool, racket sport courts, a sports hall, dance studios and a gym. A youth sports festival was held on Sharpham Road Playing Fields in 2009. In 2010 a skatepark was built in the village, funded by the Cheddar Local Action Team.
Cheddar Football Club, founded in 1892 and nicknamed "The Cheesemen", play in the Western Football League Division One. In 2009 plans were revealed to move the club from its present home at Bowdens Park on Draycott Road to a new larger site.
Cheddar Cricket Club was formed in the late 19th century and moved to Sharpham Road Playing Fields in 1964. They now play in the West of England Premier League Somerset Division. Cheddar Rugby Club, who own part of the Sharpham playing fields, was formed in 1836. The club organises an annual Cheddar Rugby Tournament. Cheddar Lawn Tennis Club, was formed in 1924, and play in the North Somerset League and also has social tennis and coaching. Cheddar Running Club organised an annual half marathon until 2009.
The village is both on the route of the West Mendip Way and Samaritans Way South West.

</doc>
<doc id="6429" url="https://en.wikipedia.org/wiki?curid=6429" title="Compact disc">
Compact disc

Compact disc (CD) is a digital optical disc data storage format that was co-developed by Philips and Sony and released in 1982. The format was originally developed to store and play only digital audio recordings (CD-DA) but was later adapted for storage of data (CD-ROM). Several other formats were further derived from these, including write-once audio and data storage (CD-R), rewritable media (CD-RW), Video CD (VCD), Super Video CD (SVCD), Photo CD, PictureCD, Compact Disc-Interactive (CD-i), and Enhanced Music CD. The first commercially available audio CD player, the Sony CDP-101, was released October 1982 in Japan.
Standard CDs have a diameter of and are designed to hold up to 74 minutes of uncompressed stereo digital audio or about 650 MiB of data. Capacity is routinely extended to 80 minutes and 700 MiB by arranging more data closely on the same sized disc. The Mini CD has various diameters ranging from ; they are sometimes used for CD singles, storing up to 24 minutes of audio, or delivering device drivers.
At the time of the technology's introduction in 1982, a CD could store much more data than a personal computer hard drive, which would typically hold 10 MB. By 2010, hard drives commonly offered as much storage space as a thousand CDs, while their prices had plummeted to commodity level. In 2004, worldwide sales of audio CDs, CD-ROMs, and CD-Rs reached about 30 billion discs. By 2007, 200 billion CDs had been sold worldwide.
From the early 2000s, CDs were increasingly being replaced by other forms of digital storage and distribution, with the result that by 2010 the number of audio CDs being sold in the U.S. had dropped about 50% from their peak; however, they remained one of the primary distribution methods for the music industry. In 2014, revenues from digital music services, such as iTunes, Spotify and YouTube, matched those from physical format sales for the first time. According to the RIAA's midyear report in 2020, vinyl record revenues surpassed those of CDs for the first time since the 1980s.
Optophonie, first presented in 1931, is a very early example of a recording device using light for both recording and playing back sound signals on a transparent photograph. More than thirty years later, American inventor James T. Russell has been credited with inventing the first system to record digital video on an optical transparent foil that is lit from behind by a high-power halogen lamp, not a laser. Russell's patent application was filed in 1966, and he was granted a patent in 1970. Following litigation, Sony and Philips licensed Russell's patents for recording, not the play-back part (then held by a Canadian company, Optical Recording Corp.) in the 1980s. It is debatable whether Russell's concepts, patents, and prototypes instigated and in some measure influenced compact disc's design.
The compact disc is an evolution of LaserDisc technology, where a focused laser beam is used that enables the high information density required for high-quality digital audio signals. Unlike the prior art by Optophonie and James Russell, the information on the disc is read from a reflective layer using a laser as a light source through a protective substrate. Prototypes were developed by Philips and Sony independently in the late 1970s. Although originally dismissed by Philips Research management as a trivial pursuit, the CD became the primary focus for Philips as the LaserDisc format struggled. In 1979, Sony and Philips set up a joint task force of engineers to design a new digital audio disc. After a year of experimentation and discussion, the "Red Book" CD-DA standard was published in 1980. After their commercial release in 1982, compact discs and their players were extremely popular. Despite costing up to $1,000, over 400,000 CD players were sold in the United States between 1983 and 1984. By 1988, CD sales in the United States surpassed those of vinyl LPs, and by 1992 CD sales surpassed those of prerecorded music cassette tapes. The success of the compact disc has been credited to the cooperation between Philips and Sony, which together agreed upon and developed compatible hardware. The unified design of the compact disc allowed consumers to purchase any disc or player from any company, and allowed the CD to dominate the at-home music market unchallenged.
In 1974, Lou Ottens, director of the audio division of Philips, started a small group to develop an analog optical audio disc with a diameter of and a sound quality superior to that of the vinyl record. However, due to the unsatisfactory performance of the analog format, two Philips research engineers recommended a digital format in March 1974. In 1977, Philips then established a laboratory with the mission of creating a digital audio disc. The diameter of Philips's prototype compact disc was set at , the diagonal of an audio cassette.
Heitaro Nakajima, who developed an early digital audio recorder within Japan's national public broadcasting organization NHK in 1970, became general manager of Sony's audio department in 1971. His team developed a digital PCM adaptor audio tape recorder using a Betamax video recorder in 1973. After this, in 1974 the leap to storing digital audio on an optical disc was easily made. Sony first publicly demonstrated an optical digital audio disc in September 1976. A year later, in September 1977, Sony showed the press a disc that could play an hour of digital audio (44,100 Hz sampling rate and 16-bit resolution) using MFM modulation. In September 1978, the company demonstrated an optical digital audio disc with a 150-minute playing time, 44,056 Hz sampling rate, 16-bit linear resolution, and cross-interleaved error correction code—specifications similar to those later settled upon for the standard compact disc format in 1980. Technical details of Sony's digital audio disc were presented during the 62nd AES Convention, held on 13–16 March 1979, in Brussels. Sony's AES technical paper was published on 1 March 1979. A week later, on 8 March, Philips publicly demonstrated a prototype of an optical digital audio disc at a press conference called "Philips Introduce Compact Disc" in Eindhoven, Netherlands. Sony executive Norio Ohga, later CEO and chairman of Sony, and Heitaro Nakajima were convinced of the format's commercial potential and pushed further development despite widespread skepticism.
In 1979, Sony and Philips set up a joint task force of engineers to design a new digital audio disc. Led by engineers Kees Schouhamer Immink and Toshitada Doi, the research pushed forward laser and optical disc technology. After a year of experimentation and discussion, the task force produced the "Red Book" CD-DA standard. First published in 1980, the standard was formally adopted by the IEC as an international standard in 1987, with various amendments becoming part of the standard in 1996.
Philips coined the term "compact disc" in line with another audio product, the Compact Cassette, and contributed the general manufacturing process, based on video LaserDisc technology. Philips also contributed eight-to-fourteen modulation (EFM), while Sony contributed the error-correction method, CIRC, which offers a certain resilience to defects such as scratches and fingerprints.
The "Compact Disc Story", told by a former member of the task force, gives background information on the many technical decisions made, including the choice of the sampling frequency, playing time, and disc diameter. The task force consisted of around 6 persons, though according to Philips, the compact disc was "invented collectively by a large group of people working as a team."
Philips established the Polydor Pressing Operations plant in Langenhagen near Hannover, Germany, and quickly passed a series of milestones.
The Japanese launch was followed in March 1983 by the introduction of CD players and discs to Europe and North America (where CBS Records released sixteen titles). This 1983 event is often seen as the "Big Bang" of the digital audio revolution. The new audio disc was enthusiastically received, especially in the early-adopting classical music and audiophile communities, and its handling quality received particular praise. As the price of players gradually came down, and with the introduction of the portable Discman the CD began to gain popularity in the larger popular and rock music markets. With the rise in CD sales, pre-recorded cassette tape sales began to decline in the late 1980s; CD sales overtook cassette sales in the early 1990s.
The first artist to sell a million copies on CD was Dire Straits, with their 1985 album "Brothers in Arms". One of the first CD markets was devoted to reissuing popular music whose commercial potential was already proven. The first major artist to have their entire catalog converted to CD was David Bowie, whose first fourteen studio albums of (then) sixteen were made available by RCA Records in February 1985, along with four greatest hits albums; his fifteenth and sixteenth albums had already been issued on CD by EMI Records in 1983 and 1984, respectively. On February 26, 1987, the first four UK albums by the Beatles were released in mono on compact disc. In 1988, 400 million CDs were manufactured by 50 pressing plants around the world.
The CD was primarily planned as the successor to the vinyl record for playing music, rather than as a data storage medium. However, CDs have grown to encompass other applications. In 1983, following the CD's introduction, Immink and Joseph Braat presented the first experiments with erasable compact discs during the 73rd AES Convention. It took, however, almost 10 years before their technology was commercialized in Sony's MiniDisc. In June 1985, the computer-readable CD-ROM (read-only memory) and, in 1990, CD-Recordable were introduced, also developed by both Sony and Philips. Recordable CDs were a new alternative to tape for recording and copying music without the defects introduced in compression used in other digital recording methods. Other newer video formats such as DVD and Blu-ray use the same physical geometry as CD, and most DVD and Blu-ray players are backward compatible with audio CD.
CD sales in the United States peaked by 2000. By the early 2000s, the CD player had largely replaced the audio cassette player as standard equipment in new automobiles, with 2010 being the final model year for any car in the United States to have a factory-equipped cassette player. With the increasing popularity of portable digital audio players, such as mobile phones, and solid state music storage, CD players are being phased out of automobiles in favor of minijack auxiliary inputs, wired connection to USB devices and wireless Bluetooth connection.
Meanwhile, with the advent and popularity of Internet-based distribution of files in lossily-compressed audio formats such as MP3, sales of CDs began to decline in the 2000s. For example, between 2000 and 2008, despite overall growth in music sales and one anomalous year of increase, major-label CD sales declined overall by 20%, although independent and DIY music sales may be tracking better according to figures released March 30, 2009, and CDs still continue to sell greatly. As of 2012, CDs and DVDs made up only 34% of music sales in the United States. , only 24% of music in the United States was purchased on physical media, 2/3 of this consisting of CDs; however, in the same year in Japan, over 80% of music was bought on CDs and other physical formats. In 2018, U.S. CD sales were 52 million units—less than 6% of the peak sales volume in 2000.
Despite the rapidly declining sales year-over-year, the pervasiveness of the technology remained for a time, with companies placing CDs in pharmacies, supermarkets, and filling station convenience stores targeting buyers least able to use Internet-based distribution. In 2018 Best Buy announced plans to decrease their focus on CD sales, however, while continuing to sell records, sales of which are growing during the vinyl revival.
Sony and Philips received praise for the development of the compact disc from professional organizations. These awards include
A CD is made from thick, polycarbonate plastic and weighs 14–33 grams. From the center outward, components are: the center spindle hole (15 mm), the first-transition area (clamping ring), the clamping area (stacking ring), the second-transition area (mirror band), the program (data) area, and the rim. The inner program area occupies a radius from 25 to 58 mm.
A thin layer of aluminum or, more rarely, gold is applied to the surface, making it reflective. The metal is protected by a film of lacquer normally spin coated directly on the reflective layer. The label is printed on the lacquer layer, usually by screen printing or offset printing.
CD data is represented as tiny indentations known as "pits", encoded in a spiral track moulded into the top of the polycarbonate layer. The areas between pits are known as "lands". Each pit is approximately 100 nm deep by 500 nm wide, and varies from 850 nm to 3.5 µm in length. The distance between the tracks (the "pitch") is 1.6 µm.
When playing an audio CD, a motor within the CD player spins the disc to a scanning velocity of 1.2–1.4 m/s (constant linear velocity, CLV)—equivalent to approximately 500  RPM at the inside of the disc, and approximately 200  RPM at the outside edge. The track on the CD begins at the inside and spirals outward so a disc played from beginning to end slows its rotation rate during playback.
The program area is 86.05 cm and the length of the recordable spiral is With a scanning speed of 1.2 m/s, the playing time is 74 minutes, or 650 MiB of data on a CD-ROM. A disc with data packed slightly more densely is tolerated by most players (though some old ones fail). Using a linear velocity of 1.2 m/s and a narrower track pitch of 1.5 µm increases the playing time to 80 minutes, and data capacity to 700 MiB.
A CD is read by focusing a 780 nm wavelength (near infrared) semiconductor laser through the bottom of the polycarbonate layer. The change in height between pits and lands results in a difference in the way the light is reflected. Because the pits are indented into the top layer of the disc and are read through the transparent polycarbonate base, the pits form bumps when read. The laser hits the disc, casting a circle of light wider than the modulated spiral track reflecting partially from the lands and partially from the top of any bumps where they are present. As the laser passes over a pit (bump), its height means that the part of the light reflected from its peak is 1/2 wavelength out of phase with the light reflected from the land around it. This causes partial cancellation of the laser's reflection from the surface. By measuring the reflected intensity change with a photodiode, a modulated signal is read back from the disc.
To accommodate the spiral pattern of data, the laser is placed on a mobile mechanism within the disc tray of any CD player. This mechanism typically takes the form of a sled that moves along a rail. The sled can be driven by a worm gear or linear motor. Where a worm gear is used, a second shorter-throw linear motor, in the form of a coil and magnet, makes fine position adjustments to track eccentricities in the disk at high speed. Some CD drives (particularly those manufactured by Philips during the 1980s and early 1990s) use a swing arm similar to that seen on a gramophone. This mechanism allows the laser to read information from the center to the edge of a disc without having to interrupt the spinning of the disc itself.
The pits and lands do "not" directly represent the 0's and 1's of binary data. Instead, non-return-to-zero, inverted encoding is used: a change from either pit to land or land to pit indicates a 1, while no change indicates a series of 0's. There must be at least 2, and no more than 10 0's between each 1, which is defined by the length of the pit. This, in turn, is decoded by reversing the eight-to-fourteen modulation used in mastering the disc, and then reversing the cross-interleaved Reed–Solomon coding, finally revealing the raw data stored on the disc. These encoding techniques (defined in the "Red Book") were originally designed for CD Digital Audio, but they later became a standard for almost all CD formats (such as CD-ROM).
CDs are susceptible to damage during handling and from environmental exposure. Pits are much closer to the label side of a disc, enabling defects and contaminants on the clear side to be out of focus during playback. Consequently, CDs are more likely to suffer damage on the label side of the disc. Scratches on the clear side can be repaired by refilling them with similar refractive plastic or by careful polishing. The edges of CDs are sometimes incompletely sealed, allowing gases and liquids to enter the CD and corrode the metal reflective layer and/or interfere with the focus of the laser on the pits, a condition known as disc rot. The fungus "Geotrichum candidum" has been found—under conditions of high heat and humidity—to consume the polycarbonate plastic and aluminium found in CDs.
The data integrity of compact discs can be measured using surface error scanning, which is able to measure the rates of different types of data errors, known as "C1", "C2", "CU" and extended (finer-grain) error measurements known as "E11", "E12", "E21", "E22", "E31" and "E32", of which higher rates indicate a possibly damaged or unclean data surface, low media quality, deteriorating media and recordable media written to by a malfunctioning CD writer.
Error scanning can reliably predict data losses caused by media deteriorating. Support of error scanning varies among vendors and models of optical disc drives, and "extended" error scanning (known as "advanced error scanning" in Nero DiscSpeed) has only been available on Plextor and some BenQ optical drives so far, as of 2020.
The digital data on a CD begins at the center of the disc and proceeds toward the edge, which allows adaptation to the different size formats available. Standard CDs are available in two sizes. By far, the most common is in diameter, with a 74- or 80-minute audio capacity and a 650 or 700 MiB (737,280,000-byte) data capacity. Discs are 1.2 mm thick, with a 15 mm center hole. The official Philips history says this capacity was specified by Sony executive Norio Ohga to be able to contain the entirety of Beethoven's Ninth Symphony on one disc. This is a myth according to Kees Immink, as the EFM code format had not yet been decided in December 1979, when the decision to adopt the 120 mm was made. The adoption of EFM in June 1980 allowed 30 percent more playing time that would have resulted in 97 minutes for 120  mm diameter or 74 minutes for a disc as small as 100  mm. Instead, however, the information density was lowered by 30 percent to keep the playing time at 74 minutes. The 120  mm diameter has been adopted by subsequent formats, including Super Audio CD, DVD, HD DVD, and Blu-ray Disc. The 80-mm-diameter discs ("Mini CDs") can hold up to 24 minutes of music or 210 MiB.
The logical format of an audio CD (officially Compact Disc Digital Audio or CD-DA) is described in a document produced in 1980 by the format's joint creators, Sony and Philips. The document is known colloquially as the "Red Book" CD-DA after the color of its cover. The format is a two-channel 16-bit PCM encoding at a 44.1 kHz sampling rate per channel. Four-channel sound was to be an allowable option within the "Red Book" format, but has never been implemented. Monaural audio has no existing standard on a "Red Book" CD; thus, the mono source material is usually presented as two identical channels in a standard "Red Book" stereo track (i.e., mirrored mono); an MP3 CD, however, can have audio file formats with mono sound.
CD-Text is an extension of the "Red Book" specification for an audio CD that allows for the storage of additional text information (e.g., album name, song name, artist) on a standards-compliant audio CD. The information is stored either in the lead-in area of the CD, where there is roughly five kilobytes of space available or in the subcode channels R to W on the disc, which can store about 31 megabytes.
Compact Disc + Graphics is a special audio compact disc that contains graphics data in addition to the audio data on the disc. The disc can be played on a regular audio CD player, but when played on a special CD+G player, it can output a graphics signal (typically, the CD+G player is hooked up to a television set or a computer monitor); these graphics are almost exclusively used to display lyrics on a television set for karaoke performers to sing along with. The CD+G format takes advantage of the channels R through W. These six bits store the graphics information.
CD + Extended Graphics (CD+EG, also known as CD+XG) is an improved variant of the Compact Disc + Graphics (CD+G) format. Like CD+G, CD+EG uses basic CD-ROM features to display text and video information in addition to the music being played. This extra data is stored in subcode channels R-W. Very few, if any, CD+EG discs have been published.
Super Audio CD (SACD) is a high-resolution read-only optical audio disc format that was designed to provide higher-fidelity digital audio reproduction than the "Red Book". Introduced in 1999, it was developed by Sony and Philips, the same companies that created the "Red Book". SACD was in a format war with DVD-Audio, but neither has replaced audio CDs. The SACD standard is referred to as the "Scarlet Book" standard.
Titles in the SACD format can be issued as hybrid discs; these discs contain the SACD audio stream as well as a standard audio CD layer which is playable in standard CD players, thus making them backward compatible.
CD-MIDI is a format used to store music-performance data, which upon playback is performed by electronic instruments that synthesize the audio. Hence, unlike the original "Red Book" CD-DA, these recordings are not digitally sampled audio recordings. The CD-MIDI format is defined as an extension of the original "Red Book".
For the first few years of its existence, the CD was a medium used purely for audio. However, in 1988, the "Yellow Book" CD-ROM standard was established by Sony and Philips, which defined a non-volatile optical data computer data storage medium using the same physical format as audio compact discs, readable by a computer with a CD-ROM drive.
Video CD (VCD, View CD, and Compact Disc digital video) is a standard digital format for storing video media on a CD. VCDs are playable in dedicated VCD players, most modern DVD-Video players, personal computers, and some video game consoles.
The VCD standard was created in 1993 by Sony, Philips, Matsushita, and JVC and is referred to as the "White Book" standard.
Overall picture quality is intended to be comparable to VHS video. Poorly compressed VCD video can sometimes be lower quality than VHS video, but VCD exhibits block artifacts rather than analog noise and does not deteriorate further with each use.
352×240 (or SIF) resolution was chosen because it is half the vertical and half the horizontal resolution of the NTSC video. 352×288 is similarly one-quarter PAL/SECAM resolution. This approximates the (overall) resolution of an analog VHS tape, which, although it has double the number of (vertical) scan lines, has a much lower horizontal resolution.
Super Video CD (Super Video Compact Disc or SVCD) is a format used for storing video media on standard compact discs. SVCD was intended as a successor to VCD and an alternative to DVD-Video and falls somewhere between both in terms of technical capability and picture quality.
SVCD has two thirds the resolution of DVD, and over 2.7 times the resolution of VCD. One CD-R disc can hold up to 60 minutes of standard-quality SVCD-format video. While no specific limit on SVCD video length is mandated by the specification, one must lower the video bit rate, and therefore quality, to accommodate very long videos. It is usually difficult to fit much more than 100 minutes of video onto one SVCD without incurring significant quality loss, and many hardware players are unable to play video with an instantaneous bit rate lower than 300 to 600 kilobits per second.
Photo CD is a system designed by Kodak for digitizing and storing photos on a CD. Launched in 1992, the discs were designed to hold nearly 100 high-quality images, scanned prints and slides using special proprietary encoding. Photo CDs are defined in the "Beige Book" and conform to the CD-ROM XA and CD-i Bridge specifications as well. They are intended to play on CD-i players, Photo CD players, and any computer with suitable software (irrespective of operating system). The images can also be printed out on photographic paper with a special Kodak machine. This format is not to be confused with Kodak Picture CD, which is a consumer product in CD-ROM format.
The Philips "Green Book" specifies a standard for interactive multimedia compact discs designed for CD-i players (1993). CD-i discs can contain audio tracks that can be played on regular CD players, but CD-i discs are not compatible with most CD-ROM drives and software. The CD-i Ready specification was later created to improve compatibility with audio CD players, and the CD-i Bridge specification was added to create CD-i compatible discs that can be accessed by regular CD-ROM drives.
Philips defined a format similar to CD-i called CD-i Ready, which puts CD-i software and data into the pregap of track 1. This format was supposed to be more compatible with older audio CD players.
Enhanced Music CD, also known as CD Extra or CD Plus, is a format which combines audio tracks and data tracks on the same disc by putting audio tracks in a first session and data in a second session. It was developed by Philips and Sony, and it is defined in the "Blue Book".
VinylDisc is the hybrid of a standard audio CD and the vinyl record. The vinyl layer on the disc's label side can hold approximately three minutes of music.
In 1995, material costs were 30 cents for the jewel case and 10 to 15 cents for the CD. Wholesale cost of CDs was $0.75 to $1.15, while the typical retail price of a prerecorded music CD was $16.98. On average, the store received 35 percent of the retail price, the record company 27 percent, the artist 16 percent, the manufacturer 13 percent, and the distributor 9 percent. When 8-track tapes, cassette tapes, and CDs were introduced, each was marketed at a higher price than the format they succeeded, even though the cost to produce the media was reduced. This was done because the apparent value increased. This continued from vinyl to CDs but was broken when Apple marketed MP3s for $0.99, and albums for $9.99. The incremental cost, though, to produce an MP3 is negligible.
Recordable Compact Discs, CD-Rs, are injection-molded with a "blank" data spiral. A photosensitive dye is then applied, after which the discs are metalized and lacquer-coated. The write laser of the CD recorder changes the color of the dye to allow the read laser of a standard CD player to see the data, just as it would with a standard stamped disc. The resulting discs can be read by most CD-ROM drives and played in most audio CD players. CD-Rs follow the "Orange Book" standard.
CD-R recordings are designed to be permanent. Over time, the dye's physical characteristics may change causing read errors and data loss until the reading device cannot recover with error correction methods. Errors can be predicted using surface error scanning. The design life is from 20 to 100 years, depending on the quality of the discs, the quality of the writing drive, and storage conditions. However, testing has demonstrated such degradation of some discs in as little as 18 months under normal storage conditions. This failure is known as disc rot, for which there are several, mostly environmental, reasons.
The recordable audio CD is designed to be used in a consumer audio CD recorder. These consumer audio CD recorders use SCMS (Serial Copy Management System), an early form of digital rights management (DRM), to conform to the AHRA (Audio Home Recording Act). The Recordable Audio CD is typically somewhat more expensive than CD-R due to lower production volume and a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.
High-capacity recordable CD is a higher-density recording format that can hold 20% more data than of conventional discs. The higher capacity is incompatible with some recorders and recording software.
CD-RW is a re-recordable medium that uses a metallic alloy instead of a dye. The write laser, in this case, is used to heat and alter the properties (amorphous vs. crystalline) of the alloy, and hence change its reflectivity. A CD-RW does not have as great a difference in reflectivity as a pressed CD or a CD-R, and so many earlier CD audio players "cannot" read CD-RW discs, although "most" later CD audio players and stand-alone DVD players can. CD-RWs follow the "Orange Book" standard.
The ReWritable Audio CD is designed to be used in a consumer audio CD recorder, which will not (without modification) accept standard CD-RW discs. These consumer audio CD recorders use the Serial Copy Management System (SCMS), an early form of digital rights management (DRM), to conform to the United States' Audio Home Recording Act (AHRA). The ReWritable Audio CD is typically somewhat more expensive than CD-R due to (a) lower volume and (b) a 3 percent AHRA royalty used to compensate the music industry for the making of a copy.
The "Red Book" audio specification, except for a simple "anti-copy" statement in the subcode, does not include any copy protection mechanism. Known at least as early as 2001, attempts were made by record companies to market "copy-protected" non-standard compact discs, which cannot be ripped, or copied, to hard drives or easily converted to other formats (like FLAC, MP3 or Vorbis). One major drawback to these copy-protected discs is that most will not play on either computer CD-ROM drives or some standalone CD players that use CD-ROM mechanisms. Philips has stated that such discs are not permitted to bear the trademarked "Compact Disc Digital Audio" logo because they violate the "Red Book" specifications. Numerous copy-protection systems have been countered by readily available, often free, software, or even by simply turning off automatic AutoPlay to prevent the running of the DRM executable program.
After the fall in popularity of CDs, old discs or failed CD-R have been repurposed, since the reflections of the sun on a moving plate may scare birds.

</doc>
<doc id="6431" url="https://en.wikipedia.org/wiki?curid=6431" title="Charles Farrar Browne">
Charles Farrar Browne

Charles Farrar Browne (April 26, 1834 – March 6, 1867) was an American humor writer, better known under his "nom de plume", Artemus Ward. He is considered to be America's first stand-up comedian. His birth name was Brown but he added the "e" after he became famous.
Browne was born in Waterford, Maine. He began his career as a compositor and occasional contributor to the daily and weekly journals. In 1858, he published in "The Plain Dealer" (Cleveland, Ohio) the first of the "Artemus Ward" series, which, in a collected form, achieved great popularity in both America and England. Brownes' companion at the Plain Dealer George Hoyt wrote "his desk was a rickety table which had been whittled and gashed until it looked as if it had been the victim of lightning. His chair was a fit companion thereto, a wabbling, unsteady affair, sometimes with four and sometimes with three legs. But Browne saw neither the table, nor the chair, nor any person who might be near, nothing, in fact, but the funny pictures which were tumbling out of his brain. When writing, his gaunt form looked ridiculous enough. One leg hung over the arm of his chair like a great hook, while he would write away, sometimes laughing to himself, and then slapping the table in the excess of his mirth."
In 1860, he became editor of "Vanity Fair", a humorous New York weekly, which proved a failure. About the same time, he began to appear as a lecturer and, by his droll and eccentric humor, attracted large audiences.
In 1863, Browne came as Artemus Ward to San Francisco to perform. Browne was an expert at publicity and by the time of his arrival, his manager had already been there for weeks advertising with notices in the local papers and talking with prominent citizens for endorsements. On November 13, 1863, he performed to a packed crowd at Platt's Music Hall. Ward played the part of Artemus as an illiterate rube but with "Yankee common sense." Writer Brett Harte was in the audience that night and he described it in "the Golden Era" as capturing American speech, "humor that belongs to the country of boundless prairies, limitless rivers, and stupendous cataracts--that fun which overlies the surface of our national life, which is met in the stage, rail-car, canal and flat-boat, which bursts out over camp-fires and around bar-room stoves.
"Artemus Ward" was the favorite author of U.S. President Abraham Lincoln. Before presenting "The Emancipation Proclamation" to his Cabinet, Lincoln read to them the latest episode, "Outrage in Utiky", also known as "High-Handed Outrage at Utica".
Browne was also known as a member of the New York Bohemian set which included leader Henry Clapp Jr., Walt Whitman, Fitz Hugh Ludlow, and actress Adah Isaacs Menken.
Ward met Mark Twain when Ward performed in Virginia City, Nevada and the two became friends. In his correspondences with Twain, Browne called him "My Dearest Love." Legend has it that, following Ward's stage performance, he, Mark Twain, and Dan De Quille were taking a drunken rooftop tour of Virginia City until a town constable threatened to blast all three of them with a shotgun loaded with rock salt. Browne recommended Twain to the editors of the New York Press and urged him to journey to New York.
In 1866, Ward visited England, where he became exceedingly popular both as a lecturer and as a contributor to "Punch". In the spring of the following year, Ward's health gave way and he died of tuberculosis at Southampton on March 6, 1867.
After initially being buried at Kensal Green Cemetery, Ward's remains were removed to the United States on May 20, 1868. He is buried at Elm Vale Cemetery in Waterford, Maine.

</doc>
<doc id="6432" url="https://en.wikipedia.org/wiki?curid=6432" title="Caelum">
Caelum

Caelum is a faint constellation in the southern sky, introduced in the 1750s by Nicolas Louis de Lacaille and counted among the 88 modern constellations. Its name means “"chisel"” in Latin, and it was formerly known as Caelum Sculptorium (“"the engravers’ chisel"”); It is a rare word, unrelated to the far more common Latin "caelum", meaning “sky, heaven, atmosphere”. It is the eighth-smallest constellation, and subtends a solid angle of around 0.038 steradians, just less than that of Corona Australis.
Due to its small size and location away from the plane of the Milky Way, Caelum is a rather barren constellation, with few objects of interest. The constellation's brightest star, Alpha Caeli, is only of magnitude 4.45, and only one other star, (Gamma) γ Caeli, is brighter than magnitude 5. Other notable objects in Caelum are RR Caeli, a binary star with one known planet approximately away; X Caeli, a Delta Scuti variable that forms an optical double with γ Caeli; and HE0450-2958, a Seyfert galaxy that at first appeared as just a jet, with no host galaxy visible.
Caelum was incepted as one of fourteen southern constellations in the 18th century by Nicolas Louis de Lacaille, a French astronomer and celebrater of the Age of Enlightenment.
It retains its name "Burin" among French speakers, latinized in his catalogue of 1763 as "Caelum Sculptoris" (“"Engraver's Chisel"”).
Francis Baily shortened this name to "Caelum", as suggested by John Herschel. In Lacaille's original chart, it was shown as a pair of engraver's tools: a standard burin and more specific shape-forming échoppe tied by a ribbon, but came to be ascribed a simple chisel. Johann Elert Bode stated the name as plural with a singular possessor, "Caela Scalptoris" – in German ("die") "Grabstichel" (“"the Engraver’s Chisels"”) – but this did not stick.
Caelum is bordered by Dorado and Pictor to the south, Horologium and Eridanus to the east, Lepus to the north, and Columba to the west. Covering only 125 square degrees, it ranks 81st of the 88 modern constellations in size. 
Its main asterism consists of four stars, and twenty stars in total are brighter than magnitude 6.5.
The constellation's boundaries, as set by Eugène Delporte in 1930, are a 12-sided polygon. In the equatorial coordinate system, the right ascension coordinates of these borders lie between and and declinations of to . The International Astronomical Union (IAU) adopted the three-letter abbreviation “Cae” for the constellation in 1922.
Its main stars are visible in favourable conditions and with a clear southern horizon, for part of the year as far as about the 41st parallel north
These stars avoid being engulfed by daylight for some of every day (when above the horizon) to viewers in mid- and well-inhabited higher latitudes of the Southern Hemisphere. Caelum shares with (to the north) Taurus, Eridanus and Orion midnight culmination in December (high summer), resulting in this fact. In winter (such as June) the constellation can be observed sufficiently inset from the horizons during its rising before dawn and/or setting after dusk as it culminates then at around mid-day, well above the sun. In South Africa, Argentina, their sub-tropical neighbouring areas and some of Australia in high June the key stars may be traced before dawn in the east; near the equator the stars lose night potential in May to June; they ill-compete with the Sun in northern tropics and sub-tropics from late February to mid-September with March being unfavorable as to post-sunset due to the light of the Milky Way.
Caelum is a faint constellation: It has no star brighter than magnitude 4 and only two stars brighter than magnitude 5.
Lacaille gave six stars Bayer designations, labeling them Alpha (α) to Zeta (ζ) in 1756, but omitted Epsilon (ε) and designated two adjacent stars as Gamma (γ). Bode extended the designations to Rho (ρ) for other stars, but most of these have fallen out of use. Caelum is too far south for any of its stars to bear Flamsteed designations.
The brightest star, (Alpha) α Caeli, is a double star, containing an F-type main-sequence star of magnitude 4.45 and a red dwarf of magnitude 12.5, from Earth. (Beta) β Caeli, another F-type star of magnitude 5.05, is further away, being located from Earth. Unlike α, β Caeli is a subgiant star, slightly evolved from the main sequence. (Delta) δ Caeli, also of magnitude 5.05, is a B-type subgiant and is much farther from Earth, at .
(Gamma) γ Caeli is a double-star with a red giant primary of magnitude 4.58 and a secondary of magnitude 8.1. The primary is from Earth. The two components are difficult to resolve with small amateur telescopes because of their difference in visual magnitude and their close separation. This star system forms an optical double with the unrelated X Caeli (previously named γ Caeli), a Delta Scuti variable located from Earth. These are a class of short-period (six hours at most) pulsating stars that have been used as standard candles and as subjects to study astroseismology. X Caeli itself is also a binary star, specifically a contact binary, meaning that the stars are so close that they share envelopes. The only other variable star in Caelum visible to the naked eye is RV Caeli, a pulsating red giant of spectral type M1III, which varies between magnitudes 6.44 and 6.56.
Three other stars in Caelum are still occasionally referred to by their Bayer designations, although they are only on the edge of naked-eye visibility. (Nu) ν Caeli is another double star, containing a white giant of magnitude 6.07 and a star of magnitude 10.66, with unknown spectral type. The system is approximately away. (Lambda) λ Caeli, at magnitude 6.24, is much redder and farther away, being a red giant around from Earth. (Zeta) ζ Caeli is even fainter, being only of magnitude 6.36. This star, located away, is a K-type subgiant of spectral type K1. The other twelve naked-eye stars in Caelum are not referred to by Bode's Bayer designations anymore, including RV Caeli.
One of the nearest stars in Caelum is the eclipsing binary star RR Caeli, at a distance of . This star system consists of a dim red dwarf and a white dwarf. Despite its closeness to the Earth, the system's apparent magnitude is only 14.40 due to the faintness of its components, and thus it cannot be easily seen with amateur equipment. In 2012, the system was found to contain a giant planet, and there is evidence for a second substellar body. The system is a post-common-envelope binary and is losing angular momentum over time, which will eventually cause mass transfer from the red dwarf to the white dwarf. In approximately 9–20 billion years, this will cause the system to become a cataclysmic variable.
Due to its small size and location away from the plane of the Milky Way, Caelum is rather devoid of deep-sky objects, and contains no Messier objects. The only deep-sky object in Caelum to receive much attention is HE0450-2958, an unusual Seyfert galaxy. Originally, the jet's host galaxy proved elusive to find, and this jet appeared to be emanating from nothing. Although it has been suggested that the object is an ejected supermassive black hole, the host is now agreed to be a small galaxy that is difficult to see due to light from the jet and a nearby starburst galaxy.
The 13th magnitude planetary nebula PN G243-37.1 is also in the eastern regions of the constellation. It is one of only a few planetary nebulae found in the galactic halo, being light-years below the Milky Way's 1000 light-year-thick disk.

</doc>
<doc id="6433" url="https://en.wikipedia.org/wiki?curid=6433" title="Clarinet">
Clarinet

The clarinet is a family of woodwind instruments. It has a single-reed mouthpiece, a straight, cylindrical tube with an almost cylindrical bore, and a flared bell. A person who plays a clarinet is called a "clarinetist" (sometimes spelled "clarinettist").
While the similarity in sound between the earliest clarinets and the trumpet may hold a clue to its name, other factors may have been involved. During the Late Baroque era, composers such as Bach and Handel were making new demands on the skills of their trumpeters, who were often required to play difficult melodic passages in the high, or as it came to be called, "clarion" register. Since the trumpets of this time had no valves or pistons, melodic passages would often require the use of the highest part of the trumpet's range, where the harmonics were close enough together to produce scales of adjacent notes as opposed to the gapped scales or arpeggios of the lower register. The trumpet parts that required this specialty were known by the term "clarino" and this in turn came to apply to the musicians themselves. It is probable that the term clarinet may stem from the diminutive version of the 'clarion' or 'clarino' and it has been suggested that clarino players may have helped themselves out by playing particularly difficult passages on these newly developed "mock trumpets".
Johann Christoph Denner is generally believed to have invented the clarinet in Germany around the year 1700 by adding a register key to the earlier chalumeau, usually in the key of C. Over time, additional keywork and airtight pads were added to improve the tone and playability.
In modern times, the most common clarinet is the B clarinet. However, the clarinet in A, just a semitone lower, is regularly used in orchestral, chamber and solo music. An orchestral clarinetist must own both a clarinet in A and B since the repertoire is divided fairly evenly between the two. Since the middle of the 19th century, the bass clarinet (nowadays invariably in B but with extra keys to extend the register down to low written C3) has become an essential addition to the orchestra. The clarinet family ranges from the (extremely rare) BBB octo-contrabass to the A piccolo clarinet. The clarinet has proved to be an exceptionally flexible instrument, used in the classical repertoire as in concert bands, military bands, marching bands, klezmer, jazz, and other styles.
The word "clarinet" may have entered the English language via the French "clarinette" (the feminine diminutive of Old French "clarin" or "clarion"), or from Provençal "", "oboe".
It would seem, however, that its real roots are to be found among some of the various names for trumpets used around the Renaissance and Baroque eras. "Clarion", "clarin", and the Italian "clarino" are all derived from the medieval term "claro", which referred to an early form of trumpet. This is probably the origin of the Italian "clarinetto", itself a diminutive of "clarino", and consequently of the European equivalents such as "clarinette" in French or the German "Klarinette". According to Johann Gottfried Walther, writing in 1732, the reason for the name is that "it sounded from far off not unlike a trumpet". The English form "clarinet" is found as early as 1733, and the now-archaic "clarionet" appears from 1784 until the early years of the 20th century.
The cylindrical bore is primarily responsible for the clarinet's distinctive timbre, which varies between its three main registers, known as the "chalumeau", "clarion", and "altissimo". The tone quality can vary greatly with the clarinetist, music, instrument, mouthpiece, and reed. The differences in instruments and geographical isolation of clarinetists led to the development from the last part of the 18th century onwards of several different schools of playing. The most prominent were the German/Viennese traditions and French school. The latter was centered on the clarinetists of the Conservatoire de Paris. The proliferation of recorded music has made examples of different styles of playing available. The modern clarinetist has a diverse palette of "acceptable" tone qualities to choose from.
The A and B clarinets have nearly the same bore and use the same mouthpiece. Orchestral clarinetists using the A and B instruments in a concert could use the same mouthpiece (and often the same barrel) (see 'usage' below). The A and B have nearly identical tonal quality, although the A typically has a slightly warmer sound. The tone of the E clarinet is brighter and can be heard even through loud orchestral or concert band textures. The bass clarinet has a characteristically deep, mellow sound, while the alto clarinet is similar in tone to the bass (though not as dark).
Clarinets have the largest pitch range of common woodwinds. The intricate key organization that makes this possible can make the playability of some passages awkward. The bottom of the clarinet's written range is defined by the keywork on each instrument, standard keywork schemes allowing a low E on the common B clarinet. The lowest concert pitch depends on the transposition of the instrument in question. The nominal highest note of the B clarinet is a semitone higher than the highest note of the oboe but this depends on the setup and skill of the player. Since the clarinet has a wider range of notes, the lowest note of the B clarinet is significantly deeper (a minor or major sixth) than the lowest note of the oboe.
Nearly all soprano and piccolo clarinets have keywork enabling them to play the E below middle C as their lowest written note (in scientific pitch notation that sounds D on a soprano clarinet or C, i.e. concert middle C, on a piccolo clarinet), though some B clarinets go down to E to enable them to match the range of the A clarinet. On the B soprano clarinet, the concert pitch of the lowest note is D, a whole tone lower than the written pitch. Most alto and bass clarinets have an extra key to allow a (written) E. Modern professional-quality bass clarinets generally have additional keywork to written C. Among the less commonly encountered members of the clarinet family, contra-alto and contrabass clarinets may have keywork to written E, D, or C; the basset clarinet and basset horn generally go to low C.
Defining the top end of a clarinet's range is difficult, since many advanced players can produce notes well above the highest notes commonly found in method books. G is usually the highest note clarinetists encounter in classical repertoire. The C above that (C i.e. resting on the fifth ledger line above the treble staff) is attainable by advanced players and is shown on many fingering charts, and fingerings as high as A exist.
The range of a clarinet can be divided into three distinct registers:
All three registers have characteristically different sounds. The chalumeau register is rich and dark. The clarion register is brighter and sweet, like a trumpet ("clarion") heard from afar. The altissimo register can be piercing and sometimes shrill.
Sound is a wave that propagates through the air as a result of a local variation in air pressure. The production of sound by a clarinet follows these steps:
The cycle repeats at a frequency relative to how long it takes a wave to travel to the first open hole and back twice (i.e. four times the length of the pipe). For example: when all the holes bar the very top one are open (i.e. the trill 'B' key is pressed), the note A4 (440 Hz) is produced. This represents a repeat of the cycle 440 times per second.
In addition to this primary compression wave, other waves, known as harmonics, are created. Harmonics are caused by factors including the imperfect wobbling and shaking of the reed, the reed sealing the mouthpiece opening for part of the wave cycle (which creates a flattened section of the sound wave), and imperfections (bumps and holes) in the bore. A wide variety of compression waves are created, but only some (primarily the odd harmonics) are reinforced. These extra waves are what gives the clarinet its characteristic tone.
The bore is cylindrical for most of the tube with an inner bore diameter between , but there is a subtle hourglass shape, with the thinnest part below the junction between the upper and lower joint. The reduction is depending on the maker. This hourglass shape, although invisible to the naked eye, helps to correct the pitch/scale discrepancy between the chalumeau and clarion registers (perfect twelfth). The diameter of the bore affects characteristics such as available harmonics, timbre, and pitch stability (how far the player can bend a note in the manner required in jazz and other music). The bell at the bottom of the clarinet flares out to improve the tone and tuning of the lowest notes.
Most modern clarinets have "undercut" tone holes that improve intonation and sound. Undercutting means chamfering the bottom edge of tone holes inside the bore. Acoustically, this makes the tone hole function as if it were larger, but its main function is to allow the air column to follow the curve up through the tone hole (surface tension) instead of "blowing past" it under the increasingly directional frequencies of the upper registers.
The fixed reed and fairly uniform diameter of the clarinet give the instrument an acoustical behavior approximating that of a cylindrical stopped pipe. Recorders use a tapered internal bore to overblow at the octave when the thumb/register hole is pinched open, while the clarinet, with its cylindrical bore, overblows at the twelfth. Adjusting the angle of the bore taper controls the frequencies of the overblown notes (harmonics). Changing the mouthpiece's tip opening and the length of the reed changes aspects of the harmonic timbre or voice of the clarinet because this changes the speed of reed vibrations. Generally, the goal of the clarinetist when producing a sound is to make as much of the reed vibrate as possible, making the sound fuller, warmer, and potentially louder.
The lip position and pressure, shaping of the vocal tract, choice of reed and mouthpiece, amount of air pressure created, and evenness of the airflow account for most of the clarinetist's ability to control the tone of a clarinet. A highly skilled clarinetist will provide the ideal lip and air pressure for each frequency (note) being produced. They will have an embouchure which places an even pressure across the reed by carefully controlling their lip muscles. The airflow will also be carefully controlled by using the strong stomach muscles (as opposed to the weaker and erratic chest muscles) and they will use the diaphragm to oppose the stomach muscles to achieve a tone softer than a forte rather than weakening the stomach muscle tension to lower air pressure. Their vocal tract will be shaped to resonate at frequencies associated with the tone being produced.
Covering or uncovering the tone holes varies the length of the pipe, changing the resonant frequencies of the enclosed air column and hence the pitch. A clarinetist moves between the chalumeau and clarion registers through use of the register key; clarinetists call the change from chalumeau register to clarion register "the break". The open register key stops the fundamental frequency from being reinforced, and the reed is forced to vibrate at three times the speed it was originally. This produces a note a twelfth above the original note.
Most instruments overblow at two times the speed of the fundamental frequency (the octave), but as the clarinet acts as a closed pipe system, the reed cannot vibrate at twice its original speed because it would be creating a 'puff' of air at the time the previous 'puff' is returning as a rarefaction. This means it cannot be reinforced and so would die away. The chalumeau register plays fundamentals, whereas the clarion register, aided by the register key, plays third harmonics (a perfect twelfth higher than the fundamentals). The first several notes of the altissimo range, aided by the register key and venting with the first left-hand hole, play fifth harmonics (a major seventeenth, a perfect twelfth plus a major sixth, above the fundamentals). The clarinet is therefore said to overblow at the twelfth and, when moving to the altissimo register, seventeenth.
By contrast, nearly all other woodwind instruments overblow at the octave or (like the ocarina and tonette) do not overblow at all. A clarinet must have holes and keys for nineteen notes, a chromatic octave and a half from bottom E to B, in its lowest register to play the chromatic scale. This overblowing behavior explains the clarinet's great range and complex fingering system. The fifth and seventh harmonics are also available, sounding a further sixth and fourth (a flat, diminished fifth) higher respectively; these are the notes of the altissimo register. This is also why the inner "waist" measurement is so critical to these harmonic frequencies.
The highest notes can have a shrill, piercing quality and can be difficult to tune accurately. Different instruments often play differently in this respect due to the sensitivity of the bore and reed measurements. Using alternate fingerings and adjusting the embouchure helps correct the pitch of these notes.
Since approximately 1850, clarinets have been nominally tuned according to twelve-tone equal temperament. Older clarinets were nominally tuned to meantone. Skilled performers can use their embouchures to considerably alter the tuning of individual notes or produce vibrato, a pulsating change of pitch often employed in jazz. Vibrato is rare in classical or concert band literature; however, certain clarinetists, such as Richard Stoltzman, use vibrato in classical music. Special fingerings may be used to play quarter tones and other microtonal intervals.
Around 1900, Dr. Richard H. Stein, a Berlin musicologist, made a quarter-tone clarinet, which was soon abandoned. Years later, another German, Fritz Schüller of Markneukirchen, built a quarter tone clarinet, with two parallel bores of slightly different lengths whose tone holes are operated using the same keywork and a valve to switch from one bore to the other.
Clarinet bodies have been made from a variety of materials including wood, plastic, hard rubber, metal, resin, and ivory. The vast majority of clarinets used by professionals are made from African hardwood, mpingo (African Blackwood) or grenadilla, rarely (because of diminishing supplies) Honduran rosewood, and sometimes even cocobolo. Historically other woods, notably boxwood, were used. Most inexpensive clarinets are made of plastic resin, such as ABS. "Resonite" is Selmer's trademark name for its type of plastic. Metal soprano clarinets were popular in the early 20th century until plastic instruments supplanted them; metal construction is still used for the bodies of some contra-alto and contrabass clarinets and the necks and bells of nearly all alto and larger clarinets. Ivory was used for a few 18th-century clarinets, but it tends to crack and does not keep its shape well. Buffet Crampon's Greenline clarinets are made from a composite of grenadilla wood powder and carbon fiber. Such clarinets are less affected by humidity and temperature changes than wooden instruments but are heavier. Hard rubber, such as ebonite, has been used for clarinets since the 1860s, although few modern clarinets are made of it. Clarinet designers Alastair Hanson and Tom Ridenour are strong advocates of hard rubber. The Hanson Clarinet Company manufactures clarinets using a grenadilla compound reinforced with ebonite, known as "BTR" (bithermal-reinforced) grenadilla. This material is also not affected by humidity, and the weight is the same as that of a wooden clarinet.
Mouthpieces are generally made of hard rubber, although some inexpensive mouthpieces may be made of plastic. Other materials such as crystal/glass, wood, ivory, and metal have also been used. Ligatures are often made of metal and plated in nickel, silver, or gold. Other materials include wire, wire mesh, plastic, naugahyde, string, or leather.
The clarinet uses a single reed made from the cane of "Arundo donax", a type of grass. Reeds may also be manufactured from synthetic materials. The ligature fastens the reed to the mouthpiece. When air is blown through the opening between the reed and the mouthpiece facing, the reed vibrates and produces the clarinet's sound.
Basic reed measurements are as follows: tip, wide; lay, long (distance from the place where the reed touches the mouthpiece to the tip); gap, (distance between the underside of the reed tip and the mouthpiece). Adjustment to these measurements is one method of affecting tone color.
Most clarinetists buy manufactured reeds, although many make adjustments to these reeds, and some make their own reeds from cane "blanks". Reeds come in varying degrees of hardness, generally indicated on a scale from one (soft) through five (hard). This numbering system is not standardized—reeds with the same number often vary in hardness across manufacturers and models. Reed and mouthpiece characteristics work together to determine ease of playability, pitch stability, and tonal characteristics.
Note: A Böhm system soprano clarinet is shown in the photos illustrating this section. However, all modern clarinets have similar components.
The "reed" is attached to the "mouthpiece" by the "ligature", and the top half-inch or so of this assembly is held in the player's mouth. In the past, clarinetists used to wrap a string around the mouthpiece and reed instead of using a ligature. The formation of the mouth around the mouthpiece and reed is called the "embouchure".
The reed is on the underside of the mouthpiece, pressing against the player's lower lip, while the top teeth normally contact the top of the mouthpiece (some players roll the upper lip under the top teeth to form what is called a 'double-lip' embouchure). Adjustments in the strength and shape of the embouchure change the tone and intonation (tuning). It is not uncommon for clarinetists to employ methods to relieve the pressure on the upper teeth and inner lower lip by attaching pads to the top of the mouthpiece or putting (temporary) padding on the front lower teeth, commonly from folded paper.
Next is the short "barrel"; this part of the instrument may be extended to fine-tune the clarinet. As the pitch of the clarinet is fairly temperature-sensitive, some instruments have interchangeable barrels whose lengths vary slightly. Additional compensation for pitch variation and tuning can be made by pulling out the barrel and thus increasing the instrument's length, particularly common in group playing in which clarinets are tuned to other instruments (such as in an orchestra or concert band). Some performers use a plastic barrel with a thumbwheel that adjusts the barrel length. On basset horns and lower clarinets, the barrel is normally replaced by a curved metal neck.
The main body of most clarinets is divided into the "upper joint", the holes and most keys of which are operated by the left hand, and the "lower joint" with holes and most keys operated by the right hand. Some clarinets have a single joint: on some basset horns and larger clarinets the two joints are held together with a screw clamp and are usually not disassembled for storage. The left thumb operates both a "tone hole" and the "register key". On some models of clarinet, such as many Albert system clarinets and increasingly some higher-end Böhm system clarinets, the register key is a 'wraparound' key, with the key on the back of the clarinet and the pad on the front. Advocates of the wraparound register key say it improves sound, and it is harder for moisture to accumulate in the tube beneath the pad. Nevertheless, there is a consensus among repair techs that this type of register key is harder to keep in adjustment, i.e., it is hard to have enough spring pressure to close the hole securely.
The body of a modern soprano clarinet is equipped with numerous "tone holes" of which seven (six front, one back) are covered with the fingertips, and the rest are opened or closed using a set of keys. These tone holes let the player produce every note of the chromatic scale. On alto and larger clarinets, and a few soprano clarinets, key-covered holes replace some or all finger holes. The most common system of keys was named the Böhm system by its designer Hyacinthe Klosé in honour of flute designer Theobald Böhm, but it is not the same as the Böhm system used on flutes. The other main system of keys is called the Oehler system and is used mostly in Germany and Austria (see History). The related Albert system is used by some jazz, klezmer, and eastern European folk musicians. The Albert and Oehler systems are both based on the early Mueller system.
The cluster of keys at the bottom of the upper joint (protruding slightly beyond the cork of the joint) are known as the "trill keys" and are operated by the right hand. These give the player alternative fingerings that make it easy to play ornaments and trills. The entire weight of the smaller clarinets is supported by the right thumb behind the lower joint on what is called the "thumb-rest". Basset horns and larger clarinets are supported with a neck strap or a floor peg.
Finally, the flared end is known as the "bell". Contrary to popular belief, the bell does not amplify the sound; rather, it improves the uniformity of the instrument's tone for the lowest notes in each register. For the other notes, the sound is produced almost entirely at the tone holes, and the bell is irrelevant. On basset horns and larger clarinets, the bell curves up and forward and is usually made of metal.
Theobald Böhm did not directly invent the key system of the clarinet. Böhm was a flautist who created the key system that is now used for the transverse flute. Klosé and Buffet applied Böhm's system to the clarinet. Although the credit goes to those people, Böhm's name was given to that key system because it was based on that used for the flute.
The current Böhm key system consists of generally 6 rings, on the thumb, 1st, 2nd, 4th, 5th, and 6th holes, and a register key just above the thumb hole, easily accessible with the thumb. Above the 1st hole, there is a key that lifts two covers creating the note A in the throat register (high part of low register) of the clarinet. A key at the side of the instrument at the same height as the A key lifts only one of the two covers, producing G, a semitone lower. The A key can be used in conjunction solely with the register key to produce A/B.
The clarinet has its roots in the early single-reed instruments or hornpipes used in Ancient Greece, Ancient Egypt, Middle East, and Europe since the Middle Ages, such as the albogue, alboka, and double clarinet.
The modern clarinet developed from a Baroque instrument called the chalumeau. This instrument was similar to a recorder, but with a single-reed mouthpiece and a cylindrical bore. Lacking a register key, it was played mainly in its fundamental register, with a limited range of about one and a half octaves. It had eight finger holes, like a recorder, and two keys for its two highest notes. At this time, contrary to modern practice, the reed was placed in contact with the upper lip.
Around the turn of the 18th century, the chalumeau was modified by converting one of its keys into a register key to produce the first clarinet. This development is usually attributed to German instrument maker Johann Christoph Denner, though some have suggested his son Jacob Denner was the inventor. This instrument played well in the middle register with a loud, shrill sound, so it was given the name "clarinetto" meaning "little trumpet" (from "clarino" + "-etto"). Early clarinets did not play well in the lower register, so players continued to play the chalumeaux for low notes. As clarinets improved, the chalumeau fell into disuse, and these notes became known as the "chalumeau register". Original Denner clarinets had two keys, and could play a chromatic scale, but various makers added more keys to get improved tuning, easier fingerings, and a slightly larger range. The classical clarinet of Mozart's day typically had eight finger holes and five keys.
Clarinets were soon accepted into orchestras. Later models had a mellower tone than the originals. Mozart (d. 1791) liked the sound of the clarinet (he considered its tone the closest in quality to the human voice) and wrote numerous pieces for the instrument., and by the time of Beethoven (c. 1800–1820), the clarinet was a standard fixture in the orchestra.
The next major development in the history of clarinet was the invention of the modern pad. Because early clarinets used felt pads to cover the tone holes, they leaked air. This required pad-covered holes to be kept to a minimum, restricting the number of notes the clarinet could play with good tone. In 1812, Iwan Müller, a Baltic German community-born clarinetist and inventor, developed a new type of pad that was covered in leather or fish bladder. It was airtight and let makers increase the number of pad-covered holes. Müller designed a new type of clarinet with seven finger holes and thirteen keys. This allowed the instrument to play in any key with near-equal ease. Over the course of the 19th-century, makers made many enhancements to Müller's clarinet, such as the Albert system and the Baermann system, all keeping the same basic design. Modern instruments may also have cork or synthetic pads.
The final development in the modern design of the clarinet used in most of the world today was introduced by Hyacinthe Klosé in 1839. He devised a different arrangement of keys and finger holes, which allow simpler fingering. It was inspired by the Boehm system developed for flutes by Theobald Böhm. Klosé was so impressed by Böhm's invention that he named his own system for clarinets the Boehm system, although it is different from the one used on flutes. This new system was slow to gain popularity but gradually became the standard, and today the Boehm system is used everywhere in the world except Germany and Austria. These countries still use a direct descendant of the Mueller clarinet known as the Oehler system clarinet. Also, some contemporary Dixieland players continue to use Albert system clarinets.
Other key systems have been developed, many built around modifications to the basic Böhm system: Full Böhm, Mazzeo, McIntyre, Benade NX, and the Reform Boehm system for example. Each of these addressed—and often improved—issues of particular "weak" tones, or simplified awkward fingerings, but none has caught on widely among players, and the Boehm system remains the standard, to date.
The modern orchestral standard of using soprano clarinets in B and A has to do partly with the history of the instrument and partly with acoustics, aesthetics, and economics. Before about 1800, due to the lack of airtight pads "(see History)", practical woodwinds could have only a few keys to control accidentals (notes outside their diatonic home scales). The low (chalumeau) register of the clarinet spans a twelfth (an octave plus a perfect fifth), so the clarinet needs keys/holes to produce all nineteen notes in this range. This involves more keywork than on instruments that "overblow" at the octave—oboes, flutes, bassoons, and saxophones, for example, which need only twelve notes before overblowing. Clarinets with few keys cannot therefore easily play chromatically, limiting any such instrument to a few closely related keys. For example, an eighteenth-century clarinet in C could be played in F, C, and G (and their relative minors) with good intonation, but with progressive difficulty and poorer intonation as the key moved away from this range. In contrast, for octave-overblowing instruments, an instrument in C with few keys could much more readily be played in any key. This problem was overcome by using three clarinets—in A, B, and C—so that early 19th-century music, which rarely strayed into the remote keys (five or six sharps or flats), could be played as follows: music in 5 to 2 sharps (B major to D major concert pitch) on A clarinet (D major to F major for the player), music in 1 sharp to 1 flat (G to F) on C clarinet, and music in 2 flats to 4 flats (B to A) on the B clarinet (C to B for the clarinetist). Difficult key signatures and numerous accidentals were thus largely avoided.
With the invention of the airtight pad, and as key technology improved and more keys were added to woodwinds, the need for clarinets in multiple keys was reduced. However, the use of multiple instruments in different keys persisted, with the three instruments in C, B, and A all used as specified by the composer.
The lower-pitched clarinets sound "mellower" (less bright), and the C clarinet—being the highest and therefore brightest of the three—fell out of favour as the other two could cover its range and their sound was considered better. While the clarinet in C began to fall out of general use around 1850, some composers continued to write C parts after this date, e.g., Bizet's Symphony in C (1855), Tchaikovsky's Symphony No. 2 (1872), Smetana's overture to "The Bartered Bride" (1866) and "Má Vlast" (1874), Dvořák's "Slavonic Dance" Op. 46, No. 1 (1878), Brahms' Symphony No. 4 (1885), Mahler's Symphony No. 6 (1906), and Richard Strauss deliberately reintroduced it to take advantage of its brighter tone, as in "Der Rosenkavalier" (1911).
While technical improvements and an equal-tempered scale reduced the need for two clarinets, the technical difficulty of playing in remote keys persisted, and the A has thus remained a standard orchestral instrument. In addition, by the late 19th century, the orchestral clarinet repertoire contained so much music for clarinet in A that the disuse of this instrument was not practical. Attempts were made to standardise to the B instrument between 1930 and 1950 (e.g., tutors recommended learning routine transposition of orchestral A parts on the B clarinet, including solos written for A clarinet, and some manufacturers provided a low E on the B to match the range of the A), but this failed in the orchestral sphere.
Similarly there have been E and D instruments in the upper soprano range, B, A, and C instruments in the bass range, and so forth; but over time the E and B instruments have become predominant. The B instrument remains dominant in concert bands and jazz. B and C instruments are used in some ethnic traditions, such as klezmer.
In classical music, clarinets are part of standard orchestral and concert band instrumentation.
The orchestra frequently includes two clarinetists playing individual parts—each player is usually equipped with a pair of standard clarinets in B and A, and clarinet parts commonly alternate between B and A instruments several times over the course of a piece, or less commonly, a movement (e.g., 1st movement Brahms' 3rd symphony). Clarinet sections grew larger during the last few decades of the 19th century, often employing a third clarinetist, an E or a bass clarinet. In the 20th century, composers such as Igor Stravinsky, Richard Strauss, Gustav Mahler, and Olivier Messiaen enlarged the clarinet section on occasion to up to nine players, employing many different clarinets including the E or D soprano clarinets, basset horn, alto clarinet, bass clarinet, and/or contrabass clarinet.
In concert bands, clarinets are an important part of the instrumentation. The E clarinet, B clarinet, alto clarinet, bass clarinet, and contra-alto/contrabass clarinet are commonly used in concert bands. Concert bands generally have multiple B clarinets; there are commonly 3 B clarinet parts with 2–3 players per part. There is generally only one player per part on the other clarinets. There are not always E clarinet, alto clarinet, and contra-alto clarinets/contrabass clarinet parts in concert band music, but all three are quite common.
This practice of using a variety of clarinets to achieve coloristic variety was common in 20th-century classical music and continues today. However, many clarinetists and conductors prefer to play parts originally written for obscure instruments on B or E clarinets, which are often of better quality and more prevalent and accessible.
The clarinet is widely used as a solo instrument. The relatively late evolution of the clarinet (when compared to other orchestral woodwinds) has left solo repertoire from the Classical period and later, but few works from the Baroque era. Many clarinet concertos have been written to showcase the instrument, with the concerti by Mozart, Copland, and Weber being well known.
Many works of chamber music have also been written for the clarinet. Common combinations are:
The clarinet was originally a central instrument in jazz, beginning with the New Orleans players in the 1910s. It remained a signature instrument of jazz music through much of the big band era into the 1940s. American players Alphonse Picou, Larry Shields, Jimmie Noone, Johnny Dodds, and Sidney Bechet were all pioneers of the instrument in jazz. The B soprano was the most common instrument, but a few early jazz musicians such as Louis Nelson Delisle and Alcide Nunez preferred the C soprano, and many New Orleans jazz brass bands have used E soprano.
Swing clarinetists such as Benny Goodman, Artie Shaw, and Woody Herman led successful big bands and smaller groups from the 1930s onward. Duke Ellington, active from the 1920s to the 1970s, used the clarinet as lead instrument in his works, with several players of the instrument (Barney Bigard, Jimmy Hamilton, and Russell Procope) spending a significant portion of their careers in his orchestra. Harry Carney, primarily Ellington's baritone saxophonist, occasionally doubled on bass clarinet. Meanwhile, Pee Wee Russell had a long and successful career in small groups.
With the decline of the big bands' popularity in the late 1940s, the clarinet faded from its prominent position in jazz. By that time, an interest in Dixieland or traditional New Orleans jazz had revived; Pete Fountain was one of the best known performers in this genre. Bob Wilber, active since the 1950s, is a more eclectic jazz clarinetist, playing in several classic jazz styles. During the 1950s and 1960s, Britain underwent a surge in the popularity of what was termed 'Trad jazz'. In 1956 the British clarinetist Acker Bilk founded his own ensemble. Several singles recorded by Bilk reached the British pop charts, including the ballad "Stranger on the Shore".
The clarinet's place in the jazz ensemble was usurped by the saxophone, which projects a more powerful sound and uses a less complicated fingering system. The requirement for an increased speed of execution in modern jazz also did not favour the clarinet, but the clarinet did not entirely disappear. The clarinetist Stan Hasselgård made a transition from swing to bebop in the mid-1940s. A few players such as Buddy DeFranco, Tony Scott, and Jimmy Giuffre emerged during the 1950s playing bebop or other styles. A little later, Eric Dolphy (on bass clarinet), Perry Robinson, John Carter, Theo Jörgensmann, and others used the clarinet in free jazz. The French composer and clarinetist Jean-Christian Michel initiated a jazz-classical cross-over on the clarinet with the drummer Kenny Clarke.
In the U.S., the prominent players on the instrument since the 1980s have included Eddie Daniels, Don Byron, Marty Ehrlich, Ken Peplowski, and others playing the clarinet in more contemporary contexts.
The clarinet is uncommon, but not unheard of, in rock music. Jerry Martini played clarinet on Sly and the Family Stone's 1968 hit, "Dance to the Music"; Don Byron, a founder of the Black Rock Coalition who was a member of hard rock guitarist Vernon Reid's band, plays clarinet on the "Mistaken Identity" album (1996). The Beatles, Pink Floyd, Radiohead, Aerosmith, Billy Joel, and Tom Waits have also all used clarinet on occasion. A clarinet is prominently featured for two different solos in "Breakfast in America", the title song from the Supertramp album of the same name.
Clarinets feature prominently in klezmer music, which entails a distinctive style of playing. The use of quarter-tones requires a different embouchure. Some klezmer musicians prefer Albert system clarinets.
The popular Brazilian music styles of choro and samba use the clarinet. Prominent contemporary players include Paulo Moura, Naylor 'Proveta' Azevedo, Paulo Sérgio dos Santos, and Cuban born Paquito D'Rivera.
Even though it has been adopted recently in Albanian folklore (around the 18th century), the clarinet, or "gërneta" as it is called, is one of the most important instruments in Albania, especially in the central and southern areas. The clarinet plays a crucial role in "saze" (folk) ensembles that perform in weddings and other celebrations. It is worth mentioning that the "kaba" (an instrumental Albanian Isopolyphony included in UNESCO's intangible cultural heritage list) is characteristic of these ensembles. Prominent Albanian clarinet players include Selim Leskoviku, Gaqo Lena, Remzi Lela (Çobani), Laver Bariu (Ustai), and Nevruz Nure (Lulushi i Korçës).
The clarinet is prominent in Bulgarian wedding music also; it is an offshoot of Roma/Romani traditional music. Ivo Papazov is a well-known clarinetist in this genre. In Moravian dulcimer bands, the clarinet is usually the only wind instrument among string instruments.
In old-town folk music in North Macedonia (called čalgija ("чалгија")), the clarinet has the most important role in wedding music; clarinet solos mark the high point of dancing euphoria. One of the most renowned Macedonian clarinet players is Tale Ognenovski, who gained worldwide fame for his virtuosity.
In Greece, the clarinet (usually referred to as "κλαρίνο"—"clarino") is prominent in traditional music, especially in central, northwest, and northern Greece (Thessaly, Epirus, and Macedonia). The double-reed zurna was the dominant woodwind instrument before the clarinet arrived in the country, although many Greeks regard the clarinet as a native instrument. Traditional dance music, wedding music, and laments include a clarinet soloist and quite often improvisations. Petroloukas Chalkias is a famous clarinetist in this genre.
The instrument is equally famous in Turkey, especially the lower-pitched clarinet in G. The western European clarinet crossed via Turkey to Arabic music, where it is widely used in Arabic pop, especially if the intention of the arranger is to imitate the Turkish style.
Also in Turkish folk music, a clarinet-like woodwind instrument, the sipsi, is used. However, it is far more rare than the soprano clarinet and is mainly limited to folk music of the Aegean Region.
Groups of clarinets playing together have become increasingly popular among clarinet enthusiasts in recent years. Common forms are:
Clarinet choirs and quartets often play arrangements of both classical and popular music, in addition to a body of literature specially written for a combination of clarinets by composers such as Arnold Cooke, Alfred Uhl, Lucien Caillet, and Václav Nelhýbel.
There is a family of many differently pitched clarinet types, some of which are very rare. The following are the most important sizes, from highest to lowest:
EEE and BBB octocontra-alto and octocontrabass clarinets have also been built. There have also been soprano clarinets in C, A, and B with curved barrels and bells marketed under the names saxonette, claribel, and clariphon.

</doc>
<doc id="6434" url="https://en.wikipedia.org/wiki?curid=6434" title="Chojnów">
Chojnów

Chojnów () (Silesian German:Hoyn) is a small town in Legnica County, Lower Silesian Voivodeship, in south-western Poland. It is located on the Skora river, a tributary of the Kaczawa at an average altitude of above sea level. Chojnów is the administrative seat of the rural gmina called Gmina Chojnów, although the town is not part of its territory and forms a separate urban gmina. it had 13,355 inhabitants.
Chojnów is located west of Legnica, east from Bolesławiec and north of Złotoryja, from the A4 motorway. It has railroad connections to Bolesławiec and Legnica.
Coat of arms of the Chojnów has is a blue escutcheon. On the dial there is a tower with three bastions of white colour. The central tower has two Windows, and one side. On the towers is located on the right side of the Moon and Sun on the left. In the gate of the Silesian Eagle on a yellow background.
The Motto of Chojnów is "Friendly City".
Chojnów is located in the Central-Western part of the Lower Silesia region. The Skora (Leather) River flows through the town in a westerly direction. The city of Chojnów is in area, including 41% agricultural land.
Chojnów has a connection with the major cities of the country (road and rail) and located south of Chojnów has the A4 Autostrada. To the South of the town is the surrounding Chojnowska Plain.
The town is first mentioned in a Latin mediaeval document issued in Wrocław on February 26, 1253, stating, the Silesian Duke Henry III when the town is mentioned under the name Honowo. Possible the name of nearby Hainau Island. The name is of Polish origin, and in more modern records from the 19th century, the Polish name appears as "Hajnów", while "Haynau" is the Germanized version of the original Polish name.
The settlement of "Haynow" was mentioned in a 1272 deed. It was already called a "civitas" in a 1288 document issued by the Piast duke Henry V of Legnica, and officially received town privileges in 1333 from Duke Bolesław III the Generous. It was part of the duchies of Wrocław, Głogów and Legnica of fragmented Poland and remained under the rule of the Piast dynasty until 1675. Its population was predominantly Polish. In 1292 the first castellan of Chojnów, Bronisław Budziwojowic, was mentioned. In the 14th and early 15th centuries Chojnów was granted various privileges, including staple right and gold mining right, thanks to which it flourished.
The town survived the Hussites, who burned almost the entire town center and castle, but it quickly helped recover its former glory. The largest boom Chojnów experienced was in the 16th century, however by the end of that century began to decline due to fires and epidemic, which claimed many victims in 1613. During the Thirty Years War (1618–1648), there was another outbreak in the city, it was occupied by the Austrians and Swedes and in 1642 it was also plundered by the Swedes. It remained part of the Piast-ruled Duchy of Legnica until its dissolution in 1675, when it was incorporated to Habsburg-ruled Bohemia.
In the 18th century, cloth production developed and a clothmaking school was established in the town. One of two main routes connecting Warsaw and Dresden ran through the town in the 18th century and Kings Augustus II the Strong and Augustus III of Poland traveled that route numerous times. In 1740 the town was captured by Prussia and subsequently annexed in 1742. In 1804 it suffered a flood. During the Napoleonic wars there were more epidemics. In 1813 in Chojnów, Napoleon Bonaparte issued instructions regarding the reorganization of the 8th Polish Corps of Prince Józef Poniatowski. The event is commemorated by a plaque in the facade of the Piast Castle. A railway line was opened in the 19th century. Sewer, Gas lighting a Newspaper and a hospital soon followed as the towns economy improved.
The city was not spared in World War II, with 30% of the town being destroyed on February 10, 1945 when Soviet Red Army troops took the abandoned town. After World War II and the implementation of the Oder-Neisse line in 1945, the town passed to the Republic of Poland. It was repopulated by Poles, expelled from former eastern Poland annexed by the Soviet Union. In 1946 it was renamed "Chojnów", a more modern version of the old Polish "Hajnów". Also Greeks, refugees of the Greek Civil War, settled in Chojnów.
Chojnów is an industrial and agricultural town. Among local products are: paper, agricultural machinery, chains, metal furniture for hospitals, equipment for the meat industry, beer, wine, leather clothing, and clothing for infants, children and adults.
Among the interesting monuments of Chojnów are the 13th-century castle of the Dukes of Legnica (currently used as a museum), two old churches, the "Baszta Tkaczy" ("Weavers' Tower") and preserved fragments of city walls.
The biggest green area in Chojnów is small forest "Park Piastowski" ("Piast's Park"), named after Piast dynasty. Wild animals that can be found in the Chojnów area are roe deer, foxes, rabbits and wild domestic animals, especially cats.
Every year in the first days of June, the "Days of Chojnów" ("Dni Chojnowa") are celebrated. The Whole-Poland bike race "Masters" has been organized yearly in Chojnów for the past few years.
Chojnów has a Municipal sports and recreation center formed in 2008 holding various events, festivals, reviews, exhibitions, and competitions. The regional Museum is housed in the old Piast era castle. The collections include tiles, relics, and the castle garden. Next to the Museum there is a municipal library. In śródmiejskim Park, near the Town Hall is the amphitheatre.
The local government-run weekly newspaper is Gazeta Chojnowska, which has been published since 1992.
It is published biweekly. Editions have a run of 900 copies and it is one of the oldest newspapers in Poland issued without interruption. The "Chojnów" is the official newspaper of Chojnów with copy run of 750 copies.
In Chojnów, there are two kindergartens, two elementary schools and two middle schools.
Chojnów is in the Catholic deanery of Chojnów and has two parishes, Immaculate Conception of the Blessed Virgin Mary and also the Holy Apostles Peter and Paul. Both parishes have active congregations.
There are also two Congregations of Jehovah's witnesses.
Chojnów is twinned with:

</doc>
<doc id="6435" url="https://en.wikipedia.org/wiki?curid=6435" title="Canes Venatici">
Canes Venatici

Canes Venatici is one of the 88 official modern constellations. It is a small northern constellation that was created by Johannes Hevelius in the 17th century. Its name is Latin for "hunting dogs", and the constellation is often depicted in illustrations as representing the dogs of Boötes the Herdsman, a neighboring constellation.
Cor Caroli is the constellation's brightest star, with an apparent magnitude of 2.9 . La Superba (Y CVn) is one of the reddest naked-eye stars and one of the brightest carbon stars. The Whirlpool Galaxy is a spiral galaxy tilted face-on to observers on Earth, and was the first galaxy whose spiral nature was discerned.
The stars of Canes Venatici are not bright. In classical times, they were listed by Ptolemy as unfigured stars below the constellation Ursa Major in his star catalogue. 
In medieval times, the identification of these stars with the dogs of Boötes arose through a mistranslation: Some of Boötes's stars were traditionally described as representing the club (Greek "κολλοροβος", kollorobos) of Boötes. When the Greek astronomer Ptolemy's "Almagest" was translated from Greek to Arabic, the translator Hunayn ibn Ishaq did not know the Greek word and rendered it as a similar-sounding compound Arabic word for a kind of weapon, writing "al-`aşā dhāt al-kullāb" العصا ذات الكُلاب, which means "the staff having a hook".
When the Arabic text was later translated into Latin, the translator, Gerard of Cremona, mistook "kullāb" كُلاب, meaning "hook", for "kilāb" كِلاب meaning "dogs". (Both written words look the same in Arabic text without diacritics.) Gerard writing it as: "Hastile habens canes" ("spearshaft having dogs"). 
In 1533, the German astronomer Peter Apian depicted Boötes as having two dogs with him.
These spurious dogs floated about the astronomical literature until Hevelius decided, in 1687, to make them a separate constellation. Hevelius chose the name "Asterion" for the northern dog and "Chara" for the southern dog, as "Canes Venatici", "the hunting dogs", in his star atlas.
In his star catalogue, the Czech astronomer Bečvář assigned the names "Asterion" to β CVn and "Chara" to α CVn.()
Although the International Astronomical Union dropped several constellations in 1930 that were Medieval and Renaissance innovations, Canes Venatici survived to become one of the 88 IAU-endorsed constellations.
Canes Venatici is bordered by Ursa Major to the north and west, Coma Berenices to the south, and Boötes to the east. The three-letter abbreviation for the constellation, as adopted by the International Astronomical Union in 1922, is "CVn". The official constellation boundaries, as set by Delporte in 1930, are defined by a polygon of 14 sides.
In the equatorial coordinate system, the right ascension coordinates of these borders lie between and , while the declination coordinates are between +27.84° and +52.36°. Covering 465 square degrees, it ranks 38th of the 88 constellations in size.
Canes Venatici contains no bright stars, Alpha and Beta Canum Venaticorum being only of 3rd and 4th magnitude respectively. Flamsteed catalogued 25 stars in the constellation, labelling them 1 to 25 Canum Venaticorum (CVn), however 1 CVn turned out to be in Ursa Major, 13 CVn was in Coma Berenices, and 22 CVn did not exist.
The Giant Void, an extremely large void (part of the universe containing very few galaxies) is within the vicinity of this constellation. It may be possibly the largest void ever discovered, slightly larger than the Eridanus Supervoid and 1,200 times the volume of expected typical voids. It was discovered in 1988 in a deep-sky survey.
Canes Venatici contains five Messier objects, including four galaxies. One of the more significant galaxies in Canes Venatici is the Whirlpool Galaxy (M 51, NGC 5194) and NGC 5195, a small barred spiral galaxy that is seen face on. This was the first galaxy recognised as having a spiral structure, this structure being first observed by Lord Rosse in 1845. It is a face-on spiral galaxy 37 million light-years from Earth. Widely considered to be one of the most beautiful galaxies visible, M 51 has many star-forming regions and nebulae in its arms, coloring them pink and blue in contrast to the older yellow core. M 51 has a smaller companion, NGC 5195, that has very few star-forming regions and thus appears yellow. It is passing behind M 51 and may be the cause of the larger galaxy's prodigious star formation.
Other notable spiral galaxies in Canes Venatici are the Sunflower Galaxy (M 63, NGC 5055), M 94 (NGC 4736), and M 106 (NGC 4258).

</doc>
<doc id="6436" url="https://en.wikipedia.org/wiki?curid=6436" title="Chamaeleon">
Chamaeleon

Chamaeleon () is a small constellation in the southern sky. It is named after the chameleon, a kind of lizard. It was first defined in the 16th century.
Chamaeleon was one of twelve constellations created by Petrus Plancius from the observations of Pieter Dirkszoon Keyser and Frederick de Houtman. It first appeared on a 35-cm diameter celestial globe published in 1597 (or 1598) in Amsterdam by Plancius and Jodocus Hondius. Johann Bayer was the first uranographer to put Chamaeleon in a celestial atlas. It was one of many constellations created by European explorers in the 15th and 16th centuries out of unfamiliar Southern Hemisphere stars.
There are four bright stars in Chamaeleon that form a compact diamond-shape approximately 10 degrees from the South Celestial Pole and about 15 degrees south of Acrux, along the axis formed by Acrux and Gamma Crucis. Alpha Chamaeleontis is a white-hued star of magnitude 4.1, 63 light-years from Earth. Beta Chamaeleontis is a blue-white hued star of magnitude 4.2, 271 light-years from Earth. Gamma Chamaeleontis is a red-hued giant star of magnitude 4.1, 413 light-years from Earth. The other bright star in Chamaeleon is Delta Chamaeleontis, a wide double star. The brighter star is Delta Chamaeleontis, a blue-hued star of magnitude 4.4. Delta Chamaeleontis, the dimmer component, is an orange-hued giant star of magnitude 5.5. They both lie about 350 light years away.
Chamaeleon is also the location of Cha 110913, a unique dwarf star or proto solar system.
In 1999, a nearby open cluster was discovered centered on the star η Chamaeleontis. The cluster, known as either
the Eta Chamaeleontis cluster or Mamajek 1, is 8 million years old, and lies 316 light years from Earth.
The constellation contains a number of molecular clouds (the Chamaeleon dark clouds) that are forming low-mass T Tauri stars. The cloud complex lies some 400 to 600 light years from Earth, and contains tens of thousands of solar masses of gas and dust. The most prominent cluster of T Tauri stars and young B-type stars are in the Chamaeleon I cloud, and are associated with the reflection nebula IC 2631.
Chamaeleon contains one planetary nebula, NGC 3195, which is fairly faint. It appears in a telescope at about the same apparent size as Jupiter.
In Chinese astronomy, the stars that form Chamaeleon were classified as the Little Dipper (小斗, "Xiǎodǒu") among the Southern Asterisms (近南極星區, "Jìnnánjíxīngōu") by Xu Guangqi. Chamaeleon is sometimes also called the Frying Pan in Australia.

</doc>
<doc id="6437" url="https://en.wikipedia.org/wiki?curid=6437" title="Cholesterol">
Cholesterol

Cholesterol (from the Ancient Greek "chole-" (bile) and "stereos" (solid), followed by the chemical suffix "-ol" for an alcohol) is an organic molecule. It is a sterol (or modified steroid), a type of liquid. Cholesterol is biosynthesized by all animal cells and is an essential structural component of animal cell membranes.
Cholesterol also serves as a precursor for the biosynthesis of steroid hormones, bile acid and vitamin D. Cholesterol is the principal sterol synthesized by all animals. In vertebrates, hepatic cells typically produce the greatest amounts. It is absent among prokaryotes (bacteria and archaea), although there are some exceptions, such as "Mycoplasma", which require cholesterol for growth.
François Poulletier de la Salle first identified cholesterol in solid form in gallstones in 1769. However, it was not until 1815 that chemist Michel Eugène Chevreul named the compound "cholesterine".
Cholesterol is essential for all animal life, with each cell capable of synthesizing it by way of a complex 37-step process. This begins with the mevalonate or HMG-CoA reductase pathway, the target of statin drugs, which encompasses the first 18 steps. This is followed by 19 additional steps to convert the resulting lanosterol into cholesterol.
A human male weighing 68 kg (150 lb) normally synthesizes about 1 gram (1,000 mg) of cholesterol per day, and his body contains about 35 g, mostly contained within the cell membranes. Typical daily cholesterol dietary intake for a man in the United States is 307 mg.
Most ingested cholesterol is esterified, which causes it to be poorly absorbed by the gut. The body also compensates for absorption of ingested cholesterol by reducing its own cholesterol synthesis. For these reasons, cholesterol in food, seven to ten hours after ingestion, has little, if any effect on concentrations of cholesterol in the blood. However, during the first seven hours after ingestion of cholesterol, as absorbed fats are being distributed around the body within extracellular water by the various lipoproteins (which transport all fats in the water outside cells), the concentrations increase.
Plants do not make cholesterol but manufacture phytosterols, chemically similar substances which can compete with cholesterol for reabsorption in the intestinal tract, thus potentially reducing cholesterol reabsorption. When intestinal lining cells absorb phytosterols, in place of cholesterol, they usually excrete the phytosterol molecules back into the GI tract, an important protective mechanism. The intake of naturally occurring phytosterols, which encompass plant sterols and stanols, ranges between ≈200–300 mg/day depending on eating habits. Specially designed vegetarian experimental diets have been produced yielding upwards of 700 mg/day.
Cholesterol, given that it composes about 30% of all animal cell membranes, is required to build and maintain membranes and modulates membrane fluidity over the range of physiological temperatures. The hydroxyl group of each cholesterol molecule interacts with water molecules surrounding the membrane, as do the polar heads of the membrane phospholipids and sphingolipids, while the bulky steroid and the hydrocarbon chain are embedded in the membrane, alongside the nonpolar fatty-acid chain of the other lipids. Through the interaction with the phospholipid fatty-acid chains, cholesterol increases membrane packing, which both alters membrane fluidity and maintains membrane integrity so that animal cells do not need to build cell walls (like plants and most bacteria). The membrane remains stable and durable without being rigid, allowing animal cells to change shape and animals to move.
The structure of the tetracyclic ring of cholesterol contributes to the fluidity of the cell membrane, as the molecule is in a "trans" conformation making all but the side chain of cholesterol rigid and planar. In this structural role, cholesterol also reduces the permeability of the plasma membrane to neutral solutes, hydrogen ions, and sodium ions.
Within the cell membrane, cholesterol also functions in intracellular transport, cell signaling and nerve conduction. Cholesterol is essential for the structure and function of invaginated caveolae and clathrin-coated pits, including caveola-dependent and clathrin-dependent endocytosis. The role of cholesterol in endocytosis of these types can be investigated by using methyl beta cyclodextrin (MβCD) to remove cholesterol from the plasma membrane.
Cholesterol regulates the biological process of substrate presentation and the enzymes that use substrate presentation as a mechanism of their activation. (PLD2) is a well-defined example of an enzyme activated by substrate presentation. The enzyme is palmitoylated causing the enzyme to traffic to cholesterol dependent lipid domains sometimes called "lipid rafts". The substrate of phospholipase D is phosphatidylcholine (PC) which is unsaturated and is of low abundance in lipid rafts. PC localizes to the disordered region of the cell along with the polyunsaturated lipid phosphatidylinositol 4,5-bisphosphate (PIP2). PLD2 has a PIP2 binding domain. When PIP2 concentration in the membrane increases, PLD2 leaves the cholesterol dependent domains and binds to PIP2 where it then gains access to its substrate PC and commences catalysis based on substrate presentation.
Cholesterol is also implicated in cell signaling processes, assisting in the formation of lipid rafts in the plasma membrane, which brings receptor proteins in close proximity with high concentrations of second messenger molecules. In multiple layers, cholesterol and phospholipids, both electrical insulators, can facilitate speed of transmission of electrical impulses along nerve tissue. For many neuron fibers, a myelin sheath, rich in cholesterol since it is derived from compacted layers of Schwann cell membrane, provides insulation for more efficient conduction of impulses. Demyelination (loss of some of these Schwann cells) is believed to be part of the basis for multiple sclerosis.
Cholesterol binds to and affects the gating of a number of ion channels such as the nicotinic acetylcholine receptor, GABA receptor, and the inward-rectifier potassium channel. Cholesterol also activates the estrogen-related receptor alpha (ERRα), and may be the endogenous ligand for the receptor. The constitutively active nature of the receptor may be explained by the fact that cholesterol is ubiquitous in the body. Inhibition of ERRα signaling by reduction of cholesterol production has been identified as a key mediator of the effects of statins and bisphosphonates on bone, muscle, and macrophages. On the basis of these findings, it has been suggested that the ERRα should be de-orphanized and classified as a receptor for cholesterol.
Within cells, cholesterol is also a precursor molecule for several biochemical pathways. For example, it is the precursor molecule for the synthesis of vitamin D in the calcium metabolism and all steroid hormones, including the adrenal gland hormones cortisol and aldosterone, as well as the sex hormones progesterone, estrogens, and testosterone, and their derivatives.
Cholesterol is recycled in the body. The liver excretes cholesterol into biliary fluids, which is then stored in the gallbladder, which then excretes it in a non-esterified form (via bile) into the digestive tract. Typically, about 50% of the excreted cholesterol is reabsorbed by the small intestine back into the bloodstream.
All animal cells manufacture cholesterol, for both membrane structure and other uses, with relative production rates varying by cell type and organ function. About 80% of total daily cholesterol production occurs in the liver and the intestines; other sites of higher synthesis rates include adrenal glands, and reproductive organs.
Synthesis within the body starts with the mevalonate pathway where two molecules of acetyl CoA condense to form acetoacetyl-CoA. This is followed by a second condensation between acetyl CoA and acetoacetyl-CoA to form 3-hydroxy-3-methylglutaryl CoA (HMG-CoA). 
This molecule is then reduced to mevalonate by the enzyme HMG-CoA reductase. Production of mevalonate is the rate-limiting and irreversible step in cholesterol synthesis and is the site of action for statins (a class of cholesterol-lowering drugs).
Mevalonate is finally converted to isopentenyl pyrophosphate (IPP) through two phosphorylation steps and one decarboxylation step that requires ATP.
Three molecules of isopentenyl pyrophosphate condense to form farnesyl pyrophosphate through the action of geranyl transferase.
Two molecules of farnesyl pyrophosphate then condense to form squalene by the action of squalene synthase in the endoplasmic reticulum. 
Oxidosqualene cyclase then cyclizes squalene to form lanosterol. Finally, lanosterol is converted to cholesterol through a 19-step process.
The final 19 steps to cholesterol contain NADPH and oxygen to help oxidize methyl groups for removal of carbons, mutases to move alkene groups, and NADH to help reduce ketones.
Konrad Bloch and Feodor Lynen shared the Nobel Prize in Physiology or Medicine in 1964 for their discoveries concerning some of the mechanisms and methods of regulation of cholesterol and fatty acid metabolism.
Biosynthesis of cholesterol is directly regulated by the cholesterol levels present, though the homeostatic mechanisms involved are only partly understood. A higher intake from food leads to a net decrease in endogenous production, whereas lower intake from food has the opposite effect. The main regulatory mechanism is the sensing of intracellular cholesterol in the endoplasmic reticulum by the protein SREBP (sterol regulatory element-binding protein 1 and 2). In the presence of cholesterol, SREBP is bound to two other proteins: SCAP (SREBP cleavage-activating protein) and INSIG-1. When cholesterol levels fall, INSIG-1 dissociates from the SREBP-SCAP complex, which allows the complex to migrate to the Golgi apparatus. Here SREBP is cleaved by S1P and S2P (site-1 protease and site-2 protease), two enzymes that are activated by SCAP when cholesterol levels are low.
The cleaved SREBP then migrates to the nucleus, and acts as a transcription factor to bind to the sterol regulatory element (SRE), which stimulates the transcription of many genes. Among these are the low-density lipoprotein (LDL) receptor and HMG-CoA reductase. The LDL receptor scavenges circulating LDL from the bloodstream, whereas HMG-CoA reductase leads to an increase of endogenous production of cholesterol. A large part of this signaling pathway was clarified by Dr. Michael S. Brown and Dr. Joseph L. Goldstein in the 1970s. In 1985, they received the Nobel Prize in Physiology or Medicine for their work. Their subsequent work shows how the SREBP pathway regulates expression of many genes that control lipid formation and metabolism and body fuel allocation.
Cholesterol synthesis can also be turned off when cholesterol levels are high. HMG-CoA reductase contains both a cytosolic domain (responsible for its catalytic function) and a membrane domain. The membrane domain senses signals for its degradation. Increasing concentrations of cholesterol (and other sterols) cause a change in this domain's oligomerization state, which makes it more susceptible to destruction by the proteosome. This enzyme's activity can also be reduced by phosphorylation by an AMP-activated protein kinase. Because this kinase is activated by AMP, which is produced when ATP is hydrolyzed, it follows that cholesterol synthesis is halted when ATP levels are low.
As an isolated molecule, cholesterol is only minimally soluble in water, or hydrophilic. Because of this, it dissolves in blood at exceedingly small concentrations. To be transported effectively, cholesterol is instead packaged within lipoproteins, complex discoidal particles with exterior amphiphilic proteins and lipids, whose outward-facing surfaces are water-soluble and inward-facing surfaces are lipid-soluble. This allows it to travel through the blood via emulsification. Unbound cholesterol, being amphipathic, is transported in the monolayer surface of the lipoprotein particle along with phospholipids and proteins. Cholesterol esters bound to fatty acid, on the other hand, are transported within the fatty hydrophilic core of the lipoprotein, along with triglyceride.
There are several types of lipoproteins in the blood. In order of increasing density, they are chylomicrons, very-low-density lipoprotein (VLDL), intermediate-density lipoprotein (IDL), low-density lipoprotein (LDL), and high-density lipoprotein (HDL). Lower protein/lipid ratios make for less dense lipoproteins. Cholesterol within different lipoproteins is identical, although some is carried as its native "free" alcohol form (the cholesterol-OH group facing the water surrounding the particles), while others as fatty acyl esters, known also as cholesterol esters, within the particles.
Lipoprotein particles are organized by complex apolipoproteins, typically 80–100 different proteins per particle, which can be recognized and bound by specific receptors on cell membranes, directing their lipid payload into specific cells and tissues currently ingesting these fat transport particles. These surface receptors serve as unique molecular signatures, which then help determine fat distribution delivery throughout the body.
Chylomicrons, the least dense cholesterol transport molecules, contain apolipoprotein B-48, apolipoprotein C, and apolipoprotein E (the principal cholesterol carrier in the brain) in their shells. Chylomicrons carry fats from the intestine to muscle and other tissues in need of fatty acids for energy or fat production. Unused cholesterol remains in more cholesterol-rich chylomicron remnants, and taken up from here to the bloodstream by the liver.
VLDL molecules are produced by the liver from triacylglycerol and cholesterol which was not used in the synthesis of bile acids. These molecules contain apolipoprotein B100 and apolipoprotein E in their shells, and can be degraded by lipoprotein lipase on the artery wall to IDL. This arterial wall cleavage allows absorption of triacylglycerol and increases concentration of circulating cholesterol. IDL molecules are then consumed in two processes: half is metabolized by HTGL and taken up by the LDL receptor on the liver cell surfaces, while the other half continues to lose triacylglycerols in the bloodstream until they become cholesterol laden LDL particles.
LDL particles are the major blood cholesterol carriers. Each one contains approximately 1,500 molecules of cholesterol ester. LDL molecule shells contain just one molecule of apolipoprotein B100, recognized by LDL receptors in peripheral tissues. Upon binding of apolipoprotein B100, many LDL receptors concentrate in clathrin-coated pits. Both LDL and its receptor form vesicles within a cell via endocytosis. These vesicles then fuse with a lysosome, where the lysosomal acid lipase enzyme hydrolyzes the cholesterol esters. The cholesterol can then be used for membrane biosynthesis or esterified and stored within the cell, so as to not interfere with the cell membranes.
LDL receptors are used up during cholesterol absorption, and its synthesis is regulated by SREBP, the same protein that controls the synthesis of cholesterol "de novo", according to its presence inside the cell. A cell with abundant cholesterol will have its LDL receptor synthesis blocked, to prevent new cholesterol in LDL molecules from being taken up. Conversely, LDL receptor synthesis proceeds when a cell is deficient in cholesterol.
When this process becomes unregulated, LDL molecules without receptors begin to appear in the blood. These LDL molecules are oxidized and taken up by macrophages, which become engorged and form foam cells. These foam cells often become trapped in the walls of blood vessels and contribute to atherosclerotic plaque formation. Differences in cholesterol homeostasis affect the development of early atherosclerosis (carotid intima-media thickness). These plaques are the main causes of heart attacks, strokes, and other serious medical problems, leading to the association of so-called LDL cholesterol (actually a lipoprotein) with "bad" cholesterol.
HDL particles are thought to transport cholesterol back to the liver, either for excretion or for other tissues that synthesize hormones, in a process known as reverse cholesterol transport (RCT). Large numbers of HDL particles correlates with better health outcomes, whereas low numbers of HDL particles is associated with atheromatous disease progression in the arteries.
Cholesterol is susceptible to oxidation and easily forms oxygenated derivatives called oxysterols. Three different mechanisms can form these: autoxidation, secondary oxidation to lipid peroxidation, and cholesterol-metabolizing enzyme oxidation. A great interest in oxysterols arose when they were shown to exert inhibitory actions on cholesterol biosynthesis. This finding became known as the “oxysterol hypothesis”. Additional roles for oxysterols in human physiology include their participation in bile acid biosynthesis, function as transport forms of cholesterol, and regulation of gene transcription.
In biochemical experiments radiolabelled forms of cholesterol, such as tritiated-cholesterol are used. These derivatives undergo degradation upon storage and it is essential to purify cholesterol prior to use. Cholesterol can be purified using small Sephadex LH-20 columns.
Cholesterol is oxidized by the liver into a variety of bile acids. These, in turn, are conjugated with glycine, taurine, glucuronic acid, or sulfate. A mixture of conjugated and nonconjugated bile acids, along with cholesterol itself, is excreted from the liver into the bile. Approximately 95% of the bile acids are reabsorbed from the intestines, and the remainder are lost in the feces. The excretion and reabsorption of bile acids forms the basis of the enterohepatic circulation, which is essential for the digestion and absorption of dietary fats. Under certain circumstances, when more concentrated, as in the gallbladder, cholesterol crystallises and is the major constituent of most gallstones (lecithin and bilirubin gallstones also occur, but less frequently). Every day, up to 1 g of cholesterol enters the colon. This cholesterol originates from the diet, bile, and desquamated intestinal cells, and can be metabolized by the colonic bacteria. Cholesterol is converted mainly into coprostanol, a nonabsorbable sterol that is excreted in the feces.
Although cholesterol is a steroid generally associated with mammals, the human pathogen "Mycobacterium tuberculosis" is able to completely degrade this molecule and contains a large number of genes that are regulated by its presence. Many of these cholesterol-regulated genes are homologues of fatty acid β-oxidation genes, but have evolved in such a way as to bind large steroid substrates like cholesterol.
Animal fats are complex mixtures of triglycerides, with lesser amounts of both the phospholipids and cholesterol molecules from which all animal (and human) cell membranes are constructed. Since all animal cells manufacture cholesterol, all animal-based foods contain cholesterol in varying amounts. Major dietary sources of cholesterol include red meat, egg yolks and whole eggs, liver, kidney, giblets, fish oil, and butter. Human breast milk also contains significant quantities of cholesterol.
Plant cells synthesize cholesterol as a precursor for other compounds, such as phytosterols and steroidal glycoalkaloids, with cholesterol remaining in plant foods only in minor amounts or absent. Some plant foods, such as avocado, flax seeds and peanuts, contain phytosterols, which compete with cholesterol for absorption in the intestines, reduce the absorption of both dietary and bile cholesterol. A typical diet contributes on the order of 0.2 gram of phytosterols, which is not enough to have a significant impact on blocking cholesterol absorption. Phytosterols intake can be supplemented through the use of phytosterol-containing functional foods or dietary supplements that are recognized as having potential to reduce levels of LDL-cholesterol.
Some supplemental guidelines have recommended doses of phytosterols in the 1.6–3.0 grams per day range (Health Canada, EFSA, ATP III, FDA). A recent meta-analysis demonstrating a 12% reduction in LDL-cholesterol at a mean dose of 2.1 grams per day. However, the benefits of a diet supplemented with phytosterols have been questioned.
In 2016, the United States Department of Agriculture Dietary Guidelines Advisory Committee recommended that Americans eat as little dietary cholesterol as possible. However, dietary cholesterol has little impact on blood cholesterol level in about 60% of people, and recent meta-analysis questioned the rigor of previous research on the effect of dietary cholesterol on cardiovascular disease risk. It is worth noting that most foods that are rich in cholesterol are also high in saturated fat and thereby may increase the risk of cardiovascular disease. Increased dietary intake of industrial trans fats is associated with an increased risk in all-cause mortality and cardiovascular diseases. Trans fats have been shown to correlate with reduced levels of HDL and increased levels of LDL. Based on this evidence, along with other claims implicating low HDL and high LDL levels in cardiovascular disease, many health authorities advocate reducing LDL-cholesterol through changes in diet in addition to other lifestyle modifications.
The related studies which correlate trans fats, as well as saturated fats, with unhealthy serum cholesterol levels, have since been contested on numerous points. The most notable challenge to these standards comes from a NCBI published meta analysis of the data used in the development of these guidelines, in which the correlation between serum cholesterol and saturated fat intake, was similarly or less significant than the correlation to visceral fat. As well as others, one of which concluded that current evidence "does not clearly support cardiovascular guidelines that encourage high consumption of polyunsaturated fatty acids and low consumption of total saturated fats." Other evidences such as metabolic ward and lab studies, including a study where rats subjected to high-fat or fructose diets became dyslipidemic are similarly questionable, given indications of an increase of produced visceral fat, which occurs as a result of metabolic differences in the processing of fructose. A general inconsistency of conclusions regarding the impact of simple carbohydrates on visceral fat, and a lack of data regarding the causal relationship between serum cholesterol and either saturated fat and visceral fat, makes drawing a definitive conclusion unreasonable, especially given the presence of numerous correlations. As such, given that well designed, adequately powered randomized controlled trials investigating patient-relevant outcomes of low-fat diets for otherwise healthy people with hypercholesterolaemia are lacking; large, parallel, randomized controlled trials are still needed to investigate the effectiveness of a cholesterol-lowering diet and the addition of omega-3 fatty acids, soya protein, plant sterols or stanols, especially in the case of familial hypercholesterolemia.
According to the lipid hypothesis, elevated levels of cholesterol in the blood lead to atherosclerosis which may increase the risk of heart attack, stroke, and peripheral artery disease. Since higher blood LDL – especially higher LDL concentrations and smaller LDL particle size – contributes to this process more than the cholesterol content of the HDL particles, LDL particles are often termed "bad cholesterol". High concentrations of functional HDL, which can remove cholesterol from cells and atheromas, offer protection and are commonly referred to as "good cholesterol". These balances are mostly genetically determined, but can be changed by body composition, medications, diet, and other factors. A 2007 study demonstrated that blood total cholesterol levels have an exponential effect on cardiovascular and total mortality, with the association more pronounced in younger subjects. Because cardiovascular disease is relatively rare in the younger population, the impact of high cholesterol on health is larger in older people.
Elevated levels of the lipoprotein fractions, LDL, IDL and VLDL, rather than the total cholesterol level, correlate with the extent and progress of atherosclerosis. Conversely, the total cholesterol can be within normal limits, yet be made up primarily of small LDL and small HDL particles, under which conditions atheroma growth rates are high. A "post hoc" analysis of the IDEAL and the EPIC prospective studies found an association between high levels of HDL cholesterol (adjusted for apolipoprotein A-I and apolipoprotein B) and increased risk of cardiovascular disease, casting doubt on the cardioprotective role of "good cholesterol".
One in 250 adults can have a genetic mutation for the LDL cholesterol receptor that causes them to have familial hypercholerolemia. Inherited high cholesterol can also include genetic mutations in the PCSK9 gene and the gene for apolipoprotein B.
Elevated cholesterol levels are treated with a strict diet consisting of low saturated fat, trans fat-free, low cholesterol foods, often followed by one of various hypolipidemic agents, such as statins, fibrates, cholesterol absorption inhibitors, nicotinic acid derivatives or bile acid sequestrants. There are several international guidelines on the treatment of hypercholesterolaemia.
Human trials using HMG-CoA reductase inhibitors, known as statins, have repeatedly confirmed that changing lipoprotein transport patterns from unhealthy to healthier patterns significantly lowers cardiovascular disease event rates, even for people with cholesterol values currently considered low for adults. Studies have shown that reducing LDL cholesterol levels by about 38.7 mg/dL with the use of statins can reduce cardiovascular disease and stroke risk by about 21%. Studies have also found that statins reduce atheroma progression. As a result, people with a history of cardiovascular disease may derive benefit from statins irrespective of their cholesterol levels (total cholesterol below 5.0 mmol/L [193 mg/dL]), and in men without cardiovascular disease, there is benefit from lowering abnormally high cholesterol levels ("primary prevention"). Primary prevention in women was originally practiced only by extension of the findings in studies on men, since, in women, none of the large statin trials conducted prior to 2007 demonstrated a significant reduction in overall mortality or in cardiovascular endpoints. Meta-analyses have demonstrated significant reductions in all-cause and cardiovascular mortality, without significant heterogeneity by sex.
The 1987 report of National Cholesterol Education Program, Adult Treatment Panels suggests the total blood cholesterol level should be: < 200 mg/dL normal blood cholesterol, 200–239 mg/dL borderline-high, > 240 mg/dL high cholesterol. The American Heart Association provides a similar set of guidelines for total (fasting) blood cholesterol levels and risk for heart disease: Statins are effective in lowering LDL cholesterol and widely used for primary prevention in people at high risk of cardiovascular disease, as well as in secondary prevention for those who have developed cardiovascular disease.
More current testing methods determine LDL ("bad") and HDL ("good") cholesterol separately, allowing cholesterol analysis to be more nuanced. The desirable LDL level is considered to be less than 130 mg/dL (2.6 mmol/L), although a newer upper limit of 70 mg/dL (1.8 mmol/L) can be considered in higher-risk individuals based on some of the above-mentioned trials. A ratio of total cholesterol to HDL—another useful measure—of far less than 5:1 is thought to be healthier.
Total cholesterol is defined as the sum of HDL, LDL, and VLDL. Usually, only the total, HDL, and triglycerides are measured. For cost reasons, the VLDL is usually estimated as one-fifth of the triglycerides and the LDL is estimated using the Friedewald formula (or a variant): estimated LDL = [total cholesterol] − [total HDL] − [estimated VLDL]. VLDL can be calculated by dividing total triglycerides by five. Direct LDL measures are used when triglycerides exceed 400 mg/dL. The estimated VLDL and LDL have more error when triglycerides are above 400 mg/dL.
In the Framingham Heart Study, in subjects over 50 years of age, they found an 11% increase overall and 14% increase in cardiovascular disease mortality per 1 mg/dL per year drop in total cholesterol levels. The researchers attributed this phenomenon to the fact that people with severe chronic diseases or cancer tend to have below-normal cholesterol levels. This explanation is not supported by the Vorarlberg Health Monitoring and Promotion Programme, in which men of all ages and women over 50 with very low cholesterol were likely to die of cancer, liver diseases, and mental diseases. This result indicates the low-cholesterol effect occurs even among younger respondents, contradicting the previous assessment among cohorts of older people that this is a proxy or marker for frailty occurring with age.
Although there is a link between cholesterol and atherosclerosis as discussed above, a 2014 review concluded there is insufficient evidence to support the recommendation of high consumption of polyunsaturated fatty acids and low consumption of total saturated fats for cardiovascular health. A 2016 review concluded that HDL cholesterol was inversely linked to mortality in people over age 60 years, and there was either no link between LDL and mortality, or that lower LDL was linked to a higher mortality risk, especially in older adults.
Abnormally low levels of cholesterol are termed "hypocholesterolemia". Research into the causes of this state is relatively limited, but some studies suggest a link with depression, cancer, and cerebral hemorrhage. In general, the low cholesterol levels seem to be a consequence, rather than a cause, of an underlying illness. A genetic defect in cholesterol synthesis causes Smith–Lemli–Opitz syndrome, which is often associated with low plasma cholesterol levels. Hyperthyroidism, or any other endocrine disturbance which causes upregulation of the LDL receptor, may result in hypocholesterolemia.
The American Heart Association recommends testing cholesterol every 4–6 years for people aged 20 years or older. A separate set of American Heart Association guidelines issued in 2013 indicates that patients taking statin medications should have their cholesterol tested 4–12 weeks after their first dose and then every 3–12 months thereafter.
A blood sample after 12-hour fasting is taken by a doctor, or a home cholesterol-monitoring device is used to measure a lipid profile, an approach used to estimate a person's lipoproteins, the vastly more important issue because lipoproteins have always been concordant with outcomes though the lipid profile is commonly discordant LDL Particle Number and Risk of Future Cardiovascular Disease in the Framingham Offspring Study.
The lipid profile measures: (a) total cholesterol, (b) cholesterol associated with HDL (i.e. Higher Density {than water} Lipids-transported-within-proteins) particles ("which can regress arterial disease"), (c) triglycerides and (d) (by a calculation and assumptions) cholesterol carried by LDL (i.e. Lower Density {than water} Lipids-transported-within-proteins) particles ("which drive arterial disease").
It is recommended to test cholesterol at least every five years if a person has total cholesterol of 5.2 mmol/L or more (200+ mg/dL), or if a man over age 45 or a woman over age 50 has HDL-C values less than 1 mmol/L (40 mg/dL), or there are other drivers heart disease and stroke. Additional drivers of heart disease include diabetes mellitus, hypertension (or use of anti-hypertensive medication), low HDL level, family history of coronary artery disease (CAD) and hypercholesterolemia, and cigarette smoking.
Some cholesterol derivatives (among other simple cholesteric lipids) are known to generate the liquid crystalline "cholesteric phase". The cholesteric phase is, in fact, a chiral nematic phase, and it changes colour when its temperature changes. This makes cholesterol derivatives useful for indicating temperature in liquid-crystal display thermometers and in temperature-sensitive paints.
Cholesterol has 256 stereoisomers that arise from its 8 stereocenters, although only two of the stereoisomers are of biochemical significance ("nat"-cholesterol and "ent"-cholesterol, for "natural" and "enantiomer", respectively), and only one occurs naturally ("nat"-cholesterol).

</doc>
<doc id="6438" url="https://en.wikipedia.org/wiki?curid=6438" title="Chromosome">
Chromosome

A chromosome is a long DNA molecule with part or all of the genetic material of an organism. Most eukaryotic chromosomes include packaging proteins which, aided by chaperone proteins, bind to and condense the DNA molecule to maintain its integrity. These chromosomes display a complex three-dimensional structure, which plays a significant role in transcriptional regulation.
Chromosomes are normally visible under a light microscope only during the metaphase of cell division (where all chromosomes are aligned in the center of the cell in their condensed form). Before this happens, each chromosome is duplicated (S phase), and both copies are joined by a centromere, resulting either in an X-shaped structure (pictured here), if the centromere is located equatorially, or a two-arm structure, if the centromere is located distally. The joined copies are now called sister chromatids. During metaphase the X-shaped structure is called a metaphase chromosome, which is highly condensed and thus easiest to distinguish and study. In animal cells, chromosomes reach their highest compaction level in anaphase during chromosome segregation.
Chromosomal recombination during meiosis and subsequent sexual reproduction play a significant role in genetic diversity. If these structures are manipulated incorrectly, through processes known as chromosomal instability and translocation, the cell may undergo mitotic catastrophe. Usually, this will make the cell initiate apoptosis leading to its own death, but sometimes mutations in the cell hamper this process and thus cause progression of cancer.
Some use the term chromosome in a wider sense, to refer to the individualized portions of chromatin in cells, either visible or not under light microscopy. Others use the concept in a narrower sense, to refer to the individualized portions of chromatin during cell division, visible under light microscopy due to high condensation.
The word "chromosome" () comes from the Greek ("chroma", "colour") and ("soma", "body"), describing their strong staining by particular dyes. The term was coined by the German scientist von Waldeyer-Hartz, referring to the term chromatin, which was introduced by Walther Flemming, the discoverer of cell division.
Some of the early karyological terms have become outdated. For example, Chromatin (Flemming 1880) and Chromosom (Waldeyer 1888), both ascribe color to a non-colored state.
The German scientists Schleiden, Virchow and Bütschli were among the first scientists who recognized the structures now familiar as chromosomes.
In a series of experiments beginning in the mid-1880s, Theodor Boveri gave definitive contributions to elucidating that chromosomes are the vectors of heredity, with two notions that became known as ‘chromosome continuity’ and ‘chromosome individuality’. 
Wilhelm Roux suggested that each chromosome carries a different genetic configuration, and Boveri was able to test and confirm this hypothesis. Aided by the rediscovery at the start of the 1900s of Gregor Mendel's earlier work, Boveri was able to point out the connection between the rules of inheritance and the behaviour of the chromosomes. Boveri influenced two generations of American cytologists: Edmund Beecher Wilson, Nettie Stevens, Walter Sutton and Theophilus Painter were all influenced by Boveri (Wilson, Stevens, and Painter actually worked with him).
In his famous textbook "The Cell in Development and Heredity", Wilson linked together the independent work of Boveri and Sutton (both around 1902) by naming the chromosome theory of inheritance the Boveri–Sutton chromosome theory (the names are sometimes reversed). Ernst Mayr remarks that the theory was hotly contested by some famous geneticists: William Bateson, Wilhelm Johannsen, Richard Goldschmidt and T.H. Morgan, all of a rather dogmatic turn of mind. Eventually, complete proof came from chromosome maps in Morgan's own lab.
The number of human chromosomes was published in 1923 by Theophilus Painter. By inspection through the microscope, he counted 24 pairs, which would mean 48 chromosomes. His error was copied by others and it was not until 1956 that the true number, 46, was determined by Indonesia-born cytogeneticist Joe Hin Tjio.
The prokaryotes – bacteria and archaea – typically have a single circular chromosome, but many variations exist. The chromosomes of most bacteria, which some authors prefer to call genophores, can range in size from only 130,000 base pairs in the endosymbiotic bacteria "Candidatus Hodgkinia cicadicola" and "Candidatus Tremblaya princeps", to more than 14,000,000 base pairs in the soil-dwelling bacterium "Sorangium cellulosum". Spirochaetes of the genus "Borrelia" are a notable exception to this arrangement, with bacteria such as "Borrelia burgdorferi", the cause of Lyme disease, containing a single "linear" chromosome.
Prokaryotic chromosomes have less sequence-based structure than eukaryotes. Bacteria typically have a one-point (the origin of replication) from which replication starts, whereas some archaea contain multiple replication origins. The genes in prokaryotes are often organized in operons, and do not usually contain introns, unlike eukaryotes.
Prokaryotes do not possess nuclei. Instead, their DNA is organized into a structure called the nucleoid. The nucleoid is a distinct structure and occupies a defined region of the bacterial cell. This structure is, however, dynamic and is maintained and remodeled by the actions of a range of histone-like proteins, which associate with the bacterial chromosome. In archaea, the DNA in chromosomes is even more organized, with the DNA packaged within structures similar to eukaryotic nucleosomes.
Certain bacteria also contain plasmids or other extrachromosomal DNA. These are circular structures in the cytoplasm that contain cellular DNA and play a role in horizontal gene transfer. In prokaryotes (see nucleoids) and viruses, the DNA is often densely packed and organized; in the case of archaea, by homology to eukaryotic histones, and in the case of bacteria, by histone-like proteins.
Bacterial chromosomes tend to be tethered to the plasma membrane of the bacteria. In molecular biology application, this allows for its isolation from plasmid DNA by centrifugation of lysed bacteria and pelleting of the membranes (and the attached DNA).
Prokaryotic chromosomes and plasmids are, like eukaryotic DNA, generally supercoiled. The DNA must first be released into its relaxed state for access for transcription, regulation, and replication.
Each eukaryotic chromosome consist on a long linear DNA molecule associated with proteins, forming a compact complex of proteins and DNA called "chromatin." Chromatin contains the vast majority of the DNA of an organism, but a small amount inherited maternally, can be found in the mitochondria. It is present in most cells, with a few exceptions, for example, red blood cells.
Histones are responsible for the first and most basic unit of chromosome organization, the nucleosome.
Eukaryotes (cells with nuclei such as those found in plants, fungi, and animals) possess multiple large linear chromosomes contained in the cell's nucleus. Each chromosome has one centromere, with one or two arms projecting from the centromere, although, under most circumstances, these arms are not visible as such. In addition, most eukaryotes have a small circular mitochondrial genome, and some eukaryotes may have additional small circular or linear cytoplasmic chromosomes.
In the nuclear chromosomes of eukaryotes, the uncondensed DNA exists in a semi-ordered structure, where it is wrapped around histones (structural proteins), forming a composite material called chromatin.
The packaging of DNA into nucleosomes causes a 10 nanometer fibre which may further condense up to 30 nm fibres Most of the euchromatin in interphase nuclei appears to be in the form of 30-nm fibers. Chromatin structure is the more decondensed state, i.e. the 10-nm conformation allows transcription.
During interphase (the period of the cell cycle where the cell is not dividing), two types of chromatin can be distinguished:
In the early stages of mitosis or meiosis (cell division), the chromatin double helix become more and more condensed. They cease to function as accessible genetic material (transcription stops) and become a compact transportable form. The loops of 30-nm chromatin fibers are thought to fold upon themselves further to form the compact metaphase chromosomes of mitotic cells. The DNA is thus condense about 10,000 folds. 
Chromosome scaffold, which is made of proteins such as condensin, TOP2A and KIF4, play an important role in holding the chromatin into compact chromosome. Loops of 30 nm structure further condense with scaffold into higher order structures. 
This highly compact form makes the individual chromosomes visible, and they form the classic four arm structure, a pair of sister chromatids attached to each other at the centromere. The shorter arms are called "p arms" (from the French "petit", small) and the longer arms are called "q arms" ("q" follows "p" in the Latin alphabet; q-g "grande"; alternatively it is sometimes said q is short for "queue" meaning tail in French). This is the only natural context in which individual chromosomes are visible with an optical microscope.
Mitotic metaphase chromosomes are best described by a linearly organized longitudinally compressed array of consecutive chromatin loops.
During mitosis, microtubules grow from centrosomes located at opposite ends of the cell and also attach to the centromere at specialized structures called kinetochores, one of which is present on each sister chromatid. A special DNA base sequence in the region of the kinetochores provides, along with special proteins, longer-lasting attachment in this region. The microtubules then pull the chromatids apart toward the centrosomes, so that each daughter cell inherits one set of chromatids. Once the cells have divided, the chromatids are uncoiled and DNA can again be transcribed. In spite of their appearance, chromosomes are structurally highly condensed, which enables these giant DNA structures to be contained within a cell nucleus.
Chromosomes in humans can be divided into two types: autosomes (body chromosome(s)) and allosome (sex chromosome(s)). Certain genetic traits are linked to a person's sex and are passed on through the sex chromosomes. The autosomes contain the rest of the genetic hereditary information. All act in the same way during cell division. Human cells have 23 pairs of chromosomes (22 pairs of autosomes and one pair of sex chromosomes), giving a total of 46 per cell. In addition to these, human cells have many hundreds of copies of the mitochondrial genome. Sequencing of the human genome has provided a great deal of information about each of the chromosomes. Below is a table compiling statistics for the chromosomes, based on the Sanger Institute's human genome information in the Vertebrate Genome Annotation (VEGA) database. Number of genes is an estimate, as it is in part based on gene predictions. Total chromosome length is an estimate as well, based on the estimated size of unsequenced heterochromatin regions.
These tables give the total number of chromosomes (including sex chromosomes) in a cell nucleus. For example, most eukaryotes are diploid, like humans who have 22 different types of autosomes, each present as two homologous pairs, and two sex chromosomes. This gives 46 chromosomes in total. Other organisms have more than two copies of their chromosome types, such as bread wheat, which is "hexaploid" and has six copies of seven different chromosome types – 42 chromosomes in total.
Normal members of a particular eukaryotic species all have the same number of nuclear chromosomes (see the table). Other eukaryotic chromosomes, i.e., mitochondrial and plasmid-like small chromosomes, are much more variable in number, and there may be thousands of copies per cell.
Asexually reproducing species have one set of chromosomes that are the same in all body cells. However, asexual species can be either haploid or diploid.
Sexually reproducing species have somatic cells (body cells), which are diploid [2n] having two sets of chromosomes (23 pairs in humans with one set of 23 chromosomes from each parent), one set from the mother and one from the father. Gametes, reproductive cells, are haploid [n]: They have one set of chromosomes. Gametes are produced by meiosis of a diploid germ line cell. During meiosis, the matching chromosomes of father and mother can exchange small parts of themselves (crossover), and thus create new chromosomes that are not inherited solely from either parent. When a male and a female gamete merge (fertilization), a new diploid organism is formed.
Some animal and plant species are polyploid [Xn]: They have more than two sets of homologous chromosomes. Plants important in agriculture such as tobacco or wheat are often polyploid, compared to their ancestral species. Wheat has a haploid number of seven chromosomes, still seen in some cultivars as well as the wild progenitors. The more-common pasta and bread wheat types are polyploid, having 28 (tetraploid) and 42 (hexaploid) chromosomes, compared to the 14 (diploid) chromosomes in the wild wheat.
Prokaryote species generally have one copy of each major chromosome, but most cells can easily survive with multiple copies. For example, "Buchnera", a symbiont of aphids has multiple copies of its chromosome, ranging from 10–400 copies per cell. However, in some large bacteria, such as "Epulopiscium fishelsoni" up to 100,000 copies of the chromosome can be present. Plasmids and plasmid-like small chromosomes are, as in eukaryotes, highly variable in copy number. The number of plasmids in the cell is almost entirely determined by the rate of division of the plasmid – fast division causes high copy number.
In general, the karyotype is the characteristic chromosome complement of a eukaryote species. The preparation and study of karyotypes is part of cytogenetics.
Although the replication and transcription of DNA is highly standardized in eukaryotes, "the same cannot be said for their karyotypes", which are often highly variable. There may be variation between species in chromosome number and in detailed organization.
In some cases, there is significant variation within species. Often there is:
Also, variation in karyotype may occur during development from the fertilized egg.
The technique of determining the karyotype is usually called "karyotyping". Cells can be locked part-way through division (in metaphase) in vitro (in a reaction vial) with colchicine. These cells are then stained, photographed, and arranged into a "karyogram", with the set of chromosomes arranged, autosomes in order of length, and sex chromosomes (here X/Y) at the end.
Like many sexually reproducing species, humans have special gonosomes (sex chromosomes, in contrast to autosomes). These are XX in females and XY in males. 
Investigation into the human karyotype took many years to settle the most basic question: "How many chromosomes does a normal diploid human cell contain?" In 1912, Hans von Winiwarter reported 47 chromosomes in spermatogonia and 48 in oogonia, concluding an XX/XO sex determination mechanism. Painter in 1922 was not certain whether the diploid number of man is 46 or 48, at first favouring 46. He revised his opinion later from 46 to 48, and he correctly insisted on humans having an XX/XY system.
New techniques were needed to definitively solve the problem:
It took until 1954 before the human diploid number was confirmed as 46. Considering the techniques of Winiwarter and Painter, their results were quite remarkable. Chimpanzees, the closest living relatives to modern humans, have 48 chromosomes as do the other great apes: in humans two chromosomes fused to form chromosome 2.
Chromosomal aberrations are disruptions in the normal chromosomal content of a cell and are a major cause of genetic conditions in humans, such as Down syndrome, although most aberrations have little to no effect. Some chromosome abnormalities do not cause disease in carriers, such as translocations, or chromosomal inversions, although they may lead to a higher chance of bearing a child with a chromosome disorder. Abnormal numbers of chromosomes or chromosome sets, called aneuploidy, may be lethal or may give rise to genetic disorders. Genetic counseling is offered for families that may carry a chromosome rearrangement.
The gain or loss of DNA from chromosomes can lead to a variety of genetic disorders. Human examples include:
Exposure of males to certain lifestyle, environmental and/or occupational hazards may increase the risk of aneuploid spermatozoa. In particular, risk of aneuploidy is increased by tobacco smoking, and occupational exposure to benzene, insecticides, and perfluorinated compounds. Increased aneuploidy is often associated with increased DNA damage in spermatozoa.

</doc>
<doc id="6439" url="https://en.wikipedia.org/wiki?curid=6439" title="Charge">
Charge

Charge or charged may refer to:

</doc>
<doc id="6440" url="https://en.wikipedia.org/wiki?curid=6440" title="Colonna family">
Colonna family

The Colonna family, also known as Sciarrillo or Sciarra, is an Italian noble family, forming part of the papal nobility. It was powerful in medieval and Renaissance Rome, supplying one Pope (Martin V) and many other church and political leaders. The family is notable for its bitter feud with the Orsini family over influence in Rome, until it was stopped by Papal Bull in 1511. In 1571, the heads of both families married nieces of Pope Sixtus V. Thereafter, historians recorded that "no peace had been concluded between the princes of Christendom, in which they had not been included by name".
According to tradition, the Colonna family is a branch of the Counts of Tusculum — by Peter (1099–1151) son of Gregory III, called Peter "de Columna" from his property the Columna Castle in Colonna, Alban Hills. Further back, they trace their lineage past the Counts of Tusculum via Lombard and Italo-Roman nobles, merchants, and clergy through the Early Middle Ages — ultimately claiming origins from the Julio-Claudian dynasty.
The first cardinal from the family was appointed in 1206, when Giovanni Colonna di Carbognano was made Cardinal Deacon of SS. Cosma e Damiano. For many years, Cardinal Giovanni di San Paolo (elevated in 1193) was identified as a member of the Colonna family and therefore its first representative in the College of Cardinals, but modern scholars have established that this was based on false information from the beginning of the 16th century.
Giovanni Colonna (born c. 1206) nephew of Cardinal Giovanni Colonna di Carbognano, made his solemn vows as a Dominican around 1228 and received his theological and philosophical training at the Roman "studium" of Santa Sabina, the forerunner of the Pontifical University of Saint Thomas Aquinas, "Angelicum". He served as the Provincial of the Roman province of the Dominican Order and led the provincial chapter of 1248 at Anagni. Colonna was appointed as Archbishop of Messina in 1255.
Margherita Colonna (died 1248) was a member of the Franciscan Order. She was beatified by Pope Pius IX in 1848.
At this time, a rivalry began with the pro-papal Orsini family, leaders of the Guelph faction. This reinforced the pro-Emperor Ghibelline course that the Colonna family followed throughout the period of conflict between the Papacy and the Holy Roman Empire.
In 1297, Cardinal Jacopo (Giacomo Colonna) disinherited his brothers Ottone, Matteo, and Landolfo of their lands. The latter three appealed to Pope Boniface VIII, who ordered Jacopo to return the land, and furthermore hand over the family's strongholds of Colonna, Palestrina, and other towns to the Papacy. Jacopo refused; in May, Boniface removed him from the College of Cardinals and excommunicated him and his followers.
The Colonna family (aside from the three brothers allied with the Pope) declared that Boniface had been elected illegally following the unprecedented abdication of Pope Celestine V. The dispute led to open warfare, and in September, Boniface appointed Landolfo to the command of his army, to put down the revolt of Landolfo's own Colonna relatives. By the end of 1298, Landolfo had captured Colonna, Palestrina and other towns, and razed them to the ground. The family's lands were distributed among Landolfo and his loyal brothers; the rest of the family fled Italy.
The exiled Colonnas allied with the Pope's other great enemy, Philip IV of France, who in his youth had been tutored by Cardinal Egidio Colonna. In September 1303, Sciarra and Philipp's advisor, Guillaume de Nogaret, led a small force into Anagni to arrest Boniface VIII and bring him to France, where he was to stand trial. The two managed to apprehend the pope, and Sciarra reportedly slapped the pope in the face in the process, which was accordingly dubbed the "Outrage of Anagni". The attempt eventually failed after a few days, when locals freed the pope. However, Boniface VIII died on 11 October, allowing France to dominate his weaker successors during the Avignon papacy.
The family remained at the centre of civic and religious life throughout the late Middle Ages. Cardinal Egidio Colonna died at the papal court in Avignon in 1314. An Augustinian, he had studied theology in Paris under St. Thomas of Aquinas to become one of the most authoritative thinkers of his time.
In the 14th century, the family sponsored the decoration of the Church of San Giovanni, most notably the floor mosaics.
In 1328, Louis IV of Germany marched into Italy for his coronation as Holy Roman Emperor. As Pope John XXII was residing in Avignon and had publicly declared that he would not crown Louis, the King decided to be crowned by a member of the Roman aristocracy, who proposed Sciarra Colonna. In honor of this event, the Colonna family was granted the privilege of using the imperial pointed crown on top of their coat of arms.
The celebrated poet Petrarch, was a great friend of the family, in particular of Giovanni Colonna and often lived in Rome as a guest of the family. He composed a number of sonnets for special occasions within the Colonna family, including "Colonna the Glorious, the great Latin name upon which all our hopes rest". In this period, the Colonna started claiming they were descendants of the Julio-Claudian dynasty.
At the Council of Constance, the Colonna finally succeeded in their papal ambitions when Oddone Colonna was elected on 14 November 1417. As Martin V, he reigned until his death on 20 February 1431.
Vittoria Colonna became famous in the sixteenth century as a poet and a figure in literate circles.
In 1627 Anna Colonna, daughter of Filippo I Colonna, married Taddeo Barberini of the family Barberini; nephew of Pope Urban VIII.
In 1728, the Carbognano branch (Colonna di Sciarra) of the Colonna family added the name Barberini to its family name when Giulio Cesare Colonna di Sciarra married Cornelia Barberini, daughter of the last male Barberini to hold the name and granddaughter of Maffeo Barberini (son of Taddeo Barberini).
The Colonna family have been Prince Assistants to the Papal Throne since 1710, though their papal princely title only dates from 1854.
The family residence in Rome, the Palazzo Colonna, is open to the public every Saturday morning.
The main 'Colonna di Paliano' line is represented today by Prince Marcantonio Colonna di Paliano, Prince and Duke of Paliano (b. 1948), whose heir is Don Giovanni Andrea Colonna di Paliano (b. 1975), and by Don Prospero Colonna di Paliano, Prince of Avella (b. 1956), whose heir is Don Filippo Colonna di Paliano (b. 1995).
The 'Colonna di Stigliano' line is represented by Don Prospero Colonna di Stigliano, Prince of Stigliano (b. 1938), whose heir is his nephew Don Stefano Colonna di Stigliano (b. 1975). 

</doc>
<doc id="6443" url="https://en.wikipedia.org/wiki?curid=6443" title="Ceuta">
Ceuta

Ceuta (, , ; ; ) is a Spanish autonomous city on the north coast of Africa.
Bordered by Morocco, it lies along the boundary between the Mediterranean Sea and the Atlantic Ocean and is one of nine populated Spanish territories in Africa and, along with Melilla, one of two populated Spanish territories on mainland Africa. It was part of province of Cádiz until 14 March 1995. On that date Statutes of Autonomy were passed for both Ceuta and Melilla.
Ceuta, like Melilla and the Canary Islands, was classified as a free port before Spain joined the European Union. Its population consists of Christians, Muslims and small minorities of Sephardic Jews and ethnic Sindhi Hindus from modern-day Pakistan.
Spanish is the official language. Darija Arabic is also spoken by the 40–50% of the population who are of Moroccan origin.
The name Abyla has been said to have been a Punic name ("Lofty Mountain" or "Mountain of God") for Jebel Musa, the southern Pillar of Hercules. The name of the mountain was in fact "Habenna" (, , "Stone" or "Stele") or "ʾAbin-ḥīq" (, , "Rock of the Bay"), in reference to the nearby Bay of Benzú. The name was hellenized variously as "Ápini" (), "Abýla" (), "Abýlē" (), "Ablýx" (), and "Abílē Stḗlē" (, "Pillar of Abyla") and in Latin as Mount Abyla (') or the Pillar of Abyla (').
The settlement below Jebel Musa was later renamed for the seven hills around the site, collectively referred to as the "Seven Brothers" (; ). In particular, the Roman stronghold at the site took the name "Fort at the Seven Brothers" (). This was gradually shortened to Septem ( "Sépton") or, occasionally, Septum or Septa. These clipped forms continued as Berber "Sebta" and Arabic "Sabtan" or "Sabtah" (), which themselves became in Portuguese () and Spanish ().
Controlling access between the Atlantic Ocean and the Mediterranean Sea, the Strait of Gibraltar is an important military and commercial chokepoint. The Phoenicians realized the extremely narrow isthmus joining the Peninsula of Almina to the African mainland makes Ceuta eminently defensible and established an outpost there in the early 1st millenniumBC. The Greek geographers record it by variations of "Abyla", the ancient name of nearby Jebel Musa. Beside Calpe, the other Pillar of Hercules now known as the Rock of Gibraltar, the Phoenicians established Kart at what is now San Roque, Spain. Other good anchorages nearby became Phoenician and then Carthaginian ports at what are now Tangiers and Cadiz.
After Carthage's destruction in the Punic Wars, most of northwest Africa was left to the Roman client states of Numidia andaround AbylaMauretania. Punic culture continued to thrive in what the Romans knew as "Septem". After the Battle of Thapsus in 46 BC, Caesar and his heirs began annexing north Africa directly as Roman provinces but, as late as Augustus, most of Septem's Berber residents continued to speak and write in Punic.
Caligula assassinated the Mauretanian king Ptolemy in AD40 and seized his kingdom, which Claudius organized in AD 42, placing Septem in the province of Tingitana and raising it to the level of a colony. It subsequently romanized and thrived into the late 3rd century, trading heavily with Roman Spain and becoming well known for its salted fish. Roads connected it overland with Tingis (Tangiers) and Volubilis. Under in the late 4th century, Septem still had 10,000 inhabitants, nearly all Christian citizens speaking Latin and African Romance.
Vandals, probably invited by Count Boniface as protection against the empress dowager, crossed the strait near Tingis around 425 and swiftly overran Roman North Africa. Their king Gaiseric focused his attention on the rich lands around Carthage; although the Romans eventually accepted his conquests and he continued to raid them anyway, he soon lost control of Tingis and Septem in a series of Berber revolts. When Justinian decided to reconquer the Vandal lands, his victorious general Belisarius continued along the coast, making Septem an outpost of the Byzantine Empire around 533. Unlike the Roman administration, however, the Byzantines did not push far into hinterland and made the more defensible Septem their regional capital in place of Tingis.
Epidemics, less capable successors, and overstretched supply lines forced a retrenchment and left Septem isolated. It is likely that its count ("") was obliged to pay homage to the Visigoth Kingdom in Spain in the early 7th century. There are no reliable contemporary accounts of the end of the Islamic conquest of the Maghreb around 710. Instead, the rapid Muslim conquest of Spain produced romances concerning Count Julian of Septem and his betrayal of Christendom in revenge for the dishonor that befell his daughter at King Roderick's court. Allegedly with Julian's encouragement and instructions, the Berber convert and freedman Tariq ibn Ziyad took his garrison from Tangiers across the strait and overran the Spanish so swiftly that both he and his master Musa bin Nusayr fell afoul of a jealous caliph, who stripped them of their wealth and titles.
After the death of Julian, sometimes also described as a king of the Ghomara Berbers, Berber converts to Islam took direct control of what they called Sebta. It was then destroyed during their great revolt against the Umayyad Caliphate around 740. Sebta subsequently remained a small village of Muslims and Christians surrounded by ruins until its resettlement in the 9th century by Mâjakas, chief of the Majkasa Berber tribe, who started the short-lived Banu Isam dynasty. His great-grandson briefly allied his tribe with the Idrisids, but Banu Isam rule ended in 931 when he abdicated in favor of Abd ar-Rahman III, the Umayyad caliph of Cordoba. Ceuta reverted to Moorish Andalusian rule in 927 along with Melilla, and later Tangier, in 951.
Chaos ensued with the fall of the Spanish Umayyads in 1031. Following this, Ceuta and Muslim Iberia were controlled by successive North African dynasties. Starting in 1084, the Almoravid Berbers ruled the region until 1147, when the Almohads conquered the land. Apart from Ibn Hud's rebellion in 1232, they ruled until the Tunisian Hafsids established control. The Hafsids' influence in the west rapidly waned, and Ceuta's inhabitants eventually expelled them in 1249. After this, a period of political instability persisted, under competing interests from the kingdoms of Fez and Granada as well as autonomous rule under the native Banu al-Azafi. The Fez finally conquered the region in 1387, with assistance from Aragon.
On the morning of 21 August 1415, King John I of Portugal led his sons and their assembled forces in a surprise assault that would come to be known as the Conquest of Ceuta. The battle was almost anti-climactic, because the 45,000 men who traveled on 200 Portuguese ships caught the defenders of Ceuta off guard and only suffered eight casualties. By nightfall the town was captured. On the morning of August 22, Ceuta was in Portuguese hands. Álvaro Vaz de Almada, 1st Count of Avranches was asked to hoist what was to become the flag of Ceuta, which is identical to the flag of Lisbon, but in which the coat of arms derived from that of the Kingdom of Portugal was added to the center; the original Portuguese flag and coat of arms of Ceuta remained unchanged, and the modern-day Ceuta flag features the configuration of the Portuguese shield.
John's son Henry the Navigator distinguished himself in the battle, being wounded during the conquest. The looting of the city proved to be less profitable than expected for John I; he decided to keep the city to pursue further enterprises in the area.
From 1415 to 1437, Pedro de Meneses became the first governor of Ceuta.
The Benemerine sultan started the 1418 siege but was defeated by the first governor of Ceuta before reinforcements arrived in the form of John, Constable of Portugal and his brother Henry the Navigator who were sent with troops to defend Ceuta.
Under King John I's son, Duarte, the colony at Ceuta rapidly became a drain on the Portuguese treasury. Trans-Saharan trade journeyed instead to Tangier. It was soon realized that without the city of Tangier, possession of Ceuta was worthless. In 1437, Duarte's brothers Henry the Navigator and Fernando, the Saint Prince persuaded him to launch an attack on the Marinid sultanate. The resulting Battle of Tangier (1437), led by Henry, was a debacle. In the resulting treaty, Henry promised to deliver Ceuta back to the Marinids in return for allowing the Portuguese army to depart unmolested, which he reneged on.
Possession of Ceuta would indirectly lead to further Portuguese expansion. The main area of Portuguese expansion, at this time, was the coast of the Maghreb, where there was grain, cattle, sugar, and textiles, as well as fish, hides, wax, and honey.
Ceuta had to endure alone for 43 years, until the position of the city was consolidated with the taking of Ksar es-Seghir (1458), Arzila and Tangier (1471) by the Portuguese.
The city was recognized as a Portuguese possession by the Treaty of Alcáçovas (1479) and by the Treaty of Tordesilhas (1494).
In the 1540s the Portuguese began building the Royal Walls of Ceuta as they are today including bastions, a navigable moat and a drawbridge. Some of these bastions are still standing, like the bastions of Coraza Alta, Bandera and Mallorquines.
Luís de Camões lived in Ceuta between 1549 and 1551, losing his right eye in battle, which influenced his work of poetry "Os Lusíadas".
In 1578 King Sebastian of Portugal died at the Battle of Alcácer Quibir (known as the Battle of Three Kings) in what is today northern Morocco, without descendants, triggering the 1580 Portuguese succession crisis. His granduncle, the elderly Cardinal Henry, succeeded him as King, but Henry also had no descendants, having taken holy orders. When the cardinal-king died two years after Sebastian's disappearance, three grandchildren of King Manuel I of Portugal claimed the throne: Infanta Catarina, Duchess of Braganza, António, Prior of Crato, and Philip II of Spain (Uncle of former King Sebastian of Portugal), who would go on to be crowned King Philip I of Portugal in 1581, uniting the two crowns and overseas empires known as the Iberian Union, which allowed the two kingdoms to continue without being merged.
During the Iberian Union 1580 to 1640, Ceuta attracted many residents of Spanish origin. Ceuta became the only city of the Portuguese Empire that sided with Spain when Portugal regained its independence in the Portuguese Restoration War of 1640.
On 1 January 1668, King Afonso VI of Portugal recognized the formal allegiance of Ceuta to Spain and formally ceded Ceuta to King Carlos II of Spain by the Treaty of Lisbon.
The city was attacked by Moroccan forces under Moulay Ismail during the Siege of Ceuta (1694–1727). During the longest siege in history, the city underwent changes leading to the loss of its Portuguese character. While most of the military operations took place around the Royal Walls of Ceuta, there were also small-scale penetrations by Spanish forces at various points on the Moroccan coast, and seizure of shipping in the Strait of Gibraltar.
Disagreements regarding the border of Ceuta resulted in the Hispano-Moroccan War (1859–60), which ended at the Battle of Tetuán.
In July 1936, General Francisco Franco took command of the Spanish Army of Africa and rebelled against the Spanish republican government; his military uprising led to the Spanish Civil War of 1936–1939. Franco transported troops to mainland Spain in an airlift using transport aircraft supplied by Germany and Italy. Ceuta became one of the first casualties of the uprising: General Franco's rebel nationalist forces seized Ceuta, while at the same time the city came under fire from the air and sea forces of the official republican government.
The Llano Amarillo monument was erected to honor Francisco Franco, it was inaugurated on 13 July 1940. The tall obelisk has since been abandoned, but the shield symbols of the Falange and Imperial Eagle remain visible.
When Spain recognized the independence of Spanish Morocco in 1956, Ceuta and the other remained under Spanish rule. Spain considered them integral parts of the Spanish state, but Morocco has disputed this point.
Culturally, modern Ceuta is part of the Spanish region of Andalusia. It was attached to the province of Cádiz until 1925, the Spanish coast being only 20 km (12.5 miles) away. It is a cosmopolitan city, with a large ethnic Arab-Berber Muslim minority as well as Sephardic Jewish and Hindu minorities.
On 5 November 2007, King Juan Carlos I visited the city, sparking great enthusiasm from the local population and protests from the Moroccan government. It was the first time a Spanish head of state had visited Ceuta in 80 years.
Since 2010, Ceuta (and Melilla) have declared the Muslim holiday of Eid al-Adha, or Feast of the Sacrifice, an official public holiday. It is the first time a non-Christian religious festival has been officially celebrated in Spain since the Reconquista.
It is separated by from the province of Cádiz on the Spanish mainland by the Strait of Gibraltar and it shares a land border with M'diq-Fnideq Prefecture in the Kingdom of Morocco.
It has an area of .
Ceuta is dominated by Monte Anyera, a hill along its western frontier with Morocco. The mountain is guarded by a military fort.
Monte Hacho on the Peninsula of Almina overlooking the port is one of the possible locations for the southern pillar of the Pillars of Hercules of Greek legend (the other possibility being Jebel Musa).
Ceuta has a maritime-influenced Subtropical/Mediterranean climate, similar to nearby Spanish and Moroccan cities such as Tarifa, Algeciras or Tangiers. The average diurnal temperature variation is relatively low; the average annual temperature is with average yearly highs of and lows of though the Ceuta weather station has only been in operation since 2003. Ceuta has relatively mild winters for the latitude, while summers are warm yet milder than in the interior of Southern Spain, due to the moderating effect of the Straits of Gibraltar. Summers are very dry, but yearly precipitation is still at , which could be considered a humid climate if the summers were not so arid.
Since 1995, Ceuta is, along with Melilla, one of the two autonomous cities of Spain.
Ceuta is known officially in Spanish as (English: "Autonomous City of Ceuta"), with a rank between a standard Spanish city and an autonomous community. Ceuta is part of the territory of the European Union. The city was a free port before Spain joined the European Union in 1986. Now it has a low-tax system within the Economic and Monetary Union of the European Union. As of 2018, its population was 85,144.
Ceuta has held elections every four years since 1979, for its 25-seat assembly. The leader of its government was the Mayor until the Autonomy Statute had the title changed to the Mayor-President. , the People's Party (PP) won 18 seats, keeping Juan Jesús Vivas as Mayor-President, which he has been since 2001. The remaining seats are held by the regionalist Caballas Coalition (4) and the Socialist Workers' Party (PSOE, 3).
Due to its small population, Ceuta elects only one member of the Congress of Deputies, the lower house of the Spanish legislature. election, this post is held by María Teresa López of Vox.
Ceuta is subdivided into 63 ("neighborhoods"), such as Barriada de Berizu, Barriada de P. Alfonso, Barriada del Sarchal, and El Hacho.
The government of Morocco has repeatedly called for Spain to transfer the sovereignty of Ceuta and Melilla, along with uninhabited islets such as the islands of Alhucemas, Velez and the Perejil island, drawing comparisons with Spain's territorial claim to Gibraltar. In both cases, the national governments and local populations of the disputed territories reject these claims by a large majority. The Spanish position states that both Ceuta and Melilla are integral parts of Spain, and have been since the 16th century, centuries prior to Morocco's independence from France in 1956, whereas Gibraltar, being a British Overseas Territory, is not and never has been part of the United Kingdom. Morocco has claimed the territories are colonies. One of the chief arguments used by Morocco to reclaim Ceuta comes from geography, as this enclave, which is surrounded by Morocco and the Mediterranean Sea, has no territorial continuity with the rest of Spanish territory. This argument was originally developed by one of the founders of the Moroccan Istiqlal Party, Alal-El Faasi, who openly advocated the Moroccan conquest of Ceuta and other territories under Spanish rule.
The official currency of Ceuta is the euro. It is part of a special low tax zone in Spain. Ceuta is one of two Spanish port cities on the northern shore of Africa, along with Melilla. They are historically military strongholds, free ports, oil ports, and also fishing ports. Today the economy of the city depends heavily on its port (now in expansion) and its industrial and retail centers. Ceuta Heliport is now used to connect the city to mainland Spain by air. Lidl, Decathlon and El Corte Inglés (hardware) have branches in Ceuta. There is also a casino.
Border trade between Ceuta and Morocco is active because of advantage of tax-free status. Thousands of Moroccan women are involved in porter trade daily. Moroccan dirham is actually used in such trade, despite the fact that prices are marked in euro.
The city's Port of Ceuta receives high numbers of ferries each day from Algeciras in Andalusia in the south of Spain, along with Melilla and the Canary Islands. The closest airport is Sania Ramel Airport in Morocco.
A single road border checkpoint to the south of Ceuta near Fnideq allows for cars and pedestrians to travel between Morocco and Ceuta. An additional border crossing for pedestrians also exists between Benzú and Belyounech on the northern coast. The rest of the border is closed and inaccessible.
There is a bus service throughout the city, and while it does not pass into neighboring Morocco, it services both frontier crossings.
The following hospitals are located within Ceuta:
Due to its location, Ceuta is home to a mixed ethnic and religious population. The two main religious groups are Christians and Muslims. As of 2006 approximately 50% of the population was Christian and approximately 48% Muslim. However, by 2012, the portion of Ceuta's population that identify as Roman Catholic was 68.0%, while the portion of Ceuta's population that identify as Muslim was 28.3%.
Spanish is the primary and official language of the enclave. Moroccan Arabic is widely spoken, as are Berber and French.
Christianity has been present in Ceuta continuously from late antiquity, as evidenced by the ruins of a basilica in downtown Ceuta and accounts of the martyrdom of St. Daniel Fasanella and his Franciscans in 1227 during the Almohad Caliphate.
The town's Grand Mosque had been built over a Byzantine-era church. In 1415, the year of the city's conquest, the Portuguese converted the Grand Mosque into Ceuta Cathedral. The present form of the cathedral dates to refurbishments undertaken in the late 17th century, combining baroque and neoclassical elements. It was dedicated to StMary of the Assumption in 1726.
The Roman Catholic Diocese of Ceuta was established in 1417. It incorporated the suppressed Diocese of Tanger in 1570. The Diocese of Ceuta was a suffragan of Lisbon until 1675, when it became a suffragan of Seville. In 1851, Ceuta's administration was notionally merged into the Diocese of Cádiz and Ceuta as part of a concordat between Spain and the Holy See; the union was not actually accomplished, however, until 1879.
Small Jewish and Hindu minorities are also present in the city.
The University of Granada offers undergraduate programs at their campus in Ceuta. Like all areas of Spain, Ceuta is also served by the National University of Distance Education (UNED).
Primary and secondary education is possible only in Spanish however a growing number of schools are entering the Bilingual Education Program.
Like Melilla, Ceuta attracts African migrants who try to use it as an entry to Europe. As a result, the enclave is surrounded by double fences that are high and hundreds of migrants congregate near the fences waiting for a chance to cross them. The fences are regularly stormed by migrants trying to claim asylum once they enter Ceuta.
Ceuta is twinned with:

</doc>
<doc id="6444" url="https://en.wikipedia.org/wiki?curid=6444" title="Cleopatra (disambiguation)">
Cleopatra (disambiguation)

Cleopatra (69-30 BC) was the last active Ptolemaic pharaoh of Egypt before it became a Roman province.
Cleopatra may also refer to:

</doc>
<doc id="6445" url="https://en.wikipedia.org/wiki?curid=6445" title="Carcinogen">
Carcinogen

A carcinogen is any substance, radionuclide, or radiation that promotes carcinogenesis, the formation of cancer. This may be due to the ability to damage the genome or to the disruption of cellular metabolic processes. Several radioactive substances are considered carcinogens, but their carcinogenic activity is attributed to the radiation, for example gamma rays and alpha particles, which they emit. Common examples of non-radioactive carcinogens are inhaled asbestos, certain dioxins, and tobacco smoke. Although the public generally associates carcinogenicity with synthetic chemicals, it is equally likely to arise in both natural and synthetic substances. Carcinogens are not necessarily immediately toxic; thus, their effect can be insidious.
Cancer is any disease in which normal cells are damaged and do not undergo programmed cell death as fast as they divide via mitosis. Carcinogens may increase the risk of cancer by altering cellular metabolism or damaging DNA directly in cells, which interferes with biological processes, and induces the uncontrolled, malignant division, ultimately leading to the formation of tumors. Usually, severe DNA damage leads to programmed cell death, but if the programmed cell death pathway is damaged, then the cell cannot prevent itself from becoming a cancer cell.
There are many natural carcinogens. Aflatoxin B, which is produced by the fungus "Aspergillus flavus" growing on stored grains, nuts and peanut butter, is an example of a potent, naturally occurring microbial carcinogen. Certain viruses such as hepatitis B and human papilloma virus have been found to cause cancer in humans. The first one shown to cause cancer in animals is Rous sarcoma virus, discovered in 1910 by Peyton Rous. Other infectious organisms which cause cancer in humans include some bacteria (e.g. "Helicobacter pylori" ) and helminths (e.g. "Opisthorchis viverrini" and "Clonorchis sinensis").
Dioxins and dioxin-like compounds, benzene, kepone, EDB, and asbestos have all been classified as carcinogenic. As far back as the 1930s, Industrial smoke and tobacco smoke were identified as sources of dozens of carcinogens, including benzo["a"]pyrene, tobacco-specific nitrosamines such as nitrosonornicotine, and reactive aldehydes such as formaldehyde, which is also a hazard in embalming and making plastics. Vinyl chloride, from which PVC is manufactured, is a carcinogen and thus a hazard in PVC production.
Co-carcinogens are chemicals that do not necessarily cause cancer on their own, but promote the activity of other carcinogens in causing cancer.
After the carcinogen enters the body, the body makes an attempt to eliminate it through a process called biotransformation. The purpose of these reactions is to make the carcinogen more water-soluble so that it can be removed from the body. However, in some cases, these reactions can also convert a less toxic carcinogen into a more toxic carcinogen.
DNA is nucleophilic; therefore, soluble carbon electrophiles are carcinogenic, because DNA attacks them. For example, some alkenes are toxicated by human enzymes to produce an electrophilic epoxide. DNA attacks the epoxide, and is bound permanently to it. This is the mechanism behind the carcinogenicity of benzo["a"]pyrene in tobacco smoke, other aromatics, aflatoxin and mustard gas.
CERCLA identifies all radionuclides as carcinogens, although the nature of the emitted radiation (alpha, beta, gamma, or neutron and the radioactive strength), its consequent capacity to cause ionization in tissues, and the magnitude of radiation exposure, determine the potential hazard. Carcinogenicity of radiation depends on the type of radiation, type of exposure, and penetration. For example, alpha radiation has low penetration and is not a hazard outside the body, but emitters are carcinogenic when inhaled or ingested. For example, Thorotrast, a (incidentally radioactive) suspension previously used as a contrast medium in x-ray diagnostics, is a potent human carcinogen known because of its retention within various organs and persistent emission of alpha particles. Low-level ionizing radiation may induce irreparable DNA damage (leading to replicational and transcriptional errors needed for neoplasia or may trigger viral interactions) leading to pre-mature aging and cancer.
Not all types of electromagnetic radiation are carcinogenic. Low-energy waves on the electromagnetic spectrum including radio waves, microwaves, infrared radiation and visible light are thought not to be, because they have insufficient energy to break chemical bonds. Evidence for carcinogenic effects of non-ionizing radiation is generally inconclusive, though there are some documented cases of radar technicians with prolonged high exposure experiencing significantly higher cancer incidence.
Higher-energy radiation, including ultraviolet radiation (present in sunlight), x-rays, and gamma radiation, generally "is" carcinogenic, if received in sufficient doses. For most people, ultraviolet radiations from sunlight is the most common cause of skin cancer. In Australia, where people with pale skin are often exposed to strong sunlight, melanoma is the most common cancer diagnosed in people aged 15–44 years.
Substances or foods irradiated with electrons or electromagnetic radiation (such as microwave, X-ray or gamma) are not carcinogenic. In contrast, non-electromagnetic neutron radiation produced inside nuclear reactors can produce secondary radiation through nuclear transmutation.
Chemicals used in processed and cured meat such as some brands of bacon, sausages and ham may produce carcinogens. For example, nitrites used as food preservatives in cured meat such as bacon have also been noted as being carcinogenic with demographic links, but not causation, to colon cancer. Cooking food at high temperatures, for example grilling or barbecuing meats, may also lead to the formation of minute quantities of many potent carcinogens that are comparable to those found in cigarette smoke (i.e., benzo["a"]pyrene). Charring of food looks like coking and tobacco pyrolysis, and produces carcinogens. There are several carcinogenic pyrolysis products, such as polynuclear aromatic hydrocarbons, which are converted by human enzymes into epoxides, which attach permanently to DNA. Pre-cooking meats in a microwave oven for 2–3 minutes before grilling shortens the time on the hot pan, and removes heterocyclic amine (HCA) precursors, which can help minimize the formation of these carcinogens.
Reports from the Food Standards Agency have found that the known animal carcinogen acrylamide is generated in fried or overheated carbohydrate foods (such as french fries and potato chips). Studies are underway at the FDA and Europe regulatory agencies to assess its potential risk to humans.
There is a strong association of smoking with lung cancer; the risk of developing lung cancer increases significantly in smokers. A large number of known carcinogens are found in cigarette smoke. Potent carcinogens found in cigarette smoke include polycyclic aromatic hydrocarbons (PAH, such as benzo[a]pyrene), Benzene, and Nitrosamine.
Carcinogens can be classified as genotoxic or nongenotoxic. Genotoxins cause irreversible genetic damage or mutations by binding to DNA. Genotoxins include chemical agents like N-nitroso-N-methylurea (NMU) or non-chemical agents such as ultraviolet light and ionizing radiation. Certain viruses can also act as carcinogens by interacting with DNA.
Nongenotoxins do not directly affect DNA but act in other ways to promote growth. These include hormones and some organic compounds.
The International Agency for Research on Cancer (IARC) is an intergovernmental agency established in 1965, which forms part of the World Health Organization of the United Nations. It is based in Lyon, France. Since 1971 it has published a series of "Monographs on the Evaluation of Carcinogenic Risks to Humans" that have been highly influential in the classification of possible carcinogens.
The Globally Harmonized System of Classification and Labelling of Chemicals (GHS) is a United Nations initiative to attempt to harmonize the different systems of assessing chemical risk which currently exist (as of March 2009) around the world. It classifies carcinogens into two categories, of which the first may be divided again into subcategories if so desired by the competent regulatory authority:
The National Toxicology Program of the U.S. Department of Health and Human Services is mandated to produce a biennial "Report on Carcinogens". As of June 2011, the latest edition was the 12th report (2011). It classifies carcinogens into two groups:
The American Conference of Governmental Industrial Hygienists (ACGIH) is a private organization best known for its publication of threshold limit values (TLVs) for occupational exposure and monographs on workplace chemical hazards. It assesses carcinogenicity as part of a wider assessment of the occupational hazards of chemicals.
The European Union classification of carcinogens is contained in the Dangerous Substances Directive and the Dangerous Preparations Directive. It consists of three categories:
This assessment scheme is being phased out in favor of the GHS scheme (see above), to which it is very close in category definitions.
Under a previous name, the NOHSC, in 1999 Safe Work Australia published the Approved Criteria for Classifying Hazardous Substances [NOHSC:1008(1999)].
Section 4.76 of this document outlines the criteria for classifying carcinogens as approved by the Australian government. This classification consists of three categories:
Occupational carcinogens are agents that pose a risk of cancer in several specific work-locations:
In this section, the carcinogens implicated as the main causative agents of the four most common cancers worldwide are briefly described. These four cancers are lung, breast, colon, and stomach cancers. Together they account for about 41% of worldwide cancer incidence and 42% of cancer deaths (for more detailed information on the carcinogens implicated in these and other cancers, see references).
Lung cancer (pulmonary carcinoma) is the most common cancer in the world, both in terms of cases (1.6 million cases; 12.7% of total cancer cases) and deaths (1.4 million deaths; 18.2% of total cancer deaths). Lung cancer is largely caused by tobacco smoke. Risk estimates for lung cancer in the United States indicate that tobacco smoke is responsible for 90% of lung cancers. Other factors are implicated in lung cancer, and these factors can interact synergistically with smoking so that total attributable risk adds up to more than 100%. These factors include occupational exposure to carcinogens (about 9-15%), radon (10%) and outdoor air pollution (1-2%). Tobacco smoke is a complex mixture of more than 5,300 identified chemicals. The most important carcinogens in tobacco smoke have been determined by a “Margin of Exposure” approach. Using this approach, the most important tumorigenic compounds in tobacco smoke were, in order of importance, acrolein, formaldehyde, acrylonitrile, 1,3-butadiene, cadmium, acetaldehyde, ethylene oxide, and isoprene. Most of these compounds cause DNA damage by forming DNA adducts or by inducing other alterations in DNA. DNA damages are subject to error-prone DNA repair or can cause replication errors. Such errors in repair or replication can result in mutations in tumor suppressor genes or oncogenes leading to cancer.
Breast cancer is the second most common cancer [(1.4 million cases, 10.9%), but ranks 5th as cause of death (458,000, 6.1%)]. Increased risk of breast cancer is associated with persistently elevated blood levels of estrogen. Estrogen appears to contribute to breast carcinogenesis by three processes; (1) the metabolism of estrogen to genotoxic, mutagenic carcinogens, (2) the stimulation of tissue growth, and (3) the repression of phase II detoxification enzymes that metabolize ROS leading to increased oxidative DNA damage. The major estrogen in humans, estradiol, can be metabolized to quinone derivatives that form adducts with DNA. These derivatives can cause dupurination, the removal of bases from the phosphodiester backbone of DNA, followed by inaccurate repair or replication of the apurinic site leading to mutation and eventually cancer. This genotoxic mechanism may interact in synergy with estrogen receptor-mediated, persistent cell proliferation to ultimately cause breast cancer. Genetic background, dietary practices and environmental factors also likely contribute to the incidence of DNA damage and breast cancer risk.
Colorectal cancer is the third most common cancer [1.2 million cases (9.4%), 608,000 deaths (8.0%)]. Tobacco smoke may be responsible for up to 20% of colorectal cancers in the United States. In addition, substantial evidence implicates bile acids as an important factor in colon cancer. Twelve studies (summarized in Bernstein et al.) indicate that the bile acids deoxycholic acid (DCA) or lithocholic acid (LCA) induce production of DNA-damaging reactive oxygen species or reactive nitrogen species in human or animal colon cells. Furthermore, 14 studies showed that DCA and LCA induce DNA damage in colon cells. Also 27 studies reported that bile acids cause programmed cell death (apoptosis). Increased apoptosis can result in selective survival of cells that are resistant to induction of apoptosis. Colon cells with reduced ability to undergo apoptosis in response to DNA damage would tend to accumulate mutations, and such cells may give rise to colon cancer. Epidemiologic studies have found that fecal bile acid concentrations are increased in populations with a high incidence of colon cancer. Dietary increases in total fat or saturated fat result in elevated DCA and LCA in feces and elevated exposure of the colon epithelium to these bile acids. When the bile acid DCA was added to the standard diet of wild-type mice invasive colon cancer was induced in 56% of the mice after 8 to 10 months. Overall, the available evidence indicates that DCA and LCA are centrally important DNA-damaging carcinogens in colon cancer.
Stomach cancer is the fourth most common cancer [990,000 cases (7.8%), 738,000 deaths (9.7%)]. "Helicobacter pylori" infection is the main causative factor in stomach cancer. Chronic gastritis (inflammation) caused by "H. pylori" is often long-standing if not treated. Infection of gastric epithelial cells with "H. pylori" results in increased production of reactive oxygen species (ROS). ROS cause oxidative DNA damage including the major base alteration 8-hydroxydeoxyguanosine (8-OHdG). 8-OHdG resulting from ROS is increased in chronic gastritis. The altered DNA base can cause errors during DNA replication that have mutagenic and carcinogenic potential. Thus "H. pylori"-induced ROS appear to be the major carcinogens in stomach cancer because they cause oxidative DNA damage leading to carcinogenic mutations. Diet is thought to be a contributing factor in stomach cancer - in Japan where very salty pickled foods are popular, the incidence of stomach cancer is high. Preserved meat such as bacon, sausages, and ham increases the risk while a diet high in fresh fruit and vegetables may reduce the risk. The risk also increases with age.

</doc>
<doc id="6446" url="https://en.wikipedia.org/wiki?curid=6446" title="Camouflage">
Camouflage

Camouflage is the use of any combination of materials, coloration, or illumination for concealment, either by making animals or objects hard to see, or by disguising them as something else. Examples include the leopard's spotted coat, the battledress of a modern soldier, and the leaf-mimic katydid's wings. A third approach, motion dazzle, confuses the observer with a conspicuous pattern, making the object visible but momentarily harder to locate. The majority of camouflage methods aim for crypsis, often through a general resemblance to the background, high contrast disruptive coloration, eliminating shadow, and countershading. In the open ocean, where there is no background, the principal methods of camouflage are transparency, silvering, and countershading, while the ability to produce light is among other things used for counter-illumination on the undersides of cephalopods such as squid. Some animals, such as chameleons and octopuses, are capable of actively changing their skin pattern and colours, whether for camouflage or for signalling. It is possible that some plants use camouflage to evade being eaten by herbivores.
Military camouflage was spurred by the increasing range and accuracy of firearms in the 19th century. In particular the replacement of the inaccurate musket with the rifle made personal concealment in battle a survival skill. In the 20th century, military camouflage developed rapidly, especially during the First World War. On land, artists such as André Mare designed camouflage schemes and observation posts disguised as trees. At sea, merchant ships and troop carriers were painted in dazzle patterns that were highly visible, but designed to confuse enemy submarines as to the target's speed, range, and heading. During and after the Second World War, a variety of camouflage schemes were used for aircraft and for ground vehicles in different theatres of war. The use of radar since the mid-20th century has largely made camouflage for fixed-wing military aircraft obsolete.
Non-military use of camouflage includes making cell telephone towers less obtrusive and helping hunters to approach wary game animals. Patterns derived from military camouflage are frequently used in fashion clothing, exploiting their strong designs and sometimes their symbolism. Camouflage themes recur in modern art, and both figuratively and literally in science fiction and works of literature.
In ancient Greece, Aristotle (384–322 BC) commented on the colour-changing abilities, both for camouflage and for signalling, of cephalopods including the octopus, in his "Historia animalium":
Camouflage has been a topic of interest and research in zoology for well over a century. According to Charles Darwin's 1859 theory of natural selection, features such as camouflage evolved by providing individual animals with a reproductive advantage, enabling them to leave more offspring, on average, than other members of the same species. In his "Origin of Species", Darwin wrote:
The English zoologist Edward Bagnall Poulton studied animal coloration, especially camouflage. In his 1890 book "The Colours of Animals", he classified different types such as "special protective resemblance" (where an animal looks like another object), or "general aggressive resemblance" (where a predator blends in with the background, enabling it to approach prey). His experiments showed that swallow-tailed moth pupae were camouflaged to match the backgrounds on which they were reared as larvae. Poulton's "general protective resemblance" was at that time considered to be the main method of camouflage, as when Frank Evers Beddard wrote in 1892 that "tree-frequenting animals are often green in colour. Among vertebrates numerous species of parrots, iguanas, tree-frogs, and the green tree-snake are examples". Beddard did however briefly mention other methods, including the "alluring coloration" of the flower mantis and the possibility of a different mechanism in the orange tip butterfly. He wrote that "the scattered green spots upon the under surface of the wings might have been intended for a rough sketch of the small flowerets of the plant [an umbellifer], so close is their mutual resemblance." He also explained the coloration of sea fish such as the mackerel: "Among pelagic fish it is common to find the upper surface dark-coloured and the lower surface white, so that the animal is inconspicuous when seen either from above or below."
The artist Abbott Handerson Thayer formulated what is sometimes called Thayer's Law, the principle of countershading. However, he overstated the case in the 1909 book "Concealing-Coloration in the Animal Kingdom", arguing that "All patterns and colors whatsoever of all animals that ever preyed or are preyed on are under certain normal circumstances obliterative" (that is, cryptic camouflage), and that "Not one 'mimicry' mark, not one 'warning color'... nor any 'sexually selected' color, exists anywhere in the world where there is not every reason to believe it the very best conceivable device for the concealment of its wearer", and using paintings such as "Peacock in the Woods" (1907) to reinforce his argument. Thayer was roundly mocked for these views by critics including Teddy Roosevelt.
The English zoologist Hugh Cott's 1940 book "Adaptive Coloration in Animals" corrected Thayer's errors, sometimes sharply: "Thus we find Thayer straining the theory to a fantastic extreme in an endeavour to make it cover almost every type of coloration in the animal kingdom." Cott built on Thayer's discoveries, developing a comprehensive view of camouflage based on "maximum disruptive contrast", countershading and hundreds of examples. The book explained how disruptive camouflage worked, using streaks of boldly contrasting colour, paradoxically making objects less visible by breaking up their outlines. While Cott was more systematic and balanced in his view than Thayer, and did include some experimental evidence on the effectiveness of camouflage, his 500-page textbook was, like Thayer's, mainly a natural history narrative which illustrated theories with examples.
Experimental evidence that camouflage helps prey avoid being detected by predators was first provided in 2016, when ground-nesting birds (plovers and coursers) were shown to survive according to how well their egg contrast matched the local environment.
Camouflage is a soft-tissue feature that is rarely preserved in the fossil record, but rare fossilised skin samples from the Cretaceous period show that some marine reptiles were countershaded. The skins, pigmented with dark-coloured eumelanin, reveal that both leatherback turtles and mosasaurs had dark backs and light bellies. There is fossil evidence of camouflaged insects going back over 100 million years, for example lacewings larvae that stick debris all over their bodies much as their modern descendants do, hiding them from their prey. Dinosaurs appear to have been camouflaged, as a 120 million year old fossil of a "Psittacosaurus" has been preserved with countershading.
Camouflage can be achieved by different methods, described below. Most of the methods help to hide against a background; but mimesis and motion dazzle protect without hiding. Methods may be applied on their own or in combination. Many mechanisms are visual, but some research has explored the use of techniques against olfactory (scent) and acoustic (sound) detection. Methods may also apply to military equipment.
Some animals' colours and patterns resemble a particular natural background. This is an important component of camouflage in all environments. For instance, tree-dwelling parakeets are mainly green; woodcocks of the forest floor are brown and speckled; reedbed bitterns are streaked brown and buff; in each case the animal's coloration matches the hues of its habitat. Similarly, desert animals are almost all desert coloured in tones of sand, buff, ochre, and brownish grey, whether they are mammals like the gerbil or fennec fox, birds such as the desert lark or sandgrouse, or reptiles like the skink or horned viper. Military uniforms, too, generally resemble their backgrounds; for example khaki uniforms are a muddy or dusty colour, originally chosen for service in South Asia. Many moths show industrial melanism, including the peppered moth which has coloration that blends in with tree bark. The coloration of these insects evolved between 1860 and 1940 to match the changing colour of the tree trunks on which they rest, from pale and mottled to almost black in polluted areas. This is taken by zoologists as evidence that camouflage is influenced by natural selection, as well as demonstrating that it changes where necessary to resemble the local background.
Disruptive patterns use strongly contrasting, non-repeating markings such as spots or stripes to break up the outlines of an animal or military vehicle, or to conceal telltale features, especially by masking the eyes, as in the common frog. Disruptive patterns may use more than one method to defeat visual systems such as edge detection. Predators like the leopard use disruptive camouflage to help them approach prey, while potential prey use it to avoid detection by predators. Disruptive patterning is common in military usage, both for uniforms and for military vehicles. Disruptive patterning, however, does not always achieve crypsis on its own, as an animal or a military target may be given away by factors like shape, shine, and shadow.
The presence of bold skin markings does not in itself prove that an animal relies on camouflage, as that depends on its behaviour. For example, although giraffes have a high contrast pattern that could be disruptive coloration, the adults are very conspicuous when in the open. Some authors have argued that adult giraffes are cryptic, since when standing among trees and bushes they are hard to see at even a few metres distance. However, adult giraffes move about to gain the best view of an approaching predator, relying on their size and ability to defend themselves, even from lions, rather than on camouflage. A different explanation is implied by young giraffes being far more vulnerable to predation than adults. More than half of all giraffe calves die within a year, and giraffe mothers hide their newly born calves, which spend much of the time lying down in cover while their mothers are away feeding. The mothers return once a day to feed their calves with milk. Since the presence of a mother nearby does not affect survival, it is argued that these juvenile giraffes must be very well camouflaged; this is supported by coat markings being strongly inherited.
The possibility of camouflage in plants has been little studied until the late 20th century. Leaf variegation with white spots may serve as camouflage in forest understory plants, where there is a dappled background; leaf mottling is correlated with closed habitats. Disruptive camouflage would have a clear evolutionary advantage in plants: they would tend to escape from being eaten by herbivores. Another possibility is that some plants have leaves differently coloured on upper and lower surfaces or on parts such as veins and stalks to make green-camouflaged insects conspicuous, and thus benefit the plants by favouring the removal of herbivores by carnivores. These hypotheses are testable.
Some animals, such as the horned lizards of North America, have evolved elaborate measures to eliminate shadow. Their bodies are flattened, with the sides thinning to an edge; the animals habitually press their bodies to the ground; and their sides are fringed with white scales which effectively hide and disrupt any remaining areas of shadow there may be under the edge of the body. The theory that the body shape of the horned lizards which live in open desert is adapted to minimise shadow is supported by the one species which lacks fringe scales, the roundtail horned lizard, which lives in rocky areas and resembles a rock. When this species is threatened, it makes itself look as much like a rock as possible by curving its back, emphasizing its three-dimensional shape. Some species of butterflies, such as the speckled wood, "Pararge aegeria", minimise their shadows when perched by closing the wings over their backs, aligning their bodies with the sun, and tilting to one side towards the sun, so that the shadow becomes a thin inconspicuous line rather than a broad patch. Similarly, some ground-nesting birds, including the European nightjar, select a resting position facing the sun. Eliminating shadow was identified as a principle of military camouflage during the Second World War.
Many prey animals have conspicuous high-contrast markings which paradoxically attract the predator's gaze. These distractive markings may serve as camouflage by distracting the predator's attention from recognising the prey as a whole, for example by keeping the predator from identifying the prey's outline. Experimentally, search times for blue tits increased when artificial prey had distractive markings.
Some animals actively seek to hide by decorating themselves with materials such as twigs, sand, or pieces of shell from their environment, to break up their outlines, to conceal the features of their bodies, and to match their backgrounds. For example, a caddisfly larva builds a decorated case and lives almost entirely inside it; a decorator crab covers its back with seaweed, sponges, and stones. The nymph of the predatory masked bug uses its hind legs and a 'tarsal fan' to decorate its body with sand or dust. There are two layers of bristles (trichomes) over the body. On these, the nymph spreads an inner layer of fine particles and an outer layer of coarser particles. The camouflage may conceal the bug from both predators and prey.
Similar principles can be applied for military purposes, for instance when a sniper wears a ghillie suit designed to be further camouflaged by decoration with materials such as tufts of grass from the sniper's immediate environment. Such suits were used as early as 1916, the British army having adopted "coats of motley hue and stripes of paint" for snipers. Cott takes the example of the larva of the blotched emerald moth, which fixes a screen of fragments of leaves to its specially hooked bristles, to argue that military camouflage uses the same method, pointing out that the "device is ... essentially the same as one widely practised during the Great War for the concealment, not of caterpillars, but of caterpillar-tractors, [gun] battery positions, observation posts and so forth."
Movement catches the eye of prey animals on the lookout for predators, and of predators hunting for prey. Most methods of crypsis therefore also require suitable cryptic behaviour, such as lying down and keeping still to avoid being detected, or in the case of stalking predators such as the tiger, moving with extreme stealth, both slowly and quietly, watching its prey for any sign they are aware of its presence. As an example of the combination of behaviours and other methods of crypsis involved, young giraffes seek cover, lie down, and keep still, often for hours until their mothers return; their skin pattern blends with the pattern of the vegetation, while the chosen cover and lying position together hide the animals' shadows. The flat-tail horned lizard similarly relies on a combination of methods: it is adapted to lie flat in the open desert, relying on stillness, its cryptic coloration, and concealment of its shadow to avoid being noticed by predators. In the ocean, the leafy sea dragon sways mimetically, like the seaweeds amongst which it rests, as if rippled by wind or water currents. Swaying is seen also in some insects, like Macleay's spectre stick insect, "Extatosoma tiaratum". The behaviour may be motion crypsis, preventing detection, or motion masquerade, promoting misclassification (as something other than prey), or a combination of the two.
Most forms of camouflage are ineffective when the camouflaged animal or object moves, because the motion is easily seen by the observing predator, prey or enemy. However, insects such as hoverflies and dragonflies use motion camouflage: the hoverflies to approach possible mates, and the dragonflies to approach rivals when defending territories. Motion camouflage is achieved by moving so as to stay on a straight line between the target and a fixed point in the landscape; the pursuer thus appears not to move, but only to loom larger in the target's field of vision. The same method can be used for military purposes, for example by missiles to minimise their risk of detection by an enemy. However, missile engineers, and animals such as bats, use the method mainly for its efficiency rather than camouflage.
Animals such as chameleon, frog, flatfish such as the peacock flounder, squid and octopus actively change their skin patterns and colours using special chromatophore cells to resemble their current background, or, as in most chameleons, for signalling. However, Smith's dwarf chameleon does use active colour change for camouflage.
Each chromatophore contains pigment of only one colour. In fish and frogs, colour change is mediated by a type of chromatophore known as melanophores that contain dark pigment. A melanophore is star-shaped; it contains many small pigmented organelles which can be dispersed throughout the cell, or aggregated near its centre. When the pigmented organelles are dispersed, the cell makes a patch of the animal's skin appear dark; when they are aggregated, most of the cell, and the animal's skin, appears light. In frogs, the change is controlled relatively slowly, mainly by hormones. In fish, the change is controlled by the brain, which sends signals directly to the chromatophores, as well as producing hormones.
The skins of cephalopods such as the octopus contain complex units, each consisting of a chromatophore with surrounding muscle and nerve cells. The cephalopod chromatophore has all its pigment grains in a small elastic sac, which can be stretched or allowed to relax under the control of the brain to vary its opacity. By controlling chromatophores of different colours, cephalopods can rapidly change their skin patterns and colours.
On a longer timescale, animals like the Arctic hare, Arctic fox, stoat, and rock ptarmigan have snow camouflage, changing their coat colour (by moulting and growing new fur or feathers) from brown or grey in the summer to white in the winter; the Arctic fox is the only species in the dog family to do so. However, Arctic hares which live in the far north of Canada, where summer is very short, remain white year-round.
The principle of varying coloration either rapidly or with the changing seasons has military applications. "Active camouflage" could in theory make use of both dynamic colour change and counterillumination. Simple methods such as changing uniforms and repainting vehicles for winter have been in use since World War II. In 2011, BAE Systems announced their Adaptiv infrared camouflage technology. It uses about 1,000 hexagonal panels to cover the sides of a tank. The Peltier plate panels are heated and cooled to match either the vehicle's surroundings (crypsis), or an object such as a car (mimesis), when viewed in infrared.
Countershading uses graded colour to counteract the effect of self-shadowing, creating an illusion of flatness. Self-shadowing makes an animal appear darker below than on top, grading from light to dark; countershading 'paints in' tones which are darkest on top, lightest below, making the countershaded animal nearly invisible against a suitable background. Thayer observed that "Animals are painted by Nature, darkest on those parts which tend to be most lighted by the sky's light, and "vice versa"". Accordingly, the principle of countershading is sometimes called "Thayer's Law". Countershading is widely used by terrestrial animals, such as gazelles and grasshoppers; marine animals, such as sharks and dolphins; and birds, such as snipe and dunlin.
Countershading is less often used for military camouflage, despite Second World War experiments that showed its effectiveness. English zoologist Hugh Cott encouraged the use of methods including countershading, but despite his authority on the subject, failed to persuade the British authorities. Soldiers often wrongly viewed camouflage netting as a kind of invisibility cloak, and they had to be taught to look at camouflage practically, from an enemy observer's viewpoint. At the same time in Australia, zoologist William John Dakin advised soldiers to copy animals' methods, using their instincts for wartime camouflage.
The term countershading has a second meaning unrelated to "Thayer's Law". It is that the upper and undersides of animals such as sharks, and of some military aircraft, are different colours to match the different backgrounds when seen from above or from below. Here the camouflage consists of two surfaces, each with the simple function of providing concealment against a specific background, such as a bright water surface or the sky. The body of a shark or the fuselage of an aircraft is not gradated from light to dark to appear flat when seen from the side. The camouflage methods used are the matching of background colour and pattern, and disruption of outlines.
Counter-illumination means producing light to match a background that is brighter than an animal's body or military vehicle; it is a form of active camouflage. It is notably used by some species of squid, such as the firefly squid and the midwater squid. The latter has light-producing organs (photophores) scattered all over its underside; these create a sparkling glow that prevents the animal from appearing as a dark shape when seen from below. Counterillumination camouflage is the likely function of the bioluminescence of many marine organisms, though light is also produced to attract or to detect prey and for signalling.
Counterillumination has rarely been used for military purposes. "Diffused lighting camouflage" was trialled by Canada's National Research Council during the Second World War. It involved projecting light on to the sides of ships to match the faint glow of the night sky, requiring awkward external platforms to support the lamps. The Canadian concept was refined in the American Yehudi lights project, and trialled in aircraft including B-24 Liberators and naval Avengers. The planes were fitted with forward-pointing lamps automatically adjusted to match the brightness of the night sky. This enabled them to approach much closer to a target – within – before being seen. Counterillumination was made obsolete by radar, and neither diffused lighting camouflage nor Yehudi lights entered active service.
Many marine animals that float near the surface are highly transparent, giving them almost perfect camouflage. However, transparency is difficult for bodies made of materials that have different refractive indices from seawater. Some marine animals such as jellyfish have gelatinous bodies, composed mainly of water; their thick mesogloea is acellular and highly transparent. This conveniently makes them buoyant, but it also makes them large for their muscle mass, so they cannot swim fast, making this form of camouflage a costly trade-off with mobility. Gelatinous planktonic animals are between 50 and 90 percent transparent. A transparency of 50 percent is enough to make an animal invisible to a predator such as cod at a depth of ; better transparency is required for invisibility in shallower water, where the light is brighter and predators can see better. For example, a cod can see prey that are 98 percent transparent in optimal lighting in shallow water. Therefore, sufficient transparency for camouflage is more easily achieved in deeper waters.
Some tissues such as muscles can be made transparent, provided either they are very thin or organised as regular layers or fibrils that are small compared to the wavelength of visible light. A familiar example is the transparency of the lens of the vertebrate eye, which is made of the protein crystallin, and the vertebrate cornea which is made of the protein collagen. Other structures cannot be made transparent, notably the retinas or equivalent light-absorbing structures of eyes – they must absorb light to be able to function. The camera-type eye of vertebrates and cephalopods must be completely opaque. Finally, some structures are visible for a reason, such as to lure prey. For example, the nematocysts (stinging cells) of the transparent siphonophore "Agalma okenii" resemble small copepods. Examples of transparent marine animals include a wide variety of larvae, including radiata (coelenterates), siphonophores, salps (floating tunicates), gastropod molluscs, polychaete worms, many shrimplike crustaceans, and fish; whereas the adults of most of these are opaque and pigmented, resembling the seabed or shores where they live. Adult comb jellies and jellyfish obey the rule, often being mainly transparent. Cott suggests this follows the more general rule that animals resemble their background: in a transparent medium like seawater, that means being transparent. The small Amazon river fish "Microphilypnus amazonicus" and the shrimps it associates with, "Pseudopalaemon gouldingi", are so transparent as to be "almost invisible"; further, these species appear to select whether to be transparent or more conventionally mottled (disruptively patterned) according to the local background in the environment.
Where transparency cannot be achieved, it can be imitated effectively by silvering to make an animal's body highly reflective. At medium depths at sea, light comes from above, so a mirror oriented vertically makes animals such as fish invisible from the side. Most fish in the upper ocean such as sardine and herring are camouflaged by silvering.
The marine hatchetfish is extremely flattened laterally, leaving the body just millimetres thick, and the body is so silvery as to resemble aluminium foil. The mirrors consist of microscopic structures similar to those used to provide structural coloration: stacks of between 5 and 10 crystals of guanine spaced about ¼ of a wavelength apart to interfere constructively and achieve nearly 100 per cent reflection. In the deep waters that the hatchetfish lives in, only blue light with a wavelength of 500 nanometres percolates down and needs to be reflected, so mirrors 125 nanometres apart provide good camouflage.
In fish such as the herring which live in shallower water, the mirrors must reflect a mixture of wavelengths, and the fish accordingly has crystal stacks with a range of different spacings. A further complication for fish with bodies that are rounded in cross-section is that the mirrors would be ineffective if laid flat on the skin, as they would fail to reflect horizontally. The overall mirror effect is achieved with many small reflectors, all oriented vertically. Silvering is found in other marine animals as well as fish. The cephalopods, including squid, octopus and cuttlefish, have multilayer mirrors made of protein rather than guanine.
Some deep sea fishes have very black skin, reflecting under 0.5% of ambient light. This can prevent detection by predators or prey fish which use bioluminescence for illumination. "Oneirodes" had a particularly black skin which reflected only 0.044% of 480 nm wavelength light. The ultra-blackness is achieved with a thin but continuous layer of particles in the dermis, melanosomes. These particles both absorb most of the light, and are sized and shaped so as to scatter rather than reflect most of the rest. Modelling suggests that this camouflage should reduce the distance at which such a fish can be seen by a factor of 6 compared to a fish with a nominal 2% reflectance. Species with this adaptation are widely dispersed in various orders of the phylogenetic tree of bony fishes (Actinopterygii), implying that natural selection has driven the convergent evolution of ultra-blackness camouflage independently many times.
In mimesis (also called "masquerade"), the camouflaged object looks like something else which is of no special interest to the observer. Mimesis is common in prey animals, for example when a peppered moth caterpillar mimics a twig, or a grasshopper mimics a dry leaf. It is also found in nest structures; some eusocial wasps, such as "Leipomeles dorsata", build a nest envelope in patterns that mimic the leaves surrounding the nest.
Mimesis is also employed by some predators and parasites to lure their prey. For example, a flower mantis mimics a particular kind of flower, such as an orchid. This tactic has occasionally been used in warfare, for example with heavily armed Q-ships disguised as merchant ships.
The common cuckoo, a brood parasite, provides examples of mimesis both in the adult and in the egg. The female lays her eggs in nests of other, smaller species of bird, one per nest. The female mimics a sparrowhawk. The resemblance is sufficient to make small birds take action to avoid the apparent predator. The female cuckoo then has time to lay her egg in their nest without being seen to do so. The cuckoo's egg itself mimics the eggs of the host species, reducing its chance of being rejected.
Most forms of camouflage are made ineffective by movement: a deer or grasshopper may be highly cryptic when motionless, but instantly seen when it moves. But one method, motion dazzle, requires rapidly moving bold patterns of contrasting stripes. Motion dazzle may degrade predators' ability to estimate the prey's speed and direction accurately, giving the prey an improved chance of escape. Motion dazzle distorts speed perception and is most effective at high speeds; stripes can also distort perception of size (and so, perceived range to the target). As of 2011, motion dazzle had been proposed for military vehicles, but never applied. Since motion dazzle patterns would make animals more difficult to locate accurately when moving, but easier to see when stationary, there would be an evolutionary trade-off between motion dazzle and crypsis.
An animal that is commonly thought to be dazzle-patterned is the zebra. The bold stripes of the zebra have been claimed to be disruptive camouflage, background-blending and countershading. After many years in which the purpose of the coloration was disputed, an experimental study by Tim Caro suggested in 2012 that the pattern reduces the attractiveness of stationary models to biting flies such as horseflies and tsetse flies. However, a simulation study by Martin How and Johannes Zanker in 2014 suggests that when moving, the stripes may confuse observers, such as mammalian predators and biting insects, by two visual illusions: the wagon-wheel effect, where the perceived motion is inverted, and the barberpole illusion, where the perceived motion is in a wrong direction.
Ship camouflage was occasionally used in ancient times. Philostratus () wrote in his "Imagines" that Mediterranean pirate ships could be painted blue-gray for concealment. Vegetius () says that "Venetian blue" (sea green) was used in the Gallic Wars, when Julius Caesar sent his "speculatoria navigia" (reconnaissance boats) to gather intelligence along the coast of Britain; the ships were painted entirely in bluish-green wax, with sails, ropes and crew the same colour. There is little evidence of military use of camouflage on land before 1800, but two unusual ceramics show men in Peru's Mochica culture from before 500 AD, hunting birds with blowpipes which are fitted with a kind of shield near the mouth, perhaps to conceal the hunters' hands and faces. Another early source is a 15th-century French manuscript, "The Hunting Book of Gaston Phebus", showing a horse pulling a cart which contains a hunter armed with a crossbow under a cover of branches, perhaps serving as a hide for shooting game. Jamaican Maroons are said to have used plant materials as camouflage in the First Maroon War ().
The development of military camouflage was driven by the increasing range and accuracy of infantry firearms in the 19th century. In particular the replacement of the inaccurate musket with weapons such as the Baker rifle made personal concealment in battle essential. Two Napoleonic War skirmishing units of the British Army, the 95th Rifle Regiment and the 60th Rifle Regiment, were the first to adopt camouflage in the form of a rifle green jacket, while the Line regiments continued to wear scarlet tunics. A contemporary study in 1800 by the English artist and soldier Charles Hamilton Smith provided evidence that grey uniforms were less visible than green ones at a range of 150 yards.
In the American Civil War, rifle units such as the 1st United States Sharp Shooters (in the Federal army) similarly wore green jackets while other units wore more conspicuous colours. The first British Army unit to adopt khaki uniforms was the Corps of Guides at Peshawar, when Sir Harry Lumsden and his second in command, William Hodson introduced a "drab" uniform in 1848. Hodson wrote that it would be more appropriate for the hot climate, and help make his troops "invisible in a land of dust". Later they improvised by dyeing cloth locally. Other regiments in India soon adopted the khaki uniform, and by 1896 khaki drill uniform was used everywhere outside Europe; by the Second Boer War six years later it was used throughout the British Army.
During the late 19th century camouflage was applied to British coastal fortifications. The fortifications around Plymouth, England were painted in the late 1880s in "irregular patches of red, brown, yellow and green." From 1891 onwards British coastal artillery was permitted to be painted in suitable colours "to harmonise with the surroundings" and by 1904 it was standard practice that artillery and mountings should be painted with "large irregular patches of different colours selected to suit local conditions."
In the First World War, the French army formed a camouflage corps, led by Lucien-Victor Guirand de Scévola, employing artists known as "camoufleurs" to create schemes such as tree observation posts and covers for guns. Other armies soon followed them. The term "camouflage" probably comes from "camoufler", a Parisian slang term meaning "to disguise", and may have been influenced by "camouflet", a French term meaning "smoke blown in someone's face". The English zoologist John Graham Kerr, artist Solomon J. Solomon and the American artist Abbott Thayer led attempts to introduce scientific principles of countershading and disruptive patterning into military camouflage, with limited success. In early 1916 the Royal Naval Air Service began to create dummy air fields to draw the attention of enemy planes to empty land. They created decoy homes and lined fake runways with flares, which were meant to help protect real towns from night raids. This strategy was not common practice and did not succeed at first, but in 1918 it caught the Germans off guard multiple times.
Ship camouflage was introduced in the early 20th century as the range of naval guns increased, with ships painted grey all over. In April 1917, when German U-boats were sinking many British ships with torpedoes, the marine artist Norman Wilkinson devised dazzle camouflage, which paradoxically made ships more visible but harder to target. In Wilkinson's own words, dazzle was designed "not for low visibility, but in such a way as to break up her form and thus confuse a submarine officer as to the course on which she was heading".
In the Second World War, the zoologist Hugh Cott, a protégé of Kerr, worked to persuade the British army to use more effective camouflage methods, including countershading, but, like Kerr and Thayer in the First World War, with limited success. For example, he painted two rail-mounted coastal guns, one in conventional style, one countershaded. In aerial photographs, the countershaded gun was essentially invisible. The power of aerial observation and attack led every warring nation to camouflage targets of all types. The Soviet Union's Red Army created the comprehensive doctrine of "Maskirovka" for military deception, including the use of camouflage. For example, during the Battle of Kursk, General Katukov, the commander of the Soviet 1st Tank Army, remarked that the enemy "did not suspect that our well-camouflaged tanks were waiting for him. As we later learned from prisoners, we had managed to move our tanks forward unnoticed". The tanks were concealed in previously prepared defensive emplacements, with only their turrets above ground level. In the air, Second World War fighters were often painted in ground colours above and sky colours below, attempting two different camouflage schemes for observers above and below. Bombers and night fighters were often black, while maritime reconnaissance planes were usually white, to avoid appearing as dark shapes against the sky. For ships, dazzle camouflage was mainly replaced with plain grey in the Second World War, though experimentation with colour schemes continued.
As in the First World War, artists were pressed into service; for example, the surrealist painter Roland Penrose became a lecturer at the newly founded Camouflage Development and Training Centre at Farnham Castle, writing the practical "Home Guard Manual of Camouflage". The film-maker Geoffrey Barkas ran the Middle East Command Camouflage Directorate during the 1941–1942 war in the Western Desert, including the successful deception of Operation Bertram. Hugh Cott was chief instructor; the artist camouflage officers, who called themselves "camoufleurs", included Steven Sykes and Tony Ayrton. In Australia, artists were also prominent in the Sydney Camouflage Group, formed under the chairmanship of Professor William John Dakin, a zoologist from Sydney University. Max Dupain, Sydney Ure Smith, and William Dobell were among the members of the group, which worked at Bankstown Airport, RAAF Base Richmond and Garden Island Dockyard. In the United States, artists like John Vassos took a certificate course in military and industrial camouflage at the American School of Design with Baron Nicholas Cerkasoff, and went on to create camouflage for the Air Force.
Camouflage has been used to protect military equipment such as vehicles, guns, ships, aircraft and buildings as well as individual soldiers and their positions.
Vehicle camouflage methods begin with paint, which offers at best only limited effectiveness. Other methods for stationary land vehicles include covering with improvised materials such as blankets and vegetation, and erecting nets, screens and soft covers which may suitably reflect, scatter or absorb near infrared and radar waves. Some military textiles and vehicle camouflage paints also reflect infrared to help provide concealment from night vision devices.
After the Second World War, radar made camouflage generally less effective, though coastal boats are sometimes painted like land vehicles. Aircraft camouflage too came to be seen as less important because of radar, and aircraft of different air forces, such as the Royal Air Force's Lightning, were often uncamouflaged.
Many camouflaged textile patterns have been developed to suit the need to match combat clothing to different kinds of terrain (such as woodland, snow, and desert). The design of a pattern effective in all terrains has proved elusive. The American Universal Camouflage Pattern of 2004 attempted to suit all environments, but was withdrawn after a few years of service. Terrain-specific patterns have sometimes been developed but are ineffective in other terrains. The problem of making a pattern that works at different ranges has been solved with multiscale designs, often with a pixellated appearance and designed digitally, that provide a fractal-like range of patch sizes so they appear disruptively coloured both at close range and at a distance. The first genuinely digital camouflage pattern was the Canadian Disruptive Pattern (CADPAT), issued to the army in 2002, soon followed by the American Marine pattern (MARPAT). A pixellated appearance is not essential for this effect, though it is simpler to design and to print.
Hunters of game have long made use of camouflage in the form of materials such as animal skins, mud, foliage, and green or brown clothing to enable them to approach wary game animals. Field sports such as driven grouse shooting conceal hunters in hides (also called blinds or shooting butts). Modern hunting clothing makes use of fabrics that provide a disruptive camouflage pattern; for example, in 1986 the hunter Bill Jordan created cryptic clothing for hunters, printed with images of specific kinds of vegetation such as grass and branches.
Camouflage is occasionally used to make built structures less conspicuous: for example, in South Africa, towers carrying cell telephone antennae are sometimes camouflaged as tall trees with plastic branches, in response to "resistance from the community". Since this method is costly (a figure of three times the normal cost is mentioned), alternative forms of camouflage can include using neutral colours or familiar shapes such as cylinders and flagpoles. Conspicuousness can also be reduced by siting masts near, or on, other structures.
Automotive manufacturers often use patterns to disguise upcoming products. This camouflage is designed to obfuscate the vehicle's visual lines, and is used along with padding, covers, and decals. The patterns' purpose is to prevent visual observation (and to a lesser degree photography), that would subsequently enable reproduction of the vehicle's form factors.
Military camouflage patterns influenced fashion and art from the time of the First World War onwards. Gertrude Stein recalled the cubist artist Pablo Picasso's reaction in around 1915:
In 1919, the attendants of a "dazzle ball", hosted by the Chelsea Arts Club, wore dazzle-patterned black and white clothing. The ball influenced fashion and art via postcards and magazine articles. The "Illustrated London News" announced:
More recently, fashion designers have often used camouflage fabric for its striking designs, its "patterned disorder" and its symbolism. Camouflage clothing can be worn largely for its symbolic significance rather than for fashion, as when, during the late 1960s and early 1970s in the United States, anti-war protestors often ironically wore military clothing during demonstrations against the American involvement in the Vietnam War.
Modern artists such as Ian Hamilton Finlay have used camouflage to reflect on war. His 1973 screenprint of a tank camouflaged in a leaf pattern, "Arcadia", is described by the Tate as drawing "an ironic parallel between this idea of a natural paradise and the camouflage patterns on a tank". The title refers to the Utopian Arcadia of poetry and art, and the "memento mori" Latin phrase "Et in Arcadia ego" which recurs in Hamilton Finlay's work. In science fiction, "Camouflage" is a novel about shapeshifting alien beings by Joe Haldeman. The word is used more figuratively in works of literature such as Thaisa Frank's collection of stories of love and loss, "A Brief History of Camouflage".

</doc>
<doc id="6449" url="https://en.wikipedia.org/wiki?curid=6449" title="Clock">
Clock

A clock is a device used to measure, keep, and indicate time. The clock is one of the oldest human inventions, meeting the need to measure intervals of time shorter than the natural units: the day, the lunar month, and the year. Devices operating on several physical processes have been used over the millennia.
Some predecessors to the modern clock may be considered as "clocks" that are based on movement in nature: A sundial shows the time by displaying the position of a shadow on a flat surface. There is a range of duration timers, a well-known example being the hourglass. Water clocks, along with the sundials, are possibly the oldest time-measuring instruments. A major advance occurred with the invention of the verge escapement, which made possible the first mechanical clocks around 1300 in Europe, which kept time with oscillating timekeepers like balance wheels.
Traditionally in horology, the term "clock" was used for a striking clock, while a clock that did not strike the hours audibly was called a timepiece. In general usage today, a "clock" refers to any device for measuring and displaying the time. Watches and other timepieces that can be carried on one's person are often distinguished from clocks.
Spring-driven clocks appeared during the 15th century. During the 15th and 16th centuries, clockmaking flourished. The next development in accuracy occurred after 1656 with the invention of the pendulum clock by Christiaan Huygens. A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The electric clock was patented in 1840. The development of electronics in the 20th century led to clocks with no clockwork parts at all.
The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates at a particular frequency.
This object can be a pendulum, a tuning fork, a quartz crystal, or the vibration of electrons in atoms as they emit microwaves.
Clocks have different ways of displaying the time. Analog clocks indicate time with a traditional clock face, with moving hands. Digital clocks display a numeric representation of time. Two numbering systems are in use; 24-hour time notation and 12-hour notation. Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays. For the blind and use over telephones, speaking clocks state the time audibly in words. There are also clocks for the blind that have displays that can be read by touch. The study of timekeeping is known as horology.
The word "clock" derives from the medieval Latin word for 'bell'——and has cognates in many European languages. Clocks spread to England from the Low Countries, so the English word came from the Middle Low German and Middle Dutch "Klocke".
The apparent position of the Sun in the sky moves over the course of each day, reflecting the rotation of the Earth. Shadows cast by stationary objects move correspondingly, so their positions can be used to indicate the time of day. A sundial shows the time by displaying the position of a shadow on a (usually) flat surface, which has markings that correspond to the hours. Sundials can be horizontal, vertical, or in other orientations. Sundials were widely used in ancient times. With the knowledge of latitude, a well-constructed sundial can measure local solar time with reasonable accuracy, within a minute or two. Sundials continued to be used to monitor the performance of clocks until the 1830s, with the use of the telegraph and train to standardize time and time zones between cities.
Many devices can be used to mark passage of time without respect to reference time (time of day, hours, minutes, etc.) and can be useful for measuring duration or intervals. Examples of such duration timers are candle clocks, incense clocks and the hourglass. Both the candle clock and the incense clock work on the same principle wherein the consumption of resources is more or less constant allowing reasonably precise and repeatable estimates of time passages. In the hourglass, fine sand pouring through a tiny hole at a constant rate indicates an arbitrary, predetermined, passage of time. The resource is not consumed but re-used.
Water clocks, along with the sundials, are possibly the oldest time-measuring instruments, with the only exceptions being the day counting tally stick. Given their great antiquity, where and when they first existed is not known and perhaps unknowable. The bowl-shaped outflow is the simplest form of a water clock and is known to have existed in Babylon and in Egypt around the 16th century BC. Other regions of the world, including India and China, also have early evidence of water clocks, but the earliest dates are less certain. Some authors, however, write about water clocks appearing as early as 4000 BC in these regions of the world.
Greek astronomer Andronicus of Cyrrhus supervised the construction of the Tower of the Winds in Athens in the 1st century B.C. The Greek and Roman civilizations advanced water clock design with improved accuracy. These advances were passed on through Byzantium and Islamic times, eventually making their way back to Europe. Independently, the Chinese developed their own advanced water clocks（水鐘）in 725 AD, passing their ideas on to Korea and Japan.
Some water clock designs were developed independently and some knowledge was transferred through the spread of trade. Pre-modern societies do not have the same precise timekeeping requirements that exist in modern industrial societies, where every hour of work or rest is monitored, and work may start or finish at any time regardless of external conditions. Instead, water clocks in ancient societies were used mainly for astrological reasons. These early water clocks were calibrated with a sundial. While never reaching the level of accuracy of a modern timepiece, the water clock was the most accurate and commonly used timekeeping device for millennia, until it was replaced by the more accurate pendulum clock in 17th-century Europe.
Islamic civilization is credited with further advancing the accuracy of clocks with elaborate engineering. In 797 (or possibly 801), the Abbasid caliph of Baghdad, Harun al-Rashid, presented Charlemagne with an Asian Elephant named Abul-Abbas together with a "particularly elaborate example" of a water clock. Pope Sylvester II introduced clocks to northern and western Europe around 1000 AD.
The first known geared clock was invented the great mathematician, physicist and engineer Archimedes during the 3rd century BC. Archimedes created his astronomical clock that was also a cuckoo clock with birds singing and moving every hour. It is the first carillon clock as it plays music and simultaneously with a person blinking his eyes surprised by the singing birds. Archimedes clock works with a system of four weights, counter weights and strings regulated by a system of floats in a water container with siphons the regulate the automatic continuation of the clock. The principles of this type of clocks are described by the mathematician and physicist Hero, who says that some of them work with a chain that turns a gear of the mechanism. Another Greek clock probably constructed at the time of Alexander was in Gaza, described by Procopius. The Gaza clock was probably a Meteoroskopeion, i.e. a building showing the celestial phenomena and the time. It had pointer for the time and some automations similar to the Archimedes clock. There were 12 doors opening one every hour with Hercules preforming his labors, the Lion at one o'clock, etc, and at night a lamp becomes visible every hour, with 12 windows opening to show the time.
Another geared clock was developed in the 11th century by the Arab engineer Ibn Khalaf al-Muradi in Islamic Iberia; it was a water clock that employed a complex gear train mechanism, including both segmental and epicyclic gearing, capable of transmitting high torque. The clock was unrivalled in its use of sophisticated complex gearing, until the mechanical clocks of the mid-14th century. Al-Muradi's clock also employed the use of mercury in its hydraulic linkages, which could function mechanical automata. Al-Muradi's work was known to scholars working under Alfonso X of Castile, hence the mechanism may have played a role in the development of the European mechanical clocks. Other monumental water clocks constructed by medieval Muslim engineers also employed complex gear trains and arrays of automata. Arab engineers at the time also developed a liquid-driven escapement mechanism which they employed in some of their water clocks. Heavy floats were used as weights and a constant-head system was used as an escapement mechanism, which was present in the hydraulic controls they used to make heavy floats descend at a slow and steady rate.
A water-powered cogwheel clock was created in China by Yi Xing and Liang Lingzan. This is not considered an escapement mechanism clock as it was unidirectional, the Song dynasty polymath and genius Su Song (1020–1101) incorporated it into his monumental innovation of the astronomical clock-tower of Kaifeng in 1088. His astronomical clock and rotating armillary sphere still relied on the use of either flowing water during the spring, summer, autumn seasons and liquid mercury during the freezing temperature of winter (i.e. hydraulics). A mercury clock, described in the "Libros del saber", a Spanish work from 1277 consisting of translations and paraphrases of Arabic works, is sometimes quoted as evidence for Muslim knowledge of a mechanical clock. A mercury-powered cogwheel clock was created by Ibn Khalaf al-Muradi.
In the 13th century, Al-Jazari, an engineer from Mesopotamia (lived 1136–1206) who worked for Artuqid king of Diyar-Bakr, Nasir al-Din, made numerous clocks of all shapes and sizes. A book on his work described 50 mechanical devices in 6 categories, including water clocks. The most reputed clocks included the Elephant, Scribe and Castle clocks, all of which have been successfully reconstructed. As well as telling the time, these grand clocks were symbols of status, grandeur and wealth of the Urtuq State.
The word (from the Greek —'hour', and —'to tell') was used to describe early mechanical clocks, but the use of this word (still used in several Romance languages) for all timekeepers conceals the true nature of the mechanisms. For example, there is a record that in 1176 Sens Cathedral installed an 'horologe' but the mechanism used is unknown. According to Jocelin of Brakelond, in 1198 during a fire at the abbey of St Edmundsbury (now Bury St Edmunds), the monks 'ran to the clock' to fetch water, indicating that their water clock had a reservoir large enough to help extinguish the occasional fire. The word "clock" (via Medieval Latin from Old Irish , both meaning 'bell'), which gradually supersedes "horologe", suggests that it was the sound of bells which also characterized the prototype mechanical clocks that appeared during the 13th century in Europe.
In Europe, between 1280 and 1320, there was an increase in the number of references to clocks and horologes in church records, and this probably indicates that a new type of clock mechanism had been devised. Existing clock mechanisms that used water power were being adapted to take their driving power from falling weights. This power was controlled by some form of oscillating mechanism, probably derived from existing bell-ringing or alarm devices. This controlled release of power—the escapement—marks the beginning of the true mechanical clock, which differed from the previously mentioned cogwheel clocks. Verge escapement mechanism derived in the surge of true mechanical clocks, which didn't need any kind of fluid power, like water or mercury, to work.
These mechanical clocks were intended for two main purposes: for signalling and notification (e.g. the timing of services and public events), and for modeling the solar system. The former purpose is administrative, the latter arises naturally given the scholarly interests in astronomy, science, astrology, and how these subjects integrated with the religious philosophy of the time. The astrolabe was used both by astronomers and astrologers, and it was natural to apply a clockwork drive to the rotating plate to produce a working model of the solar system.
Simple clocks intended mainly for notification were installed in towers, and did not always require faces or hands. They would have announced the canonical hours or intervals between set times of prayer. Canonical hours varied in length as the times of sunrise and sunset shifted. The more sophisticated astronomical clocks would have had moving dials or hands, and would have shown the time in various time systems, including Italian hours, canonical hours, and time as measured by astronomers at the time. Both styles of clock started acquiring extravagant features such as automata.
In 1283, a large clock was installed at Dunstable Priory; its location above the rood screen suggests that it was not a water clock. In 1292, Canterbury Cathedral installed a 'great horloge'. Over the next 30 years there are mentions of clocks at a number of ecclesiastical institutions in England, Italy, and France. In 1322, a new clock was installed in Norwich, an expensive replacement for an earlier clock installed in 1273. This had a large (2 metre) astronomical dial with automata and bells. The costs of the installation included the full-time employment of two clockkeepers for two years.
Besides the Chinese astronomical clock of Su Song in 1088 mentioned above, contemporary Muslim astronomers also constructed a variety of highly accurate astronomical clocks for use in their mosques and observatories, such as the water-powered astronomical clock by Al-Jazari in 1206, and the astrolabic clock by Ibn al-Shatir in the early 14th century. The most sophisticated timekeeping astrolabes were the geared astrolabe mechanisms designed by Abū Rayhān Bīrūnī in the 11th century and by Muhammad ibn Abi Bakr in the 13th century. These devices functioned as timekeeping devices and also as calendars.
A sophisticated water-powered astronomical clock was built by Al-Jazari in 1206. This castle clock was a complex device that was about high, and had multiple functions alongside timekeeping. It included a display of the zodiac and the solar and lunar paths, and a pointer in the shape of the crescent moon which travelled across the top of a gateway, moved by a hidden cart and causing doors to open, each revealing a mannequin, every hour. It was possible to reset the length of day and night in order to account for the changing lengths of day and night throughout the year. This clock also featured a number of automata including falcons and musicians who automatically played music when moved by levers operated by a hidden camshaft attached to a water wheel.
In Europe, there were the clocks constructed by Richard of Wallingford in St Albans by 1336, and by Giovanni de Dondi in Padua from 1348 to 1364. They no longer exist, but detailed descriptions of their design and construction survive, and modern reproductions have been made. They illustrate how quickly the theory of the mechanical clock had been translated into practical constructions, and also that one of the many impulses to their development had been the desire of astronomers to investigate celestial phenomena.
Wallingford's clock had a large astrolabe-type dial, showing the sun, the moon's age, phase, and node, a star map, and possibly the planets. In addition, it had a wheel of fortune and an indicator of the state of the tide at London Bridge. Bells rang every hour, the number of strokes indicating the time. Dondi's clock was a seven-sided construction, 1 metre high, with dials showing the time of day, including minutes, the motions of all the known planets, an automatic calendar of fixed and movable feasts, and an eclipse prediction hand rotating once every 18 years. It is not known how accurate or reliable these clocks would have been. They were probably adjusted manually every day to compensate for errors caused by wear and imprecise manufacture. Water clocks are sometimes still used today, and can be examined in places such as ancient castles and museums. The Salisbury Cathedral clock, built in 1386, is considered to be the world's oldest surviving mechanical clock that strikes the hours.
Clockmakers developed their art in various ways. Building smaller clocks was a technical challenge, as was improving accuracy and reliability. Clocks could be impressive showpieces to demonstrate skilled craftsmanship, or less expensive, mass-produced items for domestic use. The escapement in particular was an important factor affecting the clock's accuracy, so many different mechanisms were tried.
Spring-driven clocks appeared during the 15th century, although they are often erroneously credited to Nuremberg watchmaker Peter Henlein (or Henle, or Hele) around 1511. The earliest existing spring driven clock is the chamber clock given to Phillip the Good, Duke of Burgundy, around 1430, now in the Germanisches National museum. Spring power presented clockmakers with a new problem: how to keep the clock movement running at a constant rate as the spring ran down. This resulted in the invention of the "stackfreed" and the fusee in the 15th century, and many other innovations, down to the invention of the modern "going barrel" in 1760.
Early clock dials did not indicate minutes and seconds. A clock with a dial indicating minutes was illustrated in a 1475 manuscript by Paulus Almanus, and some 15th-century clocks in Germany indicated minutes and seconds.
An early record of a seconds hand on a clock dates back to about 1560 on a clock now in the Fremersdorf collection.
During the 15th and 16th centuries, clockmaking flourished, particularly in the metalworking towns of Nuremberg and Augsburg, and in Blois, France. Some of the more basic table clocks have only one time-keeping hand, with the dial between the hour markers being divided into four equal parts making the clocks readable to the nearest 15 minutes. Other clocks were exhibitions of craftsmanship and skill, incorporating astronomical indicators and musical movements. The cross-beat escapement was invented in 1584 by Jost Bürgi, who also developed the remontoire. Bürgi's clocks were a great improvement in accuracy as they were correct to within a minute a day. These clocks helped the 16th-century astronomer Tycho Brahe to observe astronomical events with much greater precision than before.
The next development in accuracy occurred after 1656 with the invention of the pendulum clock. Galileo had the idea to use a swinging bob to regulate the motion of a time-telling device earlier in the 17th century. Christiaan Huygens, however, is usually credited as the inventor. He determined the mathematical formula that related pendulum length to time (about 99.4 cm or 39.1 inches for the one second movement) and had the first pendulum-driven clock made. The first model clock was built in 1657 in the Hague, but it was in England that the idea was taken up. The longcase clock (also known as the "grandfather clock") was created to house the pendulum and works by the English clockmaker William Clement in 1670 or 1671. It was also at this time that clock cases began to be made of wood and clock faces to utilize enamel as well as hand-painted ceramics.
In 1670, William Clement created the anchor escapement, an improvement over Huygens' crown escapement. Clement also introduced the pendulum suspension spring in 1671. The concentric minute hand was added to the clock by Daniel Quare, a London clockmaker and others, and the second hand was first introduced.
In 1675, Huygens and Robert Hooke invented the spiral balance spring, or the hairspring, designed to control the oscillating speed of the balance wheel. This crucial advance finally made accurate pocket watches possible. The great English clockmaker, Thomas Tompion, was one of the first to use this mechanism successfully in his pocket watches, and he adopted the minute hand which, after a variety of designs were trialled, eventually stabilised into the modern-day configuration. The rack and snail striking mechanism for striking clocks, was introduced during the 17th century and had distinct advantages over the 'countwheel' (or 'locking plate') mechanism. During the 20th century there was a common misconception that Edward Barlow invented "rack and snail" striking. In fact, his invention was connected with a repeating mechanism employing the rack and snail. The repeating clock, that chimes the number of hours (or even minutes) on demand was invented by either Quare or Barlow in 1676. George Graham invented the deadbeat escapement for clocks in 1720.
A major stimulus to improving the accuracy and reliability of clocks was the importance of precise time-keeping for navigation. The position of a ship at sea could be determined with reasonable accuracy if a navigator could refer to a clock that lost or gained less than about 10 seconds per day. This clock could not contain a pendulum, which would be virtually useless on a rocking ship. In 1714, the British government offered large financial rewards to the value of 20,000 pounds for anyone who could determine longitude accurately. John Harrison, who dedicated his life to improving the accuracy of his clocks, later received considerable sums under the Longitude Act.
In 1735, Harrison built his first chronometer, which he steadily improved on over the next thirty years before submitting it for examination. The clock had many innovations, including the use of bearings to reduce friction, weighted balances to compensate for the ship's pitch and roll in the sea and the use of two different metals to reduce the problem of expansion from heat. The chronometer was tested in 1761 by Harrison's son and by the end of 10 weeks the clock was in error by less than 5 seconds.
The British had predominated in watch manufacture for much of the 17th and 18th centuries, but maintained a system of production that was geared towards high quality products for the elite. Although there was an attempt to modernise clock manufacture with mass production techniques and the application of duplicating tools and machinery by the British Watch Company in 1843, it was in the United States that this system took off. In 1816, Eli Terry and some other Connecticut clockmakers developed a way of mass-producing clocks by using interchangeable parts. Aaron Lufkin Dennison started a factory in 1851 in Massachusetts that also used interchangeable parts, and by 1861 was running a successful enterprise incorporated as the Waltham Watch Company.
In 1815, Francis Ronalds published the first electric clock powered by dry pile batteries. Alexander Bain, Scottish clockmaker, patented the electric clock in 1840. The electric clock's mainspring is wound either with an electric motor or with an electromagnet and armature. In 1841, he first patented the electromagnetic pendulum. By the end of the nineteenth century, the advent of the dry cell battery made it feasible to use electric power in clocks. Spring or weight driven clocks that use electricity, either alternating current (AC) or direct current (DC), to rewind the spring or raise the weight of a mechanical clock would be classified as an electromechanical clock. This classification would also apply to clocks that employ an electrical impulse to propel the pendulum. In electromechanical clocks the electricity serves no time keeping function. These types of clocks were made as individual timepieces but more commonly used in synchronized time installations in schools, businesses, factories, railroads and government facilities as a master clock and slave clocks.
Electric clocks that are powered from the AC supply often use synchronous motors. The supply current alternates with a frequency of 50 hertz in many countries, and 60 hertz in others. The rotor of the motor rotates at a speed that is related to the alternation frequency. Appropriate gearing converts this rotation speed to the correct ones for the hands of the analog clock. The development of electronics in the 20th century led to clocks with no clockwork parts at all. Time in these cases is measured in several ways, such as by the alternation of the AC supply, vibration of a tuning fork, the behaviour of quartz crystals, or the quantum vibrations of atoms. Electronic circuits divide these high-frequency oscillations to slower ones that drive the time display. Even mechanical clocks have since come to be largely powered by batteries, removing the need for winding.
The piezoelectric properties of crystalline quartz were discovered by Jacques and Pierre Curie in 1880. The first crystal oscillator was invented in 1917 by Alexander M. Nicholson after which, the first quartz crystal oscillator was built by Walter G. Cady in 1921. In 1927 the first quartz clock was built by Warren Marrison and J.W. Horton at Bell Telephone Laboratories in Canada. The following decades saw the development of quartz clocks as precision time measurement devices in laboratory settings—the bulky and delicate counting electronics, built with vacuum tubes, limited their practical use elsewhere. The National Bureau of Standards (now NIST) based the time standard of the United States on quartz clocks from late 1929 until the 1960s, when it changed to atomic clocks. In 1969, Seiko produced the world's first quartz wristwatch, the Astron. Their inherent accuracy and low cost of production resulted in the subsequent proliferation of quartz clocks and watches.
Currently, atomic clocks are the most accurate clocks in existence. They are considerably more accurate than quartz clocks as they can be accurate to within a few seconds over trillions of years. Atomic clocks were first theorized by Lord Kelvin in 1879. In the 1930s the development of Magnetic resonance created practical method for doing this. A prototype ammonia maser device was built in 1949 at the U.S. National Bureau of Standards (NBS, now NIST). Although it was less accurate than existing quartz clocks, it served to demonstrate the concept. The first accurate atomic clock, a caesium standard based on a certain transition of the caesium-133 atom, was built by Louis Essen in 1955 at the National Physical Laboratory in the UK. Calibration of the caesium standard atomic clock was carried out by the use of the astronomical time scale "ephemeris time" (ET). As of 2013, the most stable atomic clocks are ytterbium clocks, which are stable to within less than two parts in 1 quintillion ().
The invention of the mechanical clock in the 13th century initiated a change in timekeeping methods from continuous processes, such as the motion of the gnomon's shadow on a sundial or the flow of liquid in a water clock, to periodic oscillatory processes, such as the swing of a pendulum or the vibration of a quartz crystal, which had the potential for more accuracy. All modern clocks use oscillation.
Although the mechanisms they use vary, all oscillating clocks, mechanical, digital and atomic, work similarly and can be divided into analogous parts. They consist of an object that repeats the same motion over and over again, an "oscillator", with a precisely constant time interval between each repetition, or 'beat'. Attached to the oscillator is a "controller" device, which sustains the oscillator's motion by replacing the energy it loses to friction, and converts its oscillations into a series of pulses. The pulses are then counted by some type of "counter", and the number of counts is converted into convenient units, usually seconds, minutes, hours, etc. Finally some kind of "indicator" displays the result in human readable form.
The timekeeping element in every modern clock is a harmonic oscillator, a physical object (resonator) that vibrates or oscillates repetitively at a precisely constant frequency.
The advantage of a harmonic oscillator over other forms of oscillator is that it employs resonance to vibrate at a precise natural resonant frequency or "beat" dependent only on its physical characteristics, and resists vibrating at other rates. The possible precision achievable by a harmonic oscillator is measured by a parameter called its Q, or quality factor, which increases (other things being equal) with its resonant frequency. This is why there has been a long term trend toward higher frequency oscillators in clocks. Balance wheels and pendulums always include a means of adjusting the rate of the timepiece. Quartz timepieces sometimes include a rate screw that adjusts a capacitor for that purpose. Atomic clocks are primary standards, and their rate cannot be adjusted.
Some clocks rely for their accuracy on an external oscillator; that is, they are automatically synchronized to a more accurate clock:
This has the dual function of keeping the oscillator running by giving it 'pushes' to replace the energy lost to friction, and converting its vibrations into a series of pulses that serve to measure the time.
In mechanical clocks, the low Q of the balance wheel or pendulum oscillator made them very sensitive to the disturbing effect of the impulses of the escapement, so the escapement had a great effect on the accuracy of the clock, and many escapement designs were tried. The higher Q of resonators in electronic clocks makes them relatively insensitive to the disturbing effects of the drive power, so the driving oscillator circuit is a much less critical component.
This counts the pulses and adds them up to get traditional time units of seconds, minutes, hours, etc. It usually has a provision for "setting" the clock by manually entering the correct time into the counter.
This displays the count of seconds, minutes, hours, etc. in a human readable form.
Clocks can be classified by the type of time display, as well as by the method of timekeeping.
Analog clocks usually use a clock face which indicates time using rotating pointers called "hands" on a fixed numbered dial or dials. The standard clock face, known universally throughout the world, has a short "hour hand" which indicates the hour on a circular dial of 12 hours, making two revolutions per day, and a longer "minute hand" which indicates the minutes in the current hour on the same dial, which is also divided into 60 minutes. It may also have a "second hand" which indicates the seconds in the current minute. The only other widely used clock face today is the 24 hour analog dial, because of the use of 24 hour time in military organizations and timetables. Before the modern clock face was standardized during the Industrial Revolution, many other face designs were used throughout the years, including dials divided into 6, 8, 10, and 24 hours. During the French Revolution the French government tried to introduce a 10-hour clock, as part of their decimal-based metric system of measurement, but it didn't catch on. An Italian 6 hour clock was developed in the 18th century, presumably to save power (a clock or watch striking 24 times uses more power).
Another type of analog clock is the sundial, which tracks the sun continuously, registering the time by the shadow position of its gnomon. Because the sun does not adjust to daylight saving time, users must add an hour during that time. Corrections must also be made for the equation of time, and for the difference between the longitudes of the sundial and of the central meridian of the time zone that is being used (i.e. 15 degrees east of the prime meridian for each hour that the time zone is ahead of GMT). Sundials use some or part of the 24 hour analog dial. There also exist clocks which use a digital display despite having an analog mechanism—these are commonly referred to as flip clocks. Alternative systems have been proposed. For example, the "Twelv" clock indicates the current hour using one of twelve colors, and indicates the minute by showing a proportion of a circular disk, similar to a moon phase.
Digital clocks display a numeric representation of time. Two numeric display formats are commonly used on digital clocks:
Most digital clocks use electronic mechanisms and LCD, LED, or VFD displays; many other display technologies are used as well (cathode ray tubes, nixie tubes, etc.). After a reset, battery change or power failure, these clocks without a backup battery or capacitor either start counting from 12:00, or stay at 12:00, often with blinking digits indicating that the time needs to be set. Some newer clocks will reset themselves based on radio or Internet time servers that are tuned to national atomic clocks. Since the advent of digital clocks in the 1960s, the use of analog clocks has declined significantly.
Some clocks, called 'flip clocks', have digital displays that work mechanically. The digits are painted on sheets of material which are mounted like the pages of a book. Once a minute, a page is turned over to reveal the next digit. These displays are usually easier to read in brightly lit conditions than LCDs or LEDs. Also, they do not go back to 12:00 after a power interruption. Flip clocks generally do not have electronic mechanisms. Usually, they are driven by AC-synchronous motors.
Clocks with analog quadrants, with a digital component, usually minutes and hours displayed analogously and seconds displayed in digital mode.
For convenience, distance, telephony or blindness, auditory clocks present the time as sounds. The sound is either spoken natural language, (e.g. "The time is twelve thirty-five"), or as auditory codes (e.g. number of sequential bell rings on the hour represents the number of the hour like the bell, Big Ben). Most telecommunication companies also provide a speaking clock service as well.
Word clocks are clocks that display the time visually using sentences. E.g.: "It's about three o'clock." These clocks can be implemented in hardware or software.
Some clocks, usually digital ones, include an optical projector that shines a magnified image of the time display onto a screen or onto a surface such as an indoor ceiling or wall. The digits are large enough to be easily read, without using glasses, by persons with moderately imperfect vision, so the clocks are convenient for use in their bedrooms. Usually, the timekeeping circuitry has a battery as a backup source for an uninterrupted power supply to keep the clock on time, while the projection light only works when the unit is connected to an A.C. supply. Completely battery-powered portable versions resembling flashlights are also available.
Auditory and projection clocks can be used by people who are blind or have limited vision. There are also clocks for the blind that have displays that can be read by using the sense of touch. Some of these are similar to normal analog displays, but are constructed so the hands can be felt without damaging them. Another type is essentially digital, and uses devices that use a code such as Braille to show the digits so that they can be felt with the fingertips.
Some clocks have several displays driven by a single mechanism, and some others have several completely separate mechanisms in a single case. Clocks in public places often have several faces visible from different directions, so that the clock can be read from anywhere in the vicinity; all the faces show the same time. Other clocks show the current time in several time-zones. Watches that are intended to be carried by travellers often have two displays, one for the local time and the other for the time at home, which is useful for making pre-arranged phone calls. Some equation clocks have two displays, one showing mean time and the other solar time, as would be shown by a sundial. Some clocks have both analog and digital displays. Clocks with Braille displays usually also have conventional digits so they can be read by sighted people.
Clocks are in homes, offices and many other places; smaller ones (watches) are carried on the wrist or in a pocket; larger ones are in public places, e.g. a railway station or church. A small clock is often shown in a corner of computer displays, mobile phones and many MP3 players.
The primary purpose of a clock is to "display" the time. Clocks may also have the facility to make a loud alert signal at a specified time, typically to waken a sleeper at a preset time; they are referred to as "alarm clocks". The alarm may start at a low volume and become louder, or have the facility to be switched off for a few minutes then resume. Alarm clocks with visible indicators are sometimes used to indicate to children too young to read the time that the time for sleep has finished; they are sometimes called "training clocks".
A clock mechanism may be used to "control" a device according to time, e.g. a central heating system, a VCR, or a time bomb (see: digital counter). Such mechanisms are usually called timers. Clock mechanisms are also used to drive devices such as solar trackers and astronomical telescopes, which have to turn at accurately controlled speeds to counteract the rotation of the Earth.
Most digital computers depend on an internal signal at constant frequency to synchronize processing; this is referred to as a clock signal. (A few research projects are developing CPUs based on asynchronous circuits.) Some equipment, including computers, also maintains time and date for use as required; this is referred to as time-of-day clock, and is distinct from the system clock signal, although possibly based on counting its cycles.
In Chinese culture, giving a clock () is often taboo, especially to the elderly as the term for this act is a homophone with the term for the act of attending another's funeral (). A UK government official Susan Kramer gave a watch to Taipei mayor Ko Wen-je unaware of such a taboo which resulted in some professional embarrassment and a pursuant apology.
This homonymic pair works in both Mandarin and Cantonese, although in most parts of China only clocks and large bells, and not watches, are called "zhong", and watches are commonly given as gifts in China.
However, should such a gift be given, the "unluckiness" of the gift can be countered by exacting a small monetary payment so the recipient is buying the clock and thereby counteracting the ("give") expression of the phrase.
For some scientific work timing of the utmost accuracy is essential. It is also necessary to have a standard of the maximum accuracy against which working clocks can be calibrated. An ideal clock would give the time to unlimited accuracy, but this is not realisable. Many physical processes, in particular including some transitions between atomic energy levels, occur at exceedingly stable frequency; counting cycles of such a process can give a very accurate and consistent time—clocks which work this way are usually called atomic clocks. Such clocks are typically large, very expensive, require a controlled environment, and are far more accurate than required for most purposes; they are typically used in a standards laboratory.
Until advances in the late twentieth century, navigation depended on the ability to measure latitude and longitude. Latitude can be determined through celestial navigation; the measurement of longitude requires accurate knowledge of time. This need was a major motivation for the development of accurate mechanical clocks. John Harrison created the first highly accurate marine chronometer in the mid-18th century. The Noon gun in Cape Town still fires an accurate signal to allow ships to check their chronometers. Many buildings near major ports used to have (some still do) a large ball mounted on a tower or mast arranged to drop at a pre-determined time, for the same purpose. While satellite navigation systems such as the Global Positioning System (GPS) require unprecedentedly accurate knowledge of time, this is supplied by equipment on the satellites; vehicles no longer need timekeeping equipment.

</doc>
<doc id="6451" url="https://en.wikipedia.org/wiki?curid=6451" title="Charles Proteus Steinmetz">
Charles Proteus Steinmetz

Charles Proteus Steinmetz (born Karl August Rudolph Steinmetz, April 9, 1865 – October 26, 1923) was a German-born American mathematician and electrical engineer and professor at Union College. He fostered the development of alternating current that made possible the expansion of the electric power industry in the United States, formulating mathematical theories for engineers. He made ground-breaking discoveries in the understanding of hysteresis that enabled engineers to design better electromagnetic apparatus equipment, especially electric motors for use in industry.
At the time of his death, Steinmetz held over 200 patents. A genius in both mathematics and electronics, he did work that earned him the nicknames "Forger of Thunderbolts" and "The Wizard of Schenectady". Steinmetz's equation, Steinmetz solids, Steinmetz curves, and Steinmetz equivalent circuit theory are all named after him, as are numerous honors and scholarships, including the "IEEE Charles Proteus Steinmetz Award", one of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers professional society.
Steinmetz was born Karl August Rudolph Steinmetz on April 9, 1865 in Breslau, Province of Silesia, Prussia (now Wrocław, Poland) the son of Caroline (Neubert) and Karl Heinrich Steinmetz. He was baptized a Lutheran into the Evangelical Church of Prussia. Steinmetz, who stood only four feet tall as an adult, suffered from dwarfism, hunchback, and hip dysplasia, as did his father and grandfather. Steinmetz attended Johannes Gymnasium and astonished his teachers with his proficiency in mathematics and physics.
Following the Gymnasium, Steinmetz went on to the University of Breslau to begin work on his undergraduate degree in 1883. He was on the verge of finishing his doctorate in 1888 when he came under investigation by the German police for activities on behalf of a socialist university group and articles he had written for a local socialist newspaper.
As socialist meetings and press had been banned in Germany, Steinmetz fled to Zürich in 1888 to escape possible arrest. Cornell University Professor Ronald R. Kline, author of "Steinmetz: Engineer and Socialist", contended that other factors were more directly involved in Steinmetz's decision to leave his homeland such as being in arrears with his tuition at the University and life at home with his father, stepmother and their daughters being tension-filled.
Faced with an expiring visa, he emigrated to the United States in 1889. He changed his first name to "Charles" in order to sound more American, and chose the middle name "Proteus", a wise hunchbacked character from the "Odyssey" who knew many secrets, after a childhood epithet given by classmates Steinmetz felt suited him.
Despite his earlier efforts and interest in socialism, by 1922 Steinmetz concluded that socialism would never work in the United States, because the country lacked a "powerful, centralized government of competent men, remaining continuously in office", and because "only a small percentage of Americans accept this viewpoint today".
A member of the original Technical Alliance, which also included Thorstein Veblen and Leland Olds, Steinmetz had great faith in the ability of machines to eliminate human toil and create abundance for all. He put it this way: "Some day we make the good things of life for everybody".
Steinmetz is known for his contribution in three major fields of alternating current (AC) systems theory: hysteresis, steady-state analysis, and transients.
Shortly after arriving in the United States, Steinmetz went to work for Rudolf Eickemeyer in Yonkers, New York, and published in the field of magnetic hysteresis, earning worldwide professional recognition. Eickemeyer's firm developed transformers for use in the transmission of electrical power among many other mechanical and electrical devices. In 1893 Eickemeyer's company, along with all of its patents and designs, was bought by the newly formed General Electric Company, where Steinmetz quickly became known as the engineering wizard in GE's engineering community.
Steinmetz's work revolutionized AC circuit theory and analysis, which had been carried out using complicated, time-consuming calculus-based methods. In the groundbreaking paper, "Complex Quantities and Their Use in Electrical Engineering", presented at a July 1893 meeting published in the American Institute of Electrical Engineers (AIEE), Steinmetz simplified these complicated methods to "a simple problem of algebra". He systematized the use of complex number phasor representation in electrical engineering education texts, whereby the lower-case letter "j" is used to designate the 90-degree rotation operator in AC system analysis. His seminal books and many other AIEE papers "taught a whole generation of engineers how to deal with AC phenomena".
Steinmetz also greatly advanced the understanding of lightning. His systematic experiments resulted in the first laboratory created "man-made lightning", earning him the nickname the "Forger of Thunderbolts". These were conducted in a football field-sized laboratory at General Electric, using 120,000 volt generators. He also erected a lightning tower to attract natural lightning in order to study its patterns and effects, which resulted in several theories.
Steinmetz acted in the following professional capacities:
He was granted an honorary degree from Harvard University in 1901 and a doctorate from Union College in 1903.
Steinmetz wrote 13 books and 60 articles, not exclusively about engineering. He was a member and adviser to the fraternity Phi Gamma Delta at Union College, whose chapter house there was one of the first ever electrified residences.
While serving as president of the Schenectady Board of Education Steinmetz introduced numerous progressive reforms, including extended school hours, school meals, school nurses, special classes for the children of immigrants, and the distribution of free textbooks.
In spite of his love for children and family life, Steinmetz remained unmarried, to prevent the spinal deformity afflicting himself, his father, and grandfather from being passed on to any offspring.
When Joseph LeRoy Hayden, a loyal and hardworking lab assistant, announced that he would marry and look for his own living quarters, Steinmetz made the unusual proposal of opening his large home, complete with research lab, greenhouse, and office to the Haydens and their prospective family. Hayden favored the idea, but his future wife was very wary of the unorthodox setup. She finally agreed after Steinmetz's assurance that she could run the house as she saw fit.
After an uneasy start, the arrangement worked well for all parties, especially after three Hayden children were born. Steinmetz legally adopted Joseph Hayden as his son, becoming grandfather to the youngsters, entertaining them with fantastic stories and spectacular scientific demonstrations. The unusual but harmonious living arrangements lasted for the rest of Steinmetz's life.
Steinmetz founded America's first glider club, but none of its prototypes "could be dignified with the term 'flight'".
Steinmetz was a lifelong agnostic. He died on October 26, 1923, and was buried in Vale Cemetery in Schenectady.
The "Forger of Thunderbolts" and "Wizard of Schenectady" earned wide recognition among the scientific community and numerous awards and honors both during his life and posthumously.
"Steinmetz's equation", derived from his experiments, defines the approximate heat energy due to magnetic hysteresis released, per cycle per unit volume of magnetic material. A Steinmetz solid is the solid body generated by the intersection of two or three cylinders of equal radius at right angles. Steinmetz equivalent circuit theory is still widely used for the design and testing of induction motors.
One of the highest technical recognitions given by the Institute of Electrical and Electronics Engineers, the "IEEE Charles Proteus Steinmetz Award", is given for major contributions to standardization within the field of electrical and electronics engineering. Other awards include the Certificate of Merit of Franklin Institute, 1908; the Elliott Cresson Medal, 1913; and the Cedergren Medal, 1914.
The "Charles P. Steinmetz Memorial Lecture" series was begun in his honor in 1925, sponsored by the Schenectady branch of the IEEE. Through 2017 seventy-three gatherings have taken place, held almost exclusively at Union College, featuring notable figures such as Nobel laureate experimental physicist Robert A. Millikan, helicopter inventor Igor Sikorsky, nuclear submarine pioneer Admiral Hyman G. Rickover (1963), Nobel-winning semiconductor inventor William Shockley, and Internet 'founding father' Leonard Kleinrock. The "Charles P. Steinmetz Scholarship" is awarded annually by the college, underwritten since its inception in 1923 by the General Electric Company.
The "Charles P. Steinmetz Memorial Scholarship" was established at Union by Marjorie Hayden, daughter of Joseph and Corrine Hayden, and is awarded to students majoring in engineering or physics.
Steinmetz's connection to Union is further celebrated with the annual Steinmetz Symposium, a day-long event in which Union undergraduates give presentations on research they have done. Steinmetz Hall, which houses the Union College computer center, is named after him.
Steinmetz was portrayed in 1959 by the actor Rod Steiger in the CBS television anthology series, "The Joseph Cotten Show". The episode focused on his socialist activities in Germany.
A Chicago public high school, Steinmetz College Prep, is named for him.
A public park in north Schenectady, New York was named for him in 1931.
Steinmetz is featured in John Dos Passos' "U.S.A." trilogy in one of the biographies. He also serves as a major character in Starling Lawrence's "The Lightning Keeper".
Steinmetz is a major character in the novel "Electric City" by Elizabeth Rosner.
Moe refers to Curly as a "Steinmetz" in the 1944 Three Stooges short "Busy Buddies".
At the time of his death, Steinmetz held over 200 patents:

</doc>
<doc id="6452" url="https://en.wikipedia.org/wiki?curid=6452" title="Charles Martel">
Charles Martel

Charles Martel ( 688 – 22 October 741) was a Frankish statesman and military leader who, as Duke and Prince of the Franks and Mayor of the Palace, was the "de facto" ruler of Francia from 718 until his death. He was a son of the Frankish statesman Pepin of Herstal and Pepin's mistress, a noblewoman named Alpaida. Charles, also known as “The Hammer”, successfully asserted his claims to power as successor to his father as the power behind the throne in Frankish politics. Continuing and building on his father's work, he restored centralized government in Francia and began the series of military campaigns that re-established the Franks as the undisputed masters of all Gaul. According to a near-contemporary source, the "Liber Historiae Francorum", Charles was "a warrior who was uncommonly [...] effective in battle". 
Most notably, Martel decisively defeated a Muslim invasion of Aquitaine at the Battle of Tours. This victory is seen as a crucial, historic act of preservation of Western Culture. Alongside his military endeavours, Charles has been traditionally credited with a seminal role in the development of the Frankish system of feudalism.
At the end of his reign, Charles divided Francia between his sons, Carloman and Pepin. The latter became the first king of the Carolingian dynasty. Charles' grandson, Charlemagne, extended the Frankish realms, and became the first emperor in the West since the fall of Rome.
Charles, nicknamed "Martel", or "Charles the Hammer", in later chronicles, was the illegitimate son of Pepin of Herstal and his mistress, possible second wife, Alpaida. He had a brother named Childebrand, who later became the Frankish "dux" (that is, "duke") of Burgundy.
In older historiography, it was common to describe Charles as "illegitimate". But the dividing line between wives and concubines was not clear-cut in eighth-century Francia, and it is likely that the accusation of "illegitimacy" derives from the desire of Pepin's first wife Plectrude to see her progeny as heirs to Pepin's power.
After the reign of Dagobert I (629–639) the Merovingians effectively ceded power to the Pippinid Mayors of the Palace, who ruled the Frankish realm of Austrasia in all but name. They controlled the royal treasury, dispensed patronage, and granted land and privileges in the name of the figurehead king. Charles' father, Pepin of Herstal, was able to unite the Frankish realm by conquering Neustria and Burgundy. He was the first to call himself Duke and Prince of the Franks, a title later taken up by Charles.
In December 714, Pepin of Herstal died. Prior to his death, he had, at his wife Plectrude's urging, designated Theudoald, his grandson by their late son Grimoald, his heir in the entire realm. This was immediately opposed by the nobles because Theudoald was a child of only eight years of age. To prevent Charles using this unrest to his own advantage, Plectrude had him imprisoned in Cologne, the city which was intended to be her capital. This prevented an uprising on his behalf in Austrasia, but not in Neustria.
Pepin's death occasioned open conflict between his heirs and the Neustrian nobles who sought political independence from Austrasian control. In 715, Dagobert III named Ragenfrid mayor of their palace, effectively declaring political independence. On 26 September 715, Ragenfrid's Neustrians met the young Theudoald's forces at the Battle of Compiegne. Theudoald was defeated and fled back to Cologne.
Before the end of the year, Charles Martel had escaped from prison and been acclaimed mayor by the nobles of Austrasia. That same year, Dagobert III died and the Neustrians proclaimed Chilperic II, the cloistered son of Childeric II, as king.
In 716, Chilperic and Ragenfrid together led an army into Austrasia intent on seizing the Pippinid wealth at Cologne. The Neustrians allied with another invading force under Redbad, King of the Frisians, and met Charles in battle near Cologne, which was still held by Plectrude. Charles had little time to gather men, or prepare, and the result was the only defeat of his career. The Frisians held off Charles, while the king and his mayor besieged Plectrude at Cologne, where she bought them off with a substantial portion of Pepin's treasure. Then they withdrew.
Charles retreated to the hills of the Eifel to gather men, and train them. Having made the proper preparations, in April 716, he fell upon the triumphant army near Malmedy as it was returning to its own province. In the ensuing Battle of Amblève, Martel attacked as the enemy rested at midday. According to one source, he split his forces into several groups which fell at them from many sides. Another suggests that while this was his intention, he then decided, given the enemy's unpreparedness, this was not necessary. In any event, the suddenness of the assault lead them to believe they were facing a much larger host. Many of the enemy fled and Martel's troops gathered the spoils of the camp. Martel's reputation increased considerably as a result, and he attracted more followers. This battle is often considered by historians as the turning point in Charles's struggle.
Richard Gerberding points out that up to this time, much of Martel's support was probably from his mother's kindred in the lands around Liege. After Amblève, he seems to have won the backing of the influential Willibrord, founder of the Abbey of Echternach. The abbey had been built on land donated by Plectrude's mother, Irmina of Oeren, but most of Willibrord's missionary work had been carried out in Frisia. In joining Chilperic and Ragenfrid, Radbod of Frisia sacked Utrecht, burning churches and killing many missionaries. Willibrord and his monks were forced to flee to Echternach. Gerberding suggests that Willibrord had decided that the chances of preserving his life's work were better with a successful field commander like Martel than with Plectrude in Cologne. Willibrord subsequently baptized Martel's son Pepin. Gerberding suggests a likely date of Easter 716. Martel also received support from Bishop Pepo of Verdun.
Charles took time to rally more men and prepare. By the following spring, Charles had attracted enough support to invade Neustria. Charles sent an envoy who proposed a cessation of hostilities if Chilperic would recognize his rights as mayor of the palace in Austrasia. The refusal was not unexpected but served to impress upon Martel's forces the unreasonableness of the Neustrians. They met near Cambrai at the Battle of Vincy on 21 March 717. The victorious Martel pursued the fleeing king and mayor to Paris, but as he was not yet prepared to hold the city, he turned back to deal with Plectrude and Cologne. He took the city and dispersed her adherents. Plectrude was allowed to retire to a convent; Theudoald lived to 741 under his uncle's protection, a kindness unusual for those times, when mercy to a former gaoler, or a potential rival, was rare.
Upon this success, Charles proclaimed Chlothar IV king of Austrasia in opposition to Chilperic and deposed Rigobert, archbishop of Reims, replacing him with Milo, a lifelong supporter.
In 718, Chilperic responded to Charles' new ascendancy by making an alliance with Odo the Great (or Eudes, as he is sometimes known), the duke of Aquitaine, who had become independent during the civil war in 715, but was again defeated, at the Battle of Soissons, by Charles. Chilperic fled with his ducal ally to the land south of the Loire and Ragenfrid fled to Angers. Soon Chlotar IV died and Odo surrendered King Chilperic in exchange for Charles recognizing his dukedom. Charles recognized Chilperic as king of the Franks in return for legitimate royal affirmation of his own mayoralty over all the kingdoms.
Between 718 and 732, Charles secured his power through a series of victories. Having unified the Franks under his banner, Charles was determined to punish the Saxons who had invaded Austrasia. Therefore, late in 718, he laid waste their country to the banks of the Weser, the Lippe, and the Ruhr. He defeated them in the Teutoburg Forest and thus secured the Frankish border in the name of King Chlotaire.
When the Frisian leader Radbod died in 719, Charles seized West Frisia without any great resistance on the part of the Frisians, who had been subjected to the Franks but had rebelled upon the death of Pippin. When Chilperic II died the following year (720), Charles appointed as his successor the son of Dagobert III, Theuderic IV, who was still a minor, and who occupied the throne from 720 to 737 Charles was now appointing the kings whom he supposedly served, "rois fainéants" who were mere figureheads; by the end of his reign, he didn't appoint one at all. At this time, Charles again marched against the Saxons. Then the Neustrians rebelled under Ragenfrid, who had left the county of Anjou. They were easily defeated (724), but Ragenfrid gave up his sons as hostages in turn for keeping his county. This ended the civil wars of Charles' reign.
The next six years were devoted in their entirety to assuring Frankish authority over the neighboring political groups. Between 720 and 723, Charles was fighting in Bavaria, where the Agilolfing dukes had gradually evolved into independent rulers, recently in alliance with Liutprand the Lombard. He forced the Alemanni to accompany him, and Duke Hugbert submitted to Frankish suzerainty. In 725 he brought back the Agilolfing Princess Swanachild as a second wife.
In 725 and 728, he again entered Bavaria, but in 730, he marched against Lantfrid, Duke of Alemannia, who had also become independent, and killed him in battle. He forced the Alemanni to capitulate to Frankish suzerainty and did not appoint a successor to Lantfrid. Thus, southern Germany once more became part of the Frankish kingdom, as had northern Germany during the first years of the reign.
In 731, after defeating the Saxons, Charles turned his attention to the rival southern realm of Aquitaine, and crossed the Loire, breaking the treaty with Duke Odo. The Franks ransacked Aquitaine twice, and captured Bourges, although Odo retook it. The "Continuations of Fredegar" allege that Odo called on assistance from the recently established emirate of al-Andalus, but there had been Arab raids into Aquitaine from the 720s onwards: indeed, in 721 the Chronicle of 754 records a victory of Odo at the Battle of Toulouse, while the "Liber Pontificalis" records that Odo had killed 375,000 Saracens. It is more likely that this invasion or raid took place in revenge for Odo's support for a rebel Berber leader named Munnuza.
Whatever the precise circumstances, it is clear that an army under the leadership of Abd al-Rahman al-Ghafiqi headed north, and after some minor engagements marched on the wealthy city of Tours. According to British medieval historian Paul Fouracre, "Their campaign should perhaps be interpreted as a long-distance raid rather than the beginning of a war". They were however defeated by the army of Charles at a location between Tours and Poitiers, in a victory described by the "Continuations of Fredegar". News of this battle spread, and may be recorded in Bede's "Ecclesiastical History" (Book V, ch. 23). However, it is not given prominence in Arabic sources from the period.
Despite his victory, Charles did not gain full control of Aquitaine, and Odo remained duke until his death in 735.
Between his victory of 732 and 735, Charles reorganized the kingdom of Burgundy, replacing the counts and dukes with his loyal supporters, thus strengthening his hold on power. He was forced, by the ventures of Bubo, Duke of the Frisians, to invade independent-minded Frisia again in 734. In that year, he slew the duke at the Battle of the Boarn. Charles ordered the Frisian pagan shrines destroyed, and so wholly subjugated the populace that the region was peaceful for twenty years after.
In 735, Duke Odo of Aquitaine died. Though Charles wished to rule the duchy directly and went there to elicit the submission of the Aquitainians, the aristocracy proclaimed Odo's son, Hunald I of Aquitaine, as duke, and Charles and Hunald eventually recognised each other's position.
In 737, at the tail end of his campaigning in Provence and Septimania, the Merovingian king, Theuderic IV, died. Charles, titling himself "maior domus" and "princeps et dux Francorum", did not appoint a new king and nobody acclaimed one. The throne lay vacant until Charles' death. The interregnum, the final four years of Charles' life, was more peaceful than most of it had been but in 738, he compelled the Saxons of Westphalia to submit and pay tribute, and in 739 he checked an uprising in Provence, the rebels being under the leadership of Maurontus.
Charles used the relative peace to set about integrating the outlying realms of his empire into the Frankish church. He erected four dioceses in Bavaria (Salzburg, Regensburg, Freising, and Passau) and gave them Boniface as archbishop and metropolitan over all Germany east of the Rhine, with his seat at Mainz. Boniface had been under his protection from 723 on; indeed the saint himself explained to his old friend, Daniel of Winchester, that without it he could neither administer his church, defend his clergy, nor prevent idolatry.
In 739, Pope Gregory III begged Charles for his aid against Liutprand, but Charles was loath to fight his onetime ally and ignored the plea. Nonetheless, the pope's request for Frankish protection showed how far Charles had come from the days he was tottering on excommunication, and set the stage for his son and grandson to assert themselves in the peninsula.
Charles Martel died on 22 October 741, at Quierzy-sur-Oise in what is today the Aisne "département" in the Picardy region of France. He was buried at Saint Denis Basilica in Paris.
His territories had been divided among his adult sons a year earlier: to Carloman he gave Austrasia, Alemannia, and Thuringia, and to Pippin the Younger Neustria, Burgundy, Provence, and Metz and Trier in the "Mosel duchy"; Grifo was given several lands throughout the kingdom, but at a later date, just before Charles died.
At the beginning of Charles Martel's career, he had many internal opponents and felt the need to appoint his own kingly claimant, Chlotar IV. By his end, however, the dynamics of rulership in Francia had changed, and no hallowed Merovingian ruler was required. Charles divided his realm between his sons without opposition (though he ignored his young son Bernard). For many historians, Charles Martel laid the foundations for his son Pepin's rise to the Frankish throne in 751, and his grandson Charlemagne's imperial acclamation in 800. However, for Paul Fouracre, while Charles was "the most effective military leader in Francia", his career "finished on a note of unfinished business".
Some historical sources say that Charles Martel formed the first regular order of knights in France. They hold that among the spoils Charles Martel's forces captured after the Battle of Tours were many genets (raised for their fur) and several of their pelts. These were presented to him and found favor in his eyes due to their soft fine fur and pleasant smell (the fur was valued by aristocrats to serve as inner lining for garments). As marks of his favor, Charles Martel distributed some of the genets to leaders among his army. Soon after, to commemorate the great victory, he began the first Order of Knighthood in France - called the Order of the Genet. The order was limited to fifteen knights at a time. Charles Martel served as its Chief and that office was handed down to heirs in his bloodline. This order of knights continued for little over two centuries, when it was replaced by Robert II of France's new order - Knights of our Lady of the Star (named in honor of his devotion to the Virgin Mary). Some historians question if the story of the captured genets is a fabrication and that the order was named after small Arabian horses, while others challenge the historical existence of the order altogether.
Charles Martel married twice, his first wife being Rotrude of Treves, daughter either of Lambert II, Count of Hesbaye, or of Leudwinus, Count of Treves. They had the following children:
Most of the children married and had issue. Hiltrud married Odilo I (a Duke of Bavaria). Landrade was once believed to have married a Sigrand (Count of Hesbania) but Sigrand's wife was more likely the sister of Rotrude. Auda married Thierry IV (a Count of Autun and Toulouse). Charles also married a second time, to Swanhild, and they had a child, Grifo.
Finally, Charles Martel also had a known mistress, Ruodhaid, with whom he had children Bernard, Hieronymus, and Remigius. Remigius became an archbishop of Rouen.
For early medieval authors, Charles Martel was famous for his military victories. Paul the Deacon for instance attributed a victory against the Saracens actually won by Odo of Aquitaine to Charles. However, alongside this there soon developed a darker reputation, for his alleged abuse of church property. A ninth-century text, the "Visio Eucherii", possibly written by Hincmar of Reims, portrayed Martel as suffering in hell for this reason. According to British medieval historian Paul Fouracre, this was "the single most important text in the construction of Charles Martel's reputation as a seculariser or despoiler of church lands".
By the eighteenth century, historians such as Edward Gibbon had begun to portray the Frankish leader as the saviour of Christian Europe from a full-scale Islamic invasion. In Gibbon's "The Decline And Fall Of The Roman Empire" he wonders whether without Charles' victory, "Perhaps the interpretation of the Koran would now be taught in the schools of Oxford".
In the nineteenth century, the German historian Heinrich Brunner argued that Charles had confiscated church lands in order to fund military reforms that allowed him to defeat the Arab conquests, in this way brilliantly combining two traditions about the ruler. But Fouracre has argued that "...there is not enough evidence to show that there was a decisive change either in the way in which the Franks fought, or in the way in which they organised the resources needed to support their warriors."
Many twentieth-century European historians continued to develop Gibbon's perspectives, such as French medievalist Christian Pfister, who wrote in 1911 that
Similarly, William E. Watson who wrote of the battle's importance in Frankish and world history in 1993, suggested that
Other recent historians however argue that the importance of the battle is dramatically overstated, both for European history in general and for Charles Martel's reign in particular. This view is typified by Alessandro Barbero, who in 2004 wrote,
Similarly, in 2002 Tomaž Mastnak wrote: 
More recently, the memory of Charles Martel has been appropriated by far right and white nationalist groups, such as the 'Charles Martel Group' in France, and by Australian Brenton Harrison Tarrant, the perpetrator of the Christchurch mosque shootings at Al Noor Mosque and Linwood Islamic Centre in Christchurch, New Zealand, in 2019.

</doc>
<doc id="6456" url="https://en.wikipedia.org/wiki?curid=6456" title="Charles Edward Jones">
Charles Edward Jones

Colonel Charles Edward ("Chuck") Jones (November 8, 1952 – September 11, 2001) was a United States Air Force officer, a computer programmer, and an astronaut in the USAF Manned Spaceflight Engineer Program.
Jones was born November 8, 1952, in Clinton, Indiana. He graduated from Wichita East High School in 1970, earned a Bachelor of Science degree in Astronautical Engineering from the United States Air Force Academy in 1974, and received a Master of Science degree in Astronautics from MIT in 1980. He entered the USAF Manned Spaceflight Engineer program in 1982, and was scheduled to fly on mission STS-71-B in December 1986, but the mission was cancelled after the "Challenger" Disaster in January 1986. He left the Manned Spaceflight Engineer program in 1987.
He later worked for Defense Intelligence Agency, Bolling AFB in Washington D.C., and was Systems Program Director for Intelligence and Information Systems, Hanscom AFB, Massachusetts.
He was killed at the age of 48 in the attacks of September 11, 2001, aboard American Airlines Flight 11. He had been living as a retired U.S. Air Force Colonel in Bedford, Massachusetts, at the time of his death. He was survived by his wife Jeanette.
At the National 9/11 Memorial, Jones is memorialized at the North Pool, on Panel N-74.

</doc>
<doc id="6458" url="https://en.wikipedia.org/wiki?curid=6458" title="Ceramic">
Ceramic

A ceramic is any of the various hard, brittle, heat-resistant and corrosion-resistant materials made by shaping and then firing a nonmetallic mineral, such as clay, at a high temperature. Common examples are earthenware, porcelain, and brick.
The crystallinity of ceramic materials ranges from highly oriented to semi-crystalline, vitrified, and often completely amorphous (e.g., glasses). Most often, fired ceramics are either vitrified or semi-vitrified as is the case with earthenware, stoneware, and porcelain. Varying crystallinity and electron composition in the ionic and covalent bonds cause most ceramic materials to be good thermal and electrical insulators (extensively researched in ceramic engineering). With such a large range of possible options for the composition/structure of a ceramic (e.g. nearly all of the elements, nearly all types of bonding, and all levels of crystallinity), the breadth of the subject is vast, and identifiable attributes (e.g. hardness, toughness, electrical conductivity, etc.) are difficult to specify for the group as a whole. General properties such as high melting temperature, high hardness, poor conductivity, high moduli of elasticity, chemical resistance and low ductility are the norm, with known exceptions to each of these rules (e.g. piezoelectric ceramics, glass transition temperature, superconductive ceramics, etc.). Many composites, such as fiberglass and carbon fiber, while containing ceramic materials, are not considered to be part of the ceramic family.
The earliest ceramics made by humans were pottery objects (i.e. "pots" or "vessels") or figurines made from clay, either by itself or mixed with other materials like silica, hardened and sintered in fire. Later ceramics were glazed and fired to create smooth, colored surfaces, decreasing porosity through the use of glassy, amorphous ceramic coatings on top of the crystalline ceramic substrates. Ceramics now include domestic, industrial and building products, as well as a wide range of ceramic art. In the 20th century, new ceramic materials were developed for use in advanced ceramic engineering, such as in semiconductors.
The word "ceramic" comes from the Greek word (), "of pottery" or "for pottery", from (), "potter's clay, tile, pottery". The earliest known mention of the root "ceram-" is the Mycenaean Greek , "workers of ceramics", written in Linear B syllabic script. The word "ceramic" may be used as an adjective to describe a material, product or process, or it may be used as a noun, either singular, or, more commonly, as the plural noun "ceramics".
A ceramic material is an inorganic, non-metallic, often crystalline oxide, nitride or carbide material. Some elements, such as carbon or silicon, may be considered ceramics. Ceramic materials are brittle, hard, strong in compression, and weak in shearing and tension. They withstand chemical erosion that occurs in other materials subjected to acidic or caustic environments. Ceramics generally can withstand very high temperatures, ranging from 1,000 °C to 1,600 °C (1,800 °F to 3,000 °F). Glass is often not considered a ceramic because of its amorphous (noncrystalline) character. However, glassmaking involves several steps of the ceramic process, and its mechanical properties are similar to ceramic materials.
Traditional ceramic raw materials include clay minerals such as kaolinite, whereas more recent materials include aluminium oxide, more commonly known as alumina. The modern ceramic materials, which are classified as advanced ceramics, include silicon carbide and tungsten carbide. Both are valued for their abrasion resistance and hence find use in applications such as the wear plates of crushing equipment in mining operations. Advanced ceramics are also used in the medicine, electrical, electronics industries and body armor.
Crystalline ceramic materials are not amenable to a great range of processing. Methods for dealing with them tend to fall into one of two categories – either make the ceramic in the desired shape, by reaction "in situ", or by "forming" powders into the desired shape, and then sintering to form a solid body. Ceramic forming techniques include shaping by hand (sometimes including a rotation process called "throwing"), slip casting, tape casting (used for making very thin ceramic capacitors), injection molding, dry pressing, and other variations. 
Noncrystalline ceramics, being glass, tend to be formed from melts. The glass is shaped when either fully molten, by casting, or when in a state of toffee-like viscosity, by methods such as blowing into a mold. If later heat treatments cause this glass to become partly crystalline, the resulting material is known as a glass-ceramic, widely used as cook-tops and also as a glass composite material for nuclear waste disposal.
Human beings appear to have been making their own ceramics for at least 26,000 years, subjecting clay and silica to intense heat to fuse and form ceramic materials. The earliest found so far were in southern central Europe, and were sculpted figures, not dishes. 
The earliest known pottery was made by mixing animal products with clay, and baked in kilns at up to 800 °C. While actual pottery fragments have been found up to 19,000 years old, it was not until about ten thousand years later that regular pottery became common. 
An early people that spread across much of Europe is named after its use of pottery, the Corded Ware culture. These early Indo-European peoples decorated their pottery by wrapping it with rope while still wet. When the ceramics were fired, the rope burned off but left a decorative pattern of complex grooves in the surface.
The invention of the wheel eventually led to the production of smoother, more even pottery using the wheel-forming technique, like the pottery wheel. 
Early ceramics were porous, absorbing water easily. It became useful for more items with the discovery of glazing techniques, coating pottery with silicon, bone ash, or other materials that could melt and reform into a glassy surface, making a vessel less pervious to water.
Ceramic artifacts have an important role in archaeology for understanding the culture, technology and behavior of peoples of the past. They are among the most common artifacts to be found at an archaeological site, generally in the form of small fragments of broken pottery called sherds. Processing of collected sherds can be consistent with two main types of analysis: technical and traditional.
Traditional analysis involves sorting ceramic artifacts, sherds and larger fragments into specific types based on style, composition, manufacturing and morphology. By creating these typologies it is possible to distinguish between different cultural styles, the purpose of the ceramic and technological state of the people among other conclusions. In addition, by looking at stylistic changes of ceramics over time is it possible to separate (seriate) the ceramics into distinct diagnostic groups (assemblages). A comparison of ceramic artifacts with known dated assemblages allows for a chronological assignment of these pieces.
The technical approach to ceramic analysis involves a finer examination of the composition of ceramic artifacts and sherds to determine the source of the material and through this the possible manufacturing site. Key criteria are the composition of the clay and the temper used in the manufacture of the article under study: temper is a material added to the clay during the initial production stage, and it is used to aid the subsequent drying process. Types of temper include shell pieces, granite fragments and ground sherd pieces called 'grog'. Temper is usually identified by microscopic examination of the temper material. Clay identification is determined by a process of refiring the ceramic, and assigning a color to it using Munsell Soil Color notation. By estimating both the clay and temper compositions, and locating a region where both are known to occur, an assignment of the material source can be made. From the source assignment of the artifact further investigations can be made into the site of manufacture.
The physical properties of any ceramic substance are a direct result of its crystalline structure and chemical composition. Solid-state chemistry reveals the fundamental connection between microstructure and properties such as localized density variations, grain size distribution, type of porosity and second-phase content, which can all be correlated with ceramic properties such as mechanical strength σ by the Hall-Petch equation, hardness, toughness, dielectric constant, and the optical properties exhibited by transparent materials.
Ceramography is the art and science of preparation, examination and evaluation of ceramic microstructures. Evaluation and characterization of ceramic microstructures is often implemented on similar spatial scales to that used commonly in the emerging field of nanotechnology: from tens of angstroms (A) to tens of micrometers (µm). This is typically somewhere between the minimum wavelength of visible light and the resolution limit of the naked eye.
The microstructure includes most grains, secondary phases, grain boundaries, pores, micro-cracks, structural defects and hardness microindentions. Most bulk mechanical, optical, thermal, electrical and magnetic properties are significantly affected by the observed microstructure. The fabrication method and process conditions are generally indicated by the microstructure. The root cause of many ceramic failures is evident in the cleaved and polished microstructure. Physical properties which constitute the field of materials science and engineering include the following:
Mechanical properties are important in structural and building materials as well as textile fabrics. In modern materials science, fracture mechanics is an important tool in improving the mechanical performance of materials and components. It applies the physics of stress and strain, in particular the theories of elasticity and plasticity, to the microscopic crystallographic defects found in real materials in order to predict the macroscopic mechanical failure of bodies. Fractography is widely used with fracture mechanics to understand the causes of failures and also verify the theoretical failure predictions with real life failures.
Ceramic materials are usually ionic or covalent bonded materials, and can be crystalline or amorphous. A material held together by either type of bond will tend to fracture before any plastic deformation takes place, which results in poor toughness in these materials. Additionally, because these materials tend to be porous, the pores and other microscopic imperfections act as stress concentrators, decreasing the toughness further, and reducing the tensile strength. These combine to give catastrophic failures, as opposed to the more ductile failure modes of metals.
These materials do show plastic deformation. However, because of the rigid structure of the crystalline materials, there are very few available slip systems for dislocations to move, and so they deform very slowly. With the non-crystalline (glassy) materials, viscous flow is the dominant source of plastic deformation, and is also very slow. It is therefore neglected in many applications of ceramic materials.
To overcome the brittle behaviour, ceramic material development has introduced the class of ceramic matrix composite materials, in which ceramic fibers are embedded and with specific coatings are forming fiber bridges across any crack. This mechanism substantially increases the fracture toughness of such ceramics. Ceramic disc brakes are an example of using a ceramic matrix composite material manufactured with a specific process.
If ceramic is subjected to substantial mechanical loading it can undergo a process called ice-templating, which allows some control of the microstructure of the ceramic product and therefore some control of the mechanical properties. Ceramic engineers use this technique to tune the mechanical properties to their desired application. Specifically, strength is increased when this technique is employed. Ice templating allows the creation of macroscopic pores in a unidirectional arrangement. The applications of this oxide strengthening technique are important for solid oxide fuel cells and water filtration devices.
To process a sample through ice templating, an aqueous colloidal suspension is prepared containing the dissolved ceramic powder evenly dispersed throughout the colloid, for example Yttria-stabilized zirconia (YSZ). The solution is then cooled from the bottom to the top on a platform that allows for unidirectional cooling. This forces ice crystals to grow in compliance to the unidirectional cooling, and these ice crystals force the dissolved YSZ particles to the solidification front of the solid-liquid interphase boundary, resulting in pure ice crystals lined up unidirectionally alongside concentrated pockets of colloidal particles. The sample is then simultaneously heated and the pressure is reduced enough to force the ice crystals to sublimate and the YSZ pockets begin to anneal together to form macroscopically aligned ceramic microstructures. The sample is then further sintered to complete the evaporation of the residual water and the final consolidation of the ceramic microstructure.
During ice-templating a few variables can be controlled to influence the pore size and morphology of the microstructure. These important variables are the initial solids loading of the colloid, the cooling rate, the sintering temperature and duration, and the use of certain additives which can influence the micro-structural morphology during the process. A good understanding of these parameters is essential to understanding the relationships between processing, microstructure, and mechanical properties of anisotropically porous materials.
Some ceramics are semiconductors. Most of these are transition metal oxides that are II-VI semiconductors, such as zinc oxide.
While there are prospects of mass-producing blue LEDs from zinc oxide, ceramicists are most interested in the electrical properties that show grain boundary effects.
One of the most widely used of these is the varistor. These are devices that exhibit the property that resistance drops sharply at a certain threshold voltage. Once the voltage across the device reaches the threshold, there is a breakdown of the electrical structure in the vicinity of the grain boundaries, which results in its electrical resistance dropping from several megohms down to a few hundred ohms. The major advantage of these is that they can dissipate a lot of energy, and they self-reset – after the voltage across the device drops below the threshold, its resistance returns to being high.
This makes them ideal for surge-protection applications; as there is control over the threshold voltage and energy tolerance, they find use in all sorts of applications. The best demonstration of their ability can be found in electrical substations, where they are employed to protect the infrastructure from lightning strikes. They have rapid response, are low maintenance, and do not appreciably degrade from use, making them virtually ideal devices for this application.
Semiconducting ceramics are also employed as gas sensors. When various gases are passed over a polycrystalline ceramic, its electrical resistance changes. With tuning to the possible gas mixtures, very inexpensive devices can be produced.
Under some conditions, such as extremely low temperature, some ceramics exhibit high-temperature superconductivity. The reason for this is not understood, but there are two major families of superconducting ceramics.
Piezoelectricity, a link between electrical and mechanical response, is exhibited by a large number of ceramic materials, including the quartz used to measure time in watches and other electronics. Such devices use both properties of piezoelectrics, using electricity to produce a mechanical motion (powering the device) and then using this mechanical motion to produce electricity (generating a signal). The unit of time measured is the natural interval required for electricity to be converted into mechanical energy and back again.
The piezoelectric effect is generally stronger in materials that also exhibit pyroelectricity, and all pyroelectric materials are also piezoelectric. These materials can be used to inter-convert between thermal, mechanical, or electrical energy; for instance, after synthesis in a furnace, a pyroelectric crystal allowed to cool under no applied stress generally builds up a static charge of thousands of volts. Such materials are used in motion sensors, where the tiny rise in temperature from a warm body entering the room is enough to produce a measurable voltage in the crystal.
In turn, pyroelectricity is seen most strongly in materials which also display the ferroelectric effect, in which a stable electric dipole can be oriented or reversed by applying an electrostatic field. Pyroelectricity is also a necessary consequence of ferroelectricity. This can be used to store information in ferroelectric capacitors, elements of ferroelectric RAM.
The most common such materials are lead zirconate titanate and barium titanate. Aside from the uses mentioned above, their strong piezoelectric response is exploited in the design of high-frequency loudspeakers, transducers for sonar, and actuators for atomic force and scanning tunneling microscopes.
Increases in temperature can cause grain boundaries to suddenly become insulating in some semiconducting ceramic materials, mostly mixtures of heavy metal titanates. The critical transition temperature can be adjusted over a wide range by variations in chemistry. In such materials, current will pass through the material until joule heating brings it to the transition temperature, at which point the circuit will be broken and current flow will cease. Such ceramics are used as self-controlled heating elements in, for example, the rear-window defrost circuits of automobiles.
At the transition temperature, the material's dielectric response becomes theoretically infinite. While a lack of temperature control would rule out any practical use of the material near its critical temperature, the dielectric effect remains exceptionally strong even at much higher temperatures. Titanates with critical temperatures far below room temperature have become synonymous with "ceramic" in the context of ceramic capacitors for just this reason.
Optically transparent materials focus on the response of a material to incoming lightwaves of a range of wavelengths. Frequency selective optical filters can be utilized to alter or enhance the brightness and contrast of a digital image. Guided lightwave transmission via frequency selective waveguides involves the emerging field of fiber optics and the ability of certain glassy compositions as a transmission medium for a range of frequencies simultaneously (multi-mode optical fiber) with little or no interference between competing wavelengths or frequencies. This resonant mode of energy and data transmission via electromagnetic (light) wave propagation, though low powered, is virtually lossless. Optical waveguides are used as components in Integrated optical circuits (e.g. light-emitting diodes, LEDs) or as the transmission medium in local and long haul optical communication systems. Also of value to the emerging materials scientist is the sensitivity of materials to radiation in the thermal infrared (IR) portion of the electromagnetic spectrum. This heat-seeking ability is responsible for such diverse optical phenomena as Night-vision and IR luminescence.
Thus, there is an increasing need in the military sector for high-strength, robust materials which have the capability to transmit light (electromagnetic waves) in the visible (0.4 – 0.7 micrometers) and mid-infrared (1 – 5 micrometers) regions of the spectrum. These materials are needed for applications requiring transparent armor, including next-generation high-speed missiles and pods, as well as protection against improvised explosive devices (IED).
In the 1960s, scientists at General Electric (GE) discovered that under the right manufacturing conditions, some ceramics, especially aluminium oxide (alumina), could be made translucent. These translucent materials were transparent enough to be used for containing the electrical plasma generated in high-pressure sodium street lamps. During the past two decades, additional types of transparent ceramics have been developed for applications such as nose cones for heat-seeking missiles, windows for fighter aircraft, and scintillation counters for computed tomography scanners.
In the early 1970s, Thomas Soules pioneered computer modeling of light transmission through translucent ceramic alumina. His model showed that microscopic pores in ceramic, mainly trapped at the junctions of microcrystalline grains, caused light to scatter and prevented true transparency. The volume fraction of these microscopic pores had to be less than 1% for high-quality optical transmission.
This is basically a particle size effect. Opacity results from the incoherent scattering of light at surfaces and interfaces. In addition to pores, most of the interfaces in a typical metal or ceramic object are in the form of grain boundaries which separate tiny regions of crystalline order. When the size of the scattering center (or grain boundary) is reduced below the size of the wavelength of the light being scattered, the scattering no longer occurs to any significant extent.
In the formation of polycrystalline materials (metals and ceramics) the size of the crystalline grains is determined largely by the size of the crystalline particles present in the raw material during formation (or pressing) of the object. Moreover, the size of the grain boundaries scales directly with particle size. Thus a reduction of the original particle size below the wavelength of visible light (~ 0.5 micrometers for shortwave violet) eliminates any light scattering, resulting in a transparent material.
Recently, Japanese scientists have developed techniques to produce ceramic parts that rival the transparency of traditional crystals (grown from a single seed) and exceed the fracture toughness of a single crystal. In particular, scientists at the Japanese firm Konoshima Ltd., a producer of ceramic construction materials and industrial chemicals, have been looking for markets for their transparent ceramics.
Livermore researchers realized that these ceramics might greatly benefit high-powered lasers used in the National Ignition Facility (NIF) Programs Directorate. In particular, a Livermore research team began to acquire advanced transparent ceramics from Konoshima to determine if they could meet the optical requirements needed for Livermore's Solid-State Heat Capacity Laser (SSHCL). Livermore researchers have also been testing applications of these materials for applications such as advanced drivers for laser-driven fusion power plants.
A composite material of ceramic and metal is known as cermet.
Other ceramic materials, generally requiring greater purity in their make-up than those above, include forms of several chemical compounds, including:
For convenience, ceramic products are usually divided into four main types; these are shown below with some examples:
Frequently, the raw materials of modern ceramics do not include clays.
Those that do are classified as follows:
Ceramics can also be classified into three distinct material categories: 
Each one of these classes can be developed into unique material properties because ceramics tend to be crystalline.

</doc>
<doc id="6459" url="https://en.wikipedia.org/wiki?curid=6459" title="Wuxing (Chinese philosophy)">
Wuxing (Chinese philosophy)

Wuxing (), also known as the Five Elements, Five Agents, Five Movements, Five Phases, Five Planets, Five Processes, Five Stages, Five Poisons, Five Steps, or Five Ways, Five Virtues is the short form of "wǔ zhǒng liúxíng zhī qì" () or "the five types of chi dominating at different times". It is a fivefold conceptual scheme that many traditional Chinese fields used to explain a wide array of phenomena, from cosmic cycles to the interaction between internal organs, and from the succession of political regimes to the properties of medicinal drugs. The "Five Phases" are Fire ( "huǒ"), Water ( "shuǐ"), Wood ( "mù"), Metal ( "jīn"), and Earth ( "tǔ"). This order of presentation is known as the "Days of the Week" sequence. In the order of "mutual generation" ( "xiāngshēng"), they are Wood, Fire, Earth, Metal, and Water. In the order of "mutual overcoming" ( "xiāngkè"), they are Wood, Earth, Water, Fire, and Metal.
The system of five phases was used for describing interactions and relationships between phenomena. After it came to maturity in the second or first century BCE during the Han dynasty, this device was employed in many fields of early Chinese thought, including seemingly disparate fields such as Yi jing divination, alchemy, feng shui, astrology, traditional Chinese medicine, music, military strategy, and martial arts. 
"Xíng" () of "wǔxíng" () means moving; a planet is called a 'moving star' ( "xíngxīng") in Chinese. Wǔxíng originally refers to the five major planets (Jupiter, Saturn, Mercury, Mars, Venus) that create five dimensions of earth life. "Wǔxíng" is also widely translated as "Five Elements" and this is used extensively by many including practitioners of Five Element acupuncture. This translation arose by false analogy with the Western system of the four elements. Whereas the classical Greek elements were concerned with substances or natural qualities, the Chinese "xíng" are "primarily concerned with process and change," hence the common translation as "phases" or "agents". By the same token, "Mù" is thought of as "Tree" rather than "Wood". The word "element" is thus used within the context of Chinese medicine with a different meaning to its usual meaning.
It should be recognized that the word "phase", although commonly preferred, is not perfect. "Phase" is a better translation for the five "seasons" ( "wǔyùn") mentioned below, and so "agents" or "processes" might be preferred for the primary term "xíng". Manfred Porkert attempts to resolve this by using "Evolutive Phase" for "wǔxíng" and "Circuit Phase" for "wǔyùn", but these terms are unwieldy.
Some of the Mawangdui Silk Texts (no later than 168 BC) also present the "wǔxíng" as "five virtues" or types of activities. Within Chinese medicine texts the "wǔxíng" are also referred to as "wǔyǔn" () or a combination of the two characters ( wǔxíngyǔn) these emphasise the correspondence of five elements to five 'seasons' (four seasons plus one). Another tradition refers to the "wǔxíng" as "wǔdé" (), the .
The five phases are around 72 days each and are usually used to describe the state in nature:
The doctrine of five phases describes two cycles, a generating or creation ( "shēng") cycle, also known as "mother-son", and an overcoming or destruction ( "kè") cycle, also known as "grandfather-grandson", of interactions between the phases. Within Chinese medicine the effects of these two main relations are further elaborated:
Common verbs for the "shēng" cycle include "generate", "create" or "strengthens", as well as "grow" or "promote". The phase interactions in the "shēng" cycle are:
A deficient "shēng" cycle is called the "xiè" cycle and is the reverse of the "shēng" cycle. Common verbs for the "xiè" include "weaken", "drain", "diminish" or "exhaust". The phase interactions in the "xiè" cycle are:
Common verbs for the "kè" cycle include "controls", "restrains" and "fathers", as well as "overcome" or "regulate". The phase interactions in the "kè" cycle are:
An excessive "kè" cycle is called the "chéng" cycle. Common verbs for the "chéng" cycle include "restrict", "overwhelm", "dominate" or "destroy". The phase interactions in the "chéng" cycle are:
A deficient "kè" cycle is called the "wǔ" cycle and is the reverse of the "kè" cycle. Common verbs for the "wǔ" cycle can include "insult" or "harm". The phase interactions in the "wǔ" cycle are:
According to wuxing theory, the structure of the cosmos mirrors the five phases. Each phase has a complex series of associations with different aspects of nature, as can be seen in the following table. In the ancient Chinese form of geomancy, known as Feng Shui, practitioners all based their art and system on the five phases (wuxing). All of these phases are represented within the trigrams. Associated with these phases are colors, seasons and shapes; all of which are interacting with each other.
Based on a particular directional energy flow from one phase to the next, the interaction can be expansive, destructive, or exhaustive. A proper knowledge of each aspect of energy flow will enable the Feng Shui practitioner to apply certain cures or rearrangement of energy in a way they believe to be beneficial for the receiver of the Feng Shui Treatment.
According to the Warring States period political philosopher Zou Yan (c. 305–240 BCE), each of the five elements possesses a personified "virtue" ("de" ), which indicates the foreordained destiny ("yun" ) of a dynasty; accordingly, the cyclic succession of the elements also indicates dynastic transitions. Zou Yan claims that the Mandate of Heaven sanctions the legitimacy of a dynasty by sending self-manifesting auspicious signs in the ritual color (yellow, blue, white, red, and black) that matches the element of the new dynasty (Earth, Wood, Metal, Fire, and Water). From the Qin dynasty onward, most Chinese dynasties invoked the theory of the Five Elements to legitimize their reign.
The interdependence of zang-fu networks in the body was said to be a circle of five things, and so mapped by the Chinese doctors onto the five phases.
In order to explain the integrity and complexity of the human body, Chinese medical scientists used the Five Elements theory to classify the human body's organs, physiological activities, and pathological reactions.
In Ziwei, "neiyin" () or the method of divination is the further classification of the Five Elements into 60 "ming" (), or life orders, based on the ganzhi. Similar to the astrology zodiac, the ming is used by fortune-tellers to analyse a person's personality and future fate.
The "Yuèlìng" chapter () of the "Lǐjì" () and the "Huáinánzǐ" () make the following correlations:
T'ai chi ch'uan uses the five elements to designate different directions, positions or footwork patterns. Either forward, backward, left, right and centre, or three steps forward (attack) and two steps back (retreat).
The Five Steps ( wǔ bù):
Xingyiquan uses the five elements metaphorically to represent five different states of combat.
There are spring, summer, fall, and winter teas. The perennial tea ceremony includes four tea settings () and a tea master (). Each tea setting is arranged and stands for the four directions (North, South, East, and West). A vase of the seasons' flowers is put on the tea table. The tea settings are:

</doc>
<doc id="6462" url="https://en.wikipedia.org/wiki?curid=6462" title="Church of Christ, Scientist">
Church of Christ, Scientist

The Church of Christ, Scientist was founded in 1879 in Boston, Massachusetts, by Mary Baker Eddy, author of "Science and Health with Key to the Scriptures," and founder of Christian Science. The church was founded "to commemorate the word and works of [Christ Jesus]" and "reinstate primitive Christianity and its lost element of healing". Sunday services are held throughout the year and weekly testimony meetings are held on Wednesday evenings, where following brief readings from the Bible and the Christian Science textbook, those in attendance are invited to give testimonies of healing brought about through Christian Science prayer.
In the early decades of the 20th century, Christian Science churches sprang up in communities around the world, though in the last several decades of that century, there was a marked decline in membership, except in Africa, where there has been growth. Headquartered in Boston, the church does not officially report membership, and estimates as to worldwide membership range between about 400,000 to less than 100,000.
The church was incorporated by Mary Baker Eddy in 1879 following a claimed personal healing in 1866, which she said resulted from reading the Bible. The Bible and Eddy's textbook on Christian healing, "Science and Health with Key to the Scriptures", are together the church's key doctrinal sources and have been ordained as the church's "dual impersonal pastor".
The First Church of Christ, Scientist, is widely known for its publications, especially "The Christian Science Monitor", a weekly newspaper published internationally in print and online. The seal of Christian Science is a cross and crown with the words, "Heal the sick, raise the dead, cleanse the lepers, cast out demons," and is a registered trademark of the church.
Christian Scientists believe that prayer is effective. The Church has collected over 50,000 testimonies of incidents that it considers healing through Christian Science treatment alone. While most of these testimonies represent ailments neither diagnosed nor treated by medical professionals, the Church requires three other people to vouch for any testimony published in any of its official organ, including the "Christian Science Journal", "Christian Science Sentinel", and "Herald of Christian Science"; verifiers say that they witnessed the healing or know the testifier well enough to vouch for them.
Christian Scientists may take an intensive two-week "Primary" class from an authorized Christian Science teacher. Those who wish to become "Journal-listed" (accredited) practitioners, devoting themselves full-time to the practice of healing, must first have Primary class instruction. When they have what the church regards as a record of healing, they may submit their names for publication in the directory of practitioners and teachers in the "Christian Science Journal." A practitioner who has been listed for at least three years' may apply for "Normal" class instruction, given once every three years. Those who receive a certificate are authorized to teach. Both Primary and Normal classes are based on the Bible and the writings of Mary Baker Eddy. The Primary class focuses on the chapter, "Recapitulation" in "Science and Health with Key to the Scriptures". This chapter uses the Socratic method of teaching and contains the "Scientific Statement of Being". The "Normal" class focuses on the platform of Christian Science, contained on pages 330-340 of "Science and Health."
The First Church of Christ, Scientist is the legal title of the Mother Church and administrative headquarters of the Christian Science Church. The complex is located in a plaza alongside Huntington Avenue in the Back Bay neighborhood of Boston, Massachusetts.
The church itself was built in 1894, and an annex larger in footprint than the original structure was added in 1906. It boasts one of the world's largest pipe organs, built by the Aeolian-Skinner Company of Boston. The Mary Baker Eddy Library for the Betterment of Humanity is housed in an 11-story structure originally built for The Christian Science Publishing Society constructed between 1932 and 1934, and the present plaza was constructed in the late 1960s and early 1970s to include a 28 story administration building, a colonnade, and a reflecting pool with fountain, designed by Araldo Cossutta of I. M. Pei and Partners (now Pei Cobb Freed).
Branch churches of The Mother Church may take the title of "First Church of Christ, Scientist"; Second; but the article "The" must not be used, presumably to concede the primacy of the Boston Mother Church.
An international newspaper, the "Christian Science Monitor", founded by Eddy in 1908 and winner of seven Pulitzer prizes, is published by the church through the Christian Science Publishing Society.
Branch Christian Science churches and Christian Science societies are subordinate to the Mother Church, but are self-governed. They have their own by-laws, bank accounts, assets and officers, but in order to be recognised must abide by the by-laws in the "Manual of The Mother Church". Church services are regulated by the "Manual," the set of by-laws written by Eddy, that establishes the church organization and explains the duties and responsibilities of members, officers, practitioners, teachers and nurses; and establishes rules for discipline and other aspects of church business.
The Christian Science Board of Directors is a five-person executive entity created by Mary Baker Eddy to conduct the business of the Christian Science Church under the terms defined in the by-laws of the "Church Manual". Its functions and restrictions are defined by the "Manual."
The Board (occasionally CSBD or the BoD for short) also includes functions defined by a Deed of Trust written by Eddy (one of several, in fact) under which it consisted of four persons, though she later expanded the Board to five persons, thus in effect leaving one of its members out of Deed functions. This later bore on a dispute during the 1920s, known as the Great Litigation in CS circles, pivoting on whether the CSBD could remove trustees of the Christian Science Publishing Society or whether the CSPS trustees were established independently.
While Eddy's Manual established limited executive functions under the rule of law in place of a traditional hierarchy, the controversial 1991 publication of a book by Bliss Knapp led the then Board of Directors to make the unusual affidavit during a suit over Knapp's estate that neither acts by it violating the "Manual," nor acts refraining from required action, constituted violations of the "Manual". A traditionally-minded minority held that the Board's act in publishing Knapp's book constituted a fundamental violation of several by-laws and its legal trust, automatically mandating the offending Board members' resignations under Article I, Section 9.
Another minority believed that Eddy intended various requirements for her consent (in their view, "estoppels") to effect the church's dissolution on her death, since they could no longer be followed literally. Ironically, one of the stronger arguments against this position came from an individual highly respected by their theological quarter, Bliss Knapp, who claimed that Eddy understood through her lawyer that these consent clauses would not hinder normal operation after her decease.
Churches worldwide hold a one-hour service each Sunday, consisting of hymns, prayer, and currently, readings from the "King James Version" (KJV) of the Bible (although there is no requirement that this version of the Bible be used) and "Science and Health with Key to the Scriptures". These readings are the weekly Lesson-Sermon, which is read aloud at all Sunday services in all Christian Science churches worldwide, and is studied by individuals at home throughout the preceding week. The Lesson, as it is informally called, is compiled by a committee at The Mother Church, and is usually made up of six sections, each of which consists of passages from the Bible (read by the Second Reader) and passages from "Science and Health" (read by the First Reader).
Eddy selected 26 subjects for the Lesson-Sermon. These Lessons run in continuous rotation in the order she established, hence each subject is studied twice a year. In years in which there are 53 Sundays, the topic "Christ Jesus" occurs a third time, in December. In addition, there is a special, shortened Lesson-Sermon for Thanksgiving Day. Branch churches outside the United States may schedule their Thanksgiving service when convenient for them, most choosing a day in October or November, and the Thanksgiving Day proclamation by the United States president, may be omitted.
Because there are no clergy in the church, branch church Sunday services are conducted by two Readers: the First Reader, who reads passages from Science and Health, and the Second Reader, who reads passages from the Bible. First Readers determine the beginning "scriptural selection", hymns to be sung on Sundays, and the benediction. The vast majority of the service is the reading of the weekly Bible lesson supplied by Boston, and the order of the service set out by the Manual. To be elected the First Reader in one's branch church is one of the highest and most important positions the lay Christian Scientist may aspire to.
Churches also hold a one-hour Wednesday evening testimony meeting, with similar readings, after which, those in attendance are invited to share accounts of healing through prayer. At these services, the First Reader reads passages from the Bible and Science and Health. Departing from denominational practice for over 120 years, English language churches may now choose alternate Bible translations at these services (i.e. Phillips).
Branch churches also sponsor annual public talks (called lectures) given by speakers selected annually by the Board of Lectureship in Boston.
Beginning in the mid-1980s, church executives undertook a controversial and ambitious foray into electronic broadcast media. The first significant effort was to create a weekly half-hour syndicated television program, The Christian Science Monitor Reports. "Monitor Reports" was anchored in its first season by newspaper veteran Rob Nelson. He was replaced in the second by the "Christian Science Monitor"'s former Moscow correspondent, David Willis. The program was usually broadcast by independent stations — often at odd hours.
In 1988, Monitor Reports was supplanted by a nightly half-hour news show, World Monitor, which was broadcast by the Discovery Channel. The program was anchored by veteran journalist John Hart. The Church then purchased a Boston cable television station for elaborate in-house programming production. In parallel, the church purchased a shortwave radio station and syndicated radio production to National Public Radio. However, revenues fell far short of optimistic predictions by church managers, who had ignored early warnings by members and media experts.
In October 1991, after a series of conflicts over the boundaries between Christian Science teachings and his journalistic independence, John Hart resigned. The Monitor Channel went off the air in June 1992. Most of the other operations closed in well under a decade. Public accounts in both the mainstream and trade media reported that the church lost approximately $250 million on these ventures.
The hundreds of millions lost on broadcasting brought the church to the brink of bankruptcy. However, with the 1991 publication of "The Destiny of The Mother Church" by the late Bliss Knapp, the church secured a $90 million bequest from the Knapp trust. The trust dictated that the book be published as "Authorized Literature," with neither modification nor comment. Historically, the church had censured Knapp for deviating at several points from Eddy's teaching, and had refused to publish the work. The church's archivist, fired in anticipation of the book's publication, wrote to branch churches to inform them of the book's history. Many Christian Scientists thought the book violated the church's by-laws, and the editors of the church's religious periodicals and several other church employees resigned in protest. Alternate beneficiaries subsequently sued to contest the church's claim it had complied fully with the will's terms, and the church ultimately received only half of the original sum.
The fallout of the broadcasting debacle also sparked a minor revolt among some prominent church members. In late 1993, a group of Christian Scientists filed suit against the Board of Directors, alleging a willful disregard for the Manual of the Mother Church in its financial dealings. The suit was thrown out by the Supreme Judicial Court of Massachusetts in 1997, but a lingering discontent with the church's financial matters persists to this day.
In spite of its early meteoric rise, church membership has declined over the past eight decades, according to the church's former treasurer, J. Edward Odegaard. Though the Church is prohibited by the Manual from publishing membership figures, the number of branch churches in the United States has fallen steadily since World War II. In 2009, for the first time in church history, more new members came from Africa than the United States.
In 2005, the "Boston Globe" reported that the church was considering consolidating Boston operations into fewer buildings and leasing out space in buildings it owned. Church official Philip G. Davis noted that the administration and Colonnade buildings had not been fully used for many years and that vacancy increased after staff reductions in 2004. The church posted an $8 million financial loss in fiscal 2003, and in 2004 cut 125 jobs, a quarter of the staff, at the "Christian Science Monitor". Conversely, Davis noted that "the financial situation right now is excellent" and stated that the church was not facing financial problems.

</doc>
<doc id="6466" url="https://en.wikipedia.org/wiki?curid=6466" title="Connecticut">
Connecticut

Connecticut () is the southernmost state in the New England region of the northeastern United States. As of the 2010 Census, it has the highest per-capita income, Human Development Index (0.962), and median household income in the United States. It is bordered by Rhode Island to the east, Massachusetts to the north, New York to the west, and Long Island Sound to the south. Its capital is Hartford and its most populous city is Bridgeport. According to most sources, it is part of New England, although large portions of it are often grouped with New York and New Jersey as the tri-state area instead. The state is named for the Connecticut River which approximately bisects the state. The word "Connecticut" is derived from various anglicized spellings of a Mohegan-Pequot word for "long tidal river".
Connecticut's first European settlers were Dutchmen who established a small, short-lived settlement called Fort Hoop in Hartford at the confluence of the Park and Connecticut Rivers. Half of Connecticut was initially part of the Dutch colony New Netherland, which included much of the land between the Connecticut and Delaware Rivers, although the first major settlements were established in the 1630s by the English. Thomas Hooker led a band of followers from the Massachusetts Bay Colony and founded the Connecticut Colony; other settlers from Massachusetts founded the Saybrook Colony and the New Haven Colony. The Connecticut and New Haven colonies established documents of Fundamental Orders, considered the first constitutions in America. In 1662, the three colonies were merged under a royal charter, making Connecticut a crown colony. This was one of the Thirteen Colonies which rejected British rule in the American Revolution.
Connecticut is the third smallest state by area, the 29th most populous, and the fourth most densely populated of the fifty states. It is known as the "Constitution State", the "Nutmeg State", the "Provisions State", and the "Land of Steady Habits". It was influential in the development of the federal government of the United States (see Connecticut Compromise).
The Connecticut River, Thames River, and ports along Long Island Sound have given Connecticut a strong maritime tradition which continues today. The state also has a long history of hosting the financial services industry, including insurance companies in Hartford and hedge funds in Fairfield County.
Connecticut is bordered on the south by Long Island Sound, on the west by New York, on the north by Massachusetts, and on the east by Rhode Island. The state capital and fourth largest city is Hartford, and other major cities and towns (by population) include Bridgeport, New Haven, Stamford, Waterbury, Norwalk, Danbury, New Britain, Greenwich, and Bristol. Connecticut is slightly larger than the country of Montenegro. There are 169 incorporated towns in Connecticut.
The highest peak in Connecticut is Bear Mountain in Salisbury in the northwest corner of the state. The highest point is just east of where Connecticut, Massachusetts, and New York meet (42°3′ N, 73°29′ W), on the southern slope of Mount Frissell, whose peak lies nearby in Massachusetts. At the opposite extreme, many of the coastal towns have areas that are less than 20 feet (6 m) above sea level.
Connecticut has a long maritime history and a reputation based on that history—yet the state has no direct oceanfront (technically speaking). The coast of Connecticut sits on Long Island Sound, which is an estuary. The state's access to the open Atlantic Ocean is both to the west (toward New York City) and to the east (toward the "race" near Rhode Island). This situation provides many safe harbors from ocean storms, and many transatlantic ships seek anchor inside Long Island Sound when tropical cyclones pass off the upper East Coast.
The Connecticut River cuts through the center of the state, flowing into Long Island Sound. The most populous metropolitan region centered within the state lies in the Connecticut River Valley. Despite Connecticut's relatively small size, it features wide regional variations in its landscape; for example, in the northwestern Litchfield Hills, it features rolling mountains and horse farms, whereas in areas to the east of New Haven along the coast, the landscape features coastal marshes, beaches, and large scale maritime activities.
Connecticut's rural areas and small towns in the northeast and northwest corners of the state contrast sharply with its industrial cities such as Stamford, Bridgeport, and New Haven, located along the coastal highways from the New York border to New London, then northward up the Connecticut River to Hartford. Many towns in northeastern and northwestern Connecticut center around a green. Near the green typically stand historical visual symbols of New England towns, such as a white church, a colonial meeting house, a colonial tavern or inn, several colonial houses, and so on, establishing a scenic historical appearance maintained for both historic preservation and tourism. Many of the areas in southern and coastal Connecticut have been built up and rebuilt over the years, and look less visually like traditional New England.
The northern boundary of the state with Massachusetts is marked by the Southwick Jog or Granby Notch, an approximately square detour into Connecticut. The origin of this anomaly is clearly established in a long line of disputes and temporary agreements which were finally concluded in 1804, when southern Southwick's residents sought to leave Massachusetts, and the town was split in half.
The southwestern border of Connecticut where it abuts New York State is marked by a panhandle in Fairfield County, containing the towns of Greenwich, Stamford, New Canaan, Darien, and parts of Norwalk and Wilton. This irregularity in the boundary is the result of territorial disputes in the late 17th century, culminating with New York giving up its claim to the area, whose residents considered themselves part of Connecticut, in exchange for an equivalent area extending northwards from Ridgefield to the Massachusetts border, as well as undisputed claim to Rye, New York.
Areas maintained by the National Park Service include Appalachian National Scenic Trail, Quinebaug and Shetucket Rivers Valley National Heritage Corridor, and Weir Farm National Historic Site.
Connecticut lies at the rough transition zone between the southern end of the humid continental climate, and the northern portion of the humid subtropical climate. Northern Connecticut generally experiences a climate with cold winters with moderate snowfall and hot, humid summers. Far southern and coastal Connecticut has a climate with cool winters with a mix of rain and infrequent snow, and the long hot and humid summers typical of the middle and lower East Coast.
Connecticut sees a fairly even precipitation pattern with rainfall/snowfall spread throughout the 12 months. Connecticut averages 56% of possible sunshine (higher than the U.S. national average), averaging 2,400 hours of sunshine annually.
Early spring (April) can range from slightly cool (40s to low 50s F) to warm (65 to 70 F), while mid and late spring (late April/May) is warm. By late May, the building Bermuda High creates a southerly flow of warm and humid tropical air, bringing hot weather conditions throughout the state, with average highs in New London of and in Windsor Locks at the peak of summer in late July. On occasion, heat waves with highs from 90 to occur across Connecticut. Although summers are sunny in Connecticut, quick moving summer thunderstorms can bring brief downpours with thunder and lightning. Occasionally these thunderstorms can be severe, and the state usually averages one tornado per year. During hurricane season, the remains of tropical cyclones occasionally affect the region, though a direct hit is rare.
Weather commonly associated with the fall season typically begins in October and lasts to the first days of December. Daily high temperatures in October and November range from the 50s to 60s (Fahrenheit) with nights in the 40s and upper 30s. Colorful foliage begins across northern parts of the state in early October and moves south and east reaching southeast Connecticut by early November. Far southern and coastal areas, however, have more oak and hickory trees (and fewer maples) and are often less colorful than areas to the north. By December daytime highs are in the 40s °F for much of the state, and average overnight lows are below freezing.
Winters (December through mid-March) are generally cold from south to north in Connecticut. The coldest month (January) has average high temperatures ranging from in the coastal lowlands to in the inland and northern portions on the state. The average yearly snowfall ranges from about in the higher elevations of the northern portion of the state to only along the southeast coast of Connecticut (Branford to Groton). Generally, any locale north or west of Interstate 84 receives the most snow, during a storm, and throughout the season. Most of Connecticut has less than 60 days of snow cover. Snow usually falls from late November to late March in the northern part of the state, and from early December to mid-March in the southern and coastal parts of the state.
Connecticut's record high temperature is which occurred in Danbury on July 15, 1995; the record low is which occurred in the Northwest Hills Falls Village on February 16, 1943, and Coventry on January 22, 1961.
Forests consist of a mix of Northeastern coastal forests of Oak in southern areas of the state, to the upland New England-Acadian forests in the northwestern parts of the state. Mountain Laurel (Kalmia latifolia) is the state flower and is native to low ridges in several parts of Connecticut. Rosebay Rhododendron (Rhododendron maximum) is also native to eastern uplands of Connecticut and Pachaug State Forest is home to the Rhododendron Sanctuary Trail. Atlantic white cedar (Chamaecyparis thyoides), is found in wetlands in the southern parts of the state. Connecticut has one native cactus (Opuntia humifusa), found in sandy coastal areas and low hillsides. Several types of beach grasses and wildflowers are also native to Connecticut. Connecticut spans USDA Plant Hardiness Zones 5b to 7a. Coastal Connecticut is the broad transition zone where more southern and subtropical plants are cultivated. In some coastal communities, Magnolia grandiflora (southern magnolia), Crape Myrtles, scrub palms (Sabal minor), Needle Palms (Rhapidophyllum hystrix), and other broadleaved evergreens are cultivated in small numbers.
The name Connecticut is derived from the Mohegan-Pequot word that has been translated as "long tidal river" and "upon the long river", referring to the Connecticut River. The Connecticut region was inhabited by multiple Indian tribes before European settlement and colonization, including the Mohegans, the Pequots, and the Paugusetts.
The first European explorer in Connecticut was Dutchman Adriaen Block, who explored the region in 1614. Dutch fur traders then sailed up the Connecticut River, which they called Versche Rivier ("Fresh River"), and built a fort at Dutch Point in Hartford that they named "House of Hope" ().
The Connecticut Colony was originally a number of separate, smaller settlements at Windsor, Wethersfield, Saybrook, Hartford, and New Haven. The first English settlers came in 1633 and settled at Windsor, and then at Wethersfield the following year. John Winthrop the Younger of Massachusetts received a commission to create Saybrook Colony at the mouth of the Connecticut River in 1635.
The main body of settlers came in one large group in 1636. They were Puritans from Massachusetts Bay Colony led by Thomas Hooker, who established the Connecticut Colony at Hartford. The Quinnipiack Colony was established by John Davenport, Theophilus Eaton, and others at New Haven in March 1638. The New Haven Colony had its own constitution called "The Fundamental Agreement of the New Haven Colony", signed on June 4, 1639.
The settlements were established without official sanction of the English Crown, and each was an independent political entity. In 1662, Winthrop traveled to England and obtained a charter from CharlesII which united the settlements of Connecticut. Historically important colonial settlements included Windsor (1633), Wethersfield (1634), Saybrook (1635), Hartford (1636), New Haven (1638), Fairfield (1639), Guilford (1639), Milford (1639), Stratford (1639), Farmington (1640), Stamford (1641), and New London (1646).
The Pequot War marked the first major clash between colonists and Indians in New England. The Pequots reacted with increasing aggression to Colonial settlements in their territory—while simultaneously taking lands from the Narragansett and Mohegan tribes. Settlers responded to a murder in 1636 with a raid on a Pequot village on Block Island; the Pequots laid siege to Saybrook Colony's garrison that autumn, then raided Wethersfield in the spring of 1637. Colonists declared war on the Pequots, organized a band of militia and allies from the Mohegan and Narragansett tribes, and attacked a Pequot village on the Mystic River, with death toll estimates ranging between 300 and 700 Pequots. After suffering another major loss at a battle in Fairfield, the Pequots asked for a truce and peace terms.
The western boundaries of Connecticut have been subject to change over time. The Hartford Treaty with the Dutch was signed on September 19, 1650, but it was never ratified by the British. According to it, the western boundary of Connecticut ran north from Greenwich Bay for a distance of , "provided the said line come not within 10 miles of Hudson River". This agreement was observed by both sides until war erupted between England and The Netherlands in 1652. Conflict continued concerning colonial limits until the Duke of York captured New Netherland in 1664.
On the other hand, Connecticut's original Charter in 1662 granted it all the land to the "South Sea"—that is, to the Pacific Ocean. Most Colonial royal grants were for long east–west strips. Connecticut took its grant seriously and established a ninth county between the Susquehanna River and Delaware River named Westmoreland County. This resulted in the brief Pennamite Wars with Pennsylvania.
Yale College was established in 1701, providing Connecticut with an important institution to educate clergy and civil leaders. The Congregational church dominated religious life in the colony and, by extension, town affairs in many parts.
With more than 600 miles of coastline including along its navigable rivers, during the colonial years Connecticut developed the antecedents of a maritime tradition that would later produce booms in shipbuilding, marine transport, naval support, seafood production, and leisure boating.
Historical records list the Tryall as the first vessel built in Connecticut Colony, in 1649 at a site on the Connecticut River in present-day Wethersfield. In the two decades leading up to 1776 and the American Revolution, Connecticut boatyards launched about 100 sloops, schooners and brigs according to a database of U.S. customs records maintained online by the Mystic Seaport Museum, the largest being the 180-ton Patient Mary launched in New Haven in 1763. Connecticut's first lighthouse was constructed in 1760 at the mouth of the Thames River with the New London Harbor Lighthouse.
Connecticut designated four delegates to the Second Continental Congress who signed the Declaration of Independence: Samuel Huntington, Roger Sherman, William Williams, and Oliver Wolcott. Connecticut's legislature authorized the outfitting of six new regiments in 1775, in the wake of the clashes between British regulars and Massachusetts militia at Lexington and Concord. There were some 1,200 Connecticut troops on hand at the Battle of Bunker Hill in June 1775. In 1775, David Bushnell invented the Turtle which the following year launched the first submarine attack in history, unsuccessfully against a British warship at anchor in New York Harbor.
In 1777, the British got word of Continental Army supplies in Danbury, and they landed an expeditionary force of some 2,000 troops in Westport. This force then marched to Danbury and destroyed homes and much of the depot. Continental Army troops and militia led by General David Wooster and General Benedict Arnold engaged them on their return march at Ridgefield in 1777. For the winter of 1778–79, General George Washington decided to split the Continental Army into three divisions encircling New York City, where British General Sir Henry Clinton had taken up winter quarters. Major General Israel Putnam chose Redding as the winter encampment quarters for some 3,000 regulars and militia under his command. The Redding encampment allowed Putnam's soldiers to guard the replenished supply depot in Danbury and to support any operations along Long Island Sound and the Hudson River Valley. Some of the men were veterans of the winter encampment at Valley Forge, Pennsylvania the previous winter. Soldiers at the Redding camp endured supply shortages, cold temperatures, and significant snow, with some historians dubbing the encampment "Connecticut's Valley Forge".
The state was also the launching site for a number of raids against Long Island orchestrated by Samuel Holden Parsons and Benjamin Tallmadge, and provided men and material for the war effort, especially to Washington's army outside New York City. General William Tryon raided the Connecticut coast in July 1779, focusing on New Haven, Norwalk, and Fairfield. New London and Groton Heights were raided in September 1781 by Benedict Arnold, who had turned traitor to the British.
At the outset of the American Revolution, the Continental Congress assigned Nathaniel Shaw Jr. of New London as its naval agent in charge of recruiting privateers to seize British vessels as opportunities presented, with nearly 50 operating out of the Thames River which eventually drew the reprisal from the British force led by Arnold.
Connecticut ratified the U.S. Constitution on January 9, 1788, becoming the fifth state.
The state prospered during the era following the American Revolution, as mills and textile factories were built and seaports flourished from trade and fisheries. After Congress established in 1790 the predecessor to the U.S. Revenue Cutter Service that would evolve into the U.S. Coast Guard, President Washington assigned Jonathan Maltbie as one of seven masters to enforce customs regulations, with Maltbie monitoring the southern New England coast with a 48-foot cutter sloop named Argus.
In 1786, Connecticut ceded territory to the U.S. government that became part of the Northwest Territory. The state retained land extending across the northern part of present-day Ohio called the Connecticut Western Reserve. The Western Reserve section was settled largely by people from Connecticut, and they brought Connecticut place names to Ohio.
Connecticut made agreements with Pennsylvania and New York which extinguished the land claims within those states' boundaries and created the Connecticut Panhandle. The state then ceded the Western Reserve in 1800 to the federal government, which brought it to its present boundaries (other than minor adjustments with Massachusetts).
For the first time in 1800, Connecticut shipwrights launched more than 100 vessels in a single year. Over the following decade to the doorstep of renewed hostilities with Britain that sparked the War of 1812, Connecticut boatyards constructed close to 1,000 vessels, the most productive stretch of any decade in the 19th century.
During the war, the British launched raids in Stonington and Essex and blockaded vessels in the Thames River. Derby native Isaac Hull became Connecticut's best-known naval figure to win renown during the conflict, as captain of the USS Constitution.
The British blockade during the War of 1812 hurt exports and bolstered the influence of Federalists who opposed the war. The cessation of imports from Britain stimulated the construction of factories to manufacture textiles and machinery. Connecticut came to be recognized as a major center for manufacturing, due in part to the inventions of Eli Whitney and other early innovators of the Industrial Revolution.
The war led to the development of fast clippers that helped extend the reach of New England merchants to the Pacific and Indian oceans. The first half of the 19th century saw as well a rapid rise in whaling, with New London emerging as one of the New England industry's three biggest home ports after Nantucket and New Bedford.
The state was known for its political conservatism, typified by its Federalist party and the Yale College of Timothy Dwight. The foremost intellectuals were Dwight and Noah Webster, who compiled his great dictionary in New Haven. Religious tensions polarized the state, as the Congregational Church struggled to maintain traditional viewpoints, in alliance with the Federalists. The failure of the Hartford Convention in 1814 hurt the Federalist cause, with the Democratic-Republican Party gaining control in 1817.
Connecticut had been governed under the "Fundamental Orders" since 1639, but the state adopted a new constitution in 1818.
Connecticut manufacturers played a major role in supplying the Union forces with weapons and supplies during the Civil War. The state furnished 55,000 men, formed into thirty full regiments of infantry, including two in the U.S. Colored Troops, with several Connecticut men becoming generals. The Navy attracted 250 officers and 2,100 men, and Glastonbury native Gideon Welles was Secretary of the Navy. James H. Ward of Hartford was the first U.S. Naval Officer killed in the Civil War. Connecticut casualties included 2,088 killed in combat, 2,801 dying from disease, and 689 dying in Confederate prison camps.
A surge of national unity in 1861 brought thousands flocking to the colors from every town and city. However, as the war became a crusade to end slavery, many Democrats (especially Irish Catholics) pulled back. The Democrats took a pro-slavery position and included many Copperheads willing to let the South secede. The intensely fought 1863 election for governor was narrowly won by the Republicans.
Connecticut's extensive industry, dense population, flat terrain, and wealth encouraged the construction of railroads starting in 1839. By 1840, of line were in operation, growing to in 1850 and in 1860.
The New York, New Haven and Hartford Railroad, called the "New Haven" or "The Consolidated", became the dominant Connecticut railroad company after 1872. J. P. Morgan began financing the major New England railroads in the 1890s, dividing territory so that they would not compete. The New Haven purchased 50 smaller companies, including steamship lines, and built a network of light rails (electrified trolleys) that provided inter-urban transportation for all of southern New England. By 1912, the New Haven operated over of track with 120,000 employees.
As steam-powered passenger ships proliferated after the Civil War, Noank would produce the two largest built in Connecticut during the 19th century, with the 332-foot wooden steam paddle wheeler Rhode Island launched in 1882, and the 345-foot paddle wheeler Connecticut seven years later. Connecticut shipyards would launch more than 165 steam-powered vessels in the 19th century.
In 1875, the first telephone exchange in the world was established in New Haven.
When World War I broke out in 1914, Connecticut became a major supplier of weaponry to the U.S. military; by 1918, 80% of the state's industries were producing goods for the war effort. Remington Arms in Bridgeport produced half the small-arms cartridges used by the U.S. Army, with other major suppliers including Winchester in New Haven and Colt in Hartford.
Connecticut was also an important U.S. Navy supplier, with Electric Boat receiving orders for 85 submarines, Lake Torpedo Boat building more than 20 subs, and the Groton Iron Works building freighters. On June 21, 1916, the Navy made Groton the site for its East Coast submarine base and school.
The state enthusiastically supported the American war effort in 1917 and 1918 with large purchases of war bonds, a further expansion of industry, and an emphasis on increasing food production on the farms. Thousands of state, local, and volunteer groups mobilized for the war effort and were coordinated by the Connecticut State Council of Defense. Manufacturers wrestled with manpower shortages; Waterbury's American Brass and Manufacturing Company was running at half capacity, so the federal government agreed to furlough soldiers to work there.
In 1919, J. Henry Roraback started the Connecticut Light & Power Co. which became the state's dominant electric utility. In 1925, Frederick Rentschler spurred the creation of Pratt & Whitney in Hartford to develop engines for aircraft; the company became an important military supplier in World WarII and one of the three major manufacturers of jet engines in the world.
On September 21, 1938, the most destructive storm in New England history struck eastern Connecticut, killing hundreds of people. The eye of the "Long Island Express" passed just west of New Haven and devastated the Connecticut shoreline between Old Saybrook and Stonington from the full force of wind and waves, even though they had partial protection by Long Island. The hurricane caused extensive damage to infrastructure, homes, and businesses. In New London, a 500-foot (150 m) sailing ship was driven into a warehouse complex, causing a major fire. Heavy rainfall caused the Connecticut River to flood downtown Hartford and East Hartford. An estimated 50,000 trees fell onto roadways.
The advent of lend-lease in support of Britain helped lift Connecticut from the Great Depression, with the state a major production center for weaponry and supplies used in World WarII. Connecticut manufactured 4.1% of total U.S. military armaments produced during the war, ranking ninth among the 48 states, with major factories including Colt for firearms, Pratt & Whitney for aircraft engines, Chance Vought for fighter planes, Hamilton Standard for propellers, and Electric Boat for submarines and PT boats. In Bridgeport, General Electric produced a significant new weapon to combat tanks: the bazooka.
On May 13, 1940, Igor Sikorsky made an untethered flight of the first practical helicopter. The helicopter saw limited use in World War II, but future military production made Sikorsky Aircraft's Stratford plant Connecticut's largest single manufacturing site by the start of the 21st century.
Connecticut lost some wartime factories following the end of hostilities, but the state shared in a general post-war expansion that included the construction of highways and resulting in middle-class growth in suburban areas.
Prescott Bush represented Connecticut in the U.S. Senate from 1952 to 1963; his son George H.W. Bush and grandson George W. Bush both became presidents of the United States. In 1965, Connecticut ratified its current constitution, replacing the document that had served since 1818.
In 1968, commercial operation began for the Connecticut Yankee Nuclear Power Plant in East Haddam; in 1970, the Millstone Nuclear Power Station began operations in Waterford. In 1974, Connecticut elected Democratic Governor Ella T. Grasso, who became the first woman in any state to be elected governor.
Connecticut's dependence on the defense industry posed an economic challenge at the end of the Cold War. The resulting budget crisis helped elect Lowell Weicker as governor on a third-party ticket in 1990. Weicker's remedy was a state income tax which proved effective in balancing the budget, but only for the short-term. He did not run for a second term, in part because of this politically unpopular move.
In 1992, initial construction was completed on Foxwoods Casino at the Mashantucket Pequots reservation in eastern Connecticut, which became the largest casino in the Western Hemisphere. Mohegan Sun followed four years later.
In 2000, presidential candidate Al Gore chose Senator Joe Lieberman as his running mate, marking the first time that a major party presidential ticket included someone of the Jewish faith. Gore and Lieberman fell five votes short of George W. Bush and Dick Cheney in the Electoral College.
In the terrorist attacks of September 11, 2001, 65 state residents were killed, mostly Fairfield County residents who were working in the World Trade Center.
In 2004, Republican Governor John G. Rowland resigned during a corruption investigation, later pleading guilty to federal charges.
Connecticut was hit by three major storms in just over 14 months in 2011 and 2012, with all three causing extensive property damage and electric outages. Hurricane Irene struck Connecticut August 28, and damage totaled $235 million. Two months later, the "Halloween nor'easter" dropped extensive snow onto trees, resulting in snapped branches and trunks that damaged power lines; some areas were without electricity for 11 days. Hurricane Sandy had tropical storm-force winds when it reached Connecticut October 29, 2012. Sandy's winds drove storm surges into streets and cut power to 98% of homes and businesses, with more than $360 million in damage.
On December 14, 2012, Adam Lanza shot and killed 26 people at Sandy Hook Elementary School in Newtown, and then killed himself. The massacre spurred renewed efforts by activists for tighter laws on gun ownership nationally.
In the summer and fall of 2016, Connecticut experienced a drought in many parts of the state, causing some water-use bans. As of , 45% of the state was listed at Severe Drought by the U.S. Drought Monitor, including almost all of Hartford and Litchfield counties. All the rest of the state was in Moderate Drought or Severe Drought, including Middlesex, Fairfield, New London, New Haven, Windham, and Tolland counties. This affected the agricultural economy in the state.
The United States Census Bureau estimates that the population of Connecticut was 3,565,287 on July 1, 2019, a 0.25% decrease since the 2010 United States Census.
, Connecticut had an estimated population of 3,565,287, which is a decrease of 7,378 (0.25%) from the prior year and a decrease of 8,810 (0.25%) since 2010. This includes a natural increase since the last census of 67,427 (222,222 births minus 154,795 deaths) and an increase due to net migration of 41,718 people into the state. Immigration from outside the United States resulted in a net increase of 75,991 people, and migration within the country produced a net loss of 34,273. Based on the 2005 estimates, Connecticut moved from 29th most populous state to 30th. 2018 estimates put Connecticut's population at 3,572,665.
6.6% of its population was reported as being under5 years old, 24.7% under 18 years old, and 13.8% were 65 years of age or older. Females made up approximately 51.6% of the population, with 48.4% male.
In 1790, 97% of the population in Connecticut was classified as "rural". The first census in which less than half the population was classified as rural was 1890. In the 2000 census, only 12.3% was considered rural. Most of western and southern Connecticut (particularly the Gold Coast) is strongly associated with New York City; this area is the most affluent and populous region of the state and has high property costs and high incomes. The center of population of Connecticut is located in the town of Cheshire.
As of the 2010 United States Census, Connecticut's race and ethnic percentages were:
Hispanics and Latinos of any race made up 13.4% of the population in the 2010 Census.
The state's most populous ethnic group is Non-Hispanic White, but this has declined from 98% in 1940 to 71% in 2010.
As of 2004, 11.4% of the population (400,000) was foreign-born. In 1870, native-born Americans had accounted for 75% of the state's population, but that had dropped to 35% by 1918.
As of 2000, 81.69% of Connecticut residents age5 and older spoke English at home and 8.42% spoke Spanish, followed by Italian at 1.59%, French at 1.31%, and Polish at 1.20%.
The largest European ancestry groups are:
, 46.1% of Connecticut's population younger than age1 were minorities.
"Note: Births in table do not add up, because Hispanics are counted both by their ethnicity and by their race, giving a higher overall number."
The religious affiliations of the people of Connecticut :
A Pew survey of Connecticut residents' religious self-identification showed the following distribution of affiliations: Protestant 35%, Mormonism 1%, Jewish 3%, Roman Catholic 33%, Orthodox 1%, Non-religious 28%, Jehovah's Witness 1%, Hinduism 1%, Buddhism 1% and Islam 1%. Jewish congregations had 108,280 (3.2%) members in 2000. The Jewish population is concentrated in the towns near Long Island Sound between Greenwich and New Haven, in Greater New Haven and in Greater Hartford, especially the suburb of West Hartford. According to the Association of Religion Data Archives, the largest Christian denominations, by number of adherents, in 2010 were: the Catholic Church, with 1,252,936; the United Church of Christ, with 96,506; and non-denominational Evangelical Protestants, with 72,863.
Recent immigration has brought other non-Christian religions to the state, but the numbers of adherents of other religions are still low. Connecticut is also home to New England's largest Protestant Church: The First Cathedral in Bloomfield, Connecticut located in Hartford County. Hartford is seat to the Roman Catholic Archdiocese of Hartford, which is sovereign over the Diocese of Bridgeport and the Diocese of Norwich.
Connecticut's economic output in 2019 as measured by gross domestic product was $289 billion, up from $277.9 billion in 2018.
Connecticut's per capita personal income in 2019 was estimated at $79,087, the highest of any state. There is, however, a great disparity in incomes throughout the state; after New York, Connecticut had the second largest gap nationwide between the average incomes of the top 1% and the average incomes of the bottom 99%. According to a 2018 study by Phoenix Marketing International, Connecticut had the third-largest number of millionaires per capita in the United States, with a ratio of 7.75%. New Canaan is the wealthiest town in Connecticut, with a per capita income of $85,459. Hartford is the poorest municipality in Connecticut, with a per capita income of $13,428 in 2000.
As of December 2019, Connecticut's seasonally adjusted unemployment rate was 3.8%, with U.S. unemployment at 3.5% that month. Dating back to 1982, Connecticut recorded its lowest unemployment in 2000 between August and October, at 2.2%. The highest unemployment rate during that period occurred in November and December 2010 at 9.3%, but economists expect record new levels of layoffs as a result of business closures in the spring of 2020 as the result of the coronavirus pandemic.
Tax is collected by the Connecticut Department of Revenue Services and by local municipalities.
As of 2012, Connecticut residents had the second highest rate in the nation of combined state and local taxes after New York, at 12.6% of income compared to the national average of 9.9% as reported by the Tax Foundation.
Before 1991, Connecticut had an investment-only income tax system. Income from employment was untaxed, but income from investments was taxed at 13%, the highest rate in the U.S., with no deductions allowed for costs of producing the investment income, such as interest on borrowing.
In 1991, under Governor Lowell P. Weicker Jr., an independent, the system was changed to one in which the taxes on employment income and investment income were equalized at a maximum rate of 4%. The new tax policy drew investment firms to Connecticut; , Fairfield County was home to the headquarters for 16 of the 200 largest hedge funds in the world.
, the income tax rates on Connecticut individuals were divided into seven tax brackets of 3% (on income up to $10,000); 5% ($10,000-$50,000); 5.5% ($50,000-$100,000); 6% ($100,000-$200,000); 6.5% ($200,000-$250,000); 6.9% ($250,000-$500,000); and 6.99% above $500,000, with additional amounts owed depending on the bracket.
All wages of Connecticut residents are subject to the state's income tax, even if earned outside the state. However, in those cases, Connecticut income tax must be withheld only to the extent the Connecticut tax exceeds the amount withheld by the other jurisdiction. Since New York has higher income tax rates than Connecticut, this effectively means that Connecticut residents who work in New York have no Connecticut income tax withheld. Connecticut permits a credit for taxes paid to other jurisdictions, but since residents who work in other states are still subject to Connecticut income taxation, they may owe taxes if the jurisdictional credit does not fully offset the Connecticut tax amount.
Connecticut levies a 6.35% state sales tax on the retail sale, lease, or rental of most goods. Some items and services in general are not subject to sales and use taxes unless specifically enumerated as taxable by statute. A provision excluding clothing under $50 from sales tax was repealed . There are no additional sales taxes imposed by local jurisdictions. In 2001, Connecticut instituted what became an annual sales tax "holiday" each August lasting one week, when retailers do not have to remit sales tax on certain items and quantities of clothing that has varied from year to year.
State law authorizes municipalities to tax property, including real estate, vehicles and other personal property, with state statute providing varying exemptions, credits and abatements. All assessments are at 70% of fair market value. The maximum property tax credit is $200 per return and any excess may not be refunded or carried forward. According to the Tax Foundation, on a per capita basis in the 2017 fiscal year Connecticut residents paid the 3rd highest average property taxes in the nation after New Hampshire and New Jersey.
, gasoline taxes and fees in Connecticut were 40.13 cents per gallon, 11th highest in the United States which had a nationwide average of 36.13 cents a gallon excluding federal taxes. Diesel taxes and fees as of January 2020 in Connecticut were 46.50 cents per gallon, ninth highest nationally with the U.S. average at 37.91 cents.
In 2019, sales of single-family homes in Connecticut totaled 33,146 units, a 2.1 percent decline from the 2018 transaction total. The median home sold in 2019 recorded a transaction amount of $260,000, up 0.4 percent from 2018.
Connecticut had the seventh highest rate of home foreclosure activity in the country in 2019 at 0.53 percent of the total housing stock.
Finance, insurance and real estate was Connecticut's largest industry in 2018 as ranked by gross domestic product, generating $75.7 billion in GDP that year. Major financial industry employers include The Hartford, Travelers, Cigna, the Aetna subsidiary of CVS Health, Mass Mutual, People's United Financial, Bank of America, Realogy, Bridgewater Associates, GE Capital, William Raveis Real Estate, and Berkshire Hathaway through reinsurance and residential real estate subsidiaries.
The combined educational, health and social services sector was the largest single industry as ranked by employment, with a combined workforce of 342,600 people at the end of 2019, ranking fourth the year before in GDP at $28.3 billion.
The broad business and professional services sector had the second highest GDP total in Connecticut in 2018 at an estimated $33.7 billion.
Manufacturing was the third biggest industry in 2018 with GDP of $30.8 billion, dominated by Raytheon Technologies formed in the March 2020 merger of Hartford-based United Technologies and Waltham, Mass.-based Raytheon Co. As of the merger, Raytheon Technologies employed about 19,000 people in Connecticut through subsidiaries Pratt & Whitney and Collins Aerospace. Lockheed Martin subsidiary Sikorsky Aircraft operates Connecticut's single largest manufacturing plant in Stratford, where it makes helicopters.
Other major manufacturers include the Electric Boat division of General Dynamics, which makes submarines in Groton, Boehringer Ingelheim, a pharmaceuticals manufacturer with its U.S. headquarters in Ridgefield, and ASML, which in Wilton makes precision lithography machines used to create circuitry on semiconductors and flat-screen displays.
Connecticut historically was a center of gun manufacturing, and four gun-manufacturing firms continued to operate in the state , employing 2,000 people: Colt, Stag, Ruger, and Mossberg. Marlin, owned by Remington, closed in April 2011.
Other large components of the Connecticut economy in 2018 included wholesale trade ($18.1 billion in GDP); information services ($13.8 billion); retail ($13.7 billion); arts, entertainment and food services ($9.1 billion); and construction ($8.3 billion).
Tourists spent $9.3 billion in Connecticut in 2017 according to estimates as part of a series of studies commissioned by the state of Connecticut. Foxwoods Resort Casino and Mohegan Sun are the two biggest tourist draws and number among the state's largest employers; both are located on Indian reservations in the eastern part of Connecticut.
Connecticut's agricultural production totaled $580 million in 2017, with just over half of that revenue the result of nursery stock production. Milk production totaled $81 million that year, with other major product categories including eggs, vegetables and fruit, tobacco and shellfish.
The Interstate highways in the state are Interstate 95 (I-95) traveling southwest to northeast along the coast, I-84 traveling southwest to northeast in the center of the state, I-91 traveling north to south in the center of the state, and I-395 traveling north to south near the eastern border of the state. The other major highways in Connecticut are the Merritt Parkway and Wilbur Cross Parkway, which together form Connecticut Route 15 (Route 15), traveling from the Hutchinson River Parkway in New York parallel to I-95 before turning north of New Haven and traveling parallel to I-91, finally becoming a surface road in Berlin. I-95 and Route 15 were originally toll roads; they relied on a system of toll plazas at which all traffic stopped and paid fixed tolls. A series of major crashes at these plazas eventually contributed to the decision to remove the tolls in 1988. Other major arteries in the state include U.S. Route7 (US7) in the west traveling parallel to the New York state line, Route8 farther east near the industrial city of Waterbury and traveling north–south along the Naugatuck River Valley nearly parallel with US7, and Route9 in the east.
Between New Haven and New York City, I-95 is one of the most congested highways in the United States. Although I-95 has been widened in several spots, some areas are only three lanes and this strains traffic capacity, resulting in frequent and lengthy rush hour delays. Frequently, the congestion spills over to clog the parallel Merritt Parkway and even US1. The state has encouraged traffic reduction schemes, including rail use and ride-sharing.
Connecticut also has a very active bicycling community, with one of the highest rates of bicycle ownership and use in the United States, particularly in New Haven. According to the U.S. Census 2006 American Community Survey, New Haven has the highest percentage of commuters who bicycle to work of any major metropolitan center on the East Coast.
Rail is a popular travel mode between New Haven and New York City's Grand Central Terminal. Southwestern Connecticut is served by the Metro-North Railroad's New Haven Line, operated by the Metropolitan Transportation Authority and providing commuter service to New York City and New Haven, with branches servicing New Canaan, Danbury, and Waterbury. Connecticut lies along Amtrak's Northeast Corridor which features frequent Northeast Regional and Acela Express service from New Haven south to New York City, Philadelphia, Baltimore, Washington, DC, and Norfolk, VA.
Coastal cities and towns between New Haven and New London are also served by the Shore Line East commuter line. Several new stations were completed along the Connecticut shoreline recently, and a commuter rail service called the Hartford Line between New Haven and Springfield on Amtrak's New Haven-Springfield Line began operating in June 2018.
A proposed commuter rail service, the Central Corridor Rail Line, will connect New London with Norwich, Willimantic, Storrs, and Stafford Springs, with service continuing into Massachusetts and Brattleboro. Amtrak also operates a shuttle service (CTRail) between New Haven and Springfield, Massachusetts, serving Wallingford, Meriden, Berlin, Hartford, Windsor Locks, and Springfield, MA and the Vermonter runs from Washington to St. Albans, Vermont via the same line.
Statewide bus service is supplied by Connecticut Transit, owned by the Connecticut Department of Transportation, with smaller municipal authorities providing local service. Bus networks are an important part of the transportation system in Connecticut, especially in urban areas like Hartford, Stamford, Norwalk, Bridgeport and New Haven. Connecticut Transit also operates CTfastrak, a bus rapid transit service between New Britain and Hartford. The bus route opened to the public on March 28, 2015.
Bradley International Airport, is located in Windsor Locks, north of Hartford. Many residents of central and southern Connecticut also make heavy use of JFK International Airport and Newark International Airports, especially for international travel. Smaller regional air service is provided at Tweed New Haven Regional Airport. Larger civil airports include Danbury Municipal Airport and Waterbury-Oxford Airport in western Connecticut, Hartford–Brainard Airport in central Connecticut, and Groton-New London Airport in eastern Connecticut. Sikorsky Memorial Airport is located in Stratford and mostly services cargo, helicopter and private aviation.
The Bridgeport & Port Jefferson Ferry travels between Bridgeport, Connecticut and Port Jefferson, New York by crossing Long Island Sound. Ferry service also operates out of New London to Orient, New York; Fishers Island, New York; and Block Island, Rhode Island, which are popular tourist destinations. Small local services operate the Rocky Hill–Glastonbury Ferry and the Chester–Hadlyme Ferry which cross the Connecticut River.
Hartford has been the sole capital of Connecticut since 1875. Before then, New Haven and Hartford alternated as capitals.
Connecticut is known as the "Constitution State". The origin of this nickname is uncertain, but it likely comes from Connecticut's pivotal role in the federal constitutional convention of 1787, during which Roger Sherman and Oliver Ellsworth helped to orchestrate what became known as the Connecticut Compromise, or the Great Compromise. This plan combined the Virginia Plan and the New Jersey Plan to form a bicameral legislature, a form copied by almost every state constitution since the adoption of the federal constitution. Variations of the bicameral legislature had been proposed by Virginia and New Jersey, but Connecticut's plan was the one that was in effect until the early 20th century, when Senators ceased to be selected by their state legislatures and were instead directly elected. Otherwise, it is still the design of Congress.
The nickname also might refer to the Fundamental Orders of 1638–39. These Fundamental Orders represent the framework for the first formal Connecticut state government written by a representative body in Connecticut. The State of Connecticut government has operated under the direction of four separate documents in the course of the state's constitutional history. After the Fundamental Orders, Connecticut was granted governmental authority by King Charles II of England through the Connecticut Charter of 1662.
Separate branches of government did not exist during this period, and the General Assembly acted as the supreme authority. A constitution similar to the modern U.S. Constitution was not adopted in Connecticut until 1818. Finally, the current state constitution was implemented in 1965. The 1965 constitution absorbed a majority of its 1818 predecessor, but incorporated a handful of important modifications.
The governor heads the executive branch. , Ned Lamont is the Governor and Susan Bysiewicz is the Lieutenant Governor; both are Democrats. From 1639 until the adoption of the 1818 constitution, the governor presided over the General Assembly. In 1974, Ella Grasso was elected as the governor of Connecticut. This was the first time in United States history when a woman was a governor without her husband being governor first.
There are several executive departments: Administrative Services, Agriculture, Banking, Children and Families, Consumer Protection, Correction, Economic and Community Development, Developmental Services, Construction Services, Education, Emergency Management and Public Protection, Energy & Environmental Protection, Higher Education, Insurance, Labor, Mental Health and Addiction Services, Military, Motor Vehicles, Public Health, Public Utility Regulatory Authority, Public Works, Revenue Services, Social Services, Transportation, and Veterans Affairs. In addition to these departments, there are other independent bureaus, offices and commissions.
In addition to the Governor and Lieutenant Governor, there are four other executive officers named in the state constitution that are elected directly by voters: Secretary of the State, Treasurer, Comptroller, and Attorney General. All executive officers are elected to four-year terms.
The legislature is the General Assembly. The General Assembly is a bicameral body consisting of an upper body, the State Senate (36 senators); and a lower body, the House of Representatives (151 representatives). Bills must pass each house in order to become law. The governor can veto the bill, but this veto can be overridden by a two-thirds majority in each house. Per Article XV of the state constitution, Senators and Representatives must be at least 18 years of age and are elected to two-year terms in November on even-numbered years. There also must always be between 30 and 50 senators and 125 to 225 representatives. The Lieutenant Governor presides over the Senate, except when absent from the chamber, when the President pro tempore presides. The Speaker of the House presides over the House. , Joe Aresimowicz is the Speaker of the House of Connecticut.
, Connecticut's United States Senators are Richard Blumenthal (Democrat) and Chris Murphy (Democrat). Connecticut has five representatives in the U.S. House, all of whom are Democrats.
Locally elected representatives also develop Local ordinances to govern cities and towns. The town ordinances often include noise control and zoning guidelines. However, the State of Connecticut also provides statewide ordinances for noise control as well.
The highest court of Connecticut's judicial branch is the Connecticut Supreme Court, headed by the Chief Justice of Connecticut. The Supreme Court is responsible for deciding on the constitutionality of the law or cases as they relate to the law. Its proceedings are similar to those of the United States Supreme Court, with no testimony given by witnesses, and the lawyers of the two sides each present oral arguments no longer than thirty minutes. Following a court proceeding, the court may take several months to arrive at a judgment. the Chief Justice is Richard A. Robinson.
In 1818, the court became a separate entity, independent of the legislative and executive branches. The Appellate Court is a lesser statewide court and the Superior Courts are lower courts that resemble county courts of other states.
The State of Connecticut also offers access to Arrest warrant enforcement statistics through the Office of Policy and Management.
Connecticut does not have county government, unlike all other states except Rhode Island. Connecticut county governments were mostly eliminated in 1960, with the exception of sheriffs elected in each county. In 2000, the county sheriff was abolished and replaced with the state marshal system, which has districts that follow the old county territories. The judicial system is divided into judicial districts at the trial-court level which largely follow the old county lines. The eight counties are still widely used for purely geographical and statistical purposes, such as weather reports and census reporting.
Connecticut shares with the rest of New England a governmental institution called the New England town. The state is divided into 169 towns which serve as the fundamental political jurisdictions. There are also 21 cities, most of which simply follow the boundaries of their namesake towns and have a merged city-town government. There are two exceptions: the City of Groton, which is a subsection of the Town of Groton, and the City of Winsted in the Town of Winchester. There are also nine incorporated boroughs which may provide additional services to a section of town. Naugatuck is a consolidated town and borough.
The state is also divided into 15 planning regions defined by the state Office of Planning and Management, with the exception of the Town of Stafford in Tolland County. The Intragovernmental Policy Division of this Office coordinates regional planning with the administrative bodies of these regions. Each region has an administrative body known as a regional council of governments, a regional council of elected officials, or a regional planning agency. The regions are established for the purpose of planning "coordination of regional and state planning activities; redesignation of logical planning regions and promotion of the continuation of regional planning organizations within the state; and provision for technical aid and the administration of financial assistance to regional planning organizations".
Connecticut residents who register to vote may declare an affiliation to a political party, may become unaffiliated at will, and may change affiliations subject to certain waiting periods. about 60% of registered voters are enrolled (just over1% total in 28 third parties minor parties), and ratios among unaffiliated voters and the two major parties are about eight unaffiliated for every seven in the Democratic Party of Connecticut and for every four in the Connecticut Republican Party.
Many Connecticut towns and cities show a marked preference for moderate candidates of either party.
In April 2012 both houses of the Connecticut state legislature passed a bill (20 to 16 and 86 to 62) that abolished the capital punishment for all future crimes, while 11 inmates who were waiting on the death row at the time could still be executed.
In July 2009 the Connecticut legislature overrode a veto by Governor M. Jodi Rell to pass SustiNet, the first significant public-option health care reform legislation in the nation.
Connecticut ranked third in the nation for educational performance, according to Education Week's Quality Counts 2018 report. It earned an overall score of 83.5 out of 100 points. On average, the country received a score of 75.2.
Connecticut posted a B-plus in the Chance-for-Success category, ranking fourth on factors that contribute to a person's success both within and outside the K-12 education system. Connecticut received a mark of B-plus and finished fourth for School Finance. It ranked 12th with a grade of C on the K-12 Achievement Index.
The Connecticut State Board of Education manages the public school system for children in grades K–12. Board of Education members are appointed by the Governor of Connecticut. Statistics for each school are made available to the public through an online database system called "CEDAR". The CEDAR database also provides statistics for "ACES" or "RESC" schools for children with behavioral disorders.
Connecticut was home to the nation's first law school, Litchfield Law School, which operated from 1773 to 1833 in Litchfield. Hartford Public High School (1638) is the third-oldest secondary school in the nation after the Collegiate School (1628) in Manhattan and the Boston Latin School (1635).
The state also has many noted private day schools, and its boarding schools draw students from around the world.
There are two Connecticut teams in the American Hockey League. The Bridgeport Sound Tigers is a farm team for the New York Islanders which competes at the Webster Bank Arena in Bridgeport. The Hartford Wolf Pack is the affiliate of the New York Rangers; they play in the XL Center in Hartford.
The Hartford Yard Goats of the Eastern League are a AA affiliate of the Colorado Rockies. Also, the Norwich Sea Unicorns play in the New York-Penn League and are an A affiliate of the Detroit Tigers. The New Britain Bees play in the Atlantic League of Professional Baseball. The Connecticut Sun of the WNBA currently play at the Mohegan Sun Arena in Uncasville. In soccer, Hartford Athletic began play in the USL Championship in 2019, serving as the reserve team for the New England Revolution of Major League Soccer.
The state hosts several major sporting events. Since 1952, a PGA Tour golf tournament has been played in the Hartford area. It was originally called the "Insurance City Open" and later the "Greater Hartford Open" and is now known as the Travelers Championship. The Connecticut Open tennis tournament is held annually in the Cullman-Heyman Tennis Center at Yale University in New Haven.
Lime Rock Park in Salisbury is a road racing course, home to the International Motor Sports Association, SCCA, United States Auto Club, and K&N Pro Series East races. Thompson International Speedway, Stafford Motor Speedway, and Waterford Speedbowl are oval tracks holding weekly races for NASCAR Modifieds and other classes, including the NASCAR Whelen Modified Tour. The state also hosts several major mixed martial arts events for Bellator MMA and the Ultimate Fighting Championship.
The Hartford Whalers of the National Hockey League played in Hartford from 1975 to 1997 at the Hartford Civic Center. They departed to Raleigh, North Carolina after disputes with the state over the construction of a new arena, and they are now known as the Carolina Hurricanes. In 1926, Hartford had a franchise in the National Football League known as the Hartford Blues. They joined the National League for one season in 1876, making them the state's only Major League baseball franchise before moving to Brooklyn, New York and then disbanding one season later. From 2000 until 2006 the city was home to the Hartford FoxForce of World TeamTennis.
The Connecticut Huskies are the team of the University of Connecticut (UConn); they play NCAA Division I sports. Both the men's basketball and women's basketball teams have won multiple national championships. In 2004, UConn became the first school in NCAA DivisionI history to have its men's and women's basketball programs win the national title in the same year; they repeated the feat in 2014 and are still the only DivisionI school to win both titles in the same year. The UConn women's basketball team holds the record for the longest consecutive winning streak in NCAA college basketball at 111 games, a streak that ended in 2017. The UConn Huskies football team has played in the Football Bowl Subdivision since 2002, and has played in four bowl games.
New Haven biennially hosts "The Game" between the Yale Bulldogs and the Harvard Crimson, the country's second-oldest college football rivalry. Yale alumnus Walter Camp is deemed the "Father of American Football", and he helped develop modern football while living in New Haven. Other Connecticut universities which feature DivisionI sports teams are Quinnipiac University, Fairfield University, Central Connecticut State University, Sacred Heart University, and the University of Hartford.
The Constitution State Rivalry is an in-state college football rivalry between Sacred Heart University and Central Connecticut State University. Both teams compete at the NCAA Division 1 Football Championship Subdivision level in the Northeast Conference. Since 1998, the game has been played annually with the location of the matchup determined on a yearly basis.
The name "Connecticut" originated with the Mohegan word "quonehtacut", meaning "place of long tidal river". Connecticut's official nickname is "The Constitution State", adopted in 1959 and based on its colonial constitution of 1638–1639 which was the first in America and, arguably, the world. Connecticut is also unofficially known as "The Nutmeg State," whose origin is unknown. It may have come from its sailors returning from voyages with nutmeg, which was a very valuable spice in the 18th and 19th centuries. It may have originated in the early machined sheet tin nutmeg grinders sold by early Connecticut peddlers. It is also facetiously said to come from Yankee peddlers from Connecticut who would sell small carved nobs of wood shaped to look like nutmeg to unsuspecting customers. George Washington gave Connecticut the title of "The Provisions State" because of the material aid that the state rendered to the American Revolutionary War effort. Connecticut is also known as "The Land of Steady Habits".
According to "Webster's New International Dictionary" (1993), a person who is a native or resident of Connecticut is a "Connecticuter". There are numerous other terms coined in print but not in use, such as "Connecticotian" (Cotton Mather in 1702) and "Connecticutensian" (Samuel Peters in 1781). Linguist Allen Walker Read suggests the more playful term "connecticutie". "Nutmegger" is sometimes used, as is "Yankee" The official state song is "Yankee Doodle". The traditional abbreviation of the state's name is "Conn".; the official postal abbreviation is CT.
Commemorative stamps issued by the United States Postal Service with Connecticut themes include Nathan Hale, Eugene O'Neill, Josiah Willard Gibbs, Noah Webster, Eli Whitney, the whaling ship the "Charles W. Morgan", which is docked at Mystic Seaport, and a decoy of a broadbill duck.

</doc>
<doc id="6468" url="https://en.wikipedia.org/wiki?curid=6468" title="Country Liberal Party">
Country Liberal Party

The Country Liberal Party (CLP), officially the Country Liberals (Northern Territory), is a liberal conservative political party in Australia founded in 1974, which operates solely in the Northern Territory, however due to Christmas Island and the Cocos (Keeling) Islands forming part of the Division of Lingiari they also vote for the Country Liberal Party.
The CLP first fielded candidates at the 1975 federal election, winning one seat in the Senate and the non-voting seat in the House of Representatives. Since 1979, the CLP has been formally affiliated with both the federal Liberal Party of Australia and the National Party of Australia (previously the Country Party and National Country Party). The Liberal Party, National Party, Liberal National Party of Queensland, and CLP form the Coalition of Australian centre-right parties, with the CLP alone contesting seats for the Coalition in the Northern Territory. The CLP has full voting rights within the National Party, and observer status with the Liberal Party. Currently, the CLP has one representative in federal parliament, Senator Sam McMahon.
The CLP dominated the Northern Territory Legislative Assembly from its establishment in 1974 until the 2001 general election, when the CLP lost government winning only 10 of the 25 seats, and was reduced further to four parliamentary members at the 2005 election. At the 2008 election it increased its numbers, winning 11 seats.
The CLP returned to office following the 2012 election, winning 16 of 25 seats, and leader Terry Mills became Chief Minister of the Northern Territory. Less than a year later, Mills was replaced as Chief Minister and CLP leader by Adam Giles at the 2013 CLP leadership ballot on 13 March. Giles was the first indigenous Australian to lead a state or territory government in Australia. Giles was defeated at the 2015 CLP leadership ballot but managed to survive in the aftermath. Multiple defections saw the CLP reduced to minority government a few months later. At the 27 August 2016 Territory election, the CLP was resoundingly defeated, winning just two of 25 seats. Gary Higgins became CLP leader and opposition leader on 2 September, with Lia Finocchiaro as his deputy. On 20 January 2020, Higgins stood down as party leader and announced his retirement at the next election. Finocchiaro became CLP leader and leader of the opposition on 1 February 2020.
The Territory Country Party members first contested the 1919 federal election, with a newly established federal Country Party contesting the 1922 federal election. The 1922 election saw the main opposition party to the Australian Labor Party, the Nationalist Party of Australia deprived of a majority, and were required to form a coalition in order to command a majority on the floor of parliament. The price for such support was the resignation of Nationalist (ex-Labor) Prime Minister, Billy Hughes, who was replaced by Stanley Bruce.
In 1922, the federal Division of Northern Territory was created, with one non-voting Member in the House of Representatives. Harold George Nelson was the inaugural member serving between 16 December 1922 and 15 September 1934. He was elected as an Independent but later joined the Australian Labor Party (ALP). Between 15 September 1934 and 10 December 1949 the Division of Northern Territory was held by Adair Blain, an independent member. Between 10 December 1949 and 31 October 1966 the Division was held by Jock Nelson, a member of the ALP. The Territory seat was won by the Country Party's Sam Calder at the 1966 federal election, who held the seat from 26 November 1966 to 19 September 1980.
In 1966, the Country Party was established in the Northern Territory, while the Liberal Party was a small party. In recognition of this, the local Liberals supported the Country Party's Calder for the sole NT seat from 1969 to 1972. An alliance had formed, primarily against the conservatives' main opponent, the ALP. After the gradual extension of limited voting rights, in 1968 the federal Coalition government gave the Member for Northern Territory full voting rights.
After the 1974 federal election and the subsequent Joint Sitting of parliament, legislation was passed to give the Australian Capital Territory and the Northern Territory representation in the Australian Senate, with two senators being elected.
The Whitlam Government passed legislation in 1974 to establish a fully elected unicameral Northern Territory Legislative Assembly to replace the previous partly elected Northern Territory Legislative Council, which had been in existence since 1947. The term of the Legislative Assembly was four years. Initially, the Legislative Assembly consisted of 19 members, which was increased in 1982 to 25 members, the present number. The Northern Territory was granted self-government in 1978.
Following the creation of the Legislative Assembly in 1974, the Territory's branches of the Country and Liberal parties merged to form the "Country Liberal Party" (CLP) to field candidates at the 1974 general election for the Legislative Assembly, going on to win 17 out of 19 seats. Calder was largely responsible for the push to unite the non-Labor forces in the Territory.
The CLP fielded candidates at the 1975 federal election, winning one seat each in the Senate and in the House of Representatives. Its first two federal MPs, Sam Calder and Bernie Kilgariff, both sat with the National Country Party (NCP) in federal parliament. However, on 3 February 1979 a special conference of the CLP resolved that "the Federal CLP Parliamentarians be permitted to sit in the Party Rooms of their choice in Canberra". Despite personal misgivings, Kilgariff chose to sit with the Liberal Party from 8 March 1979 in order that the CLP have representation in both parties, a practice which has been maintained where possible.
The CLP governed the Northern Territory from 1974 until the 2001 election. During this time, it never faced more than nine opposition members. Indeed, the CLP's dominance was so absolute that its internal politics were seen as a bigger threat than any opposition party. This was especially pronounced in the mid-1980s, when a series of party-room coups resulted in the Territory having three Chief Ministers in four years and also saw the creation of the Northern Territory Nationals as a short-lived splinter group under the leadership of former CLP chief minister Ian Tuxworth.
At the 2001 election the Australian Labor Party won government by one seat, ending 27 years of CLP government. The loss marked a major turning point in Northern Territory politics, a result which was exacerbated when, at the 2005 election, the ALP won the second-largest majority government in the history of the Territory, reducing the once-dominant party to just four members in the Legislative Assembly. This result was only outdone by the 1974 election, in which the CLP faced only two independents as opposition. The CLP even lost two seats in Palmerston, an area where the ALP had never come close to winning any seats before.
In the 2001 federal election, the CLP won the newly formed seat of Solomon, based on Darwin/Palmerston, in the House of Representatives.
In the 2004 federal election, the CLP held one seat in the House of Representatives, and one seat in the Senate. The CLP lost its federal lower house seat in the 2007 federal election, but regained it when Palmerston deputy mayor Natasha Griggs won back Solomon for the CLP. She sat with the Liberals in the House.
The 2008 election saw the CLP recover from the severe loss it suffered three years earlier, increasing its representation from four to 11 members. Following the 2011 decision of ALP-turned-independent member Alison Anderson to join the CLP, this increased CLP's representation to 12 in the Assembly, leaving the incumbent Henderson Government to govern in minority with the support of Independent MP Gerry Wood.
Historically, the CLP has been particularly dominant in the Territory's two major cities, Darwin/Palmerston and Alice Springs. However, in recent years the ALP has pulled even with the CLP in the Darwin area; indeed, its 2001 victory was fueled by an unexpected swing in Darwin.
The CLP under the leadership of Terry Mills returned to power in the 2012 election with 16 of 25 seats, defeating the incumbent Labor Government led by Paul Henderson. In the lead up to the Territory election, CLP Senator Nigel Scullion sharply criticised the Federal Labor Government for its suspension of the live cattle trade to Indonesia - an economic mainstay of the territory.
The election victory ended 11 years of ALP rule in the Northern Territory. The victory was also notable for the support it achieved from indigenous people in pastoral and remote electorates. Large swings were achieved in remote Territory electorates (where the indigenous population comprised around two-thirds of voters) and a total of five Aboriginal CLP candidates won election to the Assembly. Among the indigenous candidates elected were high-profile Aboriginal activist Bess Price and former ALP member Alison Anderson. Anderson was appointed Minister for Indigenous Advancement. In a nationally reported speech in November 2012, Anderson condemned welfare dependency and a culture of entitlement in her first ministerial statement on the status of Aboriginal communities in the Territory and said the CLP would focus on improving education and on helping create real jobs for indigenous people.
Adam Giles replaced Mills as Chief Minister of the Northern Territory and party leader at the 2013 CLP leadership ballot on 13 March while Mills was on a trade mission in Japan. Giles was sworn in as Chief Minister on 14 March, becoming the first indigenous head of government of an Australian state or territory.
Willem Westra van Holthe challenged Giles at the 2015 CLP leadership ballot on 2 February and was elected leader by the party room in a late night vote conducted by phone. However, Giles refused to resign as Chief Minister following the vote. On 3 February, "ABC News" reported that officials were preparing an instrument for Giles' removal by the Administrator. The swearing-in of Westra van Holthe, which had been scheduled for 11:00 local time (01:30 UTC), was delayed. After a meeting of the parliamentary wing of the CLP, Giles announced that he would remain as party leader and Chief Minister, and that Westra van Holthe would be his deputy.
After four defections during the parliamentary term, the CLP was reduced to minority government by July 2015. Giles raised the possibility of an early election on 20 July stating that he would "love" to call a snap poll, but that it was "pretty much impossible to do". Crossbenchers dismissed the notion of voting against a confidence motion to bring down the government.
Territory government legislation passed in February 2016 changed the voting method of single-member electorates from full-preferential voting to optional preferential voting ahead of the 2016 territory election held on 27 August.
Federally, a MediaReach seat-level opinion poll of 513 voters in the seat of Solomon conducted 22−23 June ahead of the 2016 federal election held on 2 July surprisingly found Labor candidate Luke Gosling heavily leading two-term CLP incumbent Natasha Griggs 61–39 on the two-party vote from a large 12.4 percent swing. The CLP lost Solomon to Labor at the election, with Gosling defeating Griggs 56–44 on the two-party vote from a 7.4 percent swing.
At the 27 August Territory election, the CLP was swept from power in a massive Labor landslide, suffering easily the worst defeat of a sitting government in Territory history. The party not only lost all of the bush seats it picked up in 2012, but was all but shut out of Darwin/Palmerston, winning only one seat there. All told, the CLP only won two seats, easily its worst showing in an election. Giles himself lost his own seat, becoming the second Majority Leader/Chief Minister to lose his own seat. Even before Giles' defeat was confirmed, second-term MP Gary Higgins—the only surviving member of the Giles cabinet—was named the party's new leader, with Lia Finocchiaro as his deputy. On 20 January 2020, Higgins announced his resignation as party leader and announced his retirement at the next election. Finocchiaro succeeded him as CLP leader and leader of the opposition on 1 February 2020.
The CLP stands for office in the Northern Territory Assembly and Federal Parliament of Australia and primarily concerns itself with representing Territory interests. It is a regionally based party, that has parliamentary representation in both the Federal Parliament and at the Territory level. It brands as a party with strong roots in the Territory.
The CLP competes against the Australian Labor Party (Northern Territory Branch) (the local branch of Australia's social-democratic party). It is closely affiliated with, but is independent from the Liberal Party of Australia (a mainly urban, pro-private enterprise party comprising mainly liberal membership) and the National Party of Australia (a conservative-liberal agrarian and regional interests party).
The party promotes traditional Liberal Party values such as individualism and private enterprise, and what it describes as "progressive" political policy such as full statehood for the Northern Territory.
Branch delegates and members of the party's Central Council attend the Annual Conference of the Country Liberal Party to decide the party's platform. The Central Council is composed of the party's office bearers, its leaders from the Territory Assembly and the Federal Parliament and representatives of party branches.
The Annual Conference of the Country Liberal Party, attended by branch delegates and members of the party's Central Council, decides matters relating to the party's platform and philosophy. The Central Council administers the party and makes decisions on pre-selections. It is composed of the party's office bearers, its leaders in the Northern Territory Legislative Assembly, members in the Federal Parliament, and representation from each of the party's branches.
The CLP president has full voting rights with the National Party and observer status with the Liberal Party. Both the Liberals and Nationals receive Country Liberal delegations at their conventions. After federal elections, the CLP directs its federal members and senators as to which of the two other parties they should sit with in the parliamentary chamber. In practice, CLP House members usually sit with the Liberals, while CLP Senators sit with the Nationals.

</doc>
<doc id="6469" url="https://en.wikipedia.org/wiki?curid=6469" title="Canon law">
Canon law

Canon law (from , , a 'straight measuring rod, ruler') is a set of ordinances and regulations made by ecclesiastical authority (Church leadership), for the government of a Christian organization or church and its members. It is the internal ecclesiastical law, or operational policy, governing the Catholic Church (both the Latin Church and the Eastern Catholic Churches), the Eastern Orthodox and Oriental Orthodox churches, and the individual national churches within the Anglican Communion. The way that such church law is legislated, interpreted and at times adjudicated varies widely among these three bodies of churches. In all three traditions, a canon was originally a rule adopted by a church council; these canons formed the foundation of canon law.
Greek / , Arabic / , Hebrew / , 'straight'; a rule, code, standard, or measure; the root meaning in all these languages is 'reed'; see also the Romance-language ancestors of the English word "cane".
The "Apostolic Canons" or "Ecclesiastical Canons of the Same Holy Apostles" is a collection of ancient ecclesiastical decrees (eighty-five in the Eastern, fifty in the Western Church) concerning the government and discipline of the Early Christian Church, incorporated with the Apostolic Constitutions which are part of the Ante-Nicene Fathers.
In the fourth century, the First Council of Nicaea (325) calls canons the disciplinary measures of the Church: the term canon, κανὠν, means in Greek, a rule. There is a very early distinction between the rules enacted by the Church and the legislative measures taken by the State called "leges", Latin for laws.
In the Catholic Church, canon law is the system of laws and legal principles made and enforced by the Church's hierarchical authorities to regulate its external organization and government and to order and direct the activities of Catholics toward the mission of the Church.
In the Latin Church, positive ecclesiastical laws, based directly or indirectly upon immutable divine law or natural law, derive formal authority in the case of universal laws from the supreme legislator (i.e., the Supreme Pontiff), who possesses the totality of legislative, executive, and judicial power in his person, while particular laws derive formal authority from a legislator inferior to the supreme legislator. The actual subject material of the canons is not just doctrinal or moral in nature, but all-encompassing of the human condition.
The Catholic Church also includes the main five rites (groups) of churches which are in full union with the Holy See and the Latin Church:
All of these church groups are in full communion with the Supreme Pontiff and are subject to the "Code of Canons of the Eastern Churches".
The Catholic Church has what is claimed to be the oldest continuously functioning internal legal system in Western Europe, much later than Roman law but predating the evolution of modern European civil law traditions. What began with rules ("canons") adopted by the Apostles at the Council of Jerusalem in the first century has developed into a highly complex legal system encapsulating not just norms of the New Testament, but some elements of the Hebrew (Old Testament), Roman, Visigothic, Saxon, and Celtic legal traditions.
The history of Latin canon law can be divided into four periods: the "jus antiquum", the "jus novum", the "jus novissimum" and the "Code of Canon Law". In relation to the Code, history can be divided into the "jus vetus" (all law before the Code) and the "jus novum" (the law of the Code, or "jus codicis").
The canon law of the Eastern Catholic Churches, which had developed some different disciplines and practices, underwent its own process of codification, resulting in the Code of Canons of the Eastern Churches promulgated in 1990 by Pope John Paul II.
Roman canon law is a fully developed legal system, with all the necessary elements: courts, lawyers, judges, a fully articulated legal code principles of legal interpretation, and coercive penalties, though it lacks civilly-binding force in most secular jurisdictions. One example where it did not previously apply was in the English legal system, as well as systems, such as the U.S., that derived from it. Here criminals could apply for the benefit of clergy. Being in holy orders, or fraudulently claiming to be, meant that criminals could opt to be tried by ecclesiastical rather than secular courts. The ecclesiastical courts were generally more lenient. Under the Tudors, the scope of clerical benefit was steadily reduced by Henry VII, Henry VIII, and Elizabeth I. The Vatican disputed secular authority over priests' criminal offenses, and this in turn contributed to the English Reformation. The benefit of clergy was systematically removed from English legal systems over the next 200 years, although it still occurred in South Carolina in 1827.
In English Law, the use of this mechanism, which by that point was a legal fiction used for first offenders, was abolished by the Criminal Law Act 1827.
The structure that the fully developed Roman Law provides is a contribution to the Canon Law. The academic degrees in canon law are the J.C.B. ("Juris Canonici Baccalaureatus", Bachelor of Canon Law, normally taken as a graduate degree), J.C.L. ("Juris Canonici Licentiatus", Licentiate of Canon Law) and the J.C.D. ("Juris Canonici Doctor", Doctor of Canon Law). Because of its specialized nature, advanced degrees in civil law or theology are normal prerequisites for the study of canon law.
Much of the legislative style was adapted from the Roman Law Code of Justinian. As a result, Roman ecclesiastical courts tend to follow the Roman Law style of continental Europe with some variation, featuring collegiate panels of judges and an investigative form of proceeding, called "inquisitorial", from the Latin "inquirere", to enquire. This is in contrast to the adversarial form of proceeding found in the common law system of English and U.S. law, which features such things as juries and single judges.
The institutions and practices of canon law paralleled the legal development of much of Europe, and consequently, both modern civil law and common law bear the influences of canon law. Edson Luiz Sampel, a Brazilian expert in canon law, says that canon law is contained in the genesis of various institutes of civil law, such as the law in continental Europe and Latin American countries. Sampel explains that canon law has significant influence in contemporary society.
Canonical jurisprudential theory generally follows the principles of Aristotelian-Thomistic legal philosophy. While the term "law" is never explicitly defined in the Code, the Catechism of the Catholic Church cites Aquinas in defining law as "...an ordinance of reason for the common good, promulgated by the one who is in charge of the community" and reformulates it as "...a rule of conduct enacted by competent authority for the sake of the common good."
The law of the Eastern-rite Churches in full communion with the Roman papacy was in much the same state as that of the Latin or Western Church before 1917; much more diversity in legislation existed in the various Eastern Catholic Churches. Each had its own special law, in which custom still played an important part. One major difference in Eastern Europe however, specifically in the Orthodox Christian churches was in regards to divorce. Divorce started to slowly be allowed in specific instances such as adultery being committed, abuse, abandonment, impotence, and barrenness being the primary justifications for divorce. Eventually, the church began to allow remarriage to occur (for both spouses) post-divorce. In 1929 Pius XI informed the Eastern Churches of his intention to work out a Code for the whole of the Eastern Church. The publication of these Codes for the Eastern Churches regarding the law of persons was made between 1949 through 1958 but finalized nearly 30 years later.
The first Code of Canon Law (1917) was almost exclusively for the Latin Church, with extremely limited application to the Eastern Churches. After the Second Vatican Council, (1962 - 1965), another edition was published specifically for the Roman Rite in 1983. Most recently, 1990, the Vatican produced the "Code of Canons" of the Eastern Churches which became the 1st code of "Eastern Catholic Canon Law".
The Eastern Orthodox Church, principally through the work of 18th-century Athonite monastic scholar Nicodemus the Hagiorite, has compiled canons and commentaries upon them in a work known as the (, 'Rudder'), so named because it is meant to "steer" the Church in her discipline. The dogmatic determinations of the Councils are to be applied rigorously since they are considered to be essential for the Church's unity and the faithful preservation of the Gospel.
In the Church of England, the ecclesiastical courts that formerly decided many matters such as disputes relating to marriage, divorce, wills, and defamation, still have jurisdiction of certain church-related matters (e.g. discipline of clergy, alteration of church property, and issues related to churchyards). Their separate status dates back to the 12th century when the Normans split them off from the mixed secular/religious county and local courts used by the Saxons. In contrast to the other courts of England, the law used in ecclesiastical matters is at least partially a civil law system, not common law, although heavily governed by parliamentary statutes. Since the Reformation, ecclesiastical courts in England have been royal courts. The teaching of canon law at the Universities of Oxford and Cambridge was abrogated by Henry VIII; thereafter practitioners in the ecclesiastical courts were trained in civil law, receiving a Doctor of Civil Law (D.C.L.) degree from Oxford, or a Doctor of Laws (LL.D.) degree from Cambridge. Such lawyers (called "doctors" and "civilians") were centered at "Doctors Commons", a few streets south of St Paul's Cathedral in London, where they monopolized probate, matrimonial, and admiralty cases until their jurisdiction was removed to the common law courts in the mid-19th century.
Other churches in the Anglican Communion around the world (e.g., the Episcopal Church in the United States, and the Anglican Church of Canada) still function under their own private systems of canon law.
In 2002 a Legal Advisors Consultation meeting at Canterbury concluded:(1) There are principles of canon law common to the churches within the Anglican Communion; (2) Their existence can be factually established; (3) Each province or church contributes through its own legal system to the principles of canon law common within the Communion; (4) these principles have strong persuasive authority and are fundamental to the self-understanding of each of the member churches; (5) These principles have a living force, and contain within themselves the possibility for further development; and (6) The existence of the principles both demonstrates and promotes unity in the Communion.
In Presbyterian and Reformed churches, canon law is known as "practice and procedure" or "church order", and includes the church's laws respecting its government, discipline, legal practice, and worship.
Roman canon law had been criticized by the Presbyterians as early as 1572 in the Admonition to Parliament. The protest centered on the standard defense that canon law could be retained so long as it did not contradict the civil law. According to Polly Ha, the Reformed Church Government refuted this claiming that the bishops had been enforcing canon law for 1500 years.
The Book of Concord is the historic doctrinal statement of the Lutheran Church, consisting of ten credal documents recognized as authoritative in Lutheranism since the 16th century. However, the Book of Concord is a confessional document (stating orthodox belief) rather than a book of ecclesiastical rules or discipline, like canon law. Each Lutheran national church establishes its own system of church order and discipline, though these are referred to as "canons."
The Book of Discipline contains the laws, rules, policies, and guidelines for The United Methodist Church. Its last edition was published in 2016.

</doc>
<doc id="6501" url="https://en.wikipedia.org/wiki?curid=6501" title="Columbanus">
Columbanus

Columbanus (, 540 – 21 November 615) was an Irish missionary notable for founding a number of monasteries after 590 in the Frankish and Lombard kingdoms, most notably Luxeuil Abbey in present-day France and Bobbio Abbey in present-day Italy. 
Columbanus taught an Irish monastic rule and penitential practices for those repenting of sins, which emphasised private confession to a priest, followed by penances levied by the priest in reparation for the sins. Columbanus is one of the earliest identifiable Hiberno-Latin writers.
Most of what we know about Columbanus is based on Columbanus' own works (as far as they have been preserved) and Jonas of Susa's "Vita Columbani" ("Life of Columbanus"), which was written between 639 and 641. 
Jonas entered Bobbio after Columbanus' death but relied on reports of monks who still knew Columbanus. A description of miracles of Columbanus written by an anonymous monk of Bobbio is of much later date. In the second volume of his "Acta Sanctorum O.S.B.", Mabillon gives the life in full, together with an appendix on the miracles of the saint, written by an anonymous member of the Bobbio community.
Columbanus (the Latinised form of "Columbán", meaning "the white dove") was born in the Kingdom of Meath, now part of Leinster, in Ireland in 540, the year Saint Benedict died at Monte Cassino. Prior to his birth, his mother was said to have had visions of bearing a child who, in the judgment of those interpreting the visions, would become a "remarkable genius". Columbanus was well-educated in the areas of grammar, rhetoric, geometry, and the Holy Scriptures.
Columbanus left home to study under Sinell, Abbot of Cleenish in Lough Erne. Under Sinell's instruction, Columbanus composed a commentary on the Psalms. He then moved to Bangor Abbey on the coast of Down, where Saint Comgall was serving as the abbot. He stayed at Bangor until his fortieth year, when he received Comgall's permission to travel to the continent.
Columbanus gathered twelve companions for his journey—Saint Attala, Columbanus the Younger, Cummain, Domgal (Deicolus), Eogain, Eunan, Saint Gall, Gurgano, Libran, Lua, Sigisbert, and Waldoleno—and together they set sail for the continent. After a brief stop in Britain, most likely on the Scottish coast, they crossed the channel and landed in Brittany in 585. 
At Saint-Malo in Brittany, there is a granite cross bearing the saint's name to which people once came to pray for rain in times of drought. The nearby village of Saint-Coulomb commemorates him in name.
Columbanus and his companions were received with favour by King Gontram of Burgundy, and soon they made their way to Annegray, where they founded a monastery in an abandoned Roman fortress. Despite its remote location in the Vosges Mountains, the community became a popular pilgrimage site that attracted so many monastic vocations that two new monasteries had to be formed to accommodate them. 
In 590, Columbanus obtained from King Gontram the Gallo-Roman castle called "Luxovium" in present-day Luxeuil-les-Bains, some eight miles from Annegray. The castle, soon transformed into a monastery, was located in a wild region, thickly covered with pine forests and brushwood. Columbanus erected a third monastery called "Ad-fontanas" at present-day Fontaine-lès-Luxeuil, named for its numerous springs. These monastic communities remained under Columbanus' authority, and their rules of life reflected the Irish tradition in which he had been formed. 
As these communities expanded and drew more pilgrims, Columbanus sought greater solitude, spending periods of time in a hermitage and communicating with the monks through an intermediary. Often he would withdraw to a cave seven miles away, with a single companion who acted as messenger between himself and his companions.
During his twenty years in Gaul (in present-day France), Columbanus became involved in a dispute with the Frankish bishops who may have feared his growing influence. During the first half of the sixth century, the councils of Gaul had given to bishops absolute authority over religious communities. As heirs to the Irish monastic tradition, Columbanus and his monks used the Irish Easter calculation, a version of Bishop Augustalis's 84-year "computus" for determining the date of Easter (Quartodecimanism), whereas the Franks had adopted the Victorian cycle of 532 years. The bishops objected to the newcomers' continued observance of their own dating, which — among other issues — caused the end of Lent to differ. They also complained about the distinct Irish tonsure. 
In 602, the bishops assembled to judge Columbanus, but he did not appear before them as requested. Instead, he sent a letter to the prelates — a strange mixture of freedom, reverence, and charity — admonishing them to hold synods more frequently, and advising them to pay more attention to matters of equal importance to that of the date of Easter. In defence of his following his traditional paschal cycle, he wrote:
When the bishops refused to abandon the matter, Columbanus, following St Patrick's canon, appealed directly to Pope Gregory I. In the third and only surviving letter, he asks "the holy Pope, his Father" to provide "the strong support of his authority" and to render a "verdict of his favour", apologising for "presuming to argue as it were, with him who sits in the chair of Peter, Apostle and Bearer of the Keys". None of the letters were answered, most likely due to the pope's death in 604. 
Columbanus then sent a letter to Gregory's successor, Pope Boniface IV, asking him to confirm the tradition of his elders — if it is not contrary to the Faith — so 
that he and his monks could follow the rites of their ancestors. Before Boniface responded, Columbanus moved outside the jurisdiction of the Frankish bishops. As the Easter issue appears to end around that time, Columbanus may have stopped celebrating Irish date of Easter after moving to Italy.
Columbanus was also involved in a dispute with members of the Frankish royal family. Upon the death of King Gontram of Burgundy, the succession passed to his nephew, Childebert II, the son of his brother Sigebert and Sigebert's wife Brunhilda of Austrasia. When Childebert II died, he left two sons, Theuderic II who inherited the Kingdom of Burgundy, and Theudebert II who inherited the Kingdom of Austrasia. As both were minors, Brunhilda, their grandmother, declared herself their guardian and controlled the governments of the two kingdoms.
Theuderic II venerated Columbanus and often visited him, but the saint admonished and rebuked him for his behaviour. When Theuderic began living with a mistress, the saint objected, earning the displeasure of Brunhilda, who thought a royal marriage would threaten her own power. Columbanus
did not spare the demoralised court, and Brunhilda became his bitterest foe. Angered by 
Columbanus's stance, Brunhilda stirred up the bishops and nobles to find fault with his monastic rules. When Theuderic II finally confronted Columbanus at Luxeuil, ordering him to conform to the country's conventions, the saint refused and was then taken prisoner to Besançon.
Columbanus managed to escape his captors and returned to his monastery at Luxeuil. When the king and his grandmother found out, they sent soldiers to drive him back to Ireland by force, separating him from his monks by insisting that only those from Ireland could accompany him into exile.
Columbanus was taken to Nevers, then travelled by boat down the Loire river to the coast. At Tours he visited the tomb of Saint Martin, and sent a message to Theuderic II indicating that within three years he and his children would perish. When he arrived at Nantes, he wrote a letter before embarkation to his fellow monks at Luxeuil monastery.
The letter urged his brethren to obey Attala, who stayed behind as abbot of the monastic community. 
The letter concludes:
Soon after the ship set sail from Nantes, a severe storm drove the vessel back ashore. Convinced that his holy passenger caused the tempest, the captain refused further attempts to transport the monk. Columbanus made his way across Gaul to visit King Chlothar II of Neustria at Soissons where he was gladly received. Despite the king's offers to stay in his kingdom, Columbanus left Neustria in 611 for the court of King Theudebert II of Austrasia in the northeastern part of the Kingdom of the Merovingian Franks.
Columbanus travelled to Metz, where he received an honourable welcome, and then proceeding to Mainz, where he sailed upwards the Rhine river to the lands of the Suebi and Alemanni in the northern Alps, intending to preach the Gospel to these people. He followed the Rhine river and its tributaries, the Aar and the Limmat, and then on to Lake Zurich. Columbanus chose the village of Tuggen as his initial community, but the work was not successful. He continued north-east by way of Arbon to Bregenz on Lake Constance. Here the saint found an oratory dedicated to Saint Aurelia containing three brass images of their tutelary deities. Columbanus commanded Gallus, who knew the local language, to preach to the inhabitants, and many were converted. The three brass images were destroyed, and Columbanus blessed the little church, placing the relics of Saint Aurelia beneath the altar. A monastery was erected, Mehrerau Abbey, and the brethren observed their regular life. Columbanus stayed in Bregenz for about one year. Following an uprising against the community, possibly related to that region being taken over by the saint's old enemy King Theuderic II, Columbanus resolved to cross the Alps into Italy. Gallus remained in this area and died there 646. About seventy years later at the place of Gallus' cell the Monastery of Saint Gall was founded, which in itself was the origin of the city of St. Gallen again about another three hundred years later.
Columbanus arrived in Milan in 612 and was warmly greeted by King Agilulf and Queen Theodelinda of the Lombards. He immediately began refuting the teachings of Arianism, which had enjoyed a degree of acceptance in Italy. He wrote a treatise against Arianism, which has since been lost. Queen Theodelinda, the devout daughter of Duke Garibald I of Bavaria, played an important role in restoring Nicene Christianity to a position of primacy against Arianism, and was largely responsible for the king's conversion to Christianity.
At the king's request, Columbanus wrote a letter to Pope Boniface IV on the controversy over the "Three Chapters"—writings by Syrian bishops suspected of Nestorianism, which had been condemned in the fifth century as heresy. Pope Gregory I had tolerated in Lombardy those persons who defended the "Three Letters", among them King Agilulf. Columbanus agreed to take up the issue on behalf of the king. The letter begins with an apology that a "foolish Scot ("Scottus", Irishman)" would be writing for a Lombard king. After acquainting the pope with the imputations brought against him, he entreats the pontiff to prove his orthodoxy and assemble a council. He writes that his freedom of speech is consistent with the custom of his country. Some of the language used in the letter might now be regarded as disrespectful, but in that time, faith and austerity could be more indulgent. At the same time, the letter expresses the most affectionate and impassioned devotion to the Holy See.
If Columbanus' zeal for orthodoxy caused him to overstep the limits of discretion, his real attitude towards Rome is sufficiently clear, calling the pope "his Lord and Father in Christ", the "Chosen Watchman", and the "First Pastor, set higher than all mortals".
King Agilulf gave Columbanus a tract of land called Bobbio between Milan and Genoa near the Trebbia river, situated in a defile of the Apennine Mountains, to be used as a base for the conversion of the Lombard people. The area contained a ruined church and wastelands known as "Ebovium", which had formed part of the lands of the papacy prior to the Lombard invasion. Columbanus wanted this secluded place, for while enthusiastic in the instruction of the Lombards he preferred solitude for his monks and himself. Next to the little church, which was dedicated to Saint Peter, Columbanus erected a monastery in 614. Bobbio Abbey at its foundation followed the Rule of Saint Columbanus, based on the monastic practices of Celtic Christianity. For centuries it remained the stronghold of orthodoxy in northern Italy.
During the last year of his life, Columbanus received messenges from King Chlothar II, inviting the saint to return to Burgundy, now that his enemies were dead. Columbanus did not return, but requested that the king should always protect his monks at Luxeuil Abbey. He prepared for death by retiring to his cave on the mountainside overlooking the Trebbia river, where, according to a tradition, he had dedicated an oratory to Our Lady. Columbanus died at Bobbio on 21 November 615.
The Rule of Saint Columbanus embodied the customs of Bangor Abbey and other Irish monasteries. Much shorter than the Rule of Saint Benedict, the Rule of Saint Columbanus consists of ten chapters, on the subjects of obedience, silence, food, poverty, humility, chastity, choir offices, discretion, mortification, and perfection.
In the first chapter, Columbanus introduces the great principle of his Rule: obedience, absolute and unreserved. The words of seniors should always be obeyed, just as "Christ obeyed the Father up to death for us." One manifestation of this obedience was constant hard labour designed to subdue the flesh, exercise the will in daily self-denial, and set an example of industry in cultivation of the soil. The least deviation from the Rule entailed corporal punishment, or a severe form of fasting. In the second chapter, Columbanus instructs that the rule of silence be "carefully observed", since it is written: "But the nurture of righteousness is silence and peace". He also warns, "Justly will they be damned who would not say just things when they could, but preferred to say with garrulous loquacity what is evil ..." In the third chapter, Columbanus instructs, "Let the monks' food be poor and taken in the evening, such as to avoid repletion, and their drink such as to avoid intoxication, so that it may both maintain life and not harm ..." Columbanus continues:
In the fourth chapter, Columbanus presents the virtue of poverty and of overcoming greed, and that monks should be satisfied with "small possessions of utter need, knowing that greed is a leprosy for monks". Columbanus also instructs that "nakedness and disdain of riches are the first perfection of monks, but the second is the purging of vices, the third the most perfect and perpetual love of God and unceasing affection for things divine, which follows on the forgetfulness of earthly things. Since this is so, we have need of few things, according to the word of the Lord, or even of one." In the fifth chapter, Columbanus warns against vanity, reminding the monks of Jesus' warning in Luke 16:15: "You are the ones who justify yourselves in the eyes of others, but God knows your hearts. What people value highly is detestable in God's sight." In the sixth chapter, Columbanus instructs that "a monk's chastity is indeed judged in his thoughts" and warns, "What profit is it if he be virgin in body, if he be not virgin in mind? For God, being Spirit."
In the seventh chapter, Columbanus instituted a service of perpetual prayer, known as "laus perennis", by which choir succeeded choir, both day and night. In the eighth chapter, Columbanus stresses the importance of discretion in the lives of monks to avoid "the downfall of some, who beginning without discretion and passing their time without a sobering knowledge, have been unable to complete a praiseworthy life." Monks are instructed to pray to God for to "illumine this way, surrounded on every side by the world's thickest darkness". Columbanus continues: 
In the ninth chapter, Columbanus presents mortification as an essential element in the lives of monks, who are instructed, "Do nothing without counsel." Monks are warned to "beware of a proud independence, and learn true lowliness as they obey without murmuring and hesitation." According to the Rule, there are three components to mortification: "not to disagree in mind, not to speak as one pleases with the tongue, not to go anywhere with complete freedom." This mirrors the words of Jesus, "For I have come down from heaven not to do my will but to do the will of him who sent me." (John 6:38) In the tenth and final chapter, Columbanus regulates forms of penance (often corporal) for offences, and it is here that the Rule of Saint Columbanus differs significantly from that of Saint Benedict.
The Communal Rule of Columbanus required monks to fast every day until "None" or 3 p.m., this was later relaxed and observed on designated days. Columbanus' Rule regarding diet was very strict. Monks were to eat a limited diet of beans, vegetables, flour mixed with water and small bread of a loaf, taken in the evenings.
The habit of the monks consisted of a tunic of undyed wool, over which was worn the cuculla, or cowl, of the same material. A great deal of time was devoted to various kinds of manual labour, not unlike the life in monasteries of other rules. The Rule of Saint Columbanus was approved of by the Fourth Council of Mâcon in 627, but it was superseded at the close of the century by the Rule of Saint Benedict. For several centuries in some of the greater monasteries the two rules were observed conjointly.
Columbanus did not lead a perfect life. According to Jonas and other sources, he could be impetuous and even headstrong, for by nature he was eager, passionate, and dauntless. These qualities were both the source of his power and the cause of his mistakes. His virtues, however, were quite remarkable. Like many saints, he had a great love for God's creatures. Stories claim that as he walked in the woods, it was not uncommon for birds to land on his shoulders to be caressed, or for squirrels to run down from the trees and nestle in the folds of his cowl. Although a strong defender of Irish traditions, he never wavered in showing deep respect for the Holy See as the supreme authority. His influence in Europe was due to the conversions he effected and to the rule that he composed. It may be that the example and success of Saint Columba in Caledonia inspired him to similar exertions. The life of Columbanus stands as the prototype of missionary activity in Europe, followed by such men as Saint Kilian, Vergilius of Salzburg, Donatus of Fiesole, Wilfrid, Willibrord, Suitbert of Kaiserwerdt, Saint Boniface, and Ursicinus of Saint-Ursanne.
The following are the principal miracles attributed to his intercession:
Jonas relates the occurrence of a miracle during Columbanus' time in Bregenz, when that region was experiencing a period of severe famine.
Historian, Alexander O'Hara states Columbanus had a "very strong sense of Irish identity...He’s the first person to write about Irish identity, he’s the first Irish person that we have a body of literary work from, so even on that point of view he’s very important in terms of Irish identity." In 1950 a congress celebrating the 1400 anniversary of his birth took place in Luxeuil, France. It was attended by Robert Schuman, Sean MacBride, future Pope John XXIII and John A. Costello who said "All statesmen of today might well turn their thoughts to St Columban and his teaching. History records that it was by men like him that civilisation was saved in the 6th century."
Columbanus is also remembered as the first Irish person to be the subject of a biography. An Italian monk named Jonas of Bobbio wrote a biography of him some 20 years after Columbanus’ death. His use of the phrase in 600 AD totius Europae (all of Europe) in a letter to Pope Gregory the Great is the first known use of the expression.
In France, the ruins of Columbanus' first monastery at Annegray are legally protected through the efforts of the Association Internationale des Amis de St Columban, which purchased the site in 1959. The association also owns and protects the site containing the cave, which acted as Columbanus' cell, and the holy well, which he created nearby. At Luxeuil-les-Bains, the Basilica of Saint Peter stands on the site of Columbanus' first church. A statue near the entrance, unveiled in 1947, shows him denouncing the immoral life of King Theuderic II. Formally an abbey church, the basilica contains old monastic buildings, which have been used as a minor seminary since the nineteenth century. It is dedicated to Columbanus and houses a bronze statue of him in its courtyard.
In Lombardy, San Colombano al Lambro in Milan, San Colombano Belmonte in Turin, and San Colombano Certénoli in Genoa all take their names from the saint. The last monastery erected by Columbanus at Bobbio remained for centuries the stronghold of orthodoxy in northern Italy.
If Bobbio Abbey in Italy became a citadel of faith and learning, Luxeuil Abbey in France became the "nursery of saints and apostles". The monastery produced sixty-three apostles who carried his rule, together with the Gospel, into France, Germany, Switzerland, and Italy. These disciples of Columbanus are accredited with founding over one hundred different monasteries. The canton and town still bearing the name of St. Gallen testify to how well one of his disciples succeeded.
The Missionary Society of Saint Columban, founded in 1916, and the Missionary Sisters of St. Columban, founded in 1924, are both dedicated to Columbanus.
The remains of Columbanus are preserved in the crypt at Bobbio Abbey. Many miracles have been credited to his intercession. In 1482, the relics were placed in a new shrine and laid beneath the altar of the crypt. The sacristy at Bobbio possesses a portion of the skull of the saint, his knife, wooden cup, bell, and an ancient water vessel, formerly containing sacred relics and said to have been given to him by Pope Gregory I. According to some authorities, twelve teeth of the saint were taken from the tomb in the fifteenth century and kept in the treasury, but these have since disappeared.
Columbanus is named in the Roman Martyrology on 23 November, which is his feast day in Ireland. His feast is observed by the Benedictines on 21 November. Columbanus is the patron saint of motorcyclists. In art, Columbanus is represented bearded bearing the monastic cowl, holding in his hand a book with an Irish satchel, and standing in the midst of wolves. Sometimes he is depicted in the attitude of taming a bear, or with sun-beams over his head.

</doc>
<doc id="6503" url="https://en.wikipedia.org/wiki?curid=6503" title="Concord, New Hampshire">
Concord, New Hampshire

Concord () is the capital city of the U.S. state of New Hampshire and the county seat of Merrimack County. As of the 2010 census, its population was 42,695, and in 2019 the population was an estimated 43,627.
The village of Penacook, where Concord was initially settled, lies at the northern boundary of the city limits. The city is home to the University of New Hampshire School of Law, New Hampshire's only law school; St. Paul's School, a private preparatory school; NHTI, a two-year community college; the New Hampshire Police Academy; and the New Hampshire Fire Academy. It is the resting place of Franklin Pierce, 14th President of the United States.
The area that would become Concord was originally settled thousands of years ago by Abenaki Native Americans called the Pennacook. The tribe fished for migrating salmon, sturgeon, and alewives with nets strung across the rapids of the Merrimack River. The stream was also the transportation route for their birch bark canoes, which could travel from Lake Winnipesaukee to the Atlantic Ocean. The broad sweep of the Merrimack River valley floodplain provided good soil for farming beans, gourds, pumpkins, melons and maize.
The area was first settled in 1659 as "Penacook". On January 17, 1725, the Province of Massachusetts Bay, which then claimed territories west of the Merrimack River, granted the Concord area as the Plantation of Penacook. It was settled between 1725 and 1727 by Captain Ebenezer Eastman and others from Haverhill, Massachusetts. On February 9, 1734, the town was incorporated as "Rumford", from which Sir Benjamin Thompson, Count Rumford would take his title. It was renamed "Concord" in 1765 by Governor Benning Wentworth following a bitter boundary dispute between Rumford and the town of Bow; the city name was meant to reflect the new concord, or harmony, between the disputant towns. Citizens displaced by the resulting border adjustment were given land elsewhere as compensation. In 1779, New Pennacook Plantation was granted to Timothy Walker Jr. and his associates at what would be incorporated in 1800 as Rumford, Maine, the site of Pennacook Falls.
Concord grew in prominence throughout the 18th century, and some of the earliest houses from this period survive at the northern end of Main Street. In the years following the Revolution, Concord's central geographical location made it a logical choice for the state capital, particularly after Samuel Blodget in 1807 opened a canal and lock system to allow vessels passage around the Amoskeag Falls downriver, connecting Concord with Boston by way of the Middlesex Canal. In 1808, Concord was named the official seat of state government. The 1819 State House is the oldest capitol in the nation in which the state's legislative branches meet in their original chambers. The city would become noted for furniture-making and granite quarrying. In 1828, Lewis Downing joined J. Stephens Abbot to form Abbot and Downing. Their most famous product was their Concord coach, widely used in the development of the American West. In the 19th century, Concord became a hub for the railroad industry, with Penacook a textile manufacturing center using water power from the Contoocook River. Today, the city is a center for health care and several insurance companies.
Concord is located at (43.2070, −71.5371).
According to the United States Census Bureau, the city has a total area of . of it is land and of it is water, comprising 4.79% of the city. Concord is drained by the Merrimack River. Penacook Lake is in the west. The highest point in Concord is above sea level on Oak Hill, just west of the hill's summit in neighboring Loudon.
Concord lies fully within the Merrimack River watershed, and is centered on the river, which runs from northwest to southeast through the city. Downtown is located on a low terrace to the west of the river, with residential neighborhoods climbing hills to the west and extending southwards towards the town of Bow. To the east of the Merrimack, atop a bluff, is a flat, sandy plain known as Concord Heights, which has seen most of the city's commercial development since 1960. The eastern boundary of Concord (with the town of Pembroke) is formed by the Soucook River, a tributary of the Merrimack. The Turkey River winds through the southwestern quarter of the city, passing through the campus of St. Paul's School before entering the Merrimack River in Bow. In the northern part of the city, the Contoocook River enters the Merrimack at the village of Penacook.
It is north of Manchester, New Hampshire's largest city, and north of Boston.
The city of Concord is made up of the five distinct villages of Penacook, Concord Heights, East Concord, West Concord, and the downtown neighborhoods referred to as the North End and the South End.
Concord, as with much of New England, is within the humid continental climate zone (Köppen "Dfb"), with long, cold, snowy winters, very warm (and at times humid) summers, and relatively brief autumns and springs. In winter, successive storms deliver light to moderate snowfall amounts, contributing to the relatively reliable snow cover. In addition, lows reach at least on an average 15 nights per year, and the city straddles the border between USDA Hardiness Zone 5b and 6a. However, thaws are frequent, with one to three days per month with + highs from December to February. Summer can bring stretches of humid conditions as well as thunderstorms, and there is an average of 12 days of + highs annually. The window for freezing temperatures on average begins on September 27 and expires on May 14.
The monthly daily average temperature range from in January to in July. Temperature extremes have ranged from in February 1943 to in July 1966.
As of the census of 2010, there were 42,695 people, 17,592 households, and 10,052 families residing in the city. The population density was 632.5 people per square mile (244.2/km). There were 18,852 housing units at an average density of 293.2 per square mile (113.2/km). The racial makeup of the city was 91.8% White, 2.2% Black or African American, 0.3% Native American, 3.4% Asian, 0.0% Pacific Islander, 0.4% from some other race, and 1.8% from two or more races. 2.1% of the population were Hispanic or Latino of any race.
There were 17,592 households, out of which 28.7% had children under the age of 18 living with them, 41.3% were headed by married couples living together, 11.6% had a female householder with no husband present, and 42.9% were non-families. 33.6% of all households were made up of individuals, and 12.0% were someone living alone who was 65 years of age or older. The average household size was 2.26, and the average family size was 2.90.
In the city, the population was spread out, with 20.7% under the age of 18, 9.3% from 18 to 24, 28.0% from 25 to 44, 28.2% from 45 to 64, and 13.8% who were 65 years of age or older. The median age was 39.4 years. For every 100 females, there were 98.5 males. For every 100 females age 18 and over, there were 96.9 males.
For the period 2009–11, the estimated median annual income for a household in the city was $52,695, and the median income for a family was $73,457. Male full-time workers had a median income of $49,228 versus $38,782 for females. The per capita income for the city was $29,296. About 5.5% of families and 10.1% of the population were below the poverty line, including 8.4% of those under age 18 and 5.5% of those age 65 or over.
In 2019, according to Concord's 2019 Comprehensive Annual Financial Report, the top employers in the city were:
Interstate 89 and Interstate 93 are the two main interstate highways serving Concord, and join just south of the city limits. Interstate 89 links Concord with Lebanon and the state of Vermont to the northwest, while Interstate 93 connects the city to Plymouth, Littleton, and the White Mountains to the north and Manchester and Boston to the south. Interstate 393 is a spur highway leading east from Concord and merging with U.S. Route 4 as a direct route to New Hampshire's Seacoast region. North-south U.S. Route 3 serves as Concord's Main Street, while U.S. Route 202 and New Hampshire Route 9 cross the city from east to west. State routes 13 and 132 also serve the city: Route 13 leads southwest out of Concord towards Goffstown and Milford, while Route 132 travels north parallel to Interstate 93. New Hampshire Route 106 passes through the easternmost part of Concord, crossing I-393 and NH 9 before crossing the Soucook River south into the town of Pembroke. To the north, NH 106 leads to Loudon, Belmont, and Laconia.
Local bus service is provided by Concord Area Transit (CAT), with three routes through the city. Regional bus service provided by Concord Coach Lines and Greyhound Lines is available from the Concord Transportation Center at 30 Stickney Avenue next to Exit 14 on Interstate 93, with service south to Boston and points in between, as well as north to Littleton and northeast to Berlin.
There is no passenger rail service to Concord.
General aviation services are available through Concord Municipal Airport, located east of downtown. There is no commercial air service within the city limits; the nearest such airport is Manchester–Boston Regional Airport, located to the south.
Concord is governed via the council-manager system. The city council consists of 14 members, ten of which are elected from single-member wards, while the other four are elected at large. The mayor is elected directly every two years. The current mayor is Jim Bouley.
According to the Concord city charter, the mayor chairs the council (composed of 15 members, including the mayor). However, the mayor has very few formal powers over the day-to-day management of the city. The actual operations of the city are overseen by the city manager, currently Thomas J. Aspell, Jr. The current police chief is Bradley S. Osgood.
In the New Hampshire Senate, Concord is in the 15th District, represented by Democrat Dan Feltes. On the New Hampshire Executive Council, Concord is in the 2nd District, represented by Democrat Andru Volinsky. In the United States House of Representatives, Concord is in New Hampshire's 2nd congressional district, represented by Democrat Ann McLane Kuster.
New Hampshire Department of Corrections operates the New Hampshire State Prison for Men and New Hampshire State Prison for Women in Concord.
Newspapers
Radio
The city is otherwise served by . New Hampshire Public Radio is headquartered in Concord.
Television
The New Hampshire State House, designed by architect Stuart Park and constructed between 1815 and 1818, is the oldest state house in which the legislature meets in its original chambers. The building was remodeled in 1866, and the third story and west wing were added in 1910.
Across from the State House is the Eagle Hotel on Main Street, which has been a downtown landmark since its opening in 1827. U.S. Presidents Ulysses S. Grant, Rutherford Hayes, and Benjamin Harrison all dined there, and Franklin Pierce spent the night before departing for his inauguration. Other well-known guests included Jefferson Davis, Charles Lindbergh, Eleanor Roosevelt, Richard M. Nixon (who carried New Hampshire in all three of his presidential bids), and Thomas E. Dewey. The hotel closed in 1961.
South from the Eagle Hotel on Main Street is Phenix Hall, which replaced "Old" Phenix Hall, which burned in 1893. Both the old and new buildings featured multi-purpose auditoriums used for political speeches, theater productions, and fairs. Abraham Lincoln spoke at the old hall in 1860; Theodore Roosevelt, at the new hall in 1912.
North on Main Street is the Walker-Woodman House, also known as the Reverend Timothy Walker House, the oldest standing two-story house in Concord. It was built for the Reverend Timothy Walker between 1733 and 1735.
On the north end of Main Street is the Pierce Manse, in which President Franklin Pierce lived in Concord before and following his presidency. The mid-1830s Greek Revival house was moved from Montgomery Street to North Main Street in 1971 to prevent its demolition.
Beaver Meadow Golf Course, located in the northern part of Concord, is one of the oldest golf courses in New England. Besides this golf course, other important sporting venues in Concord include Everett Arena and Memorial Field.
The SNOB (Somewhat North Of Boston) Film Festival, started in the fall of 2002, brings independent films and filmmakers to Concord and has provided an outlet for local filmmakers to display their films. SNOB Film Festival was a catalyst for the building of Red River Theatres, a locally owned, nonprofit, independent cinema in 2007. The SNOB Film Festival is one of the many arts organizations in the city.
Other sites of interest include the Capitol Center for the Arts, the New Hampshire Historical Society, which has two facilities in Concord, and the McAuliffe-Shepard Discovery Center, a science museum named after Christa McAuliffe, the Concord teacher who died during the Space Shuttle Challenger disaster in 1986, and Alan Shepard, the Derry-born astronaut who was the second person and first American in space as well as the fifth and oldest person to walk on the Moon.
Concord's public schools are within the Concord School District, except for schools in the Penacook area of the city, which are within the Merrimack Valley School District, a district which also includes several towns north of Concord. The only public high school in the Concord School District is Concord High School, which has about 2,000 students. The only public middle school in the Concord School District is Rundlett Middle School, which has roughly 1,500 students. Concord School District's elementary schools underwent a major re-configuration in 2012, with three newly constructed schools opening and replacing six previous schools. Kimball School and Walker School were replaced by Christa McAuliffe School on the Kimball School site, Conant School (and Rumford School, which closed a year earlier) were replaced by Abbot-Downing School at the Conant site, and Eastman and Dame schools were replaced by Mill Brook School, serving kindergarten through grade two, located next to Broken Ground Elementary School, serving grades three to five. Beaver Meadow School, the remaining elementary school, was unaffected by the changes.
Concord schools in the Merrimack Valley School District include Merrimack Valley High School and Merrimack Valley Middle School, which are adjacent to each other and to Rolfe Park in Penacook village, and Penacook Elementary School, just south of the village.
Concord has two parochial schools, Bishop Brady High School and Saint John Regional School.
Other area private schools include Concord Christian Academy, Parker Academy, Trinity Christian School, Shaker Road School, and St. Paul's School.
Concord is also home to NHTI, Concord's Community College, Granite State College, the University of New Hampshire School of Law, and the Franklin Pierce University Doctorate of Physical Therapy program.

</doc>
<doc id="6505" url="https://en.wikipedia.org/wiki?curid=6505" title="Chlorophyceae">
Chlorophyceae

The Chlorophyceae are one of the classes of green algae, distinguished mainly on the basis of ultrastructural morphology. For example, the chlorophycean CW clade, and chlorophycean DO clade, are defined by the arrangement of their flagella. Members of the CW clade have flagella that are displaced in a "clockwise" (CW, 1–7 o'clock) direction e.g. Chlamydomonadales. Members of the DO clade have flagella that are "directly opposed" (DO, 12–6 o'clock) e.g. Sphaeropleales. They are usually green due to the dominance of pigments chlorophyll a and chlorophyll b. The chloroplast may be discoid, plate-like, reticulate, cup-shaped, spiral or ribbon shaped in different species. Most of the members have one or more storage bodies called pyrenoids located in the chloroplast. Pyrenoids contain protein besides starch. Some algae may store food in the form of oil droplets. Green algae usually have a rigid cell wall made up of an inner layer of cellulose and outer layer of pectose.
Vegetative reproduction usually takes place by fragmentation. Asexual reproduction is by flagellated zoospores. And haplospore, perrination (akinate and palmellastage). Asexual reproduction by mytospore absent in spyrogyra.
Sexual reproduction shows considerable variation in the type and formation of sex cells and it may be isogamous e.g. "Chlamydomonas, Ulothrix, Spirogyra", anisogamous e.g. "Chlamydomonas, Eudorina" or Oogamous e.g. "Chlamydomonas, Volvox". "Chlamydomonas" has all three types of sexual reproduction.
They share many similarities with the higher plants, including the presence of asymmetrical flagellated cells, the breakdown of the nuclear envelope at mitosis, and the presence of phytochromes, flavonoids, and the chemical precursors to the cuticle.
The sole method of reproduction is asexual and azosporic. The content of the cell divide into 2,4 (B), 8(C) sometimes daughter protoplasts. Each daughter protoplast rounds off to form a non-motile spore. These autospores (spores having the same distinctive shape as the parent cell) are liberated by the rupture of the parent cell wall (D). On release each autospore grows to become a new individual. the presence of sulphur in the culture medium is considered essential for cell division. it takes place even in the dark with sulphur alone as the source material but under light conditions nitrogen also required in addition. Pearsal and Loose (1937) reported the occurrence of motile cells in "Chlorella". Bendix (1964) also observed that "Chlorella" produces motile cells which might be gametes. These observations have an important bearing on the concept of the life cycle of "Chlorella," which at present is considered to be strictly asexual in character.
Asexual reproduction in "Chlorella ellipsoides" has been studied in detail and the following four phases have been observed during the asexual reproduction.
(i) Growth Phase- During this phase the cells grow in size by utilizing the photosynthetic products.
(ii) Ripening phase- In this phase the cells mature and prepare themselves for division.
(iii) Post ripening phase- During this phase, each mature cell divides twice either in dark or in light. The cells formed in dark are known as dark to light phase, cells again grow in size.
(iv) Division Phase- During this phase the parent cell wall ruptures and unicells are released.
The following orders are typically recognised:
In older classifications, the term Chlorophyceae is sometimes used to apply to all the green algae except the Charales, and the internal division is considerably different.
The Orders of the Chlorophyceae as listed by: in Hoek, Mann and Jahns (1995)

</doc>
<doc id="6508" url="https://en.wikipedia.org/wiki?curid=6508" title="Cyril">
Cyril

Cyril (also Cyrillus or Cyryl) or (Sirīl) is a masculine given name. It is derived from the Greek name Κύριλλος ("Kýrillos") meaning "Lordly, Masterful", which in turn derives from Greek κυριος ("kýrios") "lord". There are various variant forms of the Cyril name such as Cyrill, Cyrille, Ciril, Kirill, Kiryl, Kirillos, Kuriakose, Kyrylo, Kiril, Kiro and Kyrill.
It may also refer to:

</doc>
<doc id="6511" url="https://en.wikipedia.org/wiki?curid=6511" title="Computational complexity">
Computational complexity

In computer science, the computational complexity or simply complexity of an algorithm is the amount of resources required to run it. Particular focus is given to time and memory requirements.
As the amount of resources required to run an algorithm generally varies with the size of the input, the complexity is typically expressed as a function , where is the size of the input and is either the worst-case complexity (the maximum of the amount of resources that are needed over all inputs of size ) or the average-case complexity (the average of the amount of resources over all inputs of size ). Time complexity is generally expressed as the number of required elementary operations on an input of size , where elementary operations are assumed to take a constant amount of time on a given computer and change only by a constant factor when run on a different computer. Space complexity is generally expressed as the amount of memory required by an algorithm on an input of size .
The study of the complexity of explicitly given algorithms is called analysis of algorithms, while the study of the complexity of problems is called computational complexity theory. Both areas are highly related, as the complexity of an algorithm is always an upper bound on the complexity of the problem solved by this algorithm.
The resource that is most commonly considered is time. When "complexity" is used without qualification, this generally means time complexity.
The usual units of time (seconds, minutes etc.) are not used in complexity theory because they are too dependent on the choice of a specific computer and on the evolution of technology. For instance, a computer today can execute an algorithm significantly faster than a computer from the 1960s; however, this is not an intrinsic feature of the algorithm but rather a consequence of technological advances in computer hardware. Complexity theory seeks to quantify the intrinsic time requirements of algorithms, that is, the basic time constraints an algorithm would place on "any" computer. This is achieved by counting the number of "elementary operations" that are executed during the computation. These operations are assumed to take constant time (that is, not affected by the size of the input) on a given machine, and are often called "steps".
Another important resource is the size of computer memory that is needed for running algorithms.
The number of arithmetic operations is another resource that is commonly used. In this case, one talks of arithmetic complexity. If one knows an upper bound on the size of the binary representation of the numbers that occur during a computation, the time complexity is generally the product of the arithmetic complexity by a constant factor.
For many algorithms the size of the integers that are used during a computation is not bounded, and it is not realistic to consider that arithmetic operations take a constant time. Therefore, the time complexity, generally called bit complexity in this context, may be much larger than the arithmetic complexity. For example, the arithmetic complexity of the computation of the determinant of a integer matrix is formula_1 for the usual algorithms (Gaussian elimination). The bit complexity of the same algorithms is exponential in , because the size of the coefficients may grow exponentially during the computation. On the other hand, if these algorithms are coupled with multi-modular arithmetic, the bit complexity may be reduced to .
In sorting and searching, the resource that is generally considered is the number of entries comparisons. This is generally a good measure of the time complexity if data are suitably organized.
It is impossible to count the number of steps of an algorithm on all possible inputs. As the complexity generally increases with the size of the input, the complexity is typically expressed as a function of the size (in bits) of the input, and therefore, the complexity is a function of . However, the complexity of an algorithm may vary dramatically for different inputs of the same size. Therefore, several complexity functions are commonly used.
The worst-case complexity is the maximum of the complexity over all inputs of size , and the average-case complexity is the average of the complexity over all inputs of size (this makes sense, as the number of possible inputs of a given size is finite). Generally, when "complexity" is used without being further specified, this is the worst-case time complexity that is considered.
It is generally difficult to compute precisely the worst-case and the average-case complexity. In addition, these exact values provide little practical application, as any change of computer or of model of computation would change the complexity somewhat. Moreover, the resource use is not critical for small values of , and this makes that, for small , the ease of implementation is generally more interesting than a good complexity.
For these reasons, one generally focuses on the behavior of the complexity for large , that is on its asymptotic behavior when tends to the infinity. Therefore, the complexity is generally expressed by using big O notation.
For example, the usual algorithm for integer multiplication has a complexity of formula_2 this means that there is a constant formula_3 such that the multiplication of two integers of at most digits may be done in a time less than formula_4 This bound is "sharp" in the sense that the worst-case complexity and the average-case complexity are formula_5 which means that there is a constant formula_6 such that these complexities are larger than formula_7 The radix does not appear in these complexity, as changing of radix changes only the constants formula_3 and formula_9
The evaluation of the complexity relies on the choice of a model of computation, which consists in defining the basic operations that are done in a unit of time. When the model of computation is not explicitly specified, this is generally meant as being multitape Turing machine.
A deterministic model of computation is a model of computation such that the successive states of the machine and the operations to be performed are completely determined by the preceding state. Historically, the first deterministic models were recursive functions, lambda calculus, and Turing machines. The model of Random access machines (also called RAM-machines) is also widely used, as a closer counterpart to real computers.
When the model of computation is not specified, it is generally assumed to be a multitape Turing machine. For most algorithms, the time complexity is the same on multitape Turing machines as on RAM-machines, although some care may be needed in how data is stored in memory to get this equivalence.
In a non-deterministic model of computation, such as non-deterministic Turing machines, some choices may be done at some steps of the computation. In complexity theory, one considers all possible choices simultaneously, and the non-deterministic time complexity is the time needed, when the best choices are always done. In other words, one considers that the computation is done simultaneously on as many (identical) processors as needed, and the non-deterministic computation time is the time spent by the first processor that finishes the computation. This parallelism is partly amenable to quantum computing via superposed entangled states in running specific quantum algorithms, like e.g. Shor's factorization of yet only small integers (: 21 = 3 × 7).
Even when such a computation model is not realistic yet, it has theoretical importance, mostly related to the P = NP problem, which questions the identity of the complexity classes formed by taking "polynomial time" and "non-deterministic polynomial time" as least upper bounds. Simulating an NP-algorithm on a deterministic computer usually takes "exponential time". A problem is in the complexity class NP, if it may be solved in polynomial time on a non-deterministic machine. A problem is NP-complete if, roughly speaking, it is in NP and is not easier than any other NP problem. Many combinatorial problems, such as the Knapsack problem, the travelling salesman problem, and the Boolean satisfiability problem are NP-complete. For all these problems, the best known algorithm has exponential complexity. If any one of these problems could be solved in polynomial time on a deterministic machine, then all NP problems could also be solved in polynomial time, and one would have P = NP. it is generally conjectured that with the practical implication that the worst cases of NP problems are intrinsically difficult to solve, i.e., take longer than any reasonable time span (decades!) for interesting lengths of input.
Parallel and distributed computing consist of splitting computation on several processors, which work simultaneously. The difference between the different model lies mainly in the way of transmitting information between processors. Typically, in parallel computing the data transmission between processors is very fast, while, in distributed computing, the data transmission is done through a network and is therefore much slower.
The time needed for a computation on processors is at least the quotient by of the time needed by a single processor. In fact this theoretically optimal bound can never be reached, because some subtasks cannot be parallelized, and some processors may have to wait a result from another processor.
The main complexity problem is thus to design algorithms such that the product of the computation time by the number of processors is as close as possible to the time needed for the same computation on a single processor.
A quantum computer is a computer whose model of computation is based on quantum mechanics. The Church–Turing thesis applies to quantum computers; that is, every problem that can be solved by a quantum computer can also be solved by a Turing machine. However, some problems may theoretically be solved with a much lower time complexity using a quantum computer rather than a classical computer. This is, for the moment, purely theoretical, as no one knows how to build an efficient quantum computer.
Quantum complexity theory has been developed to study the complexity classes of problems solved using quantum computers. It is used in post-quantum cryptography, which consists of designing cryptographic protocols that are resistant to attacks by quantum computers.
The complexity of a problem is the infimum of the complexities of the algorithms that may solve the problem, including unknown algorithms. Thus the complexity of a problem is not greater than the complexity of any algorithm that solves the problems.
It follows that every complexity that is expressed with big O notation is a complexity of the algorithm as well as of the corresponding problem.
On the other hand, it is generally hard to obtain nontrivial lower bounds for problem complexity, and there are few methods for obtaining such lower bounds.
For solving most problems, it is required to read all input data, which, normally, needs a time proportional to the size of the data. Thus, such problems have a complexity that is at least linear, that is, using big omega notation, a complexity formula_10
The solution of some problems, typically in computer algebra and computational algebraic geometry, may be very large. In such a case, the complexity is lower bounded by the maximal size of the output, since the output must be written. For example, a system of polynomial equations of degree in indeterminates may have up to formula_11 complex solutions, if the number of solutions is finite (this is Bézout's theorem). As these solutions must be written down, the complexity of this problem is formula_12 For this problem, an algorithm of complexity formula_13 is known, which may thus be considered as asymptotically quasi-optimal.
A nonlinear lower bound of formula_14 is known for the number of comparisons needed for a sorting algorithm. Thus the best sorting algorithms are optimal, as their complexity is formula_15 This lower bound results from the fact that there are ways of ordering objects. As each comparison splits in two parts this set of orders, the number of of comparisons that are needed for distinguishing all orders must verify formula_16 which implies formula_17 by Stirling's formula.
A standard method for getting lower bounds of complexity consists of "reducing" a problem to another problem. More precisely, suppose that one may encode a problem of size into a subproblem of size of a problem , and that the complexity of is formula_18 Without loss of generality, one may suppose that the function increases with and has an inverse function . Then the complexity of the problem is formula_19 This is this method that is used for proving that, if P ≠ NP (an unsolved conjecture), the complexity of every NP-complete problem is formula_20 for every positive integer .
Evaluating the complexity of an algorithm is an important part of algorithm design, as this gives useful information on the performance that may be expected.
It is a common misconception that the evaluation of the complexity of algorithms will become less important as a result of Moore's law, which posits the exponential growth of the power of modern computers. This is wrong because this power increase allows working with large input data (big data). For example, when one wants to sort alphabetically a list of a few hundreds of entries, such as the bibliography of a book, any algorithm should work well in less than a second. On the other hand, for a list of a million of entries (the phone numbers of a large town, for example), the elementary algorithms that require formula_21 comparisons would have to do a trillion of comparisons, which would need around three hours at the speed of 10 million of comparisons per second. On the other hand, the quicksort and merge sort require only formula_22 comparisons (as average-case complexity for the former, as worst-case complexity for the latter). For , this gives approximately 30,000,000 comparisons, which would only take 3 seconds at 10 million comparisons per second.
Thus the evaluation of the complexity may allow eliminating many inefficient algorithms before any implementation. This may also be used for tuning complex algorithms without testing all variants. By determining the most costly steps of a complex algorithm, the study of complexity allows also focusing on these steps the effort for improving the efficiency of an implementation.

</doc>
<doc id="6512" url="https://en.wikipedia.org/wiki?curid=6512" title="Coercion">
Coercion

Coercion () is the practice of forcing another party to act in an involuntary manner by use of threats or force. It involves a set of various types of forceful actions that violate the free will of an individual to induce a desired response, for example: a bully demanding lunch money from a student or the student gets beaten. These actions may include extortion, blackmail, torture, threats to induce favors, or even sexual assault. In law, coercion is codified as a duress crime. Such actions are used as leverage, to force the victim to act in a way contrary to their own interests. Coercion may involve the actual infliction of physical pain/injury or psychological harm in order to enhance the credibility of a threat. The threat of further harm may lead to the cooperation or obedience of the person being coerced.
The purpose of coercion is to substitute one's aims to those of the victim. For this reason, many social philosophers have considered coercion as the polar opposite to freedom.
Various forms of coercion are distinguished: first on the basis of the "kind of injury" threatened, second according to its "aims" and "scope", and finally according to its "effects", from which its legal, social, and ethical implications mostly depend.
Physical coercion is the most commonly considered form of coercion, where the content of the conditional threat is the use of force against a victim, their relatives or property. An often used example is "putting a gun to someone's head" ("at gunpoint") or putting a "knife under the throat" ("at knifepoint" or cut-throat) to compel action or the victim gets killed or injured. These are so common that they are also used as metaphors for other forms of coercion.
Armed forces in many countries use firing squads to maintain discipline and intimidate the masses, or opposition, into submission or silent compliance. However, there also are nonphysical forms of coercion, where the threatened injury does not immediately imply the use of force. Byman and Waxman (2000) define coercion as "the use of threatened force, including the limited use of actual force to back up the threat, to induce an adversary to behave differently than it otherwise would." Coercion does not in many cases amount to destruction of property or life since compliance is the goal.
In psychological coercion, the threatened injury regards the victim's relationships with other people. The most obvious example is "blackmail", where the threat consists of the dissemination of damaging information. However, many other types are possible e.g. "emotional blackmail", which typically involves threats of rejection from or disapproval by a peer-group, or creating feelings of guilt/obligation via a display of anger or hurt by someone whom the victim loves or respects. Another example is coercive persuasion.
Psychological coercion – along with the other varieties – was extensively and systematically used by the government of the People's Republic of China during the "Thought Reform" campaign of 1951–1952. The process – carried out partly at "revolutionary universities" and partly within prisons – was investigated and reported upon by Robert Jay Lifton, then Research Professor of Psychiatry at Yale University: see Lifton (1961). The techniques used by the Chinese authorities included a technique derived from standard group psychotherapy, which was aimed at forcing the victims (who were generally intellectuals) to produce detailed and sincere ideological "confessions". For instance, a professor of formal logic called Chin Yueh-lin – who was then regarded as China's leading authority on his subject – was induced to write: "The new philosophy [of Marxism-Leninism], being scientific, is the supreme truth" [Lifton (1961) p. 545].

</doc>
<doc id="6513" url="https://en.wikipedia.org/wiki?curid=6513" title="Client–server model">
Client–server model

Client–server model is a distributed application structure that partitions tasks or workloads between the providers of a resource or service, called servers, and service requesters, called clients. Often clients and servers communicate over a computer network on separate hardware, but both client and server may reside in the same system. A server host runs one or more server programs, which share their resources with clients. A client does not share any of its resources, but it requests content or service from a server. Clients, therefore, initiate communication sessions with servers, which await incoming requests.
Examples of computer applications that use the client-server model are email, network printing, and the World Wide Web.
The "client-server" characteristic describes the relationship of cooperating programs in an application. The server component provides a function or service to one or many clients, which initiate requests for such services.
Servers are classified by the services they provide. For example, a web server serves web pages and a file server serves computer files. A shared resource may be any of the server computer's software and electronic components, from programs and data to processors and storage devices. The sharing of resources of a server constitutes a "service".
Whether a computer is a client, a server, or both, is determined by the nature of the application that requires the service functions. For example, a single computer can run a web servers and file server software at the same time to serve different data to clients making different kinds of requests. Client software can also communicate with server software within the same computer. Communication between servers, such as to synchronize data, is sometimes called "inter-server" or "server-to-server" communication.
In general, a service is an abstraction of computer resources and a client does not have to be concerned with how the server performs while fulfilling the request and delivering the response. The client only has to understand the response based on the well-known application protocol, i.e. the content and the formatting of the data for the requested service.
Clients and servers exchange messages in a request–response messaging pattern. The client sends a request, and the server returns a response. This exchange of messages is an example of inter-process communication. To communicate, the computers must have a common language, and they must follow rules so that both the client and the server know what to expect. The language and rules of communication are defined in a communications protocol. All client-server protocols operate in the application layer. The application layer protocol defines the basic patterns of the dialogue. To formalize the data exchange even further, the server may implement an application programming interface (API). The API is an abstraction layer for accessing a service. By restricting communication to a specific content format, it facilitates parsing. By abstracting access, it facilitates cross-platform data exchange.
A server may receive requests from many distinct clients in a short period of time. A computer can only perform a limited number of tasks at any moment, and relies on a scheduling system to prioritize incoming requests from clients to accommodate them. To prevent abuse and maximize availability, the server software may limit the availability to clients. Denial of service attacks are designed to exploit a server's obligation to process requests by overloading it with excessive request rates.
Encryption should be applied if sensitive information is to be communicated between the client and the server.
When a bank customer accesses online banking services with a web browser (the client), the client initiates a request to the bank's web server. The customer's login credentials may be stored in a database, and the web server accesses the database server as a client. An application server interprets the returned data by applying the bank's business logic, and provides the output to the web server. Finally, the webserver returns the result to the client web browser for display. 
In each step of this sequence of client-server message exchanges, a computer processes a request and returns data. This is the request-response messaging pattern. When all the requests are met, the sequence is complete and the web browser presents the data to the customer.
This example illustrates a design pattern applicable to the client–server model: separation of concerns.
An early form of client-server architecture is remote job entry, dating at least to OS/360 (announced 1964), where the request was to run a job, and the response was the output.
While formulating the client–server model in the 1960s and 1970s, computer scientists building ARPANET (at the Stanford Research Institute) used the terms "server-host" (or "serving host") and "user-host" (or "using-host"), and these appear in the early documents RFC 5 and RFC 4. This usage was continued at Xerox PARC in the mid-1970s.
One context in which researchers used these terms was in the design of a computer network programming language called Decode-Encode Language (DEL). The purpose of this language was to accept commands from one computer (the user-host), which would return status reports to the user as it encoded the commands in network packets. Another DEL-capable computer, the server-host, received the packets, decoded them, and returned formatted data to the user-host. A DEL program on the user-host received the results to present to the user. This is a client-server transaction. Development of DEL was just beginning in 1969, the year that the United States Department of Defense established ARPANET (predecessor of Internet).
"Client-host" and "server-host" have subtly different meanings than "client" and "server". A host is any computer connected to a network. Whereas the words "server" and "client" may refer either to a computer or to a computer program, "server-host" and "user-host" always refer to computers. The host is a versatile, multifunction computer; "clients" and "servers" are just programs that run on a host. In the client-server model, a server is more likely to be devoted to the task of serving.
An early use of the word "client" occurs in "Separating Data from Function in a Distributed File System", a 1978 paper by Xerox PARC computer scientists Howard Sturgis, James Mitchell, and Jay Israel. The authors are careful to define the term for readers, and explain that they use it to distinguish between the user and the user's network node (the client). (By 1992, the word "server" had entered into general parlance.)
The client–server model does not dictate that server-hosts must have more resources than client-hosts. Rather, it enables any general-purpose computer to extend its capabilities by using the shared resources of other hosts. Centralized computing, however, specifically allocates a large amount of resources to a small number of computers. The more computation is offloaded from client-hosts to the central computers, the simpler the client-hosts can be. It relies heavily on network resources (servers and infrastructure) for computation and storage. A diskless node loads even its operating system from the network, and a computer terminal has no operating system at all; it is only an input/output interface to the server. In contrast, a fat client, such as a personal computer, has many resources, and does not rely on a server for essential functions.
As microcomputers decreased in price and increased in power from the 1980s to the late 1990s, many organizations transitioned computation from centralized servers, such as mainframes and minicomputers, to fat clients. This afforded greater, more individualized dominion over computer resources, but complicated information technology management. During the 2000s, web applications matured enough to rival application software developed for a specific microarchitecture. This maturation, more affordable mass storage, and the advent of service-oriented architecture were among the factors that gave rise to the cloud computing trend of the 2010s.
In addition to the client–server model, distributed computing applications often use the peer-to-peer (P2P) application architecture.
In the client–server model, the server is often designed to operate as a centralized system that serves many clients. The computing power, memory and storage requirements of a server must be scaled appropriately to the expected workload. Load-balancing and failover systems are often employed to scale the server beyond a single physical machine.
In a peer-to-peer network, two or more computers ("peers") pool their resources and communicate in a decentralized system. Peers are coequal, or equipotent nodes in a non-hierarchical network. Unlike clients in a client–server or client–queue–client network, peers communicate with each other directly. In peer-to-peer networking, an algorithm in the peer-to-peer communications protocol balances load, and even peers with modest resources can help to share the load. If a node becomes unavailable, its shared resources remain available as long as other peers offer it. Ideally, a peer does not need to achieve high availability because other, redundant peers make up for any resource downtime; as the availability and load capacity of peers change, the protocol reroutes requests.
Both client-server and master-slave are regarded as sub-categories of distributed peer-to-peer systems.

</doc>
<doc id="6514" url="https://en.wikipedia.org/wiki?curid=6514" title="County Dublin">
County Dublin

County Dublin ( or "Contae Átha Cliath") is one of the thirty-two traditional counties of Ireland. Prior to 1994 it was also an administrative county covering the whole county outside of Dublin City Council. In 1994, as part of a reorganisation of local government within Dublin the boundaries of Dublin City were redrawn, Dublin County Council was abolished and three new administrative county councils were established: Dún Laoghaire–Rathdown, Fingal and South Dublin.
While it is no longer used as an administrative division for local government, it retains a strong identity in popular culture. It is in the province of Leinster, and is named after the city of Dublin, the capital city of Ireland. County Dublin was one of the first parts of Ireland to be shired by John, King of England following the Norman invasion of Ireland. 
According to the 2016 census, the total population of County Dublin was 1,345,402, approximately 27% of the Republic of Ireland's population. The county is a NUTS 3 region, and is part of the NUTS 2 region of Eastern and Midland.
There are four local authorities whose remit collectively encompasses the geographic area of the county and city of Dublin. These are Dublin City Council, South Dublin County Council, Dún Laoghaire–Rathdown County Council and Fingal County Council.
Prior to the enactment of the Local Government (Dublin) Act 1993, the county was a unified whole even though it was administered by two local authorities – Dublin County Council and Dublin Corporation. Since the enactment of the Local Government Act 2001 in particular, the geographic area of the county has been divided between three entities at the level of "county" and a further entity at the level of "city". They rank equally as first level local administrative units of the NUTS 3 Dublin Region for Eurostat purposes. There are 34 LAU 1 entities in the Republic of Ireland. Each local authority is responsible for certain local services such as sanitation, planning and development, libraries, the collection of motor taxation, local roads and social housing.
Dublin County Council (which did not include the county borough of Dublin) was abolished in 1994 and the area divided among the administrative counties of Dún Laoghaire–Rathdown, Fingal and South Dublin each with its county seat. To these areas may be added the area of Dublin city which collectively comprise the Dublin Region ("") and come under the remit of the Dublin Regional Authority.
The area lost its administrative county status in 1994, with Section 9 Part 1(a) of the "Local Government (Dublin) Act, 1993" stating that "the county shall cease to exist." In discussing the legislation to dissolve Dublin County Council, Avril Doyle TD said, "The Bill before us today effectively abolishes County Dublin, and as one born and bred in these parts of Ireland I find it rather strange that we in this House are abolishing County Dublin. I am not sure whether Dubliners realise that that is what we are about today, but in effect that is the case."
The county is part of the Dublin constituency for the purposes of European elections. For elections to Dáil Éireann, the area of the county is currently (2016) divided into eleven constituencies: Dublin Bay North, Dublin Bay South, Dublin Central, Dublin Fingal, Dublin Mid-West, Dublin North-West, Dublin Rathdown, Dublin South-Central, Dublin South-West, Dublin West, and Dún Laoghaire. Together they return 45 deputies (TDs) to the Dáil.
Despite the legal status of the Dublin Region, the term "County Dublin" is still in common usage. Many organisations and sporting teams continue to organise on a "County Dublin" or "Dublin Region" basis. The area formerly known as "County Dublin" is now defined in legislation solely as the "Dublin Region" under the "Local Government Act, 1991 (Regional Authorities) (Establishment) Order, 1993", and this is the terminology officially used by the four Dublin administrative councils in press releases concerning the former county area. The term "Greater Dublin Area", which might consist of some or all of the Dublin Region along with counties of Kildare, Meath and Wicklow, has no legal standing.
The Dublin Region is a NUTS Level III region of Ireland. The region is one of eight regions of the Republic of Ireland for the purposes of Eurostat statistics. Its NUTS code is IE061. It is co-extensive with the old county. The regional capital is Dublin City which is also the national capital.
The latest Ordnance Survey Ireland "Discovery Series" (Third Edition 2005) 1:50,000 map of the Dublin Region, Sheet 50, shows the boundaries of the city and three surrounding counties of the region. Extremities of the Dublin Region, in the north and south of the region, appear in other sheets of the series, 43 and 56 respectively.
Local radio stations include 98FM, FM104, 103.2 Dublin City FM, Q102, SPIN 1038, Sunshine 106.8, TXFM, Raidió Na Life and Radio Nova.
Local newspapers include "The Echo", "Northside People", "Southside People" and the "Liffey Champion".
Most of the area can receive the five main UK television channels as well as the main Irish channels, along with Sky TV and Virgin Media Ireland cable television.
The economy of County Dublin was identified as being the powerhouse behind the Celtic Tiger, a period of strong economic growth of the state. This resulted in the economy of the county expanding by almost 100% between the early 1990s and 2007. This growth resulted from incoming high-value industries, such as financial services and software manufacturing, as well as low-skilled retail and domestic services, which caused a shift away from older manufacturing industry. This change saw high unemployment in the 1980s and early 1990s which resulted in damage to the capital's social structure.
According to CSO figures, the region had a GDP of €87.238 bn and a GDP per capita of €68,208 in 2014 (the second highest was Cork at €50,544 per capita). 
Separately, Eurostat figures for 2012 suggested the region then had a GDP of €72.384 bn and a GDP per capita of €57,200 – the highest on the island of Ireland (the second highest being Cork with €48,500). 
As of early 2017, the unemployment rate for the Dublin region was estimated at 6%.
County Dublin is the main transport node of Ireland, and contains one international airport, Dublin Airport. It is also served by two main seaports, Dún Laoghaire port and Dublin Port, which is just located outside of the city center. The two main train stations are Dublin Heuston and Dublin Connolly, both of which serve intercity trains.
According to the 2006 census, County Dublin had a population of 1,187,176, which constitutes 30% of the national population. This was an increase of 9.5% on 2002 figures. Its population density was . The population of Dublin City, was 506,211.
The median age of the population of the county in the 2006 census was 35.6 years, with 62% of people aged between 20–64 years old. Net migration to the county between 2002 and 2006 was 48,000, with a natural increase of 33,000 people.
There are 10,469 Irish speakers in County Dublin attending the 31 Gaelscoileanna (Irish language primary schools) and eight Gaelcholáistí (Irish language secondary schools). There may be up to another 10,000 Irish speakers from the Gaeltacht living and working in Dublin also.
A list of the largest urban areas (those with over 1,000 inhabitants) in County Dublin. Administrative county seats are shown in bold.

</doc>
<doc id="6516" url="https://en.wikipedia.org/wiki?curid=6516" title="Cosmological argument">
Cosmological argument

A cosmological argument, in natural theology and natural philosophy (not cosmology), is an argument in which the existence of God is inferred from alleged facts concerning causation, explanation, change, motion, contingency, dependency, or finitude with respect to the universe or some totality of objects. It is traditionally known as an argument from universal causation, an argument from first cause, or the causal argument. (about the "origin"). Whichever term is employed, there are three basic variants of the argument, each with subtle yet important distinctions: the arguments from "in causa" (causality), "in esse" (essentiality), and "in fieri" (becoming).
The basic premises of all of these are the concept of causality. The conclusion of these arguments is first cause (for whichever group of things it is being argued must have a cause or explanation), subsequently deemed to be God. The history of this argument goes back to Aristotle or earlier, was developed in Neoplatonism and early Christianity and later in medieval Islamic theology during the 9th to 12th centuries, and re-introduced to medieval Christian theology in the 13th century by Thomas Aquinas. The cosmological argument is closely related to the principle of sufficient reason as addressed by Gottfried Leibniz and Samuel Clarke, itself a modern exposition of the claim that "nothing comes from nothing" attributed to Parmenides.
Contemporary defenders of cosmological arguments include William Lane Craig, Robert Koons, Alexander Pruss, and William L. Rowe.
Plato (c. 427–347 BC) and Aristotle (c. 384–322 BC) both posited first cause arguments, though each had certain notable caveats. In "The Laws" (Book X), Plato posited that all movement in the world and the Cosmos was "imparted motion". This required a "self-originated motion" to set it in motion and to maintain it. In "Timaeus", Plato posited a "demiurge" of supreme wisdom and intelligence as the creator of the Cosmos.
Aristotle argued "against" the idea of a first cause, often confused with the idea of a "prime mover" or "unmoved mover" ( or "primus motor") in his "Physics" and "Metaphysics". Aristotle argued in "favor" of the idea of several unmoved movers, one powering each celestial sphere, which he believed lived beyond the sphere of the fixed stars, and explained why motion in the universe (which he believed was eternal) had continued for an infinite period of time. Aristotle argued the atomist's assertion of a non-eternal universe would require a first uncaused cause – in his terminology, an efficient first cause – an idea he considered a nonsensical flaw in the reasoning of the atomists.
Like Plato, Aristotle believed in an eternal cosmos with no beginning and no end (which in turn follows Parmenides' famous statement that "nothing comes from nothing"). In what he called "first philosophy" or metaphysics, Aristotle "did" intend a theological correspondence between the prime mover and deity (presumably Zeus); functionally, however, he provided an explanation for the apparent motion of the "fixed stars" (now understood as the daily rotation of the Earth). According to his theses, immaterial unmoved movers are eternal unchangeable beings that constantly think about thinking, but being immaterial, they are incapable of interacting with the cosmos and have no knowledge of what transpires therein. From an "aspiration or desire", the celestial spheres, "imitate" that purely intellectual activity as best they can, by uniform circular motion. The unmoved movers "inspiring" the planetary spheres are no different in kind from the prime mover, they merely suffer a dependency of relation to the prime mover. Correspondingly, the motions of the planets are subordinate to the motion inspired by the prime mover in the sphere of fixed stars. Aristotle's natural theology admitted no creation or capriciousness from the immortal pantheon, but maintained a defense against dangerous charges of impiety.
Plotinus, a third-century Platonist, taught that the One transcendent absolute caused the universe to exist simply as a consequence of its existence ("creatio ex deo"). His disciple Proclus stated "The One is God".
Centuries later, the Islamic philosopher Avicenna (c. 980–1037) inquired into the question of being, in which he distinguished between essence ("Mahiat") and existence ("Wujud"). He argued that the fact of existence could not be inferred from or accounted for by the essence of existing things, and that form and matter by themselves could not originate and interact with the movement of the Universe or the progressive actualization of existing things. Thus, he reasoned that existence must be due to an agent cause that necessitates, imparts, gives, or adds existence to an essence. To do so, the cause must coexist with its effect and be an existing thing.
Steven Duncan writes that it "was first formulated by a Greek-speaking Syriac Christian neo-Platonist, John Philoponus, who claims to find a contradiction between the Greek pagan insistence on the eternity of the world and the Aristotelian rejection of the existence of any actual infinite". Referring to the argument as the "'Kalam' cosmological argument", Duncan asserts that it "received its fullest articulation at the hands of [medieval] Muslim and Jewish exponents of "Kalam" ("the use of reason by believers to justify the basic metaphysical presuppositions of the faith").
Thomas Aquinas (c. 1225–1274) adapted and enhanced the argument he found in his reading of Aristotle and Avicenna to form one of the most influential versions of the cosmological argument. His conception of First Cause was the idea that the Universe must be caused by something that is itself uncaused, which he claimed is that which we call God:
Importantly, Aquinas' Five Ways, given the second question of his Summa Theologica, are not the entirety of Aquinas' demonstration that the Christian God exists. The Five Ways form only the beginning of Aquinas' Treatise on the Divine Nature.
In the scholastic era, Aquinas formulated the "argument from contingency", following Aristotle in claiming that there must be something to explain why the Universe exists. Since the Universe could, under different circumstances, conceivably "not" exist (contingency), its existence must have a cause – not merely another contingent thing, but something that exists by necessity (something that "must" exist in order for anything else to exist). In other words, even if the Universe has always existed, it still owes its existence to an uncaused cause, Aquinas further said: "... and this we understand to be God."
Aquinas's argument from contingency allows for the possibility of a Universe that has no beginning in time. It is a form of argument from universal causation. Aquinas observed that, in nature, there were things with contingent existences. Since it is possible for such things not to exist, there must be some time at which these things did not in fact exist. Thus, according to Aquinas, there must have been a time when nothing existed. If this is so, there would exist nothing that could bring anything into existence. Contingent beings, therefore, are insufficient to account for the existence of contingent beings: there must exist a "necessary" being whose non-existence is an impossibility, and from which the existence of all contingent beings is derived.
The German philosopher Gottfried Leibniz made a similar argument with his principle of sufficient reason in 1714. "There can be found no fact that is true or existent, or any true proposition," he wrote, "without there being a sufficient reason for its being so and not otherwise, although we cannot know these reasons in most cases." He formulated the cosmological argument succinctly: "Why is there something rather than nothing? The sufficient reason ... is found in a substance which ... is a necessary being bearing the reason for its existence within itself."
Leibniz's argument from contingency is one of the most popular cosmological arguments in philosophy of religion. It attempts to prove the existence of a necessary being and infer that this being is God. Alexander Pruss formulates the argument as follows:
Premise 1 is a form of the principle of sufficient reason stating that all contingently true propositions are explained. This is one of the several variants of the PSR which differ in strength, scope, and modal implications. Premise 2 refers to what is known as the Big Conjunctive Contingent Fact (abbreviated BCCF) in philosophy of religion. The BCCF is generally taken to be the totality of all contingent beings or the logical conjunction of all contingent facts. The approach of the argument is that since a contingent fact cannot explain the BCCF, a fact involving a necessary object must be its explanation. Statement 5, which is either seen as a premise or a conclusion, infers that the necessary being which explains the totality of contingent facts is God. In academic literature, several philosophers of religion such as Joshua Rasmussen and T. Ryan Byerly have argued for the inference from (4) to (5).
The difference between the arguments from causation "in fieri" and "in esse" is a fairly important one. "In fieri" is generally translated as "becoming", while "in esse" is generally translated as "in essence". "In fieri", the process of becoming, is similar to building a house. Once it is built, the builder walks away, and it stands on its own accord; compare the watchmaker analogy. (It may require occasional maintenance, but that is beyond the scope of the first cause argument.)
"In esse" (essence) is more akin to the light from a candle or the liquid in a vessel. George Hayward Joyce, SJ, explained that, "where the light of the candle is dependent on the candle's continued existence, not only does a candle produce light in a room in the first instance, but its continued presence is necessary if the illumination is to continue. If it is removed, the light ceases. Again, a liquid receives its shape from the vessel in which it is contained; but were the pressure of the containing sides withdrawn, it would not retain its form for an instant." This form of the argument is far more difficult to separate from a purely first cause argument than is the example of the house's maintenance above, because here the First Cause is insufficient without the candle's or vessel's continued existence.
Thus, Leibniz's argument is "in fieri", while Aquinas' argument is both "in fieri" and "in esse". As a general trend, the modern slants on the cosmological argument, including the Kalam cosmological argument, tend to lean very strongly towards an "in fieri" argument.
The philosopher Robert Koons has stated a new variant on the cosmological argument. He says that to deny causation is to deny all empirical ideas – for example, if we know our own hand, we know it because of the chain of causes including light being reflected upon one's eyes, stimulating the retina and sending a message through the optic nerve into your brain. He summarised the purpose of the argument as "that if you don't buy into theistic metaphysics, you're undermining empirical science. The two grew up together historically and are culturally and philosophically inter-dependent ... If you say I just don't buy this causality principle – that's going to be a big big problem for empirical science." This "in fieri" version of the argument therefore does not intend to prove God, but only to disprove objections involving science, and the idea that contemporary knowledge disproves the cosmological argument.
William Lane Craig gives this argument in the following general form:
Craig explains, by nature of the event (the Universe coming into existence), attributes unique to (the concept of) God must also be attributed to the cause of this event, including but not limited to: enormous power (if not omnipotence), being the creator of the Heavens and the Earth (as God is according to the Christian understanding of God), being eternal and being absolutely self-sufficient. Since these attributes are unique to God, anything with these attributes must be God. Something does have these attributes: the cause; hence, the cause is God, the cause exists; hence, God exists.
Craig defends the second premise, that the Universe had a beginning starting with Al-Ghazali's proof that an actual infinity is impossible. However, If the universe never had a beginning then there would be an actual infinite, an infinite amount of cause and effect events. Hence, the Universe had a beginning.
Duns Scotus, the influential Medieval Christian theologian, created a metaphysical argument for the existence of God. Though it was inspired by Aquinas' argument from motion, he, like other philosophers and theologians, believed that his statement for God's existence could be considered separate to Aquinas'. His explanation for God's existence is long, and can be summarised as follows:
Scotus deals immediately with two objections he can see: first, that there cannot be a first, and second, that the argument falls apart when 1) is questioned. He states that infinite regress is impossible, because it provokes unanswerable questions, like, in modern English, "What is infinity minus infinity?" The second he states can be answered if the question is rephrased using modal logic, meaning that the first statement is instead "It is possible that something can be produced."
One objection to the argument is that it leaves open the question of why the First Cause is unique in that it does not require any causes. Proponents argue that the First Cause is exempt from having a cause, while opponents argue that this is special pleading or otherwise untrue. Critics often press that arguing for the First Cause's exemption raises the question of why the First Cause is indeed exempt, whereas defenders maintain that this question has been answered by the various arguments, emphasizing that none of its major forms rest on the premise that everything has a cause.
William Lane Craig, who famously uses the Kalam cosmological argument, argues that the infinite is impossible, whichever perspective the viewer takes, and so there must always have been one unmoved thing to begin the universe. He uses Hilbert's paradox of the Grand Hotel and the question 'What is infinity minus infinity?' to illustrate the idea that the infinite is metaphysically, mathematically, and even conceptually, impossible. Other reasons include the fact that it is impossible to count down from infinity, and that, had the universe existed for an infinite amount of time, every possible event, including the final end of the universe, would already have occurred. He therefore states his argument in three points- firstly, everything that begins to exist has a cause of its existence; secondly, the universe began to exist; so, thirdly, therefore, the universe has a cause of its existence. A response to this argument would be that the cause of the universe's existence (God) would need a cause for its existence, which, in turn, could be responded to as being logically inconsistent with the evidence already presented- even if God did have a cause, there would still necessarily be a cause which began everything, owing to the impossibility of the infinite stated by Craig.
Secondly, it is argued that the premise of causality has been arrived at via "a posteriori" (inductive) reasoning, which is dependent on experience. David Hume highlighted this problem of induction and argued that causal relations were not true "a priori". However, as to whether inductive or deductive reasoning is more valuable remains a matter of debate, with the general conclusion being that neither is prominent. Opponents of the argument tend to argue that it is unwise to draw conclusions from an extrapolation of causality beyond experience. Andrew Loke replies that, according to the Kalam Cosmological Argument, only things which begin to exist require a cause. On the other hand, something that is without beginning has always existed and therefore does not require a cause. The Cosmological Argument posits that there cannot be an actual infinite regress of causes, therefore there must be an uncaused First Cause that is beginningless and does not require a cause.
The basic cosmological argument merely establishes that a First Cause exists, not that it has the attributes of a theistic god, such as omniscience, omnipotence, and omnibenevolence. This is why the argument is often expanded to show that at least some of these attributes are necessarily true, for instance in the modern Kalam argument given above.
A causal loop is a form of predestination paradox arising where traveling backwards in time is deemed a possibility. A sufficiently powerful entity in such a world would have the capacity to travel backwards in time to a point before its own existence, and to then create itself, thereby initiating everything which follows from it.
The usual reason given to refute the possibility of a causal loop is that it requires that the loop as a whole be its own cause. Richard Hanley argues that causal loops are not logically, physically, or epistemically impossible: "[In timed systems,] the only possibly objectionable feature that all causal loops share is that coincidence is required to explain them." However, Andrew Loke argues that causal loop of the type that is supposed to avoid a First Cause suffers from the problem of vicious circularity and thus it would not work.
David Hume and later Paul Edwards have invoked a similar principle in their criticisms of the cosmological argument. William Rowe has called this the Hume-Edwards principle:
Nevertheless, David White argues that the notion of an infinite causal regress providing a proper explanation is fallacious. Furthermore, in Hume's Dialogues Concerning Natural Religion, the character Demea states that even if the succession of causes is infinite, the whole chain still requires a cause. To explain this, suppose there exists a causal chain of infinite contingent beings. If one asks the question, "Why are there any contingent beings at all?", it does not help to be told that "There are contingent beings because other contingent beings caused them." That answer would just presuppose additional contingent beings. An adequate explanation of why some contingent beings exist would invoke a different sort of being, a necessary being that is "not" contingent. A response might suppose each individual is contingent but the infinite chain as a whole is not; or the whole infinite causal chain to be its own cause.
Severinsen argues that there is an "infinite" and complex causal structure. White tried to introduce an argument "without appeal to the principle of sufficient reason and without denying the possibility of an infinite causal regress". A number of other arguments have been offered to demonstrate that an actual infinite regress cannot exist, viz. the argument for the impossibility of concrete actual infinities, the argument for the impossibility of traversing an actual infinite, the argument from the lack of capacity to begin to exist, and various arguments from paradoxes.
Some cosmologists and physicists argue that a challenge to the cosmological argument is the nature of time: "One finds that time just disappears from the Wheeler–DeWitt equation" (Carlo Rovelli). The Big Bang theory states that it is the point in which all dimensions came into existence, the start of both space and time. Then, the question "What was there before the Universe?" makes no sense; the concept of "before" becomes meaningless when considering a situation without time. This has been put forward by J. Richard Gott III, James E. Gunn, David N. Schramm, and Beatrice Tinsley, who said that asking what occurred before the Big Bang is like asking what is north of the North Pole. However, some cosmologists and physicists do attempt to investigate causes for the Big Bang, using such scenarios as the collision of membranes.
Philosopher Edward Feser states that classical philosophers' arguments for the existence of God do not care about the Big Bang or whether the universe had a beginning. The question is not about what got things started or how long they have been going, but rather what keeps them going.
There is also a Big Bang Argument, which is a variation of the Cosmological Argument using the Big Bang Theory to validate the premise that the Universe had a beginning.

</doc>
<doc id="6517" url="https://en.wikipedia.org/wiki?curid=6517" title="Clutch">
Clutch

A clutch is a mechanical device which engages and disengages power transmission especially from driving shaft to driven shaft.
In the simplest application, clutches connect and disconnect two rotating shafts (drive shafts or line shafts). In these devices, one shaft is typically attached to an engine or other power unit (the driving member) while the other shaft (the driven member) provides output power for work. While typically the motions involved are rotary, linear clutches are also possible.
In a torque-controlled drill, for instance, one shaft is driven by a motor and the other drives a drill chuck. The clutch connects the two shafts so they may be locked together and spin at the same speed (engaged), locked together but spinning at different speeds (slipping), or unlocked and spinning at different speeds (disengaged).
The vast majority of clutches ultimately rely on frictional forces for their operation. The purpose of friction clutches is to connect a moving member to another that is moving at a different speed or stationary, often to synchronize the speeds, and/or to transmit power. Usually, as little slippage (difference in speeds) as possible between the two members is desired.
Various materials have been used for the disc-friction facings, including asbestos in the past. Modern clutches typically use a compound organic resin with copper wire facing or a ceramic material. Ceramic materials are typically used in heavy applications such as racing or heavy-duty hauling, though the harder ceramic materials increase flywheel and pressure plate wear.
In the case of "wet" clutches, composite paper materials are very common. Since these "wet" clutches typically use an oil bath or flow-through cooling method for keeping the disc pack lubricated and cooled, very little wear is seen when using composite paper materials.
Friction-disc clutches generally are classified as "push type" or "pull type" depending on the location of the pressure plate fulcrum points. In a pull-type clutch, the action of pressing the pedal pulls the release bearing, pulling on the diaphragm spring and disengaging the vehicle drive. The opposite is true with a push type, the release bearing is pushed into the clutch disengaging the vehicle drive. In this instance, the release bearing can be known as a thrust bearing (as per the image above).
A clutch damper is a device that softens the response of the clutch engagement/disengagement. In automotive applications, this is often provided by a mechanism in the clutch disc centres. In addition to the damped disc centres, which reduce driveline vibration, pre-dampers may be used to reduce gear rattle at idle by changing the natural frequency of the disc. These weaker springs are compressed solely by the radial vibrations of an idling engine. They are fully compressed and no longer in use once the main damper springs take up drive.
Mercedes truck examples:
A clamp load of 33 kN is normal for a single plate 430. The 400 Twin application offers a clamp load of a mere 23 kN. Bursts speeds are typically around 5,000 rpm with the weakest point being the facing rivet.
Modern clutch development focuses its attention on the simplification of the overall assembly and/or manufacturing method. For example, drive straps are now commonly employed to transfer torque as well as lift the pressure plate upon disengagement of vehicle drive. With regard to the manufacture of diaphragm springs, heat treatment is crucial. Laser welding is becoming more common as a method of attaching the drive plate to the disc ring with the laser typically being between 2-3 kW and a feed rate 1m/minute.
This type of clutch has several driving members interleaved or "stacked" with several driven members. It is used in racing cars including Formula 1, IndyCar, World Rally and even most club racing. Multiplate clutches see much use in drag racing, which requires the best acceleration possible, and is notorious for the abuse the clutch is subjected to. Thus, they can be found in motorcycles, in automatic transmissions and in some diesel locomotives with mechanical transmissions. It is also used in some electronically controlled all-wheel drive systems as well as in some transfer cases. They can also be found in some heavy machinery such as tanks and AFVs (T-54) and earthmoving equipment (front-end loaders, bulldozers), as well as components in certain types of limited slip differentials. The benefit in the case of motorsports is that it is possible to achieve the same total friction force with a much smaller overall diameter (or conversely, a much greater friction force for the same diameter, important in cases where a vehicle is modified with greater power, yet the maximum physical size of the clutch unit is constrained by the clutch housing). In motorsports vehicles that run at high engine/drivetrain speeds, the smaller diameter reduces rotational inertia, making the drivetrain components accelerate more rapidly, as well as reducing the velocity of the outer areas of the clutch unit, which could become highly stressed and fail at the extremely high drivetrain rotational rates achieved in sports such as Formula 1 or drag racing. In the case of heavy equipment, which often deal with very high torque forces and drivetrain loads, a single plate clutch of the necessary strength would be too large to easily package as a component of the driveline.
Another, different theme on the multiplate clutch is the clutches used in the fastest classes of drag racing, highly specialized, purpose-built cars such as Top Fuel dragsters or Funny Cars. These cars are so powerful that to attempt a start with a simple clutch would result in complete loss of traction. To avoid this problem, Top Fuel cars actually use a single, fixed gear ratio, and a "series" of clutches that are engaged one at a time, rather than in unison, progressively allowing more power to the wheels. A single one of these clutch plates (as designed) cannot hold more than a fraction of the power of the engine, so the driver starts with only the first clutch engaged. This clutch is overwhelmed by the power of the engine, allowing only a fraction of the power to the wheels, much like "slipping the clutch" in a slower car, but working without requiring concentration from the driver. As speed builds, the driver pulls a lever, which engages a second clutch, sending a bit more of the engine power to the wheels, and so on. This continues through several clutches until the car has reached a speed where the last clutch can be engaged. With all clutches engaged, the engine is now sending all of its power to the rear wheels. This is far more predictable and repeatable than the driver manually slipping the clutch himself and then shifting through the gears, given the extreme violence of the run and the speed at which it all unfolds. Another benefit is that there is no need to break the power flow in order to swap gears (a conventional manual cannot transmit power while between gears, which is important because 1/100ths of a second are important in Top Fuel races). A traditional multiplate clutch would be more prone to overheating and failure, as all the plates must be subjected to heat and friction together until the clutch is fully engaged, while a Top Fuel car keeps its last clutches in "reserve" until the cars speed allows full engagement. It is relatively easy to design the last stages to be much more powerful than the first, in order to ensure they can absorb the power of the engine even if the first clutches burn out or overheat from the extreme friction.
A "wet clutch" is immersed in a cooling lubricating fluid that also keeps surfaces clean and provides smoother performance and longer life. Wet clutches, however, tend to lose some energy to the liquid. Since the surfaces of a wet clutch can be slippery (as with a motorcycle clutch bathed in engine oil), stacking multiple clutch discs can compensate for the lower coefficient of friction and so eliminate slippage under power when fully engaged.
The Hele-Shaw clutch was a wet clutch that relied entirely on viscous effects, rather than on friction.
A "dry clutch", as the name implies, is not bathed in liquid and uses friction to engage.
A centrifugal clutch is used in some vehicles (e.g., mopeds) and also in other applications where the speed of the engine defines the state of the clutch, for example, in a chainsaw. This clutch system employs centrifugal force to automatically engage the clutch when the engine rpm rises above a threshold and to automatically disengage the clutch when the engine rpm falls low enough. See Saxomat and Variomatic.
As the name implies, a cone clutch has conical friction surfaces. The cone's taper means that a given amount of movement of the actuator makes the surfaces approach (or recede) much more slowly than in a disc clutch. As well, a given amount of actuating force creates more pressure on the mating surfaces.
The best known example of a cone clutch is a synchronizer ring in a manual transmission. The synchronizer ring is responsible for "synchronizing" the speeds of the shift hub and the gear wheel to ensure a smooth gear change.
Also known as a slip clutch or "safety clutch", this device allows a rotating shaft to slip when higher than normal resistance is encountered on a machine. An example of a safety clutch is the one mounted on the driving shaft of a large grass mower. The clutch yields if the blades hit a rock, stump, or other immobile object, thus avoiding a potentially damaging torque transfer to the engine, possibly twisting or fracturing the crankshaft.
Motor-driven mechanical calculators had these between the drive motor and gear train, to limit damage when the mechanism jammed, as motors used in such calculators had high stall torque and were capable of causing damage to the mechanism if torque was not limited.
Carefully designed clutches operate, but continue to transmit maximum permitted torque, in such tools as controlled-torque screwdrivers.
Some clutches are designed not to slip; torque may only be transmitted either fully engaged or disengaged to avoid catastrophic damage. An example of this is the dog clutch, most commonly used in non-synchromesh transmissions.
There are multiple designs of vehicle clutch, but most are based on one or more friction discs pressed tightly together or against a flywheel using springs. The friction material varies in composition depending on many considerations such as whether the clutch is "dry" or "wet". Friction discs once contained asbestos, but this has been largely discontinued. Clutches found in heavy duty applications such as trucks and competition cars use ceramic plates that have a greatly increased friction coefficient. However, these have a "grabby" action generally considered unsuitable for passenger cars. The spring pressure is released when the clutch pedal is depressed thus either pushing or pulling the diaphragm of the pressure plate, depending on type. Raising the engine speed too high while engaging the clutch causes excessive clutch plate wear. Engaging the clutch abruptly when the engine is turning at high speed causes a harsh, jerky start. This kind of start is necessary and desirable in drag racing and other competitions, where speed is more important than comfort.
In a modern car with a manual transmission the clutch is operated by the left-most pedal using a hydraulic or cable connection from the pedal to the clutch mechanism. On older cars the clutch might be operated by a mechanical linkage. Even though the clutch may physically be located very close to the pedal, such remote means of actuation are necessary to eliminate the effect of vibrations and slight engine movement, engine mountings being flexible by design. With a rigid mechanical linkage, smooth engagement would be near-impossible because engine movement inevitably occurs as the drive is "taken up."
The default state of the clutch is "engaged" - that is the connection between engine and gearbox is always "on" unless the driver presses the pedal and disengages it. If the engine is running with the clutch engaged and the transmission in neutral, the engine spins the input shaft of the transmission but power is not transmitted to the wheels.
The clutch is located between the engine and the gearbox, as disengaging it is usually required to change gear. Although the gearbox does not stop rotating during a gear change, there is no torque transmitted through it, thus less friction between gears and their engagement dogs. The output shaft of the gearbox is permanently connected to the final drive, then the wheels, and so both always rotate together, at a fixed speed ratio. With the clutch disengaged, the gearbox input shaft is free to change its speed as the internal ratio is changed. Any resulting difference in speed between the engine and gearbox is evened out as the clutch slips slightly during re-engagement.
Clutches in typical cars are mounted directly to the face of the engine's flywheel, as this already provides a convenient large diameter steel disk that can act as one driving plate of the clutch. Some racing clutches use small multi-plate disk packs that are not part of the flywheel. Both clutch and flywheel are enclosed in a conical bellhousing, which (in a rear-wheel drive car) usually forms the main mounting for the gearbox.
A few cars, notably the Alfa Romeo Alfetta and 75, Porsche 924, and Chevrolet Corvette (since 1997), sought a more even weight distribution between front and back by placing the weight of the transmission at the rear of the car, combined with the rear axle to form a transaxle. The clutch was mounted with the transaxle and so the propeller shaft rotated continuously with the engine, even when in neutral gear or declutched.
Motorcycles typically employ a wet clutch with the clutch riding in the same oil as the transmission. These clutches are usually made up of a stack of alternating friction plates and steel plates. The friction plates have lugs on their outer diameters that lock them to a basket that is turned by the crankshaft. The steel plates have lugs on their inner diameters that lock them to the transmission input shaft. A set of coil springs or a diaphragm spring plate force the plates together when the clutch is engaged.
On motorcycles the clutch is operated by a hand lever on the left handlebar. No pressure on the lever means that the clutch plates are engaged (driving), while pulling the lever back towards the rider disengages the clutch plates through cable or hydraulic actuation, allowing the rider to shift gears or coast. Racing motorcycles often use slipper clutches to eliminate the effects of engine braking, which, being applied only to the rear wheel, can cause instability.
Cars use clutches in places other than the drive train. For example, a belt-driven engine cooling fan may have a heat-activated clutch. The driving and driven members are separated by a silicone-based fluid and a valve controlled by a bimetallic spring. When the temperature is low, the spring winds and closes the valve, which lets the fan spin at about 20% to 30% of the shaft speed. As the temperature of the spring rises, it unwinds and opens the valve, allowing fluid past the valve, makes the fan spin at about 60% to 90% of shaft speed. Other clutches—such as for an air conditioning compressor—electronically engage clutches using magnetic force to couple the driving member to the driven member.
Single-revolution clutches were developed in the 19th century to power machinery such as shears or presses where a single pull of the operating lever or (later) press of a button would trip the mechanism, engaging the clutch between the power source and the machine's crankshaft for exactly one revolution before disengaging the clutch. When the clutch is disengaged and the driven member is stationary. Early designs were typically dog clutches with a cam on the driven member used to disengage the dogs at the appropriate point.
Greatly simplified single-revolution clutches were developed in the 20th century, requiring much smaller operating forces and in some variations, allowing for a fixed fraction of a revolution per operation. Fast action friction clutches replaced dog clutches in some applications, eliminating the problem of impact loading on the dogs every time the clutch engaged.
In addition to their use in heavy manufacturing equipment, single-revolution clutches were applied to numerous small machines. In tabulating machines, for example, pressing the operate key would trip a single revolution clutch to process the most recently entered number. In typesetting machines, pressing any key selected a particular character and also engaged a single rotation clutch to cycle the mechanism to typeset that character. Similarly, in teleprinters, the receipt of each character tripped a single-revolution clutch to operate one cycle of the print mechanism.
In 1928, Frederick G. Creed developed a single-turn spring clutch (see above) that was particularly well suited to the repetitive start-stop action required in teleprinters. In 1942, two employees of Pitney Bowes Postage Meter Company developed an improved single turn spring clutch. In these clutches, a coil spring is wrapped around the driven shaft and held in an expanded configuration by the trip lever. When tripped, the spring rapidly contracts around the power shaft engaging the clutch. At the end of one revolution, if the trip lever has been reset, it catches the end of the spring (or a pawl attached to it) and the angular momentum of the driven member releases the tension on the spring. These clutches have long operating lives—many have performed tens and perhaps hundreds of millions of cycles without need of maintenance other than occasional lubrication.
These superseded wrap-spring single-revolution clutches in page printers, such as teleprinters, including the Teletype Model 28 and its successors, using the same design principles. IBM Selectric typewriters also used them. These are typically disc-shaped assemblies mounted on the driven shaft. Inside the hollow disc-shaped drive drum are two or three freely floating pawls arranged so that when the clutch is tripped, the pawls spring outward much like the shoes in a drum brake. When engaged, the load torque on each pawl transfers to the others to keep them engaged. These clutches do not slip once locked up, and they engage very quickly, on the order of milliseconds. A trip projection extends out from the assembly. If the trip lever engaged this projection, the clutch was disengaged. When the trip lever releases this projection, internal springs and friction engage the clutch. The clutch then rotates one or more turns, stopping when the trip lever again engages the trip projection.
These mechanisms were found in some types of synchronous-motor-driven electric clocks. Many different types of synchronous clock motors were used, including the pre-World War II Hammond manual-start clocks. Some types of self-starting synchronous motors always started when power was applied, but in detail, their behaviour was chaotic and they were equally likely to start rotating in the wrong direction. Coupled to the rotor by one (or possibly two) stages of reduction gearing was a wrap-spring clutch-brake. The spring did not rotate. One end was fixed; the other was free. It rode freely but closely on the rotating member, part of the clock's gear train. The clutch-brake locked up when rotated backwards, but also had some spring action. The inertia of the rotor going backwards engaged the clutch and wound the spring. As it unwound, it restarted the motor in the correct direction. Some designs had no explicit spring as such—but were simply compliant mechanisms. The mechanism was lubricated and wear did not present a problem.
A Lock-up clutch is used in some automatic transmissions for motor vehicles. Above a certain speed (usually 60 km/h) it locks the torque converter to minimise power loss and improve fuel efficiency.

</doc>
<doc id="6520" url="https://en.wikipedia.org/wiki?curid=6520" title="Cow tipping">
Cow tipping

Cow tipping is the purported activity of sneaking up on any unsuspecting or sleeping upright cow and pushing it over for entertainment. The practice of cow tipping is generally considered an urban legend, and stories of such feats viewed as tall tales. The implication that rural citizens seek such entertainment due to lack of alternatives is viewed as a stereotype. The concept of cow tipping apparently developed in the 1970s, though tales of animals that cannot rise if they fall has historical antecedents dating to the Roman Empire.
Cows routinely lie down and can easily regain their footing unless sick or injured. Scientific studies have been conducted to determine if cow tipping is theoretically possible, with varying conclusions. All agree that cows are large animals that are difficult to surprise and will generally resist attempts to be tipped. Estimates suggest a force of between is needed, and that at least four and possibly as many as fourteen people would be required to achieve this. In real-life situations where cattle have to be laid on the ground, or "cast", such as for branding, hoof care or veterinary treatment, either rope restraints are required or specialized mechanical equipment is used that confines the cow and then tips it over. On rare occasions, cattle can lie down or fall down in proximity to a ditch or hill that restricts their normal ability to rise without help. Cow tipping has many references in popular culture and is also used as a figure of speech.
The urban legend of cow tipping relies upon the presumption that cattle are slow-moving, dim-witted, and weak-legged, thus easily pushed over without much force. Some versions suggest that because cows sleep standing up, it is possible to approach them and push them over without the animals reacting. However, cows only sleep lightly while standing up, and they are easily awakened. They lie down to sleep deeply. Furthermore, numerous sources have questioned the practice's feasibility, since most cows weigh over half a ton and easily resist any lesser force.
A 2005 study led by Margo Lillie, a zoologist at the University of British Columbia, and her student Tracy Boechler, concluded that tipping a cow would require a force of nearly and is therefore impossible to accomplish by a single person. Her calculations found that it would require more than four people to apply enough force to push over a cow, based on an estimate that a single person could exert of force. However, since a cow can brace itself, Lillie and Boechler suggested that five or six people would, most likely, be needed. Further, cattle are well aware of their surroundings and are very difficult to surprise, due to excellent senses of both smell and hearing. Lillie and Boechler's analysis found that if a cow did not move, the principles of static physics suggest that two people might be able to tip a cow if its centre of mass were pushed over its hooves before the cow could react. However, cows are not rigid or unresponsive, and the faster humans have to move, the less force they can exert. Thus Lillie and Boechler concluded that it is unlikely that cows can actually be tipped over in this way. Lillie stated, "It just makes the physics of it all, in my opinion, impossible."
Although he agrees that it would take a force of about 3,000 newtons to push over a standing cow, biologist Steven Vogel thinks that the study by Lillie and Boechler overestimates the pushing ability of an individual human. Using data from Cotterell and Kamminga, who estimated that humans exert a pushing force of 280 newtons, Vogel suggests that someone applying force at the requisite height to topple a cow might generate a maximum push of no more than 300 newtons. By this calculation, at least 10 people would be needed to tip over a non-reacting cow. However, this combined force requirement, he says, might not be the greatest impediment to such a prank. Standing cows are not asleep and like other animals have ever-vigilant reflexes. "If the cow does no more than modestly widen its stance without an overall shift of its center of gravity", he says, "about 4,000 newtons or 14 pushers would be needed—quite a challenge to deploy without angering the cow."
The belief that certain animals cannot rise if pushed over has historical antecedents, though cattle have never been so classified. Julius Caesar recorded a belief that a European elk had no knee joints and could not get up if it fell. Pliny said the same about the hind legs of an animal he called the achlis, which Pliny's 19th-century translators Bostock and Riley said was merely another name for the elk. They also noted that Pliny's belief about the jointless back legs of the achlis (elk) was false.
In 1255, Louis IX of France gave an elephant to Henry III of England for his menagerie in the Tower of London. A drawing by the historian Matthew Paris for his "Chronica Majora" can be seen in his bestiary at Parker Library of Corpus Christi College, Cambridge. An accompanying text cites elephant lore suggesting that elephants did not have knees and were unable to get up if they fell.
Journalist Jake Steelhammer believes the American urban myth of cow tipping originated in the 1970s. It "stampeded into the '80s", he says, "when movies like "Tommy Boy" and "Heathers" featured cow tipping expeditions." Stories about cow tipping tend to be second-hand, he says, told by someone who does not claim to have tipped a cow but who knows someone else who says he or she did.
Cattle may need to be deliberately thrown or tipped over for certain types of husbandry practices and medical treatment. When done for medical purposes, this is often called "casting", and when performed without mechanical assistance requires the attachment of of rope around the body and legs of the animal. After the rope is secured by non-slip bowline knots, it is pulled to the rear until the animal is off-balance. Once the cow is forced to lie down in sternal recumbency (on its chest), it can be rolled onto its side and its legs tied to prevent kicking.
A calf table or calf cradle, also called a "tipping table" or a "throw down", is a relatively modern invention designed to be used on calves that are being branded. A calf is run into a chute, confined, and then tipped by the equipment onto its side for easier branding and castration.
Hydraulic tilt tables for adult cattle have existed since the 1970s and are designed to lift and tip cattle onto their sides to enable veterinary care, particularly of the animals' genitalia, and for hoof maintenance. (Unlike horses, cows generally do not cooperate with a farrier when standing.) A Canadian veterinarian explained, "Using the table is much safer and easier than trying to get underneath to examine the animal", and noted that cows tipped over on a padded table usually stop struggling and become calm fairly quickly. One design, developed at the Western College of Veterinary Medicine in Saskatoon, Saskatchewan, included "cow comfort" as a unique aspect of care using this type of apparatus.
Cows may tip themselves inadvertently. Due to their bulk and relatively short legs, cattle cannot roll over. Those that lie down and roll to their sides with their feet pointing uphill may become stuck and unable to rise without assistance, with potentially fatal results. In such cases, two humans can roll or flip a cow onto its other side, so that its feet are aimed downhill, thus allowing it to rise on its own.
In one documented case of "real-life cow tipping", a pregnant cow rolled into a gully in New Hampshire and became trapped in an inverted state until rescued by volunteer fire fighters. The owner of the cow commented that he had seen this happen "once or twice" before.
Trauma or illness may also result in a cow unable to rise to its feet. Such animals are sometimes called "downers." Sometimes this occurs as a result of muscle and nerve damage from calving or a disease such as mastitis. Leg injuries, muscle tears, or a massive infection of some sort may also be causes. Downer cows are encouraged to get to their feet and have a much greater chance of recovery if they do. If unable to rise, some have survived—with medical care—as long as 14 days and were ultimately able to get back on their feet. Appropriate medical treatment for a downer cow to prevent further injury includes rolling from one side to the other every three hours, careful and frequent feeding of small amounts of fodder, and access to clean water.
Dead animals may appear to have been tipped over. But this is actually the process of rigor mortis, which stiffens the muscles of the carcass, beginning six to eight hours after death and lasting for one to two days. It is particularly noticeable in the limbs, which stick out straight. Post-mortem bloat also occurs because of gas formation inside the body. The process may result in cattle carcasses that wind up on their back with all four feet in the air.
Assorted individuals have claimed to have performed cow tipping, often while under the influence of alcohol. These claims, to date, cannot be reliably verified, with Jake Swearingen of "Modern Farmer" noting in 2013 that YouTube, a popular source of videos of challenges and stunts, "fails to deliver one single actual cow-tipping video".
Pranksters have sometimes pushed over artificial cows. Along Chicago's Michigan Avenue in 1999, two "apparently drunk" men felled six fiberglass cows that were part of a Cows on Parade public art exhibit. Four other vandals removed a "Wow cow" sculpture from its lifeguard chair at Oak Street Beach and abandoned it in a pedestrian underpass. A year later, New York City anchored its CowParade art cows, including "A Streetcow Named Desire", to concrete bases "to prevent the udder disrespect of cow-tippers and thieves."
Cow tipping has been featured in films from the 1980s and later, such as "Heathers" (1988), "Tommy Boy" (1995), " Barnyard" (2006), and "I Love You, Beth Cooper" (2009). It was also used in the title of a 1992 documentary film by Randy Redroad, "Cow Tipping–The Militant Indian Waiter". The film "Cars" (2006) features a vehicular variant called tractor-tipping.
In The Little Willies song "Lou Reed" from their 2006 eponymous debut album, Norah Jones sings about a fictional event during which musician Lou Reed tips cows in Texas. In another medium, "The Big Bang Theory", a television show, uses cow tipping lore as an element to establish the nature of a rural character, Penny.
The term "cow tipping" is sometimes used as a figure of speech for pushing over something big. In "A Giant Cow-Tipping by Savages", author John Weir Close uses the term to describe contemporary mergers and acquisitions. "Tipping sacred cows" has been used as a deliberate mixed metaphor in titles of books on Christian ministry and business management.

</doc>
<doc id="6526" url="https://en.wikipedia.org/wiki?curid=6526" title="Cassandra">
Cassandra

Cassandra or Kassandra (Ancient Greek: Κασσάνδρα, , also ), (sometimes referred to as Alexandra), was a priestess of Apollo in Greek mythology cursed to utter true prophecies, but never to be believed. In modern usage her name is employed as a rhetorical device to indicate someone whose accurate prophecies are not believed.
Cassandra was reputed to be a daughter of King Priam and Queen Hecuba of Troy. Her older brother was Hector, hero of the Greco-Trojan war. The older and most common versions state that she was admired by the god Apollo, who sought to win her with the gift to see the future. According to Aeschylus, she promised him her favors, but after receiving the gift, she went back on her word and refused the god. The enraged Apollo could not revoke a divine power, so he added to it the curse that though she would see the future, nobody would believe her prophecies. In other sources, such as Hyginus and Pseudo-Apollodorus, Cassandra broke no promise; the powers were given to her as an enticement. When these failed to make her love him, Apollo cursed Cassandra to always be disbelieved, in spite of the truth of her words.
Some later versions have her falling asleep in a temple, where the snakes licked (or whispered in) her ears so that she could hear the future.
Cassandra became a figure of epic tradition and of tragedy.
Hjalmar Frisk ("Griechisches Etymologisches Wörterbuch", Heidelberg, 1960–1970) notes "unexplained etymology", citing "various hypotheses" found in Wilhelm Schulze, Edgar Howard Sturtevant, J. Davreux, and . R. S. P. Beekes cites García Ramón's derivation of the name from the Proto-Indo-European root *"(s)kend-" "raise".
Cassandra was a princess of Troy, the daughter of King Priam and Queen Hecuba and the fraternal twin sister of Helenus. Cassandra is described as beautiful and clever, but was considered insane.
Cassandra was given the gift of prophecy, but was also cursed by the god Apollo so that her true prophecies would not be believed. Many versions of the myth relate that she incurred the god's wrath by refusing him sex, after promising herself to him in exchange for the power of prophecy. In Aeschylus' "Agamemnon", she bemoans her relationship with Apollo:
<poem>Apollo, Apollo!
God of all ways, but only Death's to me,
Once and again, O thou, Destroyer named,
Thou hast destroyed me, thou, my love of old!</poem>
And she acknowledges her fault
<poem>I consented [marriage] to Loxias [Apollo] but broke my word. ... Ever since that fault I could persuade no one of anything.</poem>
Latin author Hyginus in Fabulae says:
In some versions of the myth, Apollo curses her by spitting into her mouth.
Cassandra had served as a priestess of Apollo and taken a sacred vow of chastity to remain a virgin for life.
Her cursed gift from Apollo became an endless pain and frustration to her. She was seen as a liar and a madwoman by her family and by the Trojan people. In some versions, she was often locked up in a pyramidal building on the citadel on the orders of her father, King Priam. She was accompanied there by the wardress, who cared for her under orders to inform the King of all of his daughter's "prophetic utterances".
According to legend, Cassandra had instructed her twin brother Helenus in the art of prophecy. Like her, Helenus was always correct whenever he had made his predictions, but he was believed.
Cassandra made many predictions, all disbelieved except one, when she foresaw who Paris was and proclaimed that he was her abandoned brother. Cassandra foresaw that Paris’ abduction of Helen for his wife would bring about the Trojan War and warned Paris not to go to Sparta. Helenus echoed her prophecy, but his warnings were ignored. Cassandra saw Helen coming into Troy when Paris returned home from Sparta. Though the people rejoiced, Cassandra furiously snatched away Helen's golden veil and tore at her hair, for she foresaw that Helen's arrival would bring the city's destruction in the Trojan War.
Cassandra foresaw the destruction of Troy. In various accounts of the war, she warned the Trojans about the Greeks hiding inside the Trojan Horse, Agamemnon's death, her own demise at the hands of Aegisthus and Clytemnestra, her mother Hecuba's fate, Odysseus's ten-year wanderings before returning to his home, and the murder of Aegisthus and Clytemnestra by the latter's children Electra and Orestes. Cassandra predicted that her cousin Aeneas would escape during the fall of Troy and found a new nation in Rome. However, her warnings were all disregarded.
Coroebus and Othronus came to the aid of Troy during the Trojan War out of love for Cassandra and in exchange for her hand in marriage, but both were killed. According to one account, Priam offered Cassandra to Telephus’s son Eurypylus, in order to induce Eurypylus to fight on the side of the Trojans. Cassandra was also the first to see the body of her brother Hector being brought back to the city.
In "The Fall of Troy", told by Quintus Smyrnaeus, Cassandra had attempted to warn the Trojan people that Greek warriors were hiding in the Trojan Horse while they were celebrating their victory over the Greeks with feasting. They disbelieved her, calling her names and degrading her with insults. She grabbed an axe in one hand and a burning torch in her other, and ran towards the Trojan Horse, intent on destroying the Greeks herself, but the Trojans stopped her. The Greeks hiding inside the Horse were relieved, but alarmed by how clearly she had divined their plan.
At the fall of Troy, Cassandra sought shelter in the temple of Athena. There she embraced the wooden statue of Athena in supplication for her protection, but was abducted and brutally raped by Ajax the Lesser. Cassandra clung so tightly to the statue of the goddess that Ajax knocked it from its stand as he dragged her away. One account claimed that even Athena, who had worked hard to help the Greeks destroy Troy, was not able to restrain her tears and her cheeks burned with anger. In one account, this caused her image to give forth a sound that shook the floor of the temple at the sight of Cassandra's rape, and her image turned its eyes away as Cassandra was violated, although others found this account too bold. Ajax's actions were a sacrilege because Cassandra was a supplicant at the sanctuary, and thus under the protection of the goddess. He further defiled the temple with sexual intercourse by raping her.
Odysseus insisted to the other Greek leaders that Ajax should be stoned to death for his sacrilege, which had enraged Athena and the other gods. Ajax avoided their wrath, because none of them dared to punish him after he clung, as a supplicant, to Athena's altar and swore an oath proclaiming his innocence. Athena was furious at the Greeks' failure to punish Ajax, and she avenged herself with the help of Poseidon and Zeus. Poseidon sent storms and strong winds to destroy much of the Greek fleet on their way home from Troy. Athena herself inflicted a terrible death on Ajax, although the sources differ as to the manner of his death. The Locrians had to atone for Ajax's crimes by sending two maidens to Troy every year for a thousand years to serve as slaves in Athena's temple. However, if they were caught by the inhabitants before they reached the temple, they were executed.
In some versions, Cassandra intentionally left a chest behind in Troy, with a curse on whichever Greek opened it first. Inside the chest was an image of Dionysus, made by Hephaestus and presented to the Trojans by Zeus. It was given to the Greek leader Eurypylus as a part of his share of the victory spoils of Troy. When he opened the chest and saw the image of the god, he went mad.
Cassandra was then taken as a "pallake" (concubine) by King Agamemnon of Mycenae. Unbeknown to Agamemnon, while he was away at war, his wife, Clytemnestra, had betrayed him by taking Aegisthus as her lover. Clytemnestra and Aegisthus then murdered both Agamemnon and Cassandra. Some sources mention that Cassandra and Agamemnon had twin boys, Teledamus and Pelops, both of whom were killed by Aegisthus.
Cassandra was sent to the Elysian Fields after her death, because her soul was judged worthy due to her dedication to the gods, and her piety during her life.
Cassandra was buried either at Amyclae or Mycenae. The two towns disputed the possession of her grave. Heinrich Schliemann was certain that he had discovered Cassandra's tomb when he had excavated Mycenae, because he found the remains of a woman and two infants in one of the circle graves at Mycenae.
The play "Agamemnon" from Aeschylus's trilogy "Oresteia" depicts the king treading the scarlet cloth laid down for him, and walking offstage to his death. After the chorus's ode of foreboding, time is suspended in Cassandra's "mad scene". She has been onstage, silent and ignored. Her madness that is unleashed now is not the physical torment of other characters in Greek tragedy, such as in Euripides' "Heracles" or Sophocles' "Ajax".
According to author Seth Schein, two further familiar descriptions of her madness are that of Heracles in "The Women of Trachis" or Io in "Prometheus Bound". She speaks, disconnectedly and transcendent, in the grip of her psychic possession by Apollo, witnessing past and future events. Schein says, "She evokes the same awe, horror and pity as do schizophrenics". Cassandra is one of those "who often combine deep, true insight with utter helplessness, and who retreat into madness."
Eduard Fraenkel remarked on the powerful contrasts between declaimed and sung dialogue in this scene. The frightened and respectful chorus are unable to comprehend her. She goes to her inevitable offstage murder by Clytemnestra with full knowledge of what is to befall her.
Cassandra is an enduring archetype. Modern invocations of Cassandra are most frequently an example of a Cassandra complex. To emphasize such a situation, Cassandra's name is frequently used in fiction when the prophecy comes up, especially true prophecy that is not believed. This can include the names of people, objects, or places.
Cassandra has been used as a metaphor and allegory in psychological and philosophical tracts. For example, Florence Nightingale's book "Suggestions for Thought to Searchers after Religious Truth" has a section named for Cassandra, using her as a metaphor for the helplessness of women that she attributes to over-feminization (further examples are located on the Cassandra complex page).
The Cassandra myth itself has also been retold several times by modern authors of novels and dramatizations, including works by Eric Shanower, Lindsay Clarke, Christa Wolf, Lesya Ukrainka, Woody Allen, Marion Zimmer Bradley, David Gemmell, and Hector Berlioz. Several songs have also referred to her, such as "Cassandra" (1982), by Swedish pop band ABBA, and Al Stewart's, "Helen & Cassandra" (1988). 
Cassandra appears as a minor character in William Shakespeare's play Troilus and Cressida.

</doc>
<doc id="6530" url="https://en.wikipedia.org/wiki?curid=6530" title="Couplet">
Couplet

A couplet is a pair of successive lines of metre in poetry. A couplet usually consists of two successive lines that rhyme and have the same metre. A couplet may be formal (closed) or run-on (open). In a formal (or closed) couplet, each of the two lines is end-stopped, implying that there is a grammatical pause at the end of a line of verse. In a run-on (or open) couplet, the meaning of the first line continues to the second.
The word "couplet" comes from the French word meaning "two pieces of iron riveted or hinged together". The term "couplet" was first used to describe successive lines of verse in Sir P. Sidney's " Arcadia " in 1590: "In singing some short coplets, whereto the one halfe beginning, the other halfe should answere."
While couplets traditionally rhyme, not all do. Poems may use white space to mark out couplets if they do not rhyme. Couplets in iambic pentameter are called "heroic couplets". John Dryden in the 17th century and Alexander Pope in the 18th century were both well known for their writing in heroic couplets. The Poetic epigram is also in the couplet form. Couplets can also appear as part of more complex rhyme schemes, such as sonnets.
Rhyming couplets are one of the simplest rhyme schemes in poetry. Because the rhyme comes so quickly, it tends to call attention to itself. Good rhyming couplets tend to "explode" as both the rhyme and the idea come to a quick close in two lines. Here are some examples of rhyming couplets where the sense as well as the sound "rhymes":
On the other hand, because rhyming couplets have such a predictable rhyme scheme, they can feel artificial and plodding. Here is a Pope parody of the predictable rhymes of his era:
Rhyming couplets are often used in Early Modern English poetry, as seen in Chaucer's "The Canterbury Tales". This work of literature is written almost entirely in rhyming couplets. Similarly, Shakespearean sonnets often employ rhyming couplets at the end to emphasize the theme. Take one of Shakespeare's most famous sonnets, Sonnet 18, for example (the rhyming couplet is shown in italics):
Chinese couplets or "contrapuntal couplets" may be seen on doorways in Chinese communities worldwide. Couplets displayed as part of the Chinese New Year festival, on the first morning of the New Year, are called "chunlian" (春联). These are usually purchased at a market a few days before and glued to the doorframe. The text of the couplets is often traditional and contains hopes for prosperity. Other chunlian reflect more recent concerns. For example, the CCTV New Year's Gala usually promotes couplets reflecting current political themes in mainland China.
Some Chinese couplets may consist of two lines of four characters each. Couplets are read from top to bottom where the first pline starts from the right. But is also a 6 word diagraph with 19 lines
Tamil literature contains some of the best known examples of ancient couplet poetry. The Tamil language has a rich and refined grammar for couplet poetry, and distichs in Tamil poetry follow the venpa metre. The most famous example for Tamil couplet poetry is the ancient Tamil moral text of Tirukkural, which contains a total of 1330 couplets written in the kural venpa metre from which the title of the work was derived centuries later. Each Kural couplet is made of exactly 7 words—4 in the first line and 3 in the second. The first word may rhyme with the fourth or the fifth word. Below is an example of a couplet:
The American poet J. V. Cunningham was noted for many distichs included in the various forms of epigrams included in his poetry collections, as exampled here:
Deep summer, and time passes. Sorrow wastes<br>To a new sorrow. While Time heals time hastes

</doc>
<doc id="6532" url="https://en.wikipedia.org/wiki?curid=6532" title="Charlotte Brontë">
Charlotte Brontë

Charlotte Brontë (, ; 21 April 1816 – 31 March 1855) was an English novelist and poet, the eldest of the three Brontë sisters who survived into adulthood and whose novels became classics of English literature.
She enlisted in school at Roe Head in January 1831, aged 14 years. She left the year after to teach her sisters, Emily and Anne, at home, returning in 1835 as a governess. In 1839 she undertook the role as governess for the Sidgwick family but left after a few months to return to Haworth where the sisters opened a school, but failed to attract pupils. Instead, they turned to writing and they each first published in 1846 under the pseudonyms of Currer, Ellis and Acton Bell. While her first novel, "The Professor", was rejected by publishers, her second novel, "Jane Eyre", was published in 1847. The sisters admitted to their Bell pseudonyms in 1848, and by the following year were celebrated in London literary circles.
Brontë was the last to die of all her siblings. She became pregnant shortly after her marriage in June 1854 but died on 31 March 1855, almost certainly from hyperemesis gravidarum, a complication of pregnancy which causes excessive nausea and vomiting.
Charlotte Brontë was born on 21 April 1816 in Market Street Thornton, west of Bradford in the West Riding of Yorkshire, the third of the six children of Maria (née Branwell) and Patrick Brontë (formerly surnamed Brunty), an Irish Anglican clergyman. In 1820 her family moved a few miles to the village of Haworth, where her father had been appointed perpetual curate of St Michael and All Angels Church. Maria died of cancer on 15 September 1821, leaving five daughters, Maria, Elizabeth, Charlotte, Emily and Anne, and a son, Branwell, to be taken care of by her sister, Elizabeth Branwell.
In August 1824, Patrick sent Charlotte, Emily, Maria, and Elizabeth to the Clergy Daughters' School at Cowan Bridge in Lancashire. Charlotte maintained that the school's poor conditions permanently affected her health and physical development, and hastened the deaths of Maria (born 1814) and Elizabeth (born 1815), who both died of tuberculosis in June 1825. After the deaths of his older daughters, Patrick removed Charlotte and Emily from the school. Charlotte used the school as the basis for Lowood School in "Jane Eyre".
At home in Haworth Parsonage, Brontë acted as "the motherly friend and guardian of her younger sisters". Brontë wrote her first known poem at the age of 13 in 1829, and was to go on to write more than 200 poems in the course of her life. Many of her poems were "published" in their homemade magazine "Branwell's Blackwood's Magazine", and concerned the fictional Glass Town Confederacy. She and her surviving siblings – Branwell, Emily and Anne – created their own fictional worlds, and began chronicling the lives and struggles of the inhabitants of their imaginary kingdoms. Charlotte and Branwell wrote Byronic stories about their jointly imagined country, Angria, and Emily and Anne wrote articles and poems about Gondal. The sagas they created were episodic and elaborate, and they exist in incomplete manuscripts, some of which have been published as juvenilia. They provided them with an obsessive interest during childhood and early adolescence, which prepared them for literary vocations in adulthood.
Between 1831 and 1832, Brontë continued her education at Roe Head in Mirfield, where she met her lifelong friends and correspondents Ellen Nussey and Mary Taylor. In 1833 she wrote a novella, "The Green Dwarf", using the name Wellesley. Around about 1833, her stories shifted from tales of the supernatural to more realistic stories. She returned to Roe Head as a teacher from 1835 to 1838. Unhappy and lonely as a teacher at Roe Head, Brontë took out her sorrows in poetry, writing a series of melancholic poems. In "We wove a Web in Childhood" written in December 1835, Brontë drew a sharp contrast between her miserable life as a teacher and the vivid imaginary worlds she and her siblings had created. In another poem "Morning was its freshness still" written at the same time, Brontë wrote "Tis bitter sometimes to recall/Illusions once deemed fair". Many of her poems concerned the imaginary world of Angria, often concerning Byronic heroes, and in December 1836 she wrote to the Poet Laureate Robert Southey asking him for encouragement of her career as a poet. Southey replied, famously, that "Literature cannot be the business of a woman's life, and it ought not to be. The more she is engaged in her proper duties, the less leisure will she have for it even as an accomplishment and a recreation." This advice she respected but did not heed.
In 1839 she took up the first of many positions as governess to families in Yorkshire, a career she pursued until 1841. In particular, from May to July 1839 she was employed by the Sidgwick family at their summer residence, Stone Gappe, in Lothersdale, where one of her charges was John Benson Sidgwick (1835–1927), an unruly child who on one occasion threw a Bible at Charlotte, an incident that may have been the inspiration for a part of the opening chapter of "Jane Eyre" in which John Reed throws a book at the young Jane. Brontë did not enjoy her work as a governess, noting her employers treated her almost as a slave, constantly humiliating her.
Brontë was of slight build and was less than five feet tall.
In 1842 Charlotte and Emily travelled to Brussels to enrol at the boarding school run by Constantin Héger (1809–1896) and his wife Claire Zoé Parent Héger (1804–1887). During her time in Brussels, Brontë, who favoured the Protestant ideal of an individual in direct contact with God, objected to the stern Catholicism of Madame Héger, which she considered a tyrannical religion that enforced conformity and submission to the Pope. In return for board and tuition Charlotte taught English and Emily taught music. Their time at the school was cut short when their aunt Elizabeth Branwell, who had joined the family in Haworth to look after the children after their mother's death, died of internal obstruction in October 1842. Charlotte returned alone to Brussels in January 1843 to take up a teaching post at the school. Her second stay was not happy: she was homesick and deeply attached to Constantin Héger. She returned to Haworth in January 1844 and used the time spent in Brussels as the inspiration for some of the events in "The Professor" and "Villette".
After returning to Haworth, Charlotte and her sisters made headway with opening their own boarding school in the family home. It was advertised as "The Misses Brontë's Establishment for the Board and Education of a limited number of Young Ladies" and inquiries were made to prospective pupils and sources of funding. But none were attracted and in October 1844, the project was abandoned.
In May 1846 Charlotte, Emily, and Anne self-financed the publication of a joint collection of poems under their assumed names Currer, Ellis and Acton Bell. The pseudonyms veiled the sisters' sex while preserving their initials; thus Charlotte was Currer Bell. "Bell" was the middle name of Haworth's curate, Arthur Bell Nicholls whom Charlotte later married, and "Currer" was the surname of Frances Mary Richardson Currer who had funded their school (and maybe their father). Of the decision to use "noms de plume", Charlotte wrote:
Although only two copies of the collection of poems were sold, the sisters continued writing for publication and began their first novels, continuing to use their "noms de plume" when sending manuscripts to potential publishers.
Brontë's first manuscript, "The Professor", did not secure a publisher, although she was heartened by an encouraging response from Smith, Elder & Co. of Cornhill, who expressed an interest in any longer works Currer Bell might wish to send. Brontë responded by finishing and sending a second manuscript in August 1847. Six weeks later, "Jane Eyre" was published. It tells the story of a plain governess, Jane, who, after difficulties in her early life, falls in love with her employer, Mr Rochester. They marry, but only after Rochester's insane first wife, of whom Jane initially has no knowledge, dies in a dramatic house fire. The book's style was innovative, combining naturalism with gothic melodrama, and broke new ground in being written from an intensely evoked first-person female perspective. Brontë believed art was most convincing when based on personal experience; in "Jane Eyre" she transformed the experience into a novel with universal appeal.
"Jane Eyre" had immediate commercial success and initially received favourable reviews. G. H. Lewes wrote that it was "an utterance from the depths of a struggling, suffering, much-enduring spirit", and declared that it consisted of ""suspiria de profundis"!" (sighs from the depths). Speculation about the identity and gender of the mysterious Currer Bell heightened with the publication of "Wuthering Heights" by Ellis Bell (Emily) and "Agnes Grey" by Acton Bell (Anne). Accompanying the speculation was a change in the critical reaction to Brontë's work, as accusations were made that the writing was "coarse", a judgement more readily made once it was suspected that Currer Bell was a woman. However, sales of "Jane Eyre" continued to be strong and may even have increased as a result of the novel developing a reputation as an "improper" book. A talented amateur artist, Brontë personally did the drawings for the second edition of "Jane Eyre" and in the summer of 1834 two of her paintings were shown at an exhibition by the Royal Northern Society for the Encouragement of the Fine Arts in Leeds.
In 1848 Brontë began work on the manuscript of her second novel, "Shirley". It was only partially completed when the Brontë family suffered the deaths of three of its members within eight months. In September 1848 Branwell died of chronic bronchitis and marasmus, exacerbated by heavy drinking, although Brontë believed that his death was due to tuberculosis. Branwell may have had a laudanum addiction. Emily became seriously ill shortly after his funeral and died of pulmonary tuberculosis in December 1848. Anne died of the same disease in May 1849. Brontë was unable to write at this time.
After Anne's death Brontë resumed writing as a way of dealing with her grief, and "Shirley", which deals with themes of industrial unrest and the role of women in society, was published in October 1849. Unlike "Jane Eyre", which is written in the first person, "Shirley" is written in the third person and lacks the emotional immediacy of her first novel, and reviewers found it less shocking. Brontë, as her late sister's heir, suppressed the republication of Anne's second novel, "The Tenant of Wildfell Hall", an action which had a deleterious effect on Anne's popularity as a novelist and has remained controversial among the sisters' biographers ever since.
In view of the success of her novels, particularly "Jane Eyre", Brontë was persuaded by her publisher to make occasional visits to London, where she revealed her true identity and began to move in more exalted social circles, becoming friends with Harriet Martineau and Elizabeth Gaskell, and acquainted with William Makepeace Thackeray and G.H. Lewes. She never left Haworth for more than a few weeks at a time, as she did not want to leave her ageing father. Thackeray's daughter, writer Anne Isabella Thackeray Ritchie, recalled a visit to her father by Brontë:
Brontë's friendship with Elizabeth Gaskell, while not particularly close, was significant in that Gaskell wrote the first biography of Brontë after her death in 1855.
Brontë's third novel, the last published in her lifetime, was "Villette", which appeared in 1853. Its main themes include isolation, how such a condition can be borne, and the internal conflict brought about by social repression of individual desire. Its main character, Lucy Snowe, travels abroad to teach in a boarding school in the fictional town of Villette, where she encounters a culture and religion different from her own and falls in love with a man (Paul Emanuel) whom she cannot marry. Her experiences result in a breakdown but eventually, she achieves independence and fulfilment through running her own school. A substantial amount of the novel's dialogue is in the French language. "Villette" marked Brontë's return to writing from a first-person perspective (that of Lucy Snowe), the technique she had used in "Jane Eyre". Another similarity to "Jane Eyre" lies in the use of aspects of her own life as inspiration for fictional events, in particular her reworking of the time she spent at the "pensionnat" in Brussels. "Villette" was acknowledged by critics of the day as a potent and sophisticated piece of writing although it was criticised for "coarseness" and for not being suitably "feminine" in its portrayal of Lucy's desires.
Before the publication of "Villette", Brontë received an expected proposal of marriage from Arthur Bell Nicholls, her father's curate, who had long been in love with her. She initially turned down his proposal and her father objected to the union at least partly because of Nicholls's poor financial status. Elizabeth Gaskell, who believed that marriage provided "clear and defined duties" that were beneficial for a woman, encouraged Brontë to consider the positive aspects of such a union and tried to use her contacts to engineer an improvement in Nicholls's finances. Brontë meanwhile was increasingly attracted to Nicholls and by January 1854 she had accepted his proposal. They gained the approval of her father by April and married in June. Her father Patrick had intended to give Charlotte away, but at the last minute decided he could not, and Charlotte had to make her way to the church without him. The married couple took their honeymoon in Banagher, County Offaly, Ireland. By all accounts, her marriage was a success and Brontë found herself very happy in a way that was new to her.
Brontë became pregnant soon after her wedding, but her health declined rapidly and, according to Gaskell, she was attacked by "sensations of perpetual nausea and ever-recurring faintness". She died, with her unborn child, on 31 March 1855, three weeks before her 39th birthday. Her death certificate gives the cause of death as tuberculosis, but biographers including Claire Harman and others suggest that she died from dehydration and malnourishment due to vomiting caused by severe morning sickness or hyperemesis gravidarum. Brontë was buried in the family vault in the Church of St Michael and All Angels at Haworth.
"The Professor", the first novel Brontë had written, was published posthumously in 1857. The fragment of a new novel she had been writing in her last years has been twice completed by recent authors, the more famous version being "Emma Brown: A Novel from the Unfinished Manuscript by Charlotte Brontë" by Clare Boylan in 2003. Most of her writings about the imaginary country Angria have also been published since her death. In 2018, "The New York Times" published a belated obituary for her.
The daughter of an Irish Anglican clergyman, Brontë was herself an Anglican. In a letter to her publisher, she claims to "love the Church of England. Her Ministers indeed, I do not regard as infallible personages, I have seen too much of them for that – but to the Establishment, with all her faults – the profane Athanasian Creed excluded – I am sincerely attached."
In a letter to Ellen Nussey she wrote: 
Elizabeth Gaskell's biography "The Life of Charlotte Brontë" was published in 1857. It was an important step for a leading female novelist to write a biography of another, and Gaskell's approach was unusual in that, rather than analysing her subject's achievements, she concentrated on private details of Brontë's life, emphasising those aspects that countered the accusations of "coarseness" that had been levelled at her writing. The biography is frank in places, but omits details of Brontë's love for Héger, a married man, as being too much of an affront to contemporary morals and a likely source of distress to Brontë's father, widower, and friends. Mrs Gaskell also provided doubtful and inaccurate information about Patrick Brontë, claiming that he did not allow his children to eat meat. This is refuted by one of Emily Brontë's diary papers, in which she describes preparing meat and potatoes for dinner at the parsonage. It has been argued that Gaskell's approach transferred the focus of attention away from the 'difficult' novels, not just Brontë's, but all the sisters', and began a process of sanctification of their private lives.
On 29 July 1913 "The Times" of London printed four letters Brontë had written to Constantin Héger after leaving Brussels in 1844. Written in French except for one postscript in English, the letters broke the prevailing image of Brontë as an angelic martyr to Christian and female duties that had been constructed by many biographers, beginning with Gaskell. The letters, which formed part of a larger and somewhat one-sided correspondence in which Héger frequently appears not to have replied, reveal that she had been in love with a married man, although they are complex and have been interpreted in numerous ways, including as an example of literary self-dramatisation and an expression of gratitude from a former pupil.
In 1980 a commemorative plaque was unveiled at the Centre for Fine Arts, Brussels (BOZAR), on the site of the Madam Heger's school, in honour of Charlotte and Emily. In May 2017 the plaque was cleaned.
"The Green Dwarf, A Tale of the Perfect Tense" was written in 1833 under the pseudonym Lord Charles Albert Florian Wellesley. It shows the influence of Walter Scott, and Brontë's modifications to her earlier gothic style have led Christine Alexander to comment that, in the work, "it is clear that Brontë was becoming tired of the gothic mode "per se"".

</doc>
<doc id="6533" url="https://en.wikipedia.org/wiki?curid=6533" title="Charles Williams (British writer)">
Charles Williams (British writer)

Charles Walter Stansby Williams (20 September 1886 – 15 May 1945) was a British poet, novelist, playwright, theologian, literary critic, and member of the Inklings.
Williams was born in London in 1886, the only son of (Richard) Walter Stansby Williams (1848–1929), a journalist and foreign business correspondent for an importing firm, writing in French and German, who was a 'regular and valued' contributor of verse, stories and articles to many popular magazines, and his wife Mary (née Wall, the sister of the ecclesiologist and historian J. Charles Wall), a former milliner, of Islington. He had one sister, Edith, born in 1889. The Williams family lived in 'shabby-genteel' circumstances, owing to Walter's increasing blindness and the decline of the firm by which he was employed, in Holloway.
In 1894 the family moved to St Albans in Hertfordshire, where Williams lived until his marriage in 1917.
Educated at St Albans School, Williams was awarded a scholarship to University College London, but he left school in 1904 without attempting to gain a degree due to an inability to pay tuition fees.
Williams began work in 1904 in a Methodist bookroom. He was hired by the Oxford University Press (OUP) as a proofreading assistant in 1908 and quickly climbed to the position of editor. He continued to work at the OUP in various positions of increasing responsibility until his death in 1945. One of his greatest editorial achievements was the publication of the first major English-language edition of the works of Søren Kierkegaard. His work was part of the literature event in the art competition at the 1924 Summer Olympics.
Although chiefly remembered as a novelist, Williams also published poetry, works of literary criticism, theology, drama, history, biography, and a voluminous number of book reviews. Some of his best known novels are "War in Heaven" (1930), "Descent into Hell" (1937), and "All Hallows' Eve" (1945). T. S. Eliot, who wrote an introduction for the last of these, described Williams's novels as "supernatural thrillers" because they explore the sacramental intersection of the physical with the spiritual while also examining the ways in which power, even spiritual power, can corrupt as well as sanctify. All of Williams's fantasies, unlike those of J. R. R. Tolkien and most of those of C. S. Lewis, are set in the contemporary world. Williams has been described by Colin Manlove as one of the three main writers of "Christian fantasy" in the twentieth century (the other two being C.S. Lewis and T. F. Powys). More recent writers of fantasy novels with contemporary settings, notably Tim Powers, cite Williams as a model and inspiration. W. H. Auden, one of Williams's greatest admirers, reportedly re-read Williams's extraordinary and highly unconventional history of the church, "The Descent of the Dove" (1939), every year. Williams's study of Dante entitled "The Figure of Beatrice" (1944) was very highly regarded at its time of publication and continues to be consulted by Dante scholars today. His work inspired Dorothy L. Sayers to undertake her translation of "The Divine Comedy". Williams, however, regarded his most important work to be his extremely dense and complex Arthurian poetry, of which two books were published, "Taliessin through Logres" (1938) and "The Region of the Summer Stars" (1944), and more remained unfinished at his death. Some of Williams's essays were collected and published posthumously in "Image of the City and Other Essays" (1958), edited by Anne Ridler.
Williams gathered many followers and disciples during his lifetime. He was, for a period, a member of the Salvator Mundi Temple of the Fellowship of the Rosy Cross. He met fellow Anglican Evelyn Underhill (who was affiliated with a similar group, the Order of the Golden Dawn) in 1937 and was later to write the introduction to her published "Letters" in 1943.
When World War II broke out in 1939, Oxford University Press moved its offices from London to Oxford. Williams was reluctant to leave his beloved city, and his wife Florence refused to go. From the nearly 700 letters he wrote his wife during the war years a generous selection has been published; "primarily… love letters," the editor calls them. But the move to Oxford did allow him to participate regularly in Lewis's literary society known as the Inklings. In this setting Williams was able to read (and improve) his final published novel, "All Hallows' Eve", as well as to hear J. R. R. Tolkien read aloud to the group some of his early drafts of "The Lord of the Rings". In addition to meeting in Lewis's rooms at Oxford, they also regularly met at The Eagle and Child pub in Oxford (better known by its nickname "The Bird and Baby"). During this time Williams also gave lectures at Oxford on John Milton, William Wordsworth, and other authors, and received an honorary M.A. degree. Williams is buried in Holywell Cemetery in Oxford: his headstone bears the word "poet", followed by the words "Under the Mercy", a phrase often used by Williams himself.
In 1917 Williams married his first sweetheart, Florence Conway, following a long courtship during which he presented her with a sonnet sequence that would later become his first published book of poetry, "The Silver Stair". Their son Michael was born in 1922.
Williams was an unswerving and devoted member of the Church of England, reputedly with a tolerance of the scepticism of others and a firm belief in the necessity of a "doubting Thomas" in any apostolic body.
Although Williams attracted the attention and admiration of some of the most notable writers of his day, including T. S. Eliot and W. H. Auden, his greatest admirer was probably C. S. Lewis, whose novel "That Hideous Strength" (1945) has been regarded as partially inspired by his acquaintance with both the man and his novels and poems. Williams came to know Lewis after reading Lewis's then-recently published study "The Allegory of Love"; he was so impressed he jotted down a letter of congratulation and dropped it in the mail. Coincidentally, Lewis had just finished reading Williams's novel "The Place of the Lion" and had written a similar note of congratulation. The letters crossed in the mail and led to an enduring and fruitful friendship.
Williams developed the concept of co-inherence and gave rare consideration to the theology of romantic love. Falling in love for Williams was a form of mystical envisioning in which one saw the beloved as he or she was seen through the eyes of God. Co-inherence was a term used in Patristic theology to describe the relationship between the human and divine natures of Jesus Christ and the relationship between the persons of the blessed Trinity. Williams extended the term to include the ideal relationship between the individual parts of God's creation, including human beings. It is our mutual indwelling: Christ in us and we in Christ, interdependent. It is also the web of interrelationships, social and economic and ecological, by which the social fabric and the natural world function. But especially for Williams, co-inherence is a way of talking about the Body of Christ and the communion of saints. For Williams, salvation was not a solitary affair: "The thread of the love of God was strong enough to save you and all the others, but not strong enough to save you alone." He proposed an order, the Companions of the Co-inherence, who would practice substitution and exchange, living in love-in-God, truly bearing one another's burdens, being willing to sacrifice and to forgive, living from and for one another in Christ. According to Gunnar Urang, co-inherence is the focus of all Williams's novels.

</doc>
<doc id="6535" url="https://en.wikipedia.org/wiki?curid=6535" title="Celery">
Celery

Celery ("Apium graveolens") is a marshland plant in the family Apiaceae that has been cultivated as a vegetable since antiquity. Celery has a long fibrous stalk tapering into leaves. Depending on location and cultivar, either its stalks, leaves or hypocotyl are eaten and used in cooking. Celery seed is also used as a spice and its extracts have been used in herbal medicine.
Celery leaves are pinnate to bipinnate with rhombic leaflets long and broad. The flowers are creamy-white, in diameter, and are produced in dense compound umbels. The seeds are broad ovoid to globose, long and wide. Modern cultivars have been selected for solid petioles, leaf stalks. A celery stalk readily separates into "strings" which are bundles of angular collenchyma cells exterior to the vascular bundles.
Wild celery, "Apium graveolens" var. "graveolens", grows to tall.
It occurs around the globe. The first cultivation is thought to have happened in the Mediterranean region, where the natural habitats were salty and wet, or marshy soils near the coast where celery grew in agropyro-rumicion-plant communities.
North of the Alps, wild celery is found only in the foothill zone on soils with some salt content. It prefers moist or wet, nutrient rich, muddy soils. It cannot be found in Austria and is increasingly rare in Germany.
First attested in English in 1664, the word "celery" derives from the French "céleri", in turn from Italian "seleri", the plural of "selero", which comes from Late Latin "selinon", the latinisation of the , "celery". The earliest attested form of the word is the Mycenaean Greek "se-ri-no", written in Linear B syllabic script.
Celery was described by Carl Linnaeus in Volume One of his "Species Plantarum" in 1753.
The plants are raised from seed, sown either in a hot bed or in the open garden according to the season of the year, and, after one or two thinnings and transplantings, they are, on attaining a height of , planted out in deep trenches for convenience of blanching, which is effected by earthing up to exclude light from the stems.
Celery was first grown as a winter and early spring vegetable. It was considered a cleansing tonic to counter the deficiencies of a winter diet based on salted meats without fresh vegetables. By the 19th century, the season for celery in England had been extended, to last from the beginning of September to late in April.
In North America, commercial production of celery is dominated by the cultivar called 'Pascal' celery. Gardeners can grow a range of cultivars, many of which differ from the wild species, mainly in having stouter leaf stems. They are ranged under two classes, white and red.
The stalks grow in tight, straight, parallel bunches, and are typically marketed fresh that way. They market it without roots and just a little green leaf remaining.
The stalks can be eaten raw, or as an ingredient in salads, or as a flavoring in soups, stews, and also in pot roasts.
In Europe, another popular variety is celeriac (also known as "celery root"), "Apium graveolens" var. "rapaceum", grown because its hypocotyl forms a large bulb, white on the inside. The bulb can be kept for months in winter and mostly serves as a main ingredient in soup. It can also be shredded and used in salads.
The leaves are used as seasoning; the small, fibrous stalks find only marginal use.
Leaf celery (Chinese celery, "Apium graveolens var. secalinum") is a cultivar from East Asia that grows in marshlands. Leaf celery has characteristically thin skin stalks and a stronger taste and smell compared to other cultivars. It is used as a flavoring in soups and sometimes pickled as a side dish.
The wild form of celery is known as "smallage". It has a furrowed stalk with wedge-shaped leaves, the whole plant having a coarse, earthy taste, and a distinctive smell. The stalks are not usually eaten (except in soups or stews in French cuisine), but the leaves may be used in salads, and its seeds are those sold as a spice. With cultivation and blanching, the stalks lose their acidic qualities and assume the mild, sweetish, aromatic taste particular to celery as a salad plant.
Because wild celery is rarely eaten, yet susceptible to the same diseases as more well-used cultivars, it is often removed from fields to help prevent transmission of viruses like celery mosaic virus.
Harvesting occurs when the average size of celery in a field is marketable; due to extremely uniform crop growth, fields are harvested only once. The petioles and leaves are removed and harvested; celery is packed by size and quality (determined by color, shape, straightness and thickness of petiole, stalk and midrib length and absence of disease, cracks, splits, insect damage and rot). During commercial harvesting, celery is packaged into cartons which contain between 36 and 48 stalks and weigh up to . Under optimal conditions, celery can be stored for up to seven weeks from . Inner stalks may continue growing if kept at temperatures above . Shelf life can be extended by packaging celery in anti-fogging, micro-perforated shrink wrap. Freshly cut petioles of celery are prone to decay, which can be prevented or reduced through the use of sharp blades during processing, gentle handling, and proper sanitation. 
Celery stalk may be preserved through pickling by first removing the leaves, then boiling the stalks in water before finally adding vinegar, salt, and vegetable oil.
In the past, restaurants used to store celery in a container of water with powdered vegetable preservative, but it was found that the sulfites in the preservative caused allergic reactions in some people. In 1986, the U.S. Food and Drug Administration banned the use of sulfites on fruits and vegetables intended to be eaten raw.
Celery is eaten around the world as a vegetable. In North America the crisp petiole (leaf stalk) is used. In Europe the hypocotyl is used as a root vegetable. The leaves are strongly flavored and are used less often, either as a flavoring in soups and stews or as a dried herb. Celery, onions, and bell peppers are the "holy trinity" of Louisiana Creole and Cajun cuisine. Celery, onions, and carrots make up the French mirepoix, often used as a base for sauces and soups. Celery is a staple in many soups, such as chicken noodle soup. 
Phthalides occur naturally in celery.
Celery leaves are frequently used in cooking to add a mild spicy flavor to foods, similar to, but milder than black pepper. Celery leaves are suitable dried as a sprinkled on seasoning for use with baked, fried or roasted fish, meats and as part of a blend of fresh seasonings suitable for use in soups and stews. They may also be eaten raw, mixed into a salad or as a garnish.
In temperate countries, celery is also grown for its seeds. Actually very small fruit, these "seeds" yield a valuable essential oil that is used in the perfume industry. The oil contains the chemical compound apiole. Celery seeds can be used as flavoring or spice, either as whole seeds or ground.
The seeds can be ground and mixed with salt, to produce celery salt. Celery salt can be made from an extract of the roots or using dried leaves. Celery salt is used as a seasoning, in cocktails (notably to enhance the flavor of Bloody Mary cocktails), on the Chicago-style hot dog, and in Old Bay Seasoning. Similarly, combinations of celery powder and salt are used to flavor & preserve cured pork and other processed meats as an all natural alternative to industrial curing salt. The naturally occurring nitrites in celery work synergistically with the added salt to cure food.
Celery seeds have been used widely in Eastern herbal traditions such as Ayurveda. Aulus Cornelius Celsus wrote that celery seeds could relieve pain in around AD 30.
In 2019, a trend in drinking celery juice was reported in the United States, based on "detoxification" claims from blogger Anthony William, author of "Medical Medium", who says he receives advanced health information from what he calls "Spirit of Compassion" which he says he channels. The health claims have no scientific basis, but the trend caused a sizable spike in celery prices.
Celery is used in weight loss diets, where it provides low-calorie dietary fiber bulk. Celery is often incorrectly thought to be a "negative-calorie food", the digestion of which burns more calories than the body can obtain. In fact, eating celery provides positive net calories, with digestion consuming only a small proportion of the calories taken in.
Celery is among a small group of foods (headed by peanuts) that appear to provoke the most severe allergic reactions; for people with celery allergy, exposure can cause potentially fatal anaphylactic shock. The allergen does not appear to be destroyed at cooking temperatures.
Celery root—commonly eaten as celeriac, or put into drinks—is known to contain more allergen than the stalk. Seeds contain the highest levels of allergen content. Exercise-induced anaphylaxis may be exacerbated.
An allergic reaction also may be triggered by eating foods that have been processed with machines that have previously processed celery, making avoiding such foods difficult.
In contrast with peanut allergy being most prevalent in the US, celery allergy is most prevalent in Central Europe. In the European Union, foods that contain or may contain celery, even in trace amounts, must be clearly marked as such.
Polyynes can be found in Apiaceae vegetables like celery, and their extracts show cytotoxic activities.
Celery contains phenolic acid, which is an antioxidant.
Apiin and apigenin can be extracted from celery and parsley. Lunularin is a dihydrostilbenoid found in common celery.
The main chemicals responsible for the aroma and taste of celery are butylphthalide and sedanolide.
Daniel Zohary and Maria Hopf note that celery leaves and inflorescences were part of the garlands found in the tomb of pharaoh Tutankhamun (died 1323 BC), and celery mericarps dated to the seventh century BC were recovered in the Heraion of Samos. However, they note "since "A. graveolens" grows wild in these areas, it is hard to decide whether these remains represent wild or cultivated forms." Only by classical times is it certain that celery was cultivated.
M. Fragiska mentions an archeological find of celery dating to the 9th century BC, at Kastanas; however, the literary evidence for ancient Greece is far more abundant. In Homer's "Iliad", the horses of the Myrmidons graze on wild celery that grows in the marshes of Troy, and in "Odyssey", there is mention of the meadows of violet and wild celery surrounding the cave of Calypso.
In the "Capitulary" of Charlemagne, compiled ca. 800, "apium" appears, as does "olisatum", or alexanders, among medicinal herbs and vegetables the Frankish emperor desired to see grown. At some later point in medieval Europe celery displaced alexanders.
The name "celery" retraces the plant's route of successive adoption in European cooking, as the English "celery" (1664) is derived from the French "céleri" coming from the Lombard term, "seleri", from the Latin "selinon", borrowed from Greek.
Celery's late arrival in the English kitchen is an end-product of the long tradition of seed selection needed to reduce the sap's bitterness and increase its sugars. By 1699, John Evelyn could recommend it in his "Acetaria. A Discourse of Sallets": "Sellery, apium Italicum, (and of the Petroseline Family) was formerly a stranger with us (nor very long since in Italy) is an hot and more generous sort of Macedonian Persley or Smallage... and for its high and grateful Taste is ever plac'd in the middle of the Grand Sallet, at our Great Men's tables, and Praetors feasts, as the Grace of the whole Board".
Celery makes a minor appearance in colonial American gardens; its culinary limitations are reflected in the observation by the author of "A Treatise on Gardening, by a Citizen of Virginia" that it is "one of the species of parsley." Its first extended treatment in print was in Bernard M'Mahon's "American Gardener's Calendar" (1806). 
After the mid-19th century, continued selections for refined crisp texture and taste brought celery to American tables, where it was served in celery vases to be salted and eaten raw. Celery was so popular in the United States in the 1800s and early 1900s that the New York Public Library's historical menu archive shows that it was the third most popular dish in New York City menus during that time, behind only coffee and tea. In those days celery cost more than caviar, as it was difficult to cultivate. There were also many varieties of celery back then that are no longer around because they are difficult to grow and do not ship well.
A chthonian symbol among the ancient Greeks, celery was said to have sprouted from the blood of Kadmilos, father of the Cabeiri, chthonian divinities celebrated in Samothrace, Lemnos, and Thebes . The spicy odor and dark leaf color encouraged this association with the cult of death. In classical Greece, celery leaves were used as garlands for the dead, and the wreaths of the winners at the Isthmian Games were first made of celery before being replaced by crowns made of pine. According to Pliny the Elder in Achaea, the garland worn by the winners of the sacred Nemean Games was also made of celery. The Ancient Greek colony of Selinous (, "Selinous"), on Sicily, was named after wild parsley that grew abundantly there; Selinountian coins depicted a parsley leaf as the symbol of the city.

</doc>
<doc id="6536" url="https://en.wikipedia.org/wiki?curid=6536" title="CPM">
CPM

CPM may refer to:

</doc>
<doc id="6537" url="https://en.wikipedia.org/wiki?curid=6537" title="Celestines">
Celestines

The Celestines were a Roman Catholic monastic order, a branch of the Benedictines, founded in 1244. At the foundation of the new rule, they were called Hermits of St Damiano, or Moronites (or Murronites), and did not assume the appellation of Celestines until after the election of their founder, Peter of Morone (Pietro Murrone), to the Papacy as Celestine V. They used the post-nominal initials O.S.B. Cel. The order was absorbed by Order of the Most Holy Annunciation from 1778 by order of Pius VI in 1776. In 1810 the last Celestines were transferred.
The fame of the holy life and the austerities practised by Pietro Morone in his solitude on the Mountain of Majella, near Sulmona, attracted many visitors, several of whom were moved to remain and share his mode of life. They built a small convent on the spot inhabited by the holy hermit, which became too small for the accommodation of those who came to share their life of privations. Peter of Morone (later Pope Celestine V), their founder, built a number of other small oratories in that neighborhood.
About the year 1254, Peter of Morone gave the order a rule formulated in accordance with his own practices. In 1264 the new institution was approved as a branch of the Benedictines by Urban IV; however, the next pope Pope Gregory X had commanded that all orders founded since the prior Lateran Council should not be further multiplied. Hearing a rumor that the order was to be suppressed, the reclusive Peter traveled to Lyon, where the Pope was holding a council. There he persuaded Gregory to approve his new order, making it a branch of the Benedictines and following the rule of Saint Benedict, but adding to it additional severities and privations. Gregory took it under the Papal protection, assured to it the possession of all property it might acquire, and endowed it with exemption from the authority of the ordinary. Nothing more was needed to ensure the rapid spread of the new association and Peter the hermit of Morone lived to see himself "Superior-General" to thirty-six monasteries and more than six hundred monks. 
As soon as he had seen his new order thus consolidated he gave up the government of it to a certain Robert, and retired once again to an even more remote site to devote himself to solitary penance and prayer. Shortly afterwards, in a chapter of the order held in 1293, the original monastery of Majella being judged to be too desolate and exposed to too rigorous a climate, it was decided that the Abbey of the Holy Spirit at Monte Morrone, located in Sulmona, should be the headquarters of the order and the residence of the General-Superior, where it continued for centuries. The next year Peter of Morrone, despite his reluctance, was elected Pope by the name of Celestine V. From there on, the order he had founded took the name of Celestines. During his short reign as Pope, the former hermit confirmed the rule of the order, which he had himself composed, and conferred on the society a variety of special graces and privileges. In the only creation of cardinals promoted by him, among the twelve raised to the purple, there were two monks of his order. He also visited personally the Benedictine monastery on Monte Cassino, where he persuaded the monks to accept his more rigorous rule. He sent fifty monks of his order to introduce it, who remained there, however, for only a few months.
After the death of the founder the order was favoured and privileged by Benedict XI, and rapidly spread through Italy, Germany, Flanders, and France, where they were received by Philip the Fair in 1300. The administration of the order was carried on somewhat after the pattern of Cluny, that is all monasteries were subject to the Abbey of the Holy Ghost at Sulmona, and these dependent houses were divided into provinces. The Celestines had ninety-six houses in Italy, twenty-one in France, and a few in Germany.
Subsequently, the French Celestines, with the consent of the Italian superiors of the order, and of Pope Martin V in 1427, obtained the privilege of making new constitutions for themselves, which they did in the 17th century in a series of regulations accepted by the provincial chapter in 1667. At that time the French congregation of the order was composed of twenty-one monasteries, the head of which was that of Paris, and was governed by a Provincial with the authority of General. Paul V was a notable benefactor of the order. The order became extinct in the eighteenth century.
According to their special constitutions the Celestines were bound to say matins in the choir at two o'clock in the morning, and always to abstain from eating meat, save in illness. The distinct rules of their order with regard to fasting are numerous, but not more severe than those of similar congregations, though much more so than is required by the old Benedictine rule. In reading their minute directions for divers degrees of abstinence on various days, it is impossible to avoid being struck by the conviction that the great object of the framers of these rules was the general purpose of ensuring an ascetic mode of life.
The Celestines wore a white woollen cassock bound with a linen band, and a leathern girdle of the same colour, with a scapular unattached to the body of the dress, and a black hood. It was not permitted to them to wear any shirt save of serge. Their dress in short was very like that of the Cistercians. But it is a tradition in the order that in the time of the founder they wore a coarse brown cloth. The church and monastery of San Pietro in Montorio originally belonged to the Celestines in Rome; but they were turned out of it by Sixtus IV to make way for Franciscans, receiving from the Pope in exchange the Church of St Eusebius of Vercelli with the adjacent mansion for a monastery.

</doc>
<doc id="6539" url="https://en.wikipedia.org/wiki?curid=6539" title="Cessna">
Cessna

The Cessna Aircraft Company () was an American general aviation aircraft manufacturing corporation headquartered in Wichita, Kansas. Cessna produced small, piston-powered aircraft, as well as business jets. For many years the company was one of the highest-volume producers of general aviation aircraft in the world. The company was founded in 1927. It was purchased by General Dynamics in 1985, then by Textron, Inc., in 1992. In March 2014, when Textron purchased the Beechcraft and Hawker Aircraft businesses, Cessna ceased operations as a subsidiary company and joined the others as one of the three distinct brands produced by Textron Aviation.
Clyde Cessna, a farmer in Rago, Kansas, built his own aircraft and flew it in June 1911. He was the first person to do so between the Mississippi River and the Rocky Mountains. Cessna started his wood-and-fabric aircraft ventures in Enid, Oklahoma, testing many of his early planes on the salt flats. When bankers in Enid refused to lend him more money to build his planes, he moved to Wichita.
Cessna Aircraft was formed when Clyde Cessna and Victor Roos became partners in the Cessna-Roos Aircraft Company in 1927. Roos resigned just one month into the partnership, selling back his interest to Cessna. Shortly afterward, Roos's name was dropped from the company name.
The Cessna DC-6 earned certification on the same day as the stock market crash of 1929, October 29, 1929.
In 1932, the Cessna Aircraft Company closed its doors due to the Great Depression.
However, the Cessna CR-3 custom racer made its first flight in 1933. The plane won the 1933 American Air Race in Chicago and later set a new world speed record for engines smaller than 500 cubic inches by averaging .
Cessna's nephews, brothers Dwane and Dwight Wallace, bought the company from Cessna in 1934. They reopened it and began the process of building it into what would become a global success.
The Cessna C-37 was introduced in 1937 as Cessna's first seaplane when equipped with Edo floats. In 1940, Cessna received their largest order to date, when they signed a contract with the U.S. Army for 33 specially equipped Cessna T-50s. Later in 1940, the Royal Canadian Air Force placed an order for 180 T-50s.
Cessna returned to commercial production in 1946, after the revocation of wartime production restrictions (L-48), with the release of the Model 120 and Model 140. The approach was to introduce a new line of all-metal aircraft that used production tools, dies and jigs, rather than the hand-built tube-and-fabric construction process used before the war.
The Model 140 was named by the US Flight Instructors Association as the "Outstanding Plane of the Year", in 1948.
Cessna's first helicopter, the Cessna CH-1, received FAA type certification in 1955.
Cessna introduced the Cessna 172 in 1956. It became the most produced airplane in history.
In 1960, Cessna affiliated itself with Reims Aviation of Reims, France. In 1963, Cessna produced its 50,000th airplane, a Cessna 172.
Cessna's first business jet, the Cessna Citation I, performed its maiden flight on September 15, 1969.
Cessna produced its 100,000th single-engine airplane in 1975.
In 1985, Cessna ceased to be an independent company. It was purchased by General Dynamics Corporation and became a wholly owned subsidiary. Production of the Cessna Caravan began. General Dynamics in turn sold Cessna to Textron in 1992.
Late in 2007, Cessna purchased the bankrupt Columbia Aircraft company for US$26.4M and would continue production of the Columbia 350 and 400 as the Cessna 350 and Cessna 400 at the Columbia factory in Bend, Oregon. However, production of both aircraft had ended by 2018.
On November 27, 2007, Cessna announced the then-new Cessna 162 would be built in the People's Republic of China by Shenyang Aircraft Corporation, which is a subsidiary of the China Aviation Industry Corporation I (AVIC I), a Chinese government-owned consortium of aircraft manufacturers. Cessna reported that the decision was made to save money and also that the company had no more plant capacity in the United States at the time. Cessna received much negative feedback for this decision, with complaints centering on the recent quality problems with Chinese production of other consumer products, China's human rights record, exporting of jobs and China's less than friendly political relationship with the United States. The customer backlash surprised Cessna and resulted in a company public relations campaign. In early 2009, the company attracted further criticism for continuing plans to build the 162 in China while laying off large numbers of workers in the United States. In the end, the Cessna 162 was not a commercial success and only a small number were delivered before production was cancelled.
The company's business suffered notably during the late-2000s recession, laying off more than half its workforce between January 2009 and September 2010.
On November 4, 2008, Cessna's parent company, Textron, indicated that Citation production would be reduced from the original 2009 target of 535 "due to continued softening in the global economic environment" and that this would result in an undetermined number of lay-offs at Cessna.
On November 8, 2008, at the Aircraft Owners and Pilots Association (AOPA) Expo, CEO Jack Pelton indicated that sales of Cessna aircraft to individual buyers had fallen, but piston and turboprop sales to businesses had not. "While the economic slowdown has created a difficult business environment, we are encouraged by brisk activity from new and existing propeller fleet operators placing almost 200 orders for 2009 production aircraft," Pelton stated.
Beginning in January 2009, a total of 665 jobs were cut at Cessna's Wichita and Bend, Oregon plants. The Cessna factory at Independence, Kansas, which builds the Cessna piston-engined aircraft and the Cessna Mustang, did not see any layoffs, but one third of the workforce at the former Columbia Aircraft facility in Bend was laid off. This included 165 of the 460 employees who built the Cessna 350 and 400. The remaining 500 jobs were eliminated at the main Cessna Wichita plant.
In January 2009, the company laid off an additional 2,000 employees, bringing the total to 4,600. The job cuts included 120 at the Bend, Oregon, facility reducing the plant that built the Cessna 350 and 400 to fewer than half the number of workers that it had when Cessna bought it. Other cuts included 200 at the Independence, Kansas, plant that builds the single-engined Cessnas and the Mustang, reducing that facility to 1,300 workers.
On April 29, 2009, the company suspended the Citation Columbus program and closed the Bend, Oregon, facility. The Columbus program was finally cancelled in early July 2009. The company reported, "Upon additional analysis of the business jet market related to this product offering, we decided to formally cancel further development of the Citation Columbus". With the 350 and 400 production moving to Kansas, the company indicated that it would lay off 1,600 more workers, including the remaining 150 employees at the Bend plant and up to 700 workers from the Columbus program.
In early June 2009, Cessna laid off an additional 700 salaried employees, bringing the total number of lay-offs to 7,600, which was more than half the company's workers at the time.
The company closed its three Columbus, Georgia, manufacturing facilities between June 2010 and December 2011. The closures included the new facility that was opened in August 2008 at a cost of US$25M, plus the McCauley Propeller Systems plant. These closures resulted in total job losses of 600 in Georgia. Some of the work was relocated to Cessna's Independence, Kansas, or Mexican facilities.
Cessna's parent company, Textron, posted a loss of US$8M in the first quarter of 2010, largely driven by continuing low sales at Cessna, which were down 44%. Half of Cessna's workforce remained laid-off and CEO Jack Pelton stated that he expected the recovery to be long and slow.
In September 2010, a further 700 employees were laid off, bringing the total to 8,000 jobs lost. CEO Jack Pelton indicated this round of layoffs was due to a "stalled [and] lackluster economy" and noted that while the number of orders cancelled for jets had been decreasing new orders had not met expectations. Pelton added "our strategy is to defend and protect our current markets while investing in products and services to secure our future, but we can do this only if we succeed in restructuring our processes and reducing our costs."
On May 2, 2011, CEO Jack J. Pelton retired. The new CEO, Scott A. Ernest, started on May 31, 2011. Ernest joined Textron after 29 years at General Electric, where he had most recently served as vice president and general manager, global supply chain for GE Aviation. Ernest previously worked for Textron CEO Scott Donnelly when both worked at General Electric.
In September 2011, the Federal Aviation Administration (FAA) proposed a US$2.4 million fine against the company for its failure to follow quality assurance requirements while producing fiberglass components at its plant in Chihuahua, Mexico. Excess humidity meant that the parts did not cure correctly and quality assurance did not detect the problems. The failure to follow procedures resulted in the delamination in flight of a section of one Cessna 400's wing skin from the spar while the aircraft was being flown by an FAA test pilot. The aircraft was landed safely. The FAA also discovered 82 other aircraft parts that had been incorrectly made and not detected by the company's quality assurance. The investigation resulted in an emergency Airworthiness Directive that affected 13 Cessna 400s.
Since March 2012, Cessna has been pursuing building business jets in China as part of a joint venture with Aviation Industry Corporation of China (AVIC). The company stated that it intends to eventually build all aircraft models in China, saying "The agreements together pave the way for a range of business jets, utility single-engine turboprops and single-engine piston aircraft to be manufactured and certified in China."
In late April 2012, the company added 150 workers in Wichita as a result of anticipated increased demand for aircraft production. Overall, they have cut more than 6000 jobs in the Wichita plant since 2009.
In March 2014, Cessna ceased operations as a company and instead became a brand of Textron Aviation.
During the 1950s and 1960s, Cessna's marketing department followed the lead of Detroit automakers and came up with many unique marketing terms in an effort to differentiate its product line from their competitions'.
Other manufacturers and the aviation press widely ridiculed and spoofed many of the marketing terms, but Cessna built and sold more aircraft than any other manufacturer during the boom years of the 1960s and 1970s.
Generally, the names of Cessna models do not follow a theme, but there is logic to the numbering: the 100 series are the light singles, the 200s are the heftier, the 300s are light to medium twins, the 400s have “wide oval” cabin-class accommodation and the 500s are jets. Many Cessna models have names starting with C for the sake of alliteration (e.g. Citation, Crusader, Chancellor).
Cessna marketing terminology includes:
As of July 2018, Textron Aviation is producing the following Cessna models:

</doc>
<doc id="6542" url="https://en.wikipedia.org/wiki?curid=6542" title="Czesław Miłosz">
Czesław Miłosz

Czesław Miłosz (, , ; 30 June 1911 – 14 August 2004) was a Polish-American poet, prose writer, translator, and diplomat. Regarded as one of the great poets of the 20th century, he won the 1980 Nobel Prize in Literature. In its citation, the Swedish Academy called Miłosz a writer who "voices man's exposed condition in a world of severe conflicts".
Miłosz survived the German occupation of Warsaw during World War II and became a cultural attaché for the Polish government during the postwar period. When communist authorities threatened his safety, he defected to France and ultimately chose exile in the United States, where he became a professor at the University of California, Berkeley. His poetry—particularly about his wartime experience—and his appraisal of Stalinism in a prose book, "The Captive Mind", brought him renown as a leading "émigré" artist and intellectual.
Throughout his life and work, Miłosz tackled questions of morality, politics, history, and faith. As a translator, he introduced Western works to a Polish audience, and as a scholar and editor, he championed a greater awareness of Slavic literature in the West. Faith played a role in his work as he explored his Catholicism and personal experience.
Miłosz died in Kraków, Poland, in 2004. He is interred in Skałka, a church known in Poland as a place of honor for distinguished Poles.
Czesław Miłosz was born on 30 June 1911, in the village of Šeteniai (), Kovno Governorate, Russian Empire (now Kėdainiai district, Kaunas County, Lithuania). He was the son of Aleksander Miłosz (1883–1959), a Polish civil engineer, and his wife, Weronika (née Kunat; 1887–1945).
Miłosz was born into a prominent family. On his mother's side, his grandfather was Zygmunt Kunat, a descendant of a Polish family that traced its lineage to the 13th century and owned an estate in Krasnogruda (in present-day Poland). Having studied agriculture in Warsaw, Zygmunt settled in Šeteniai after marrying Miłosz's grandmother, Jozefa, a descendant of the noble Syruć family, which was of Lithuanian origin. One of her ancestors, Szymon Syruć, had been personal secretary to Stanisław I, King of Poland and Grand Duke of Lithuania. Miłosz's paternal grandfather, Artur Miłosz, was also from a noble family and fought in the 1863 January Uprising for Polish independence. Miłosz's grandmother, Stanisława, was a doctor's daughter from Riga, Latvia, and a member of the German/Polish von Mohl family. The Miłosz estate was in Serbiny, a name that Miłosz's biographer Andrzej Franaszek has suggested could indicate Serbian origin; it is possible the Miłosz family originated in Serbia and settled in present-day Lithuania after being expelled from Germany centuries earlier. Miłosz's father was born and educated in Riga. Miłosz's mother was born in Šeteniai and educated in Kraków.
Despite this noble lineage, Miłosz's childhood on his maternal grandfather's estate in Šeteniai lacked the trappings of wealth or the customs of the upper class. He memorialized his childhood in a 1955 novel, "The Issa Valley", and a 1959 memoir, "Native Realm." In these works, he described the influence of his Catholic grandmother, Jozefa, his burgeoning love for literature, and his early awareness, as a member of the Polish gentry in Lithuania, of the role of class in society.
Miłosz's early years were marked by upheaval. When his father was hired to work on infrastructure projects in Siberia, he and his mother traveled to be with him. After World War I broke out in 1914, Miłosz's father was conscripted into the Russian army, tasked with engineering roads and bridges for troop movements. Miłosz and his mother were sheltered in Wilno when the German army captured it in 1915. Afterward, they once again joined Miłosz's father, following him as the front moved further into Russia, where, in 1917, Miłosz's brother, Andrzej, was born. Finally, after moving through Estonia and Latvia, the family returned to Šeteniai in 1918. But the Polish–Soviet War broke out in 1919, during which Miłosz's father was involved in a failed attempt to incorporate the newly independent Lithuania into the Second Polish Republic, resulting in his expulsion from Lithuania and the family's move to Wilno, which had become part of Poland after the Polish–Lithuanian War of 1920. The Polish-Soviet War continued, forcing the family to move again. At one point during the conflict, Polish soldiers fired at Miłosz and his mother, an episode he recounted in "Native Realm." The family returned to Wilno when the war ended in 1921.
Despite the interruptions of wartime wanderings, Miłosz proved to be an exceptional student with a facility for languages. He ultimately learned Polish, Lithuanian, Russian, English, French, and Hebrew. After graduation from Sigismund Augustus Gymnasium in Wilno, he entered Stefan Batory University in 1929 as a law student. While at university, Miłosz joined a student group called The Intellectuals' Club and a student poetry group called Żagary, along with the young poets Jerzy Zagórski, Teodor Bujnicki, Aleksander Rymkiewicz, Jerzy Putrament, and Józef Maśliński. His first published poems appeared in the university's student magazine in 1930.
In 1931, he visited Paris, where he first met his distant cousin, Oscar Milosz, a French-language poet of Lithuanian descent who had become a Swedenborgian. Oscar became a mentor and inspiration. Returning to Wilno, Miłosz's early awareness of class difference and sympathy for those less fortunate than himself inspired his defense of Jewish students at the university who were being harassed by an anti-Semitic mob. Stepping between the mob and the Jewish students, Miłosz fended off attacks. One student was killed when a rock was thrown at his head.
Miłosz's first volume of poetry, "A Poem on Frozen Time", was published in Polish in 1933. In the same year, he publicly read his poetry at an anti-racist "Poetry of Protest" event in Wilno, occasioned by Hitler's rise to power in Germany. In 1934, he graduated with a law degree, and the poetry group Żagary disbanded. Miłosz relocated to Paris on a scholarship to study for one year and write articles for a newspaper back in Wilno. In Paris, he frequently met with his cousin Oscar.
By 1936, he had returned to Wilno, where he worked on literary programs at Radio Wilno. His second poetry collection, "Three Winters", was published that same year, eliciting from one critic a comparison to Adam Mickiewicz. After only one year at Radio Wilno, Miłosz was dismissed due to an accusation that he was a left-wing sympathizer: as a student, he had adopted socialist views from which, by then, he had publicly distanced himself, and he and his boss, Tadeusz Byrski, had produced programming that included performances by Jews and Byelorussians, which angered right-wing nationalists. After Byrski made a trip to the Soviet Union, an anonymous complaint was lodged with the management of Radio Wilno that the station housed a communist cell, and Byrski and Miłosz were dismissed. In summer 1937, Miłosz moved to Warsaw, where he found work at Polish Radio and met his future wife, Janina (née Dłuska; 1909–1986), who was at the time married to another man.
Miłosz was in Warsaw when it was bombarded as part of the German invasion of Poland in September 1939. Along with colleagues from Polish Radio, he escaped the city, making his way to Lwów. But when he learned that Janina had remained in Warsaw with her parents, he looked for a way back. The Soviet invasion of Poland thwarted his plans, and, to avoid the incoming Red Army, he fled to Bucharest. There he obtained a Lithuanian identity document and Soviet visa that allowed him to travel by train to Kiev and then Wilno. After the Red Army invaded Lithuania, he procured fake documents that he used to enter the part of German-occupied Poland the Germans had dubbed the "General Government". It was a difficult journey, mostly on foot, that ended in summer 1940. Finally back in Warsaw, he reunited with Janina.
Like many Poles at the time, to evade notice by German authorities, Miłosz participated in underground activities. For example, with higher education officially forbidden to Poles, he attended underground lectures by Władysław Tatarkiewicz, the Polish philosopher and historian of philosophy and aesthetics. He translated Shakespeare's "As You Like It" and T. S. Eliot's "The Waste Land" into Polish. Along with his friend the novelist Jerzy Andrzejewski, he also arranged for the publication of his third volume of poetry, "Poems", under a pseudonym in September 1940. The pseudonym was "Jan Syruć" and the title page said the volume had been published by a fictional press in Lwów in 1939; in fact, it may have been the first clandestine book published in occupied Warsaw. In 1942, Miłosz arranged for the publication of an anthology of Polish poets, "Invincible Song: Polish Poetry of War Time", by an underground press.
Miłosz's riskiest underground wartime activity was aiding Jews in Warsaw, which he did through an underground socialist organization called Freedom. His brother, Andrzej, was also active in helping Jews in Nazi-occupied Poland; in 1943, he transported the Polish Jew Seweryn Tross and his wife from Wilno to Warsaw. Miłosz took in the Trosses, found them a hiding place, and supported them financially. The Trosses ultimately died during the Warsaw Uprising. Miłosz helped at least three other Jews in similar ways: Felicja Wołkomińska and her brother and sister.
Despite his willingness to engage in underground activity and vehement opposition to the Nazis, Miłosz did not join the Polish Home Army. In later years, he explained that this was partly out of an instinct for self-preservation and partly because he saw its leadership as right-wing and dictatorial. He also did not participate in the planning or execution of the Warsaw Uprising. According to Irena Grudzińska-Gross, he saw the uprising as a "doomed military effort" and lacked the "patriotic elation" for it. He called the uprising "a blameworthy, lightheaded enterprise", but later criticized the Red Army for failing to support it when it had the opportunity to do so.
As German troops began torching Warsaw buildings in August 1944, Miłosz was captured and held in a prisoner transit camp; he was later rescued by a Catholic nun—a stranger to him—who pleaded with the Germans on his behalf. Once freed, he and Janina escaped the city, ultimately settling in a village outside Kraków, where they were staying when the Red Army swept through Poland in January 1945, after Warsaw had been largely destroyed.
In the preface to his 1953 book "The Captive Mind", Miłosz wrote, "I do not regret those years in Warsaw, which was, I believe, the most agonizing spot in the whole of terrorized Europe. Had I then chosen emigration, my life would certainly have followed a very different course. But my knowledge of the crimes which Europe has witnessed in the twentieth century would be less direct, less concrete than it is". Immediately after the war, Miłosz published his fourth poetry collection, "Rescue"; it focused on his wartime experiences and contains some of his most critically praised work, including the 20-poem cycle "The World," composed like a primer for naïve schoolchildren, and the cycle "Voices of Poor People". The volume also contains some of his most frequently anthologized poems, including "A Song on the End of the World", "Campo Dei Fiori", and "A Poor Christian Looks at the Ghetto".
From 1945 to 1951, Miłosz served as a cultural attaché for the newly formed People's Republic of Poland. It was in this capacity that he first met Jane Zielonko, the future translator of "The Captive Mind", with whom he had a brief relationship. He moved from New York City to Washington, D.C., and finally to Paris, organizing and promoting Polish cultural occasions such as musical concerts, art exhibitions, and literary and cinematic events. Although he was a representative of Poland, which had become a Soviet satellite country behind the Iron Curtain, he was not a member of any communist party. In "The Captive Mind", he explained his reasons for accepting the role:My mother tongue, work in my mother tongue, is for me the most important thing in life. And my country, where what I wrote could be printed and could reach the public, lay within the Eastern Empire. My aim and purpose was to keep alive freedom of thought in my own special field; I sought in full knowledge and conscience to subordinate my conduct to the fulfillment of that aim. I served abroad because I was thus relieved from direct pressure and, in the material which I sent to my publishers, could be bolder than my colleagues at home. I did not want to become an émigré and so give up all chance of taking a hand in what was going on in my own country.Miłosz did not publish a book while a representative of the Polish government. Instead, he wrote articles for various Polish periodicals introducing readers to American writers like Eliot, William Faulkner, Ernest Hemingway, Norman Mailer, Robert Lowell, and W. H. Auden. He also translated into Polish Shakespeare's "Othello" and the work of Walt Whitman, Carl Sandburg, Pablo Neruda, and others.
In 1947, Miłosz's son, Anthony, was born in Washington, D.C.
In 1948, Miłosz arranged for the Polish government to fund a Department of Polish Studies at Columbia University. Named for Adam Mickiewicz, the department featured lectures by Manfred Kridl, Miłosz's friend who was then on the faculty of Smith College, and produced a scholarly book about Mickiewicz. Mickiewicz's granddaughter wrote a letter to Dwight D. Eisenhower, then the president of Columbia University, to express her approval, but the Polish American Congress, an influential group of Polish émigrés, denounced the arrangement in a letter to Eisenhower that they shared with the press, which alleged a communist infiltration at Columbia. Students picketed and called for boycotts. One faculty member resigned in protest. Despite the controversy, the department was established, the lectures took place, and the book was produced, but the department was discontinued in 1954 when funding from Poland ceased.
In 1949, Miłosz visited Poland for the first time since joining its diplomatic corps and was appalled by the conditions he saw, including an atmosphere of pervasive fear of the government. After returning to the U.S., he began to look for a way to leave his post, even soliciting advice from Albert Einstein, whom he met in the course of his duties.
As the Polish government, influenced by Josef Stalin, became more oppressive, his superiors began to view Miłosz as a threat: he was outspoken in his reports to Warsaw and met with people not approved by his superiors. Consequently, his superiors called him "an individual who ideologically is totally alien". Toward the end of 1950, when Janina was pregnant with their second child, Miłosz was recalled to Warsaw, where in December 1950 his passport was confiscated, ostensibly until it could be determined that he did not plan to defect. After intervention by Poland's foreign minister, Zygmunt Modzelewski, Miłosz's passport was returned. Realizing that he was in danger if he remained in Poland, Miłosz left for Paris in January 1951.
Upon arriving in Paris, Miłosz went into hiding, aided by the staff of the Polish émigré magazine "Kultura." With his wife and son still in the United States, he applied to enter the U.S. and was denied. At the time, the U.S. was in the grip of McCarthyism, and influential Polish émigrés had convinced American officials that Miłosz was a communist. Unable to leave France, Miłosz was not present for the birth of his second son, John Peter, in Washington, D.C., in 1951.
With the United States closed to him, Miłosz requested—and was granted—political asylum in France. After three months in hiding, he announced his defection at a press conference and in a "Kultura" article, "No", that explained his refusal to live in Poland or continue working for the Polish regime. He was the first artist of note from a communist country to make public his reasons for breaking ties with his government. His case attracted attention in Poland, where his work was banned and he was attacked in the press, and in the West, where prominent individuals voiced criticism and support. For example, the future Nobel laureate Pablo Neruda, then a supporter of the Soviet Union, attacked him in a communist newspaper as "The Man Who Ran Away". On the other hand, Albert Camus, another future Nobel laureate, visited Miłosz and offered his support. Another supporter during this period was the Swiss philosopher Jeanne Hersch, with whom Miłosz had a brief romantic affair.
Miłosz was finally reunited with his family in 1953, when Janina and the children joined him in France. That same year saw the publication of "The Captive Mind", a nonfiction work that uses case studies to dissect the methods and consequences of Soviet communism, which at the time had prominent admirers in the West. The book brought Miłosz his first readership in the United States, where it was credited by some on the political left (such as Susan Sontag) with helping to change perceptions about communism. The German philosopher Karl Jaspers described it as a "significant historical document". It became a staple of political science courses and is considered a classic work in the study of totalitarianism.
Miłosz's years in France were productive. In addition to "The Captive Mind", he published two poetry collections ("Daylight" (1954) and "A Treatise on Poetry" (1957)), two novels ("The Seizure of Power" (1955) and "The Issa Valley" (1955)), and a memoir ("Native Realm" (1959)). All were published in Polish by an émigré press in Paris.
Andrzej Franaszek has called "A Treatise on Poetry" Miłosz's magnum opus, while the scholar Helen Vendler compared it to "The Waste Land", a work "so powerful that it bursts the bounds in which it was written—the bounds of language, geography, epoch". A long poem divided into four sections, "A Treatise on Poetry" surveys Polish history, recounts Miłosz's experience of war, and explores the relationship between art and history.
In 1956, Miłosz and Janina were married.
In 1960, Miłosz was offered a position as a visiting lecturer at the University of California at Berkeley. With this offer, and with the climate of McCarthyism abated, he was able to move to the United States. He proved to be an adept and popular teacher, and was offered tenure after only two months. The rarity of this, and the degree to which he had impressed his colleagues, are underscored by the fact that Miłosz lacked a PhD and teaching experience. Yet his deep learning was obvious, and after years of working administrative jobs that he found stifling, he told friends that he was in his element in a classroom. With stable employment as a tenured professor of Slavic languages and literatures, Miłosz was able to secure American citizenship and purchase a home in Berkeley.
Miłosz began to publish scholarly articles in English and Polish on a variety of authors, including Fyodor Dostoevsky. But despite his successful transition to the U.S., he described his early years at Berkeley as frustrating, as he was isolated from friends and viewed as a political figure rather than a great poet. (In fact, some of his Berkeley faculty colleagues, unaware of his creative output, expressed astonishment when he won the Nobel Prize.) His poetry was not available in English, and he was not able to publish in Poland.
As part of an effort to introduce American readers to his poetry, as well as to his fellow Polish poets' work, Miłosz conceived and edited the anthology "Postwar Polish Poetry", which was published in English in 1965. American poets like W.S. Merwin, and American scholars like Clare Cavanagh, have credited it with a profound impact. It was many English-language readers' first exposure to Miłosz's poetry, as well as that of Polish poets like Wisława Szymborska, Zbigniew Herbert, and Tadeusz Różewicz. (In the same year, Miłosz's poetry also appeared in the first issue of "Modern Poetry in Translation," an English-language journal founded by prominent literary figures Ted Hughes and Daniel Weissbort. The issue also featured Miroslav Holub, Yehuda Amichai, Ivan Lalić, Vasko Popa, Zbigniew Herbert, and Andrei Voznesensky.) In 1969, Miłosz's textbook "The History of Polish Literature" was published in English. He followed this with a volume of his own work, "Selected Poems" (1973), some of which he translated into English himself.
At the same time, Miłosz continued to publish in Polish with an émigré press in Paris. His poetry collections from this period include "King Popiel and Other Poems" (1962), "Bobo’s Metamorphosis" (1965), "City Without a Name" (1969), and "From the Rising of the Sun" (1974).
During Miłosz's time at Berkeley, the campus became a hotbed of student protest, notably as the home of the Free Speech Movement, which has been credited with helping to "define a generation of student activism" across the United States. Miłosz's relationship to student protesters was sometimes antagonistic: he called them "spoiled children of the bourgeoisie" and their political zeal naïve. At one campus event in 1970, he mocked protesters who claimed to be demonstrating for peace and love: "Talk to me about love when they come into your cell one morning, line you all up, and say 'You and you, step forward—it’s your time to die—unless any of your friends loves you so much he wants to take your place!'" Comments like these were in keeping with his stance toward American counterculture of the 1960s in general. For example, in 1968, when Miłosz was listed as a signatory of an open letter of protest written by poet and counterculture figure Allen Ginsberg and published in "The New York Review of Books", Miłosz responded by calling the letter "dangerous nonsense" and insisting that he had not signed it.
After 18 years, Miłosz retired from teaching in 1978. To mark the occasion, he was awarded a "Berkeley Citation", the University of California's equivalent of an honorary doctorate. But when his wife, Janina, fell ill and required expensive medical treatment, Miłosz returned to teaching seminars.
On 9 October 1980, the Swedish Academy announced that Miłosz had won the Nobel Prize in Literature. The award catapulted him to global fame. On the day the prize was announced, Miłosz held a brief press conference and then left to teach a class on Dostoevsky. In his Nobel lecture, Miłosz described his view of the role of the poet, lamented the tragedies of the 20th century, and paid tribute to his cousin Oscar.
Many Poles became aware of Miłosz for the first time when he won the Nobel Prize. After a 30-year ban in Poland, his writing was finally published there in limited selections. He was also able to visit Poland for the first time since fleeing in 1951 and was greeted by crowds with a hero's welcome. He met with leading Polish figures like Lech Wałęsa and Pope John Paul II. At the same time, his early work, until then only available in Polish, began to be translated into English and many other languages.
In 1981, Miłosz was appointed the Norton Professor of Poetry at Harvard University, where he was invited to deliver the Charles Eliot Norton Lectures. He used the opportunity, as he had before becoming a Nobel laureate, to draw attention to writers who had been unjustly imprisoned or persecuted. The lectures were published as "The Witness of Poetry" (1983).
Miłosz continued to publish work in Polish through his longtime publisher in Paris, including the poetry collections "Hymn of the Pearl" (1981), "Bells in Winter" (1984) and "Unattainable Earth" (1986), and the essay collection "Beginning with My Streets" (1986).
In 1986, Miłosz's wife, Janina, died.
In 1988, Miłosz's "Collected Poems" appeared in English; it was the first of several attempts to collect all his poetry into a single volume. After the fall of communism in Poland, he split his time between Berkeley and Kraków, and he began to publish his writing in Polish with a publisher based in Kraków. When Lithuania broke free from the Soviet Union in 1991, Miłosz visited for the first time since 1939. In 2000, he moved to Kraków.
In 1992, Miłosz married Carol Thigpen, an academic at Emory University in Atlanta, Georgia. They remained married until her death in 2002. His work from the 1990s includes the poetry collections "Facing the River" (1994) and "Roadside Dog" (1997), and the collection of short prose "Miłosz’s ABC’s" (1997). Miłosz's last stand-alone volumes of poetry were "This" (2000), and "The Second Space" (2002). Uncollected poems written afterward appeared in English in "New and Selected Poems" (2004) and, posthumously, in "Selected and Last Poems" (2011).
Czesław Miłosz died on 14 August 2004, at his Kraków home, aged 93. He was given a state funeral at the historic Mariacki Church in Kraków. Polish Prime Minister Marek Belka attended, as did the former president of Poland, Lech Wałęsa. Thousands of people lined the streets to witness his coffin moved by military escort to his final resting place at Skałka Roman Catholic Church, where he was one of the last to be commemorated. In front of that church, the poets Seamus Heaney, Adam Zagajewski, and Robert Hass read Miłosz's poem "In Szetejnie" in Polish, French, English, Russian, Lithuanian, and Hebrew—all the languages Miłosz knew. Media from around the world covered the funeral.
Protesters threatened to disrupt the proceedings on the grounds that Miłosz was anti-Polish, anti-Catholic, and had signed a petition supporting gay and lesbian freedom of speech and assembly. Pope John Paul II, along with Miłosz's confessor, issued public messages confirming that Miłosz had received the sacraments, which quelled the protest.
Miłosz's brother, Andrzej Miłosz (1917–2002), was a Polish journalist, translator, and documentary film producer. His work included Polish documentaries about his brother.
Miłosz's son, Anthony, is a composer and software designer. He studied linguistics, anthropology, and chemistry at the University of California at Berkeley, and neuroscience at the University of California Medical Center in San Francisco. In addition to releasing recordings of his own compositions, he has translated some of his father's poems into English.
In addition to the Nobel Prize in Literature, Miłosz received the following awards:
Miłosz was named a distinguished visiting professor or fellow at many institutions, including the University of Michigan and University of Oklahoma, where he was a Puterbaugh Fellow in 1999. He was an elected member of both the American Academy of Arts and Sciences and the American Academy of Arts and Letters. He received honorary doctorates from Harvard University, the University of Michigan, the University of California at Berkeley, Jagiellonian University, Catholic University of Lublin, and Vytautas Magnus University in Lithuania. The last institution also has an academic center named for Miłosz.
In 1992, Miłosz was made an honorary citizen of Lithuania, where his birthplace was made into a museum and conference center. In 1993, he was made an honorary citizen of Kraków.
His books also received awards. His first, "A Poem on Frozen Time", won an award from the Union of Polish Writers in Wilno. "The Seizure of Power" received the Prix Littéraire Européen (European Literary Prize). The collection "Roadside Dog" received a Nike Award in Poland.
In 1989, Miłosz was named one of the "Righteous Among the Nations" at Israel's Yad Vashem memorial to the Holocaust, in recognition of his efforts to save Jews in Warsaw during World War II.
Miłosz has also been honored posthumously. The Polish Parliament declared 2011, the centennial of his birth, the "Year of Miłosz". It was marked by conferences and tributes throughout Poland, as well as in New York City, at Yale University, and at the Dublin Writers Festival, among many other locations. The same year, he was featured on a Lithuanian postage stamp. Streets are named for him near Paris, Vilnius, and in the Polish cities of Kraków, Poznań, Gdańsk, Białystok, and Wrocław. In Gdańsk there is a Czesław Miłosz Square. In 2013, a primary school in Vilnius was named for Miłosz, joining schools in Mierzecice, Poland, and Schaumburg, Illinois, that bear his name.
In 1978, the Russian-American poet Joseph Brodsky called Miłosz "one of the great poets of our time; perhaps the greatest". Miłosz has been cited as an influence by numerous writers—contemporaries and succeeding generations. For example, scholars have written about Miłosz's influence on the writing of Seamus Heaney, and Clare Cavanagh has identified the following poets as having benefited from Miłosz's influence: Robert Pinsky, Edward Hirsch, Rosanna Warren, Robert Hass, Charles Simic, Mary Karr, Carolyn Forché, Mark Strand, Ted Hughes, Joseph Brodsky, and Derek Walcott.
By being smuggled into Poland, Miłosz's writing was a source of inspiration to the anti-communist Solidarity movement there in the early 1980s. Lines from his poem "You Who Wronged" are inscribed on the Monument to the Fallen Shipyard Workers of 1970 in Gdańsk, where Solidarity originated.
Of the effect of Miłosz's edited volume "Postwar Polish Poetry" on English-language poets, Merwin wrote, "Miłosz’s book had been a talisman and had made most of the literary bickering among the various ideological encampments, then most audible in the poetic doctrines in English, seem frivolous and silly". Similarly, the British poet and scholar Donald Davie argued that, for many English-language writers, Miłosz's work encouraged an expansion of poetry to include multiple viewpoints and an engagement with subjects of intellectual and historical importance: "I have suggested, going for support to the writings of Miłosz, that no concerned and ambitious poet of the present day, aware of the enormities of twentieth-century history, can for long remain content with the privileged irresponsibility allowed to, or imposed on, the lyric poet".
Miłosz's writing continues to be the subject of academic study, conferences, and cultural events. His papers, including manuscripts, correspondence, and other materials, are housed at the Beinecke Rare Book and Manuscript Library at Yale University.
Miłosz's birth in a time and place of shifting borders and overlapping cultures, and his later naturalization as an American citizen, have led to competing claims about his nationality. Although his family identified as Polish and Polish was his primary language, and although he frequently spoke of Poland as his country, he also publicly identified himself as one of the last citizens of the multi-ethnic Grand Duchy of Lithuania. Writing in a Polish newspaper in 2000, he claimed, "I was born in the very center of Lithuania and so have a greater right than my great forebear, Mickiewicz, to write 'O Lithuania, my country.'" But in his Nobel lecture, he said, "My family in the 16th century already spoke Polish, just as many families in Finland spoke Swedish and in Ireland English, so I am a Polish, not a Lithuanian, poet".
Public statements such as these, and numerous others, inspired discussion about his nationality, including a claim that he was "arguably the greatest spokesman and representative of a Lithuania that, in Miłosz’s mind, was bigger than its present incarnation". Others have viewed Miłosz as an American author, hosting exhibitions about him from that perspective and including his work in anthologies of American poetry. In "The New York Review of Books" in 1981, the critic John Bayley wrote, "nationality is not a thing [Miłosz] can take seriously; it would be hard to imagine a greater writer more emancipated from even its most subtle pretensions". Echoing this notion, the scholar and diplomat Piotr Wilczek argued that, even when he was greeted as a national hero in Poland, Miłosz "made a distinct effort to remain a universal thinker". Speaking at a ceremony to celebrate his birth centenary in 2011, Lithuanian President Dalia Grybauskaitė stressed that Miłosz's works "unite the Lithuanian and Polish people and reveal how close and how fruitful the ties between our people can be".
Though raised Catholic, Miłosz as a young man came to adopt a "scientific, atheistic position mostly", though he later returned to the Catholic faith. He translated parts of the Bible into Polish, and allusions to Catholicism pervade his poetry, culminating in a long 2001 poem, "A Theological Treatise". For some critics, Miłosz's belief that literature should provide spiritual fortification was outdated: Franaszek suggests that Miłosz's belief was evidence of a "beautiful naïveté", while David Orr, citing Miłosz's dismissal of "poetry which does not save nations or people", accused him of "pompous nonsense".
Miłosz expressed some criticism of both Catholicism and Poland (a majority-Catholic country), causing furor in some quarters when it was announced that he would be interred in Kraków's historic Skałka church. Cynthia Haven writes that, to some readers, Miłosz's embrace of Catholicism can seem surprising and complicates the understanding of him and his work.
Miłosz's body of work comprised multiple literary genres: poetry, fiction (particularly the novel), autobiography, scholarship, personal essay, and lectures. His letters are also of interest to scholars and lay readers; for example, his correspondence with writers such as Jerzy Andrzejewski, Witold Gombrowicz, and Thomas Merton have been published.
At the outset of his career, Miłosz was known as a "catastrophist" poet—a label critics applied to him and other poets from the Żagary poetry group to describe their use of surreal imagery and formal inventiveness in reaction to a Europe beset by extremist ideologies and war. While Miłosz evolved away from the apocalyptic view of catastrophist poetry, he continued to pursue formal inventiveness throughout his career. As a result, his poetry demonstrates a wide-ranging mastery of form, from long or epic poems (e.g., "A Treatise on Poetry") to poems of just two lines (e.g., "On the Death of a Poet" from the collection "This"), and from prose poems and free verse to classic forms such as the ode or elegy. Some of his poems use rhyme, but many do not. In numerous cases, Miłosz used form to illuminate meaning in his poetry; for example, by juxtaposing variable stanzas to accentuate ideas or voices that challenge each other.
Miłosz's work is known for its complexity; according to the scholars Leonard Nathan and Arthur Quinn, Miłosz "prided himself on being an esoteric writer accessible to a mere handful of readers". Nevertheless, some common themes are readily apparent throughout his body of work.
The poet, critic, and frequent Miłosz translator Robert Hass has described Miłosz as "a poet of great inclusiveness", with a fidelity to capturing life in all of its sensuousness and multiplicities. According to Hass, Miłosz's poems can be viewed as "dwelling in contradiction", where one idea or voice is presented only to be immediately challenged or changed. According to Donald Davie, this allowance for contradictory voices—a shift from the solo lyric voice to a chorus—is among the most important aspects of Miłosz's work.
The poetic chorus is deployed not just to highlight the complexity of the modern world but also to search for morality, another of Miłosz's recurrent themes. Nathan and Quinn write, "Miłosz’s work is devoted to unmasking man’s fundamental duality; he wants to make his readers admit the contradictory nature of their own experience" because doing so "forces us to assert our preferences as preferences". That is, it forces readers to make conscious choices, which is the arena of morality. At times, Miłosz's exploration of morality was explicit and concrete, such as when, in "The Captive Mind", he ponders the right way to respond to three Lithuanian women who were forcibly moved to a Russian communal farm and wrote to him for help, or when, in the poems "Campo Dei Fiori" and "A Poor Christian Looks at the Ghetto", he addresses survivor's guilt and the morality of writing about another's suffering.
Miłosz's exploration of morality takes place in the context of history, and confrontation with history is another of his major themes. Vendler wrote, "for Miłosz, the person is irrevocably a person in history, and the interchange between external event and the individual life is the matrix of poetry". Having experienced both Nazism and Stalinism, Miłosz was particularly concerned with the notion of "historical necessity", which, in the 20th century, was used to justify human suffering on a previously unheard-of scale. Yet Miłosz did not reject the concept entirely. Nathan and Quinn summarize Miłosz's appraisal of historical necessity as it appears in his essay collection "Views from San Francisco Bay": "Some species rise, others fall, as do human families, nations, and whole civilizations. There may well be an internal logic to these transformations, a logic that when viewed from sufficient distance has its own elegance, harmony, and grace. Our reason tempts us to be enthralled by this superhuman splendor; but when so enthralled we find it difficult to remember, except perhaps as an element in an abstract calculus, the millions of individuals, the millions upon millions, who unwillingly paid for this splendor with pain and blood".
Miłosz's willingness to accept a form of logic in history points to another recurrent aspect of his writing: his capacity for wonder, amazement, and, ultimately, faith—not always religious faith, but "faith in the objective reality of a world to be known by the human mind but not constituted by that mind". At other times, Miłosz was more explicitly religious in his work. According to scholar and translator Michael Parker, "crucial to any understanding of Miłosz’s work is his complex relationship to Catholicism". His writing is filled with allusions to Christian figures, symbols, and theological ideas, though Miłosz was closer to Gnosticism, or what he called Manichaeism, in his personal beliefs, viewing the universe as ruled by an evil whose influence human beings must try to escape. From this perspective, "he can at once admit that the world is ruled by necessity, by evil, and yet still find hope and sustenance in the beauty of the world. History reveals the pointlessness of human striving, the instability of human things; but time also is the moving image of eternity". According to Hass, this viewpoint left Miłosz "with the task of those heretical Christians…to suffer time, to contemplate being, and to live in the hope of the redemption of the world".
Miłosz had numerous literary and intellectual influences, although scholars of his work—and Miłosz himself, in his writings—have identified the following as significant: Oscar Miłosz (who inspired Miłosz's interest in the metaphysical) and, through him, Emanuel Swedenborg; Lev Shestov; Simone Weil (whose work Miłosz translated into Polish); Dostoevsky; William Blake (whose concept of "Ulro" Miłosz borrowed for his book "The Land of Ulro"), and Eliot.

</doc>
<doc id="6543" url="https://en.wikipedia.org/wiki?curid=6543" title="Carnivore">
Carnivore

A carnivore , meaning "meat eater" (Latin, "caro", genitive "carnis", meaning "meat" or "flesh" and "vorare" meaning "to devour"), is an animal whose food and energy requirements derive solely from animal tissue or meat, whether through hunting or scavenging. Animals that depend solely on animal flesh for their nutrient requirements are called obligate carnivores while those that also consume non-animal food are called facultative carnivores. Omnivores also consume both animal and non-animal food, and, apart from the more general definition, there is no clearly defined ratio of plant to animal material that would distinguish a facultative carnivore from an omnivore. A carnivore at the top of the food chain, not preyed upon by other animals, is termed an apex predator.
"Carnivore" also may refer to the mammalian order Carnivora, but this is somewhat misleading: many, but not all, Carnivora are meat eaters, and even fewer are true obligate carnivores (see below). For example, while the Arctic polar bear eats meat almost exclusively (more than 90% of its diet is meat), most species of bears are omnivorous, and the giant panda is exclusively herbivorous. There are also many carnivorous species that are not members of Carnivora. The correct term for mammals in this group is "carnivoran". Besides, some mammals, especially the cetaceans, are highly carnivorous yet are not true Carnivorans. 
Outside the animal kingdom, there are several genera containing carnivorous plants (predominantly insectivores) and several phyla containing carnivorous fungi (preying mostly on microscopic invertebrates such as nematodes, amoebae and springtails).
Carnivores are sometimes characterized by their type of prey. For example, animals that eat mainly insects and similar invertebrates are called insectivores, while those that eat mainly fish are called piscivores. The first tetrapods, or land-dwelling vertebrates, were piscivorous amphibians known as labyrinthodonts. They gave rise to insectivorous vertebrates and, later, to predators of other tetrapods.
Carnivores may alternatively be classified according to the percentage of meat in their diet. The diet of a hypercarnivore consists of more than 70% meat, that of a mesocarnivore 30–70%, and that of a hypocarnivore less than 30%, with the balance consisting of non-animal foods such as fruits, other plant material, or fungi.
Obligate or "true" carnivores are those whose diet requires nutrients found only in animal flesh. While obligate carnivores might be able to ingest small amounts of plant matter, they lack the necessary physiology required to fully digest it. In fact, some obligate carnivorous mammals will only ingest vegetation to use as an emetic, to self-induce vomiting of the vegetation along with the other food it had ingested that upset its stomach.
Obligate carnivores include the axolotl, which consumes mainly worms and larvae in its environment, but if necessary will consume algae, as well as all felids (including the domestic cat) which require a diet of primarily animal flesh and organs. Specifically, cats have high protein requirements and their metabolisms appear unable to synthesize essential nutrients such as retinol, arginine, taurine, and arachidonic acid; thus, in nature, they must consume flesh to supply these nutrients.
Characteristics commonly associated with carnivores include strength, speed, and keen senses for hunting, as well as teeth and claws for capturing and tearing prey. However, some carnivores do not hunt and are scavengers, lacking the physical characteristics to bring down prey; in addition, most hunting carnivores will scavenge when the opportunity arises. Carnivores have comparatively short digestive systems, as they are not required to break down the tough cellulose found in plants.
Many hunting animals have evolved eyes facing forward, enabling depth perception. This is almost universal among mammalian predators, while most reptile and amphibian predators have eyes facing sideways.
"Predation" (the eating of one living creature by another for nutrition) predates the rise of commonly recognized carnivores by hundreds of millions (perhaps billions) of years. The earliest predators were microbial organisms, which engulfed or grazed on others. Because the fossil record is poor, these first predators could date back anywhere between 1 and over 2.7 Gya (billion years ago). The rise of eukaryotic cells at around 2.7 Gya, the rise of multicellular organisms at about 2 Gya, and the rise of mobile predators (around 600 Mya – 2 Gya, probably around 1 Gya) have all been attributed to early predatory behavior, and many very early remains show evidence of boreholes or other markings attributed to small predator species.
Among more familiar species, the first vertebrate carnivores were fish, and then amphibians that moved on to land. Early tetrapods were large amphibious piscivores. Some scientists assert that "Dimetrodon" "was the first terrestrial vertebrate to develop the curved, serrated teeth that enable a predator to eat prey much larger than itself." While amphibians continued to feed on fish and later insects, reptiles began exploring two new food types: tetrapods (carnivory) and then plants (herbivory). Carnivory was a natural transition from insectivory for medium and large tetrapods, requiring minimal adaptation; in contrast, a complex set of adaptations was necessary for feeding on highly fibrous plant materials.
In the Mesozoic, some theropod dinosaurs such as "Tyrannosaurus rex" were probably obligate carnivores. Though the theropods were the larger carnivores, several carnivorous mammal groups were already present. Most notable are the gobiconodontids, the triconodontid "Jugulator", the deltatheroideans and "Cimolestes". Many of these, such as "Repenomamus", "Jugulator" and "Cimolestes", were among the largest mammals in their faunal assemblages, capable of attacking dinosaurs.
In the early-to-mid-Cenozoic, the dominant predator forms were mammals: hyaenodonts, oxyaenids, entelodonts, ptolemaiidans, arctocyonids and mesonychians, representing a great diversity of eutherian carnivores in the northern continents and Africa. In South America, sparassodonts were dominant, while Australia saw the presence of several marsupial predators, such as the dasyuromorphs and thylacoleonids. From the Miocene to the present, the dominant carnivorous mammals have been carnivoramorphs.
Most carnivorous mammals, from dogs to "Deltatheridium", share several dental adaptations, such as carnassialiforme teeth, long canines and even similar tooth replacement patterns. Most aberrant are thylacoleonids, with a diprodontan dentition completely unlike that of any other mammal; and eutriconodonts like gobioconodontids and "Jugulator", with a three-cusp anatomy which nevertheless functioned similarly to carnassials.

</doc>
<doc id="6546" url="https://en.wikipedia.org/wiki?curid=6546" title="Celts">
Celts

The Celts (, see pronunciation of "Celt" for different usages) are a collection of Indo-European peoples in parts of Europe and Anatolia identified by their use of the Celtic languages and other cultural similarities. The history of pre-Celtic Europe and the exact relationship between ethnic, linguistic and cultural factors in the Celtic world remains uncertain and controversial. The exact geographic spread of the ancient Celts is disputed; in particular, the ways in which the Iron Age inhabitants of Great Britain and Ireland should be regarded as Celts have become a subject of controversy. According to one theory, the common root of the Celtic languages, the Proto-Celtic language, arose in the Late Bronze Age Urnfield culture of Central Europe, which flourished from around 1200 BC.
According to another theory proposed in the 19th century, the first people to adopt cultural characteristics regarded as Celtic were the people of the Iron Age Hallstatt culture in central Europe (c. 800–450 BC), named for the rich grave finds in Hallstatt, Austria. It is thus that this area is sometimes called the "Celtic homeland". By or during the later La Tène period (c. 450 BC to the Roman conquest), named after the La Tène site in Switzerland, this Celtic culture was supposed to have expanded by trans-cultural diffusion or migration to the British Isles (Insular Celts), France and the Low Countries (Gauls), Bohemia, Poland and much of Central Europe, the Iberian Peninsula (Celtiberians, Celtici, Lusitanians and Gallaeci) and northern Italy (Golasecca culture and Cisalpine Gauls) and, following the Celtic settlement of Southeast Europe beginning in 279 BC, as far east as central Anatolia (Galatians) in modern-day Turkey.
The earliest undisputed direct examples of a Celtic language are the Lepontic inscriptions beginning in the 6th century BC. Continental Celtic languages are attested almost exclusively through inscriptions and place-names. Insular Celtic languages are attested beginning around the 4th century in Ogham inscriptions, although they were clearly being spoken much earlier. Celtic literary tradition begins with Old Irish texts around the 8th century AD. Coherent texts of Early Irish literature, such as the "Táin Bó Cúailnge" ("Cattle Raid of Cooley"), survive in 12th-century recensions.
By the mid-1st millennium, with the expansion of the Roman Empire and migrating Germanic tribes, Celtic culture and Insular Celtic languages had become restricted to Ireland, the western and northern parts of Great Britain (Wales, Scotland, and Cornwall), the Isle of Man, and Brittany. Between the 5th and 8th centuries, the Celtic-speaking communities in these Atlantic regions emerged as a reasonably cohesive cultural entity. They had a common linguistic, religious and artistic heritage that distinguished them from the culture of the surrounding polities. By the 6th century, however, the Continental Celtic languages were no longer in wide use.
Insular Celtic culture diversified into that of the Gaels (Irish, Scottish and Manx) and the Celtic Britons (Welsh, Cornish, and Bretons) of the medieval and modern periods. A modern Celtic identity was constructed as part of the Romanticist Celtic Revival in Great Britain, Ireland, and other European territories, such as Portugal and Spanish Galicia. Today, Irish, Scottish Gaelic, Welsh, and Breton are still spoken in parts of their historical territories, and Cornish and Manx are undergoing a revival.
The first recorded use of the name of Celts – as ("Keltoi") in Greek – to refer to an ethnic group was by Hecataeus of Miletus, the Greek geographer, in 517 BC, when writing about a people living near Massilia (modern Marseille). In the fifth century BC, Herodotus referred to "Keltoi" living around the head of the Danube and also in the far west of Europe. The etymology of the term "Keltoi" is unclear. Possible roots include Indo-European *"kʲel" 'to hide' (present also in Old Irish "ceilid"), IE *"kʲel" 'to heat' or *"kel" 'to impel'. Several authors have supposed it to be Celtic in origin, while others view it as a name coined by Greeks. Linguist Patrizia De Bernardo Stempel falls in the latter group, and suggests the meaning "the tall ones".
In the 1st century BC, Julius Caesar reported that the people known to the Romans as Gauls () called themselves Celts, which suggests that even if the name "Keltoi" was bestowed by the Greeks, it had been adopted to some extent as a collective name by the tribes of Gaul. The geographer Strabo, writing about Gaul towards the end of the first century BC, refers to the "race which is now called both Gallic and Galatic," though he also uses the term Celtica as a synonym for Gaul, which is separated from Iberia by the Pyrenees. Yet he reports Celtic peoples in Iberia, and also uses the ethnic names Celtiberi and Celtici for peoples there, as distinct from Lusitani and Iberi. Pliny the Elder cited the use of Celtici in Lusitania as a tribal surname, which epigraphic findings have confirmed.
Latin Gallus (pl. "Galli") might stem from a Celtic ethnic or tribal name originally, perhaps one borrowed into Latin during the Celtic expansions into Italy during the early fifth century BC. Its root may be the Proto-Celtic "*galno", meaning "power, strength", hence Old Irish "gal" "boldness, ferocity" and Welsh "gallu" "to be able, power". The tribal names of Gallaeci and the Greek Γαλάται ("Galatai", Latinized "Galatae"; see the region Galatia in Anatolia) most probably have the same origin. The suffix "-atai" might be an Ancient Greek inflection. Classical writers did not apply the terms ("Keltoi") or "Celtae" to the inhabitants of Britain or Ireland, which has led to some scholars preferring not to use the term for the Iron Age inhabitants of those islands.
Celt is a modern English word, first attested in 1707, in the writing of Edward Lhuyd, whose work, along with that of other late 17th-century scholars, brought academic attention to the languages and history of the early Celtic inhabitants of Great Britain. The English form Gaul (first recorded in the 17th century) and Gaulish come from the French "Gaule" and "Gaulois", a borrowing from Frankish "*Walholant", "Roman land" (see Gaul: Name), the root of which is Proto-Germanic "*walha-", "foreigner, Roman, Celt", whence the English word Welsh (Old English "wælisċ" < *"walhiska-"), South German "", meaning "Celtic speaker", "French speaker" or "Italian speaker" in different contexts, and Old Norse "valskr", pl. "valir", "Gaulish, French"). Proto-Germanic "*walha" is derived ultimately from the name of the Volcae, a Celtic tribe who lived first in the south of Germany and in central Europe and then migrated to Gaul. This means that English Gaul, despite its superficial similarity, is not actually derived from Latin "Gallia" (which should have produced "**Jaille" in French), though it does refer to the same ancient region.
Celtic refers to a family of languages and, more generally, means "of the Celts" or "in the style of the Celts". Several archaeological cultures are considered Celtic in nature, based on unique sets of artefacts. The link between language and artefact is aided by the presence of inscriptions. The relatively modern idea of an identifiable Celtic cultural identity or "Celticity" generally focuses on similarities among languages, works of art, and classical texts, and sometimes also among material artefacts, social organisation, homeland and mythology. Earlier theories held that these similarities suggest a common racial origin for the various Celtic peoples, but more recent theories hold that they reflect a common cultural and language heritage more than a genetic one. Celtic cultures seem to have been widely diverse, with the use of a Celtic language being the main thing they had in common.
Today, the term Celtic generally refers to the languages and respective cultures of Ireland, Scotland, Wales, Cornwall, the Isle of Man, and Brittany, also known as the Celtic nations. These are the regions where four Celtic languages are still spoken to some extent as mother tongues. The four are Irish Gaelic, Scottish Gaelic, Welsh, and Breton; plus two recent revivals, Cornish (one of the Brittonic languages) and Manx (one of the Goidelic languages). There are also attempts to reconstruct Cumbric, a Brittonic language from North West England and South West Scotland. Celtic regions of Continental Europe are those whose residents claim a Celtic heritage, but where no Celtic language has survived; these areas include the western Iberian Peninsula, i.e. Portugal and north-central Spain (Galicia, Asturias, Cantabria, Castile and León, Extremadura).
Continental Celts are the Celtic-speaking people of mainland Europe and Insular Celts are the Celtic-speaking peoples of the British and Irish islands and their descendants. The Celts of Brittany derive their language from migrating insular Celts, mainly from Wales and Cornwall, and so are grouped accordingly.
The Celtic languages form a branch of the larger Indo-European family. By the time speakers of Celtic languages entered history around 400 BC, they were already split into several language groups, and spread over much of Western continental Europe, the Iberian Peninsula, Ireland and Britain.
The Greek historian Ephorus of Cyme in Asia Minor, writing in the 4th century BC, believed that the Celts came from the islands off the mouth of the Rhine and were "driven from their homes by the frequency of wars and the violent rising of the sea".
Some scholars think that the Urnfield culture of western Middle Europe represents an origin for the Celts as a distinct cultural branch of the Indo-European family. This culture was preeminent in central Europe during the late Bronze Age, from circa 1200 BC until 700 BC, itself following the Unetice and Tumulus cultures. The Urnfield period saw a dramatic increase in population in the region, probably due to innovations in technology and agriculture.
The spread of iron-working led to the development of the Hallstatt culture directly from the Urnfield (c. 700 to 500 BC). Proto-Celtic, the latest common ancestor of all known Celtic languages, is considered by this school of thought to have been spoken at the time of the late Urnfield or early Hallstatt cultures, in the early 1st millennium BC. The spread of the Celtic languages to Iberia, Ireland and Britain would have occurred during the first half of the 1st millennium BC, the earliest chariot burials in Britain dating to c. 500 BC. Other scholars see Celtic languages as covering Britain and Ireland, and parts of the Continent, long before any evidence of "Celtic" culture is found in archaeology. Over the centuries the language(s) developed into the separate Celtiberian, Goidelic and Brittonic languages.
The Hallstatt culture was succeeded by the La Tène culture of central Europe, which was overrun by the Roman Empire, though traces of La Tène style are still to be seen in Gallo-Roman artefacts. In Britain and Ireland La Tène style in art survived precariously to re-emerge in Insular art. Early Irish literature casts light on the flavour and tradition of the heroic warrior elites who dominated Celtic societies. Celtic river-names are found in great numbers around the upper reaches of the Danube and Rhine, which led many Celtic scholars to place the ethnogenesis of the Celts in this area.
Diodorus Siculus and Strabo both suggest that the heartland of the people they called Celts was in southern France. The former says that the Gauls were to the north of the Celts, but that the Romans referred to both as Gauls (in linguistic terms the Gauls were certainly Celts). Before the discoveries at Hallstatt and La Tène, it was generally considered that the Celtic heartland was southern France, see Encyclopædia Britannica for 1813.
Myles Dillon and Nora Kershaw Chadwick accepted that "the Celtic settlement of the British Isles" might have to be dated to the Bell Beaker culture concluding that "There is no reason why so early a date for the coming of the Celts should be impossible". Martín Almagro Gorbea proposed the origins of the Celts could be traced back to the 3rd millennium BC, also seeking the initial roots in the Beaker period, thus offering the wide dispersion of the Celts throughout western Europe, as well as the variability of the different Celtic peoples, and the existence of ancestral traditions and ancient perspective. Using a multidisciplinary approach, Alberto J. Lorrio and Gonzalo Ruiz Zapatero reviewed and built on Almagro Gorbea's work to present a model for the origin of the Celtic archaeological groups in the Iberian Peninsula (Celtiberian, Vetton, Vaccean, the Castro culture of the northwest, Asturian-Cantabrian and Celtic of the southwest) and proposing a rethinking of the meaning of "Celtic" from a European perspective. More recently, John Koch and Barry Cunliffe have suggested that Celtic origins lie with the Atlantic Bronze Age, roughly contemporaneous with the Hallstatt culture but positioned considerably to the West, extending along the Atlantic coast of Europe.
Stephen Oppenheimer points out that the only written evidence that locates the Keltoi near the source of the Danube (i.e. in the Hallstatt region) is in the "Histories" of Herodotus. However, Oppenheimer shows that Herodotus seemed to believe the Danube rose near the Pyrenees, which would place the Ancient Celts in a region which is more in agreement with later classical writers and historians (i.e. in Gaul and the Iberian peninsula).
The Proto-Celtic language is usually dated to the Late Bronze Age. The earliest records of a Celtic language are the Lepontic inscriptions of Cisalpine Gaul (Northern Italy), the oldest of which predate the La Tène period. Other early inscriptions, appearing from the early La Tène period in the area of Massilia, are in Gaulish, which was written in the Greek alphabet until the Roman conquest. Celtiberian inscriptions, using their own Iberian script, appear later, after about 200 BC. Evidence of Insular Celtic is available only from about 400 AD, in the form of Primitive Irish Ogham inscriptions.
Besides epigraphical evidence, an important source of information on early Celtic is toponymy.
Historically many scholars postulated that there was genetic evidence of a common origin of the European Atlantic populations i.e.: Orkney Islands, Scottish, Irish, British, Bretons, and Iberians (Basques, Galicians).
More recent genetic evidence does not support the notion of a significant genetic link between these populations, beyond the fact that they are all West Eurasians. Sardinian-like Neolithic farmers did populate Britain (and all of Northern Europe) during the Neolithic period, however, recent genetics research has claimed that, between 2400BC and 2000BC, over 90% of British DNA was overturned by a North European population of ultimate Russian Steppe origin as part of an ongoing migration process that brought large amounts of Steppe DNA (including the R1b haplogroup) to North and West Europe. Modern autosomal genetic clustering is testament to this fact, as both modern and Iron Age British and Irish samples cluster genetically very closely with other North European populations, and somewhat limited with Galicians, Basques or those from the south of France. Such findings have largely put to rest the theory that there is a significant ancestral genetic link (beyond being Europeans) between the various 'Celtic' peoples in the Atlantic area, instead, they are related in that male lines are brother R1b L151 subclades with the local native maternal line admixture explaining the genetic distance noted.
Before the 19th century, scholars assumed that the original land of the Celts was west of the Rhine, more precisely in Gaul, because it was where Greek and Roman ancient sources, namely Caesar, located the Celts. This view was challenged by the 19th-century historian Marie Henri d'Arbois de Jubainville who placed the land of origin of the Celts east of the Rhine. Jubainville based his arguments on a phrase of Herodotus' that placed the Celts at the source of the Danube, and argued that Herodotus had meant to place the Celtic homeland in southern Germany.
The finding of the prehistoric cemetery of Hallstat in 1846 by Johan Ramsauer and the finding of the archaeological site of La Tène by Hansli Kopp in 1857 drew attention to this area.
The concept that the Hallstatt and La Tène cultures could be seen not just as chronological periods but as "Culture Groups", entities composed of people of the same ethnicity and language, had started to grow by the end of the 19th century. At the beginning of the 20th century the belief that these "Culture Groups" could be thought of in racial or ethnic terms was strongly held by Gordon Childe whose theory was influenced by the writings of Gustaf Kossinna. As the 20th century progressed, the racial ethnic interpretation of La Tène culture became much more strongly rooted, and any findings of La Tène culture and flat inhumation cemeteries were directly associated with the Celts and the Celtic language.
The Iron Age Hallstatt (c. 800–475 BC) and La Tène (c. 500–50 BC) cultures are typically associated with Proto-Celtic and Celtic culture.
In various academic disciplines the Celts were considered a Central European Iron Age phenomenon, through the cultures of Hallstatt and La Tène. However, archaeological finds from the Halstatt and La Tène culture were rare in the Iberian Peninsula, in southwestern France, northern and western Britain, southern Ireland and Galatia and did not provide enough evidence for a cultural scenario comparable to that of Central Europe. It is considered equally difficult to maintain that the origin of the Peninsular Celts can be linked to the preceding Urnfield culture. This has resulted in a more recent approach that introduces a 'proto-Celtic' substratum and a process of Celticisation, having its initial roots in the Bronze Age Bell Beaker culture.
The La Tène culture developed and flourished during the late Iron Age (from 450 BC to the Roman conquest in the 1st century BC) in eastern France, Switzerland, Austria, southwest Germany, the Czech Republic, Slovakia and Hungary. It developed out of the Hallstatt culture without any definite cultural break, under the impetus of considerable Mediterranean influence from Greek, and later Etruscan civilisations. A shift of settlement centres took place in the 4th century.
The western La Tène culture corresponds to historical Celtic Gaul. Whether this means that the whole of La Tène culture can be attributed to a unified Celtic people is difficult to assess; archaeologists have repeatedly concluded that language, material culture, and political affiliation do not necessarily run parallel. Frey notes that in the 5th century, "burial customs in the Celtic world were not uniform; rather, localised groups had their own beliefs, which, in consequence, also gave rise to distinct artistic expressions". Thus, while the La Tène culture is certainly associated with the Gauls, the presence of La Tène artefacts may be due to cultural contact and does not imply the permanent presence of Celtic speakers.
Polybius published a history of Rome about 150 BC in which he describes the Gauls of Italy and their conflict with Rome. Pausanias in the 2nd century AD says that the Gauls "originally called Celts", "live on the remotest region of Europe on the coast of an enormous tidal sea". Posidonius described the southern Gauls about 100 BC. Though his original work is lost it was used by later writers such as Strabo. The latter, writing in the early 1st century AD, deals with Britain and Gaul as well as Hispania, Italy and Galatia. Caesar wrote extensively about his Gallic Wars in 58–51 BC. Diodorus Siculus wrote about the Celts of Gaul and Britain in his 1st-century history.
The Romans knew the Celts then living in present-day France as Gauls. The territory of these peoples probably included the Low Countries, the Alps and present-day northern Italy. Julius Caesar in his "Gallic Wars" described the 1st-century BC descendants of those Gauls.
Eastern Gaul became the centre of the western La Tène culture. In later Iron Age Gaul, the social organisation resembled that of the Romans, with large towns. From the 3rd century BC the Gauls adopted coinage. Texts with Greek characters from southern Gaul have survived from the 2nd century BC.
Greek traders founded Massalia about 600 BC, with some objects (mostly drinking ceramics) being traded up the Rhone valley. But trade became disrupted soon after 500 BC and re-oriented over the Alps to the Po valley in the Italian peninsula. The Romans arrived in the Rhone valley in the 2nd century BC and encountered a mostly Celtic-speaking Gaul. Rome wanted land communications with its Iberian provinces and fought a major battle with the Saluvii at Entremont in 124–123 BC. Gradually Roman control extended, and the Roman Province of Gallia Transalpina developed along the Mediterranean coast. The Romans knew the remainder of Gaul as Gallia Comata – "Hairy Gaul".
In 58 BC the Helvetii planned to migrate westward but Julius Caesar forced them back. He then became involved in fighting the various tribes in Gaul, and by 55 BC had overrun most of Gaul. In 52 BC Vercingetorix led a revolt against the Roman occupation but was defeated at the Siege of Alesia and surrendered.
Following the Gallic Wars of 58–51 BC, Caesar's "Celtica" formed the main part of Roman Gaul, becoming the province of Gallia Lugdunensis. This territory of the Celtic tribes was bounded on the south by the Garonne and on the north by the Seine and the Marne. The Romans attached large swathes of this region to neighboring provinces Belgica and Aquitania, particularly under Augustus.
Place- and personal-name analysis and inscriptions suggest that the Gaulish Celtic language was spoken over most of what is now France.
Until the end of the 19th century, traditional scholarship dealing with the Celts did acknowledge their presence in the Iberian Peninsula as a material culture relatable to the Hallstatt and La Tène cultures. However, since according to the definition of the Iron Age in the 19th century Celtic populations were supposedly rare in Iberia and did not provide a cultural scenario that could easily be linked to that of Central Europe, the presence of Celtic culture in that region was generally not fully recognised. Modern scholarship, however, has clearly proven that Celtic presence and influences were most substantial in what is today Spain and Portugal (with perhaps the highest settlement saturation in Western Europe), particularly in the central, western and northern regions.
In addition to Gauls infiltrating from the north of the Pyrenees, the Roman and Greek sources mention Celtic populations in three parts of the Iberian Peninsula: the eastern part of the "Meseta" (inhabited by the Celtiberians), the southwest (Celtici, in modern-day Alentejo) and the northwest (Gallaecia and Asturias). A modern scholarly review found several archaeological groups of Celts in Spain:
The origins of the Celtiberians might provide a key to understanding the Celticisation process in the rest of the Peninsula. The process of Celticisation of the southwestern area of the peninsula by the Keltoi and of the northwestern area is, however, not a simple Celtiberian question. Recent investigations about the Callaici and Bracari in northwestern Portugal are providing new approaches to understanding Celtic culture (language, art and religion) in western Iberia.
John T. Koch of Aberystwyth University suggested that Tartessian inscriptions of the 8th century BC might be classified as Celtic. This would mean that Tartessian is the earliest attested trace of Celtic by a margin of more than a century.
The Canegrate culture represented the first migratory wave of the proto-Celtic population from the northwest part of the Alps that, through the Alpine passes, had already penetrated and settled in the western Po valley between Lake Maggiore and Lake Como (Scamozzina culture). It has also been proposed that a more ancient proto-Celtic presence can be traced back to the beginning of the Middle Bronze Age, when North Westwern Italy appears closely linked regarding the production of bronze artefacts, including ornaments, to the western groups of the Tumulus culture. La Tène cultural material appeared over a large area of mainland Italy, the southernmost example being the Celtic helmet from Canosa di Puglia.
Italy is home to Lepontic, the oldest attested Celtic language (from the 6th century BC). Anciently spoken in Switzerland and in Northern-Central Italy, from the Alps to Umbria. According to the "Recueil des Inscriptions Gauloises", more than 760 Gaulish inscriptions have been found throughout present-day France – with the notable exception of Aquitaine – and in Italy, which testifies the importance of Celtic heritage in the peninsula.
In 391 BC, Celts "who had their homes beyond the Alps streamed through the passes in great strength and seized the territory that lay between the Apennine mountains and the Alps" according to Diodorus Siculus. The Po Valley and the rest of northern Italy (known to the Romans as Cisalpine Gaul) was inhabited by Celtic-speakers who founded cities such as Milan. Later the Roman army was routed at the battle of Allia and Rome was sacked in 390 BC by the Senones.
At the battle of Telamon in 225 BC, a large Celtic army was trapped between two Roman forces and crushed.
The defeat of the combined Samnite, Celtic and Etruscan alliance by the Romans in the Third Samnite War sounded the beginning of the end of the Celtic domination in mainland Europe, but it was not until 192 BC that the Roman armies conquered the last remaining independent Celtic kingdoms in Italy.
The Celts also expanded down the Danube river and its tributaries. One of the most influential tribes, the Scordisci, had established their capital at Singidunum in the 3rd century BC, which is present-day Belgrade, Serbia. The concentration of hill-forts and cemeteries shows a density of population in the Tisza valley of modern-day Vojvodina, Serbia, Hungary and into Ukraine. Expansion into Romania was however blocked by the Dacians.
The Serdi were a Celtic tribe inhabiting Thrace. They were located around and founded Serdika (, , ), now Sofia in Bulgaria, which reflects their ethnonym. They would have established themselves in this area during the Celtic migrations at the end of the 4th century BC, though there is no evidence for their existence before the 1st century BC. "Serdi" are among traditional tribal names reported into the Roman era. They were gradually Thracianized over the centuries but retained their Celtic character in material culture up to a late date. According to other sources they may have been simply of Thracian origin, according to others they may have become of mixed Thraco-Celtic origin. Further south, Celts settled in Thrace (Bulgaria), which they ruled for over a century, and Anatolia, where they settled as the Galatians "(see also: Gallic Invasion of Greece)". Despite their geographical isolation from the rest of the Celtic world, the Galatians maintained their Celtic language for at least 700 years. St Jerome, who visited Ancyra (modern-day Ankara) in 373 AD, likened their language to that of the Treveri of northern Gaul.
For Venceslas Kruta, Galatia in central Turkey was an area of dense Celtic settlement.
The Boii tribe gave their name to Bohemia, Bologna and possibly Bavaria, and Celtic artefacts and cemeteries have been discovered further east in what is now Poland and Slovakia. A Celtic coin (Biatec) from Bratislava's mint was displayed on the old Slovak 5-crown coin.
As there is no archaeological evidence for large-scale invasions in some of the other areas, one current school of thought holds that Celtic language and culture spread to those areas by contact rather than invasion. However, the Celtic invasions of Italy and the expedition in Greece and western Anatolia, are well documented in Greek and Latin history.
There are records of Celtic mercenaries in Egypt serving the Ptolemies. Thousands were employed in 283–246 BC and they were also in service around 186 BC. They attempted to overthrow Ptolemy II.
All Celtic languages extant today belong to the Insular Celtic languages, derived from the Celtic languages spoken in Iron Age Britain and Ireland. They were separated into a Goidelic and a Brythonic branch from an early period.
Linguists have been arguing for many years whether a Celtic language came to Britain and Ireland and then split or whether there were two separate "invasions". The older view of prehistorians was that the Celtic influence in the British Isles was the result of successive invasions from the European continent by diverse Celtic-speaking peoples over the course of several centuries, accounting for the P-Celtic vs. Q-Celtic isogloss. This view has been challenged by the hypothesis that the Celtic languages of the British Isles form a phylogenetic Insular Celtic dialect group.
In the 19th and 20th centuries, scholars commonly dated the "arrival" of Celtic culture in Britain (via an invasion model) to the 6th century BC, corresponding to archaeological evidence of Hallstatt influence and the appearance of chariot burials in what is now England. Some Iron Age migration does seem to have occurred but the nature of the interactions with the indigenous populations of the isles is unknown. According to this model, by about the 6th century (Sub-Roman Britain), most of the inhabitants of the Isles were speaking Celtic languages of either the Goidelic or the Brythonic branch. Since the late 20th century, a new model has emerged (championed by archaeologists such as Barry Cunliffe and Celtic historians such as John T. Koch) which places the emergence of Celtic culture in Britain much earlier, in the Bronze Age, and credits its spread not to invasion, but due to a gradual emergence "in situ" out of Proto-Indo-European culture (perhaps introduced to the region by the Bell Beaker People, and enabled by an extensive network of contacts that existed between the peoples of Britain and Ireland and those of the Atlantic seaboard.
Classical writers did not apply the terms ("Keltoi") or "Celtae" to the inhabitants of Britain or Ireland, leading a number of scholars to question the use of the term Celt to describe the Iron Age inhabitants of those islands. The first historical account of the islands of Britain and Ireland was by Pytheas, a Greek from the city of Massalia, who around 310–306 BC, sailed around what he called the "Pretannikai nesoi", which can be translated as the "Pretannic Isles". In general, classical writers referred to the inhabitants of Britain as Pretannoi or Britanni.
Strabo, writing in the Roman era, clearly distinguished between the Celts and Britons.
Under Caesar the Romans conquered Celtic Gaul, and from Claudius onward the Roman empire absorbed parts of Britain. Roman local government of these regions closely mirrored pre-Roman tribal boundaries, and archaeological finds suggest native involvement in local government.
The native peoples under Roman rule became Romanised and keen to adopt Roman ways. Celtic art had already incorporated classical influences, and surviving Gallo-Roman pieces interpret classical subjects or keep faith with old traditions despite a Roman overlay.
The Roman occupation of Gaul, and to a lesser extent of Britain, led to Roman-Celtic syncretism. In the case of the continental Celts, this eventually resulted in a language shift to Vulgar Latin, while the Insular Celts retained their language.
There was also considerable cultural influence exerted by Gaul on Rome, particularly in military matters and horsemanship, as the Gauls often served in the Roman cavalry. The Romans adopted the Celtic cavalry sword, the spatha, and Epona, the Celtic horse goddess.
To the extent that sources are available, they depict a pre-Christian Iron Age Celtic social structure based formally on class and kingship, although this may only have been a particular late phase of organization in Celtic societies. Patron-client relationships similar to those of Roman society are also described by Caesar and others in the Gaul of the 1st century BC.
In the main, the evidence is of tribes being led by kings, although some argue that there is also evidence of oligarchical republican forms of government eventually emerging in areas which had close contact with Rome. Most descriptions of Celtic societies portray them as being divided into three groups: a warrior aristocracy; an intellectual class including professions such as druid, poet, and jurist; and everyone else. In historical times, the offices of high and low kings in Ireland and Scotland were filled by election under the system of tanistry, which eventually came into conflict with the feudal principle of primogeniture in which succession goes to the first-born son.
Little is known of family structure among the Celts. Patterns of settlement varied from decentralised to urban. The popular stereotype of non-urbanised societies settled in hillforts and duns, drawn from Britain and Ireland (there are about 3,000 hill forts known in Britain) contrasts with the urban settlements present in the core Hallstatt and La Tène areas, with the many significant "oppida" of Gaul late in the first millennium BC, and with the towns of Gallia Cisalpina.
Slavery, as practised by the Celts, was very likely similar to the better documented practice in ancient Greece and Rome. Slaves were acquired from war, raids, and penal and debt servitude. Slavery was hereditary, though manumission was possible. The Old Irish and Welsh words for 'slave', "cacht" and "caeth" respectively, are cognate with Latin "captus" 'captive' suggesting that the slave trade was an early means of contact between Latin and Celtic societies. In the Middle Ages, slavery was especially prevalent in the Celtic countries. Manumissions were discouraged by law and the word for "female slave", "cumal", was used as a general unit of value in Ireland.
Archaeological evidence suggests that the pre-Roman Celtic societies were linked to the network of overland trade routes that spanned Eurasia. Archaeologists have discovered large prehistoric trackways crossing bogs in Ireland and Germany. Due to their substantial nature, these are believed to have been created for wheeled transport as part of an extensive roadway system that facilitated trade. The territory held by the Celts contained tin, lead, iron, silver and gold. Celtic smiths and metalworkers created weapons and jewellery for international trade, particularly with the Romans.
The myth that the Celtic monetary system consisted of wholly barter is a common one, but is in part false. The monetary system was complex and is still not understood (much like the late Roman coinages), and due to the absence of large numbers of coin items, it is assumed that "proto-money" was used. This included bronze items made from the early La Tène period and onwards, which were often in the shape of axeheads, rings, or bells. Due to the large number of these present in some burials, it is thought they had a relatively high monetary value, and could be used for "day to day" purchases. Low-value coinages of potin, a bronze alloy with high tin content, were minted in most Celtic areas of the continent and in South-East Britain prior to the Roman conquest of these lands. Higher-value coinages, suitable for use in trade, were minted in gold, silver, and high-quality bronze. Gold coinage was much more common than silver coinage, despite being worth substantially more, as while there were around 100 mines in Southern Britain and Central France, silver was more rarely mined. This was due partly to the relative sparsity of mines and the amount of effort needed for extraction compared to the profit gained. As the Roman civilisation grew in importance and expanded its trade with the Celtic world, silver and bronze coinage became more common. This coincided with a major increase in gold production in Celtic areas to meet the Roman demand, due to the high value Romans put on the metal. The large number of gold mines in France is thought to be a major reason why Caesar invaded.
There are only very limited records from pre-Christian times written in Celtic languages. These are mostly inscriptions in the Roman and sometimes Greek alphabets. The Ogham script, an Early Medieval alphabet, was mostly used in early Christian times in Ireland and Scotland (but also in Wales and England), and was only used for ceremonial purposes such as inscriptions on gravestones. The available evidence is of a strong oral tradition, such as that preserved by bards in Ireland, and eventually recorded by monasteries. Celtic art also produced a great deal of intricate and beautiful metalwork, examples of which have been preserved by their distinctive burial rites.
In some regards the Atlantic Celts were conservative: for example, they still used chariots in combat long after they had been reduced to ceremonial roles by the Greeks and Romans. However, despite being outdated, Celtic chariot tactics were able to repel the invasion of Britain attempted by Julius Caesar.
According to Diodorus Siculus:
During the later Iron Age the Gauls generally wore long-sleeved shirts or tunics and long trousers (called "braccae" by the Romans). Clothes were made of wool or linen, with some silk being used by the rich. Cloaks were worn in the winter. Brooches and armlets were used, but the most famous item of jewellery was the torc, a neck collar of metal, sometimes gold. The horned Waterloo Helmet in the British Museum, which long set the standard for modern images of Celtic warriors, is in fact a unique survival, and may have been a piece for ceremonial rather than military wear.
Very few reliable sources exist regarding Celtic views on gender divisions and societal status, though some archaeological evidence does suggest that their views of gender roles may differ from contemporary and less egalitarian classical counterparts of the Roman era. There are some general indications from Iron Age burial sites in the Champagne and Bourgogne regions of Northeastern France suggesting that women may have had roles in combat during the earlier "La Tène" period. However, the evidence is far from conclusive. Examples of individuals buried with both female jewellery and weaponry have been identified, such as the Vix Grave, and there are questions about the gender of some skeletons that were buried with warrior assemblages. However, it has been suggested that "the weapons may indicate rank instead of masculinity".
Among the insular Celts, there is a greater amount of historic documentation to suggest warrior roles for women. In addition to commentary by Tacitus about Boudica, there are indications from later period histories that also suggest a more substantial role for "women as warriors", in symbolic if not actual roles. Posidonius and Strabo described an island of women where men could not venture for fear of death, and where the women ripped each other apart. Other writers, such as Ammianus Marcellinus and Tacitus, mentioned Celtic women inciting, participating in, and leading battles. Posidonius' anthropological comments on the Celts had common themes, primarily primitivism, extreme ferocity, cruel sacrificial practices, and the strength and courage of their women.
Under Brehon Law, which was written down in early Medieval Ireland after conversion to Christianity, a woman had the right to divorce her husband and gain his property if he was unable to perform his marital duties due to impotence, obesity, homosexual inclination or preference for other women.
Classical literature records the views of the Celts' neighbours, though historians are not sure how much relation to reality these had. According to Aristotle, most "belligerent nations" were strongly influenced by their women, but the Celts were unusual because their men openly preferred male lovers ("Politics" II 1269b). H. D. Rankin in "Celts and the Classical World" notes that "Athenaeus echoes this comment (603a) and so does Ammianus (30.9). It seems to be the general opinion of antiquity." In book XIII of his "Deipnosophists", the Roman Greek rhetorician and grammarian Athenaeus, repeating assertions made by Diodorus Siculus in the 1st century BC (Bibliotheca historica 5:32), wrote that Celtic women were beautiful but that the men preferred to sleep together. Diodorus went further, stating that "the young men will offer themselves to strangers and are insulted if the offer is refused". Rankin argues that the ultimate source of these assertions is likely to be Posidonius and speculates that these authors may be recording male "bonding rituals".
The sexual freedom of women in Britain was noted by Cassius Dio:
There are instances recorded where women participated both in warfare and in kingship, although they were in the minority in these areas. Plutarch reports that Celtic women acted as ambassadors to avoid a war among Celts chiefdoms in the Po valley during the 4th century BC.
Celtic art is generally used by art historians to refer to art of the La Tène period across Europe, while the Early Medieval art of Britain and Ireland, that is what "Celtic art" evokes for much of the general public, is called Insular art in art history. Both styles absorbed considerable influences from non-Celtic sources, but retained a preference for geometrical decoration over figurative subjects, which are often extremely stylised when they do appear; narrative scenes only appear under outside influence. Energetic circular forms, triskeles and spirals are characteristic. Much of the surviving material is in precious metal, which no doubt gives a very unrepresentative picture, but apart from Pictish stones and the Insular high crosses, large monumental sculpture, even with decorative carving, is very rare; possibly it was originally common in wood. Celts were also able to create developed musical instruments such as the carnyces, these famous war trumpets used before the battle to frighten the enemy, as the best preserved found in Tintignac (Gaul) in 2004 and which were decorated with a boar head or a snake head.
The interlace patterns that are often regarded as typical of "Celtic art" were characteristic of the whole of the British Isles, a style referred to as Insular art, or Hiberno-Saxon art. This artistic style incorporated elements of La Tène, Late Roman, and, most importantly, animal Style II of Germanic Migration Period art. The style was taken up with great skill and enthusiasm by Celtic artists in metalwork and illuminated manuscripts. Equally, the forms used for the finest Insular art were all adopted from the Roman world: Gospel books like the Book of Kells and Book of Lindisfarne, chalices like the Ardagh Chalice and Derrynaflan Chalice, and penannular brooches like the Tara Brooch. These works are from the period of peak achievement of Insular art, which lasted from the 7th to the 9th centuries, before the Viking attacks sharply set back cultural life.
In contrast the less well known but often spectacular art of the richest earlier Continental Celts, before they were conquered by the Romans, often adopted elements of Roman, Greek and other "foreign" styles (and possibly used imported craftsmen) to decorate objects that were distinctively Celtic. After the Roman conquests, some Celtic elements remained in popular art, especially Ancient Roman pottery, of which Gaul was actually the largest producer, mostly in Italian styles, but also producing work in local taste, including figurines of deities and wares painted with animals and other subjects in highly formalised styles. Roman Britain also took more interest in enamel than most of the Empire, and its development of champlevé technique was probably important to the later Medieval art of the whole of Europe, of which the energy and freedom of Insular decoration was an important element. Rising nationalism brought Celtic revivals from the 19th century.
Tribal warfare appears to have been a regular feature of Celtic societies. While epic literature depicts this as more of a sport focused on raids and hunting rather than organised territorial conquest, the historical record is more of tribes using warfare to exert political control and harass rivals, for economic advantage, and in some instances to conquer territory.
The Celts were described by classical writers such as Strabo, Livy, Pausanias, and Florus as fighting like "wild beasts", and as hordes. Dionysius said that their Such descriptions have been challenged by contemporary historians.
Polybius (2.33) indicates that the principal Celtic weapon was a long bladed sword which was used for hacking edgewise rather than stabbing. Celtic warriors are described by Polybius and Plutarch as frequently having to cease fighting in order to straighten their sword blades. This claim has been questioned by some archaeologists, who note that Noric steel, steel produced in Celtic Noricum, was famous in the Roman Empire period and was used to equip the Roman military. However, Radomir Pleiner, in "The Celtic Sword" (1993) argues that "the metallographic evidence shows that Polybius was right up to a point", as around one third of surviving swords from the period might well have behaved as he describes.
Polybius also asserts that certain of the Celts fought naked, "The appearance of these naked warriors was a terrifying spectacle, for they were all men of splendid physique and in the prime of life." According to Livy, this was also true of the Celts of Asia Minor.
Celts had a reputation as head hunters. According to Paul Jacobsthal, "Amongst the Celts the human head was venerated above all else, since the head was to the Celt the soul, centre of the emotions as well as of life itself, a symbol of divinity and of the powers of the other-world." Arguments for a Celtic cult of the severed head include the many sculptured representations of severed heads in La Tène carvings, and the surviving Celtic mythology, which is full of stories of the severed heads of heroes and the saints who carry their own severed heads, right down to "Sir Gawain and the Green Knight", where the Green Knight picks up his own severed head after Gawain has struck it off, just as St. Denis carried his head to the top of Montmartre. Physical evidence exists for the ritual importance of the severed head at the religious centre at Roquepertuse (southern France), destroyed by the Romans in 124 BC, where stone pillars with prominent niches for displaying severed heads were found.
A further example of this regeneration after beheading lies in the tales of Connemara's St. Feichin, who after being beheaded by Viking pirates carried his head to the Holy Well on Omey Island and on dipping the head into the well placed it back upon his neck and was restored to full health.
Diodorus Siculus, in his 1st-century "History" had this to say about Celtic head-hunting:
In "Gods and Fighting Men", Lady Gregory's Celtic Revival translation of Irish mythology, heads of men killed in battle are described in the beginning of the story "The Fight with the Fir Bolgs" as pleasing to Macha, one aspect of the war goddess Morrigu.
Like other European Iron Age tribal societies, the Celts practised a polytheistic religion.
Many Celtic gods are known from texts and inscriptions from the Roman period.
Rites and sacrifices were carried out by priests known as druids. The Celts did not see their gods as having human shapes until late in the Iron Age. Celtic shrines were situated in remote areas such as hilltops, groves, and lakes.
Celtic religious patterns were regionally variable; however, some patterns of deity forms, and ways of worshipping these deities, appeared over a wide geographical and temporal range. The Celts worshipped both gods and goddesses. In general, Celtic gods were deities of particular skills, such as the many-skilled Lugh and Dagda, while goddesses were associated with natural features, particularly rivers (such as Boann, goddess of the River Boyne). This was not universal, however, as goddesses such as Brighid and The Morrígan were associated with both natural features (holy wells and the River Unius) and skills such as blacksmithing and healing.
Triplicity is a common theme in Celtic cosmology, and a number of deities were seen as threefold. This trait is exhibited by The Three Mothers, a group of goddesses worshipped by many Celtic tribes (with regional variations).
The Celts had hundreds of deities, some of which were unknown outside a single family or tribe, while others were popular enough to have a following that crossed lingual and cultural barriers. For instance, the Irish god Lugh, associated with storms, lightning, and culture, is seen in similar forms as Lugos in Gaul and Lleu in Wales. Similar patterns are also seen with the continental Celtic horse goddess Epona and what may well be her Irish and Welsh counterparts, Macha and Rhiannon, respectively.
Roman reports of the druids mention ceremonies being held in sacred groves. La Tène Celts built temples of varying size and shape, though they also maintained shrines at sacred trees and votive pools.
Druids fulfilled a variety of roles in Celtic religion, serving as priests and religious officiants, but also as judges, sacrificers, teachers, and lore-keepers. Druids organised and ran religious ceremonies, and they memorised and taught the calendar. Other classes of druids performed ceremonial sacrifices of crops and animals for the perceived benefit of the community.
The Coligny calendar, which was found in 1897 in Coligny, Ain, was engraved on a bronze tablet, preserved in 73 fragments, that originally was wide and high (Lambert p. 111). Based on the style of lettering and the accompanying objects, it probably dates to the end of the 2nd century. It is written in Latin inscriptional capitals, and is in the Gallic language. The restored tablet contains 16 vertical columns, with 62 months distributed over 5 years.
The French archaeologist J. Monard speculated that it was recorded by druids wishing to preserve their tradition of timekeeping in a time when the Julian calendar was imposed throughout the Roman Empire. However, the general form of the calendar suggests the public peg calendars (or "parapegmata") found throughout the Greek and Roman world.
The Roman invasion of Gaul brought a great deal of Celtic peoples into the Roman Empire. Roman culture had a profound effect on the Celtic tribes which came under the empire's control. Roman influence led to many changes in Celtic religion, the most noticeable of which was the weakening of the druid class, especially religiously; the druids were to eventually disappear altogether. Romano-Celtic deities also began to appear: these deities often had both Roman and Celtic attributes, combined the names of Roman and Celtic deities, and/or included couples with one Roman and one Celtic deity. Other changes included the adaptation of the Jupiter Column, a sacred column set up in many Celtic regions of the empire, primarily in northern and eastern Gaul. Another major change in religious practice was the use of stone monuments to represent gods and goddesses. The Celts had only created wooden idols (including monuments carved into trees, which were known as sacred poles) previously to Roman conquest.
While the regions under Roman rule adopted Christianity along with the rest of the Roman empire, unconquered areas of Ireland and Scotland began to move from Celtic polytheism to Christianity in the 5th century. Ireland was converted by missionaries from Britain, such as Saint Patrick. Later missionaries from Ireland were a major source of missionary work in Scotland, Anglo-Saxon parts of Britain, and central Europe (see Hiberno-Scottish mission). Celtic Christianity, the forms of Christianity that took hold in Britain and Ireland at this time, had for some centuries only limited and intermittent contact with Rome and continental Christianity, as well as some contacts with Coptic Christianity. Some elements of Celtic Christianity developed, or retained, features that made them distinct from the rest of Western Christianity, most famously their conservative method of calculating the date of Easter. In 664, the Synod of Whitby began to resolve these differences, mostly by adopting the current Roman practices, which the Gregorian Mission from Rome had introduced to Anglo-Saxon England.
Genetic studies on the limited amount of material available suggest continuity between Iron Age people from areas considered Celtic and the earlier Bell Beaker culture of Bronze Age Western Europe. Like the Bell Beakers, ancient Celts carried a substantial amount of steppe ancestry, which is derived from pastoralists who expanded westwards from the Pontic-Caspian steppe during late Neolithic and early Bronze Age. Examined individuals overwhelmingly carry types of the paternal haplogroup R-M269, while the maternal haplogroups H and U are frequent. These lineages are associated with steppe ancestry. The spread of Celts into Iberia and the emergence of the Celtiberians is associated with an increase in north-central European ancestry in Iberia, and may be connected to the expansion of the Urnfield culture. The paternal haplogroup haplogroup I2a1a1a has been detected among Celtiberians. There appears to have been significant gene flow between among Celts of Western Europe during the Iron Age. Modern populations of Western Europe, particularly those who still speak Celtic languages, display substantial genetic continuity with the Iron Age populations of the same areas.
Geography
Organisations

</doc>
<doc id="6547" url="https://en.wikipedia.org/wiki?curid=6547" title="Conductor">
Conductor

Conductor or conduction may refer to:

</doc>
<doc id="6548" url="https://en.wikipedia.org/wiki?curid=6548" title="Claude Monet">
Claude Monet

Oscar-Claude Monet (, , ; 14 November 1840 – 5 December 1926) was a French painter, a founder of French Impressionist painting and the most consistent and prolific practitioner of the movement's philosophy of expressing one's perceptions before nature, especially as applied to plein air landscape painting. The term "Impressionism" is derived from the title of his painting "Impression, soleil levant" ("Impression, Sunrise"), which was exhibited in 1874 in the first of the independent exhibitions mounted by Monet and his associates as an alternative to the Salon de Paris.
Monet's ambition of documenting the French countryside led him to adopt a method of painting the same scene many times in order to capture the changing of light and the passing of the seasons. From 1883, Monet lived in Giverny, where he purchased a house and property and began a vast landscaping project which included lily ponds that would become the subjects of his best-known works. He began painting the water lilies in 1899, first in vertical views with a Japanese bridge as a central feature and later in the series of large-scale paintings that was to occupy him continuously for the next 20 years of his life.
Claude Monet was born on 14 November 1840 on the fifth floor of 45 rue Laffitte, in the 9th arrondissement of Paris. He was the second son of Claude Adolphe Monet and Louise Justine Aubrée Monet, both of them second-generation Parisians. On 20 May 1841, he was baptized in the local parish church, Notre-Dame-de-Lorette, as Oscar-Claude, but his parents called him simply Oscar. (He signed his juvenilia "O. Monet".) Despite being baptized Catholic, Monet later became an atheist.
In 1845, his family moved to Le Havre in Normandy. His father wanted him to go into the family's ship-chandling and grocery business, but Monet wanted to become an artist. His mother was a singer, and supported Monet's desire for a career in art.
On 1 April 1851, Monet entered Le Havre secondary school of the arts. Locals knew him well for his charcoal caricatures, which he would sell for ten to twenty francs. Monet also undertook his first drawing lessons from Jacques-François Ochard, a former student of Jacques-Louis David. On the beaches of Normandy around 1856 he met fellow artist Eugène Boudin, who became his mentor and taught him to use oil paints. Boudin taught Monet "en plein air" (outdoor) techniques for painting. Both were influenced by Johan Barthold Jongkind.
On 28 January 1857, his mother died. At the age of sixteen, he left school and went to live with his widowed, childless aunt, Marie-Jeanne Lecadre.
When Monet traveled to Paris to visit the Louvre, he witnessed painters copying from the old masters. Having brought his paints and other tools with him, he would instead go and sit by a window and paint what he saw. Monet was in Paris for several years and met other young painters, including Édouard Manet and others who would become friends and fellow Impressionists.
After drawing a low ballot number in March 1861, Monet was drafted into the First Regiment of African Light Cavalry ("Chasseurs d'Afrique") in Algeria for a seven-year period of military service. His prosperous father could have purchased Monet's exemption from conscription but declined to do so when his son refused to give up painting. While in Algeria, Monet did only a few sketches of casbah scenes, a single landscape, and several portraits of officers, all of which have been lost. In a "Le Temps" interview of 1900 however he commented that the light and vivid colours of North Africa "contained the germ of my future researches". After about a year of garrison duty in Algiers, Monet contracted typhoid fever and briefly went absent without leave. Following convalescence, Monet's aunt intervened to remove him from the army if he agreed to complete a course at an art school. It is possible that the Dutch painter Johan Barthold Jongkind, whom Monet knew, may have prompted his aunt on this matter.
Disillusioned with the traditional art taught at art schools, in 1862 Monet became a student of Charles Gleyre in Paris, where he met Pierre-Auguste Renoir, Frédéric Bazille and Alfred Sisley. Together they shared new approaches to art, painting the effects of light "en plein air" with broken colour and rapid brushstrokes, in what later came to be known as Impressionism.
In January 1865 Monet was working on a version of "Le déjeuner sur l'herbe", aiming to present it for hanging at the Salon, which had rejected Manet's "Le déjeuner sur l'herbe" two years earlier. Monet's painting was very large and could not be completed in time. (It was later cut up, with parts now in different galleries.) Monet submitted instead a painting of "Camille" or "The Woman in the Green Dress" ("La femme à la robe verte"), one of many works using his future wife, Camille Doncieux, as his model. Both this painting and a small landscape were hung. The following year Monet used Camille for his model in "Women in the Garden", and "On the Bank of the Seine, Bennecourt" in 1868. Camille became pregnant and gave birth to their first child, Jean, in 1867. Monet and Camille married on 28 June 1870, just before the outbreak of the Franco-Prussian War, and, after their excursion to London and Zaandam, they moved to Argenteuil, in December 1871. During this time Monet painted various works of modern life. He and Camille lived in poverty for most of this period. Following the successful exhibition of some maritime paintings, and the winning of a silver medal at Le Havre, Monet's paintings were seized by creditors, from whom they were bought back by a shipping merchant, Gaudibert, who was also a patron of Boudin.
From the late 1860s, Monet and other like-minded artists met with rejection from the conservative Académie des Beaux-Arts, which held its annual exhibition at the Salon de Paris. During the latter part of 1873, Monet, Pierre-Auguste Renoir, Camille Pissarro, and Alfred Sisley organized the (Anonymous Society of Painters, Sculptors, and Engravers) to exhibit their artworks independently. At their first exhibition, held in April 1874, Monet exhibited the work that was to give the group its lasting name. He was inspired by the style and subject matter of previous modern painters Camille Pissarro and Edouard Manet.
"Impression, Sunrise" was painted in 1872, depicting a Le Havre port landscape. From the painting's title the art critic Louis Leroy, in his review, "L'Exposition des Impressionnistes," which appeared in "Le Charivari", coined the term "Impressionism". It was intended as disparagement but the Impressionists appropriated the term for themselves.
After the outbreak of the Franco-Prussian War (19 July 1870), Monet and his family took refuge in England in September 1870, where he studied the works of John Constable and Joseph Mallord William Turner, both of whose landscapes would serve to inspire Monet's innovations in the study of colour. In the spring of 1871, Monet's works were refused authorisation for inclusion in the Royal Academy exhibition.
In May 1871, he left London to live in Zaandam, in the Netherlands, where he made twenty-five paintings (and the police suspected him of revolutionary activities). He also paid a first visit to nearby Amsterdam. In October or November 1871, he returned to France. From December 1871 to 1878 he lived at Argenteuil, a village on the right bank of the Seine river near Paris, and a popular Sunday-outing destination for Parisians, where he painted some of his best-known works. In 1873, Monet purchased a small boat equipped to be used as a floating studio. From the boat studio Monet painted landscapes and also portraits of Édouard Manet and his wife; Manet in turn depicted Monet painting aboard the boat, accompanied by Camille, in 1874. In 1874, he briefly returned to Holland.
The first Impressionist exhibition was held in 1874 at 35 boulevard des Capucines, Paris, from 15 April to 15 May. The primary purpose of the participants was not so much to promote a new style, but to free themselves from the constraints of the Salon de Paris. The exhibition, open to anyone prepared to pay 60 francs, gave artists the opportunity to show their work without the interference of a jury.
Renoir chaired the hanging committee and did most of the work himself, as others members failed to present themselves.
In addition to "" (pictured above), Monet presented four oil paintings and seven pastels. Among the paintings he displayed was "The Luncheon" (1868), which features Camille Doncieux and Jean Monet, and which had been rejected by the Paris Salon of 1870. Also in this exhibition was a painting titled "Boulevard des Capucines", a painting of the boulevard done from the photographer Nadar's apartment at no. 35. Monet painted the subject twice, and it is uncertain which of the two pictures, that now in the Pushkin Museum in Moscow, or that in the Nelson-Atkins Museum of Art in Kansas City, was the painting that appeared in the groundbreaking 1874 exhibition, though more recently the Moscow picture has been favoured. Altogether, 165 works were exhibited in the exhibition, including 4 oils, 2 pastels and 3 watercolours by Morisot; 6 oils and 1 pastel by Renoir; 10 works by Degas; 5 by Pissarro; 3 by Cézanne; and 3 by Guillaumin. Several works were on loan, including Cézanne's "Modern Olympia", Morisot's "Hide and Seek" (owned by Manet) and 2 landscapes by Sisley that had been purchased by Durand-Ruel.
The total attendance is estimated at 3500, and some works did sell, though some exhibitors had placed their prices too high. Pissarro was asking 1000 francs for "The Orchard" and Monet the same for "Impression: Sunrise", neither of which sold. Renoir failed to obtain the 500 francs he was asking for "La Loge", but later sold it for 450 francs to Père Martin, dealer and supporter of the group.
In 1876, Camille Monet became ill with tuberculosis. Their second son, Michel, was born on 17 March 1878. This second child weakened her already fading health. In the summer of that year, the family moved to the village of Vétheuil where they shared a house with the family of Ernest Hoschedé, a wealthy department store owner and patron of the arts. In 1878, Camille Monet was diagnosed with uterine cancer. She died on 5 September 1879 at the age of thirty-two.
Monet made a study in oils of his dead wife. Many years later, Monet confessed to his friend Georges Clemenceau that his need to analyse colours was both the joy and torment of his life. He explained,
I one day found myself looking at my beloved wife's dead face and just systematically noting the colours according to an automatic reflex!
John Berger describes the work as "a blizzard of white, grey, purplish paint ... a terrible blizzard of loss which will forever efface her features. In fact there can be very few death-bed paintings which have been so intensely felt or subjectively expressive."
After several difficult months following the death of Camille, Monet began to create some of his best paintings of the 19th century. During the early 1880s, Monet painted several groups of landscapes and seascapes in what he considered to be campaigns to document the French countryside. These began to evolve into series of pictures in which he documented the same scene many times in order to capture the changing of light and the passing of the seasons.
Monet's friend Ernest Hoschedé became bankrupt, and left in 1878 for Belgium. After the death of Camille Monet in September 1879, and while Monet continued to live in the house in Vétheuil, Alice Hoschedé helped Monet to raise his two sons, Jean and Michel. She took them to Paris to live alongside her own six children, Blanche (who married Jean Monet), Germaine, Suzanne, Marthe, Jean-Pierre, and Jacques. In the spring of 1880, Alice Hoschedé and all the children left Paris and rejoined Monet at Vétheuil. In 1881, all of them moved to Poissy, which Monet hated. In April 1883, looking out the window of the little train between Vernon and Gasny, he discovered Giverny in Normandy. Monet, Alice Hoschedé and the children moved to Vernon, then to the house in Giverny, where he planted a large garden and where he painted for much of the rest of his life. Following the death of her estranged husband, Monet married Alice Hoschedé in 1892.
Monet rented and eventually purchased a house and gardens in Giverny. At the beginning of May 1883, Monet and his large family rented the home and from a local landowner. The house was situated near the main road between the towns of Vernon and Gasny at Giverny. There was a barn that doubled as a painting studio, orchards and a small garden. The house was close enough to the local schools for the children to attend, and the surrounding landscape offered many suitable motifs for Monet's work.
The family worked and built up the gardens, and Monet's fortunes began to change for the better as his dealer, Paul Durand-Ruel, had increasing success in selling his paintings. By November 1890, Monet was prosperous enough to buy the house, the surrounding buildings and the land for his gardens. During the 1890s, Monet built a greenhouse and a second studio, a spacious building well lit with skylights.
Monet wrote daily instructions to his gardener, precise designs and layouts for plantings, and invoices for his floral purchases and his collection of botany books. As Monet's wealth grew, his garden evolved. He remained its architect, even after he hired seven gardeners.
Monet purchased additional land with a water meadow. In 1893 he began a vast landscaping project which included lily ponds that would become the subjects of his best-known works. White water lilies local to France were planted along with imported cultivars from South America and Egypt, resulting in a range of colours including yellow, blue and white lilies that turned pink with age. In 1899 he began painting the water lilies, first in vertical views with a Japanese bridge as a central feature, and later in the series of large-scale paintings that was to occupy him continuously for the next 20 years of his life. This scenery, with its alternating light and mirror-like reflections, became an integral part of his work. By the mid-1910s Monet had achieved:
Monet's second wife, Alice, died in 1911, and his oldest son Jean, who had married Alice's daughter Blanche, Monet's particular favourite, died in 1914. After Alice died, Blanche looked after and cared for Monet. It was during this time that Monet began to develop the first signs of cataracts.
During World War I, in which his younger son Michel served and his friend and admirer Georges Clemenceau led the French nation, Monet painted a series of weeping willow trees as homage to the French fallen soldiers. In 1923, he underwent two operations to remove his cataracts. The paintings done while the cataracts affected his vision have a general reddish tone, which is characteristic of the vision of cataract victims. It may also be that after surgery he was able to see certain ultraviolet wavelengths of light that are normally excluded by the lens of the eye; this may have had an effect on the colours he perceived. After his operations he even repainted some of these paintings, with bluer water lilies than before.
Monet died of lung cancer on 5 December 1926 at the age of 86 and is buried in the Giverny church cemetery. Monet had insisted that the occasion be simple; thus only about fifty people attended the ceremony. At his funeral, his long-time friend Georges Clemenceau removed the black cloth draped over the coffin, stating, "No black for Monet!" and replaced it with a flower-patterned cloth. Monet did not leave a will and so his son Michel inherited his entire estate.
Monet's home, garden, and waterlily pond were bequeathed by Michel to the French Academy of Fine Arts (part of the Institut de France) in 1966. Through the "Fondation Claude Monet", the house and gardens were opened for visits in 1980, following restoration. In addition to souvenirs of Monet and other objects of his life, the house contains his collection of Japanese woodcut prints. The house and garden, along with the Museum of Impressionism, are major attractions in Giverny, which hosts tourists from all over the world.
Monet has been described as "the driving force behind Impressionism". Crucial to the art of the Impressionist painters was the understanding of the effects of light on the local colour of objects, and the effects of the juxtaposition of colours with each other. Monet's long career as a painter was spent in the pursuit of this aim.
In 1856, his chance meeting with Eugene Boudin, a painter of small beach scenes, opened his eyes to the possibility of plein-air painting. From that time, with a short interruption for military service, he dedicated himself to searching for new and improved methods of painterly expression. To this end, as a young man, he visited the Paris Salon and familiarised himself with the works of older painters, and made friends with other young artists. The five years that he spent at Argenteuil, spending much time on the River Seine in a little floating studio, were formative in his study of the effects of light and reflections. He began to think in terms of colours and shapes rather than scenes and objects. He used bright colours in dabs and dashes and squiggles of paint. Having rejected the academic teachings of Gleyre's studio, he freed himself from theory, saying "I like to paint as a bird sings."
In 1877 a series of paintings at St-Lazare Station had Monet looking at smoke and steam and the way that they affected colour and visibility, being sometimes opaque and sometimes translucent. He was to further use this study in the painting of the effects of mist and rain on the landscape. The study of the effects of atmosphere was to evolve into a number of series of paintings in which Monet repeatedly painted the same subject (such as his water lilies series) in different lights, at different hours of the day, and through the changes of weather and season. This process began in the 1880s and continued until the end of his life in 1926.
His first series exhibited as such was of Haystacks, painted from different points of view and at different times of the day. Fifteen of the paintings were exhibited at the Galerie Durand-Ruel in 1891. In 1892 he produced what is probably his best-known series, twenty-six views of "Rouen Cathedral". In these paintings Monet broke with painterly traditions by cropping the subject so that only a portion of the façade is seen on the canvas. The paintings do not focus on the grand Medieval building, but on the play of light and shade across its surface, transforming the solid masonry.
Other series include "Poplars", "Mornings on the Seine", and the "Water Lilies" that were painted on his property at Giverny. Between 1883 and 1908, Monet traveled to the Mediterranean, where he painted landmarks, landscapes, and seascapes, including a series of paintings in Venice. In London he painted four series: "the Houses of Parliament, London", "Charing Cross Bridge", "Waterloo Bridge", and "Views of Westminster Bridge". Helen Gardner writes:
In 2004, "London, the Parliament, Effects of Sun in the Fog" ("Londres, le Parlement, trouée de soleil dans le brouillard"; 1904), sold for US$20.1 million. In 2006, the journal "Proceedings of the Royal Society" published a paper providing evidence that these were painted in situ at St Thomas' Hospital over the river Thames.
"Falaises près de Dieppe" ("Cliffs Near Dieppe") has been stolen on two separate occasions: once in 1998 (in which the museum's curator was convicted of the theft and jailed for five years and two months along with two accomplices) and most recently in August 2007. It was recovered in June 2008.
Monet's "Le Pont du chemin de fer à Argenteuil", an 1873 painting of a railway bridge spanning the Seine near Paris, was bought by an anonymous telephone bidder for a record $41.4 million at Christie's auction in New York on 6 May 2008. The previous record for his painting stood at $36.5 million. A few weeks later, "Le bassin aux nymphéas" (from the water lilies series) sold at Christie's 24 June 2008 auction in London for £40,921,250 ($80,451,178), nearly doubling the record for the artist. 
This purchase represented one of the top 20 highest prices paid for a painting at the time.
In October 2013, Monet's paintings, "L'Eglise de Vetheuil" and "Le Bassin aux Nympheas", became subjects of a legal case in New York against NY-based Vilma Bautista, one-time aide to Imelda Marcos, wife of dictator Ferdinand Marcos, after she sold "Le Bassin aux Nympheas" for $32 million to a Swiss buyer. The said Monet paintings, along with two others, were acquired by Imelda during her husband's presidency and allegedly bought using the nation's funds. Bautista's lawyer claimed that the aide sold the painting for Imelda but did not have a chance to give her the money. The Philippine government seeks the return of the painting. "Le Bassin aux Nympheas", also known as "Japanese Footbridge over the Water-Lily Pond at Giverny", is part of Monet's famed Water Lilies series.

</doc>
<doc id="6555" url="https://en.wikipedia.org/wiki?curid=6555" title="Carthage">
Carthage

Carthage was the capital city of the ancient Carthaginian civilization, on the eastern side of the Lake of Tunis in what is now Tunisia. Carthage was the most important trading hub of the Ancient Mediterranean and one of the most affluent cities of the classical world.
The city developed from a Phoenician colony into the capital of a Punic empire which dominated large parts of the Southwest Mediterranean during the first millennium BC. The legendary Queen Alyssa or Dido is regarded as the founder of the city, though her historicity has been questioned. According to accounts by Timaeus of Tauromenium, she purchased from a local tribe the amount of land that could be covered by an oxhide. Cutting the skin into strips, she laid out her claim and founded an empire that would become, through the Punic Wars, the only existential threat to Rome until the coming of the Vandals several centuries later.
The ancient city was destroyed by the Roman Republic in the Third Punic War in 146 BC and then re-developed as Roman Carthage, which became the major city of the Roman Empire in the province of Africa. The city was sacked and destroyed by Umayyad forces after the Battle of Carthage in 698 to prevent it from being reconquered by the Byzantine Empire. It remained occupied during the Muslim period and was used as a fort by the Muslims until the Hafsid period when it was taken by the Crusaders with its inhabitants massacred during the Eighth Crusade. The Hafsids decided to destroy its defenses so it could not be used as a base by a hostile power again. It also continued to function as an episcopal see.
The regional power had shifted to Kairouan and the Medina of Tunis in the medieval period, until the early 20th century, when it began to develop into a coastal suburb of Tunis, incorporated as Carthage municipality in 1919. The archaeological site was first surveyed in 1830, by Danish consul Christian Tuxen Falbe. Excavations were performed in the second half of the 19th century by Charles Ernest Beulé and by Alfred Louis Delattre. The Carthage National Museum was founded in 1875 by Cardinal Charles Lavigerie. Excavations performed by French archaeologists in the 1920s first attracted an extraordinary amount of attention because of the evidence they produced for child sacrifice. There has been considerable disagreement among scholars concerning whether child sacrifice was practiced by ancient Carthage. The open-air Carthage Paleo-Christian Museum has exhibits excavated under the auspices of UNESCO from 1975 to 1984.
The name "Carthage" is the Early Modern anglicisation of Middle French "Carthage" , from Latin ' and ' (cf. Greek "Karkhēdōn" () and Etruscan "*Carθaza") from the Punic ' "new city", implying it was a "new Tyre". The Latin adjective "pūnicus", meaning "Phoenician", is reflected in English in some borrowings from Latin—notably the Punic Wars and the Punic language.
The Modern Standard Arabic form ("") is an adoption of French "Carthage", replacing an older local toponym reported as "Cartagenna" that directly continued the Latin name.
Carthage was built on a promontory with sea inlets to the north and the south. The city's location made it master of the Mediterranean's maritime trade. All ships crossing the sea had to pass between Sicily and the coast of Tunisia, where Carthage was built, affording it great power and influence. Two large, artificial harbors were built within the city, one for harboring the city's massive navy of 220 warships and the other for mercantile trade. A walled tower overlooked both harbors. The city had massive walls, long, which was longer than the walls of comparable cities. Most of the walls were on the shore and so could be less impressive, as Carthaginian control of the sea made attack from that direction difficult. The of wall on the isthmus to the west were truly massive and were never penetrated.
Carthage was one of the largest cities of the Hellenistic period and was among the largest cities in preindustrial history. Whereas by AD 14, Rome had at least 750,000 inhabitants and in the following century may have reached 1 million, the cities of Alexandria and Antioch numbered only a few hundred thousand or less. According to the not-always-reliable history of Herodian, Carthage rivaled Alexandria for second place in the Roman empire.
The Punic Carthage was divided into four equally sized residential areas with the same layout, had religious areas, market places, council house, towers, a theater, and a huge necropolis; roughly in the middle of the city stood a high citadel called the Byrsa. Surrounding Carthage were walls "of great strength" said in places to rise above 13 m, being nearly 10 m thick, according to ancient authors. To the west, three parallel walls were built. The walls altogether ran for about to encircle the city. The heights of the Byrsa were additionally fortified; this area being the last to succumb to the Romans in 146 BC. Originally the Romans had landed their army on the strip of land extending southward from the city.
Outside the city walls of Carthage is the "Chora" or farm lands of Carthage. "Chora" encompassed a limited area: the north coastal "tell", the lower Bagradas river valley (inland from Utica), Cape Bon, and the adjacent "sahel" on the east coast. Punic culture here achieved the introduction of agricultural sciences first developed for lands of the eastern Mediterranean, and their adaptation to local African conditions.
The "urban landscape" of Carthage is known in part from ancient authors, augmented by modern digs and surveys conducted by archeologists. The "first urban nucleus" dating to the seventh century, in area about , was apparently located on low-lying lands along the coast (north of the later harbors). As confirmed by archaeological excavations, Carthage was a "creation "ex nihilo"", built on 'virgin' land, and situated at what was then the end of a peninsula. Here among "mud brick walls and beaten clay floors" (recently uncovered) were also found extensive cemeteries, which yielded evocative grave goods like clay masks. "Thanks to this burial archaeology we know more about archaic Carthage than about any other contemporary city in the western Mediterranean." Already in the eighth century, fabric dyeing operations had been established, evident from crushed shells of murex (from which the 'Phoenician purple' was derived). Nonetheless, only a "meager picture" of the cultural life of the earliest pioneers in the city can be conjectured, and not much about housing, monuments or defenses. The Roman poet Virgil (70–19 BC) imagined early Carthage, when his legendary character Aeneas had arrived there:
"Aeneas found, where lately huts had been,
marvelous buildings, gateways, cobbled ways,
and din of wagons. There the Tyrians
were hard at work: laying courses for walls,
rolling up stones to build the citadel,
while others picked out building sites and plowed
a boundary furrow. Laws were being enacted,
magistrates and a sacred senate chosen.
Here men were dredging harbors, there they laid
the deep foundations of a theatre,
and quarried massive pillars... ."
The two inner harbours, named "cothon" in Punic, were located in the southeast; one being commercial, and the other for war. Their definite functions are not entirely known, probably for the construction, outfitting, or repair of ships, perhaps also loading and unloading cargo. Larger anchorages existed to the north and south of the city. North and west of the "cothon" were located several industrial areas, e.g., metalworking and pottery (e.g., for amphora), which could serve both inner harbours, and ships anchored to the south of the city.
About the Byrsa, the citadel area to the north, considering its importance our knowledge of it is patchy. Its prominent heights were the scene of fierce combat during the fiery destruction of the city in 146 BC. The Byrsa was the reported site of the Temple of Eshmun (the healing god), at the top of a stairway of sixty steps. A temple of Tanit (the city's queen goddess) was likely situated on the slope of the 'lesser Byrsa' immediately to the east, which runs down toward the sea. Also situated on the Byrsa were luxury homes.
South of the citadel, near the "cothon" was the "tophet", a special and very old cemetery, which when begun lay outside the city's boundaries. Here the "Salammbô" was located, the "Sanctuary of Tanit", not a temple but an enclosure for placing stone stelae. These were mostly short and upright, carved for funeral purposes. The presence of infant skeletons from here may indicate the occurrence of child sacrifice, as claimed in the Bible, although there has been considerable doubt among archeologists as to this interpretation and many consider it simply a cemetery devoted to infants. Probably the "tophet" burial fields were "dedicated at an early date, perhaps by the first settlers." Recent studies, on the other hand, indicate that child sacrifice was practiced by the Carthaginians.
Between the sea-filled "cothon" for shipping and the Byrsa heights lay the "agora" [Greek: "market"], the city-state's central marketplace for business and commerce. The "agora" was also an area of public squares and plazas, where the people might formally assemble, or gather for festivals. It was the site of religious shrines, and the location of whatever were the major municipal buildings of Carthage. Here beat the heart of civic life. In this district of Carthage, more probably, the ruling suffets presided, the council of elders convened, the tribunal of the 104 met, and justice was dispensed at trials in the open air.
Early residential districts wrapped around the Byrsa from the south to the north east. Houses usually were whitewashed and blank to the street, but within were courtyards open to the sky. In these neighborhoods multistory construction later became common, some up to six stories tall according to an ancient Greek author. Several architectural floorplans of homes have been revealed by recent excavations, as well as the general layout of several city blocks. Stone stairs were set in the streets, and drainage was planned, e.g., in the form of soakways leaching into the sandy soil. Along the Byrsa's southern slope were located not only fine old homes, but also many of the earliest grave-sites, juxtaposed in small areas, interspersed with daily life.
Artisan workshops were located in the city at sites north and west of the harbours. The location of three metal workshops (implied from iron slag and other vestiges of such activity) were found adjacent to the naval and commercial harbours, and another two were further up the hill toward the Byrsa citadel. Sites of pottery kilns have been identified, between the "agora" and the harbours, and further north. Earthenware often used Greek models. A fuller's shop for preparing woolen cloth (shrink and thicken) was evidently situated further to the west and south, then by the edge of the city. Carthage also produced objects of rare refinement. During the 4th and 3rd centuries, the sculptures of the sarcophagi became works of art. "Bronze engraving and stone-carving reached their zenith."
The elevation of the land at the promontory on the seashore to the north-east (now called Sidi Bou Saïd), was twice as high above sea level as that at the Byrsa (100 m and 50 m). In between runs a ridge, several times reaching 50 m; it continues northwestward along the seashore, and forms the edge of a plateau-like area between the Byrsa and the sea. Newer urban developments lay here in these northern districts.
Due to the Roman's leveling of the city, the original Punic urban landscape of Carthage was largely lost. Since 1982, French archaeologist Serge Lancel excavated a residential area of the Punic Carthage on top of Byrsa hill near the Forum of the Roman Carthage. The neighborhood can be dated back to early second century BC, and with its houses, shops, and private spaces, is significant for what it reveals about daily life of the Punic Carthage.
The remains have been preserved under embankments, the substructures of the later Roman forum, whose foundation piles dot the district. The housing blocks are separated by a grid of straight streets about wide, with a roadway consisting of clay; "in situ" stairs compensate for the slope of the hill. Construction of this type presupposes organization and political will, and has inspired the name of the neighborhood, "Hannibal district", referring to the legendary Punic general or sufet (consul) at the beginning of the second century BC. The habitat is typical, even stereotypical. The street was often used as a storefront/shopfront; cisterns were installed in basements to collect water for domestic use, and a long corridor on the right side of each residence led to a courtyard containing a sump, around which various other elements may be found. In some places, the ground is covered with mosaics called punica pavement, sometimes using a characteristic red mortar.
Punic culture and agricultural sciences, when arrived at Carthage from eastern Mediterranean, gradually adapted to the local African conditions. The merchant harbor at Carthage was developed after settlement of the nearby Punic town of Utica, and eventually the surrounding African countryside was brought into the orbit of the Punic urban centers, first commercially, then politically. Direct management over cultivation of neighbouring lands by Punic owners followed. A 28-volume work on agriculture written in Punic by Mago, a retired army general (c. 300), was translated into Latin and later into Greek. The original and both translations have been lost; however, some of Mago's text has survived in other Latin works. Olive trees (e.g., grafting), fruit trees (pomegranate, almond, fig, date palm), viniculture, bees, cattle, sheep, poultry, implements, and farm management were among the ancient topics which Mago discussed. As well, Mago addresses the wine-maker's art (here a type of sherry).
In Punic farming society, according to Mago, the small estate owners were the chief producers. They were, two modern historians write, not absent landlords. Rather, the likely reader of Mago was "the master of a relatively modest estate, from which, by great personal exertion, he extracted the maximum yield." Mago counselled the rural landowner, for the sake of their own 'utilitarian' interests, to treat carefully and well their managers and farm workers, or their overseers and slaves. Yet elsewhere these writers suggest that rural land ownership provided also a new power base among the city's nobility, for those resident in their country villas. By many, farming was viewed as an alternative endeavour to an urban business. Another modern historian opines that more often it was the urban merchant of Carthage who owned rural farming land to some profit, and also to retire there during the heat of summer. It may seem that Mago anticipated such an opinion, and instead issued this contrary advice (as quoted by the Roman writer Columella):
The man who acquires an estate must sell his house, lest he prefer to live in the town rather than in the country. Anyone who prefers to live in a town has no need of an estate in the country." "One who has bought land should sell his town house, so that he will have no desire to worship the household gods of the city rather than those of the country; the man who takes greater delight in his city residence will have no need of a country estate.
The issues involved in rural land management also reveal underlying features of Punic society, its structure and stratification. The hired workers might be considered 'rural proletariat', drawn from the local Berbers. Whether there remained Berber landowners next to Punic-run farms is unclear. Some Berbers became sharecroppers. Slaves acquired for farm work were often prisoners of war. In lands outside Punic political control, independent Berbers cultivated grain and raised horses on their lands. Yet within the Punic domain that surrounded the city-state of Carthage, there were ethnic divisions in addition to the usual quasi feudal distinctions between lord and peasant, or master and serf. This inherent instability in the countryside drew the unwanted attention of potential invaders. Yet for long periods Carthage was able to manage these social difficulties.
The many amphorae with Punic markings subsequently found about ancient Mediterranean coastal settlements testify to Carthaginian trade in locally made olive oil and wine. Carthage's agricultural production was held in high regard by the ancients, and rivaled that of Rome—they were once competitors, e.g., over their olive harvests. Under Roman rule, however, grain production ([wheat] and barley) for export increased dramatically in 'Africa'; yet these later fell with the rise in Roman Egypt's grain exports. Thereafter olive groves and vineyards were re-established around Carthage. Visitors to the several growing regions that surrounded the city wrote admiringly of the lush green gardens, orchards, fields, irrigation channels, hedgerows (as boundaries), as well as the many prosperous farming towns located across the rural landscape.
Accordingly, the Greek author and compiler Diodorus Siculus (fl. 1st century BC), who enjoyed access to ancient writings later lost, and on which he based most of his writings, described agricultural land near the city of Carthage circa 310 BC:
It was divided into market gardens and orchards of all sorts of fruit trees, with many streams of water flowing in channels irrigating every part. There were country homes everywhere, lavishly built and covered with stucco. ... Part of the land was planted with vines, part with olives and other productive trees. Beyond these, cattle and sheep were pastured on the plains, and there were meadows with grazing horses.
Greek cities contested with Carthage for the Western Mediterranean culminating in the Sicilian Wars and the Pyrrhic War over Sicily, while the Romans fought three wars against Carthage, known as the Punic Wars, "Punic" meaning "Phoenician" in Latin, as Carthage was a Phoenician colony grown into a kingdom.
The Carthaginian republic was one of the longest-lived and largest states in the ancient Mediterranean. Reports relay several wars with Syracuse and finally, Rome, which eventually resulted in the defeat and destruction of Carthage in the Third Punic War. The Carthaginians were Phoenician settlers originating in the Mediterranean coast of the Near East. They spoke Canaanite, a Semitic language, and followed a local variety of the ancient Canaanite religion.
The fall of Carthage came at the end of the Third Punic War in 146 BC at the Battle of Carthage. Despite initial devastating Roman naval losses and Rome's recovery from the brink of defeat after the terror of a 15-year occupation of much of Italy by Hannibal, the end of the series of wars resulted in the end of Carthaginian power and the complete destruction of the city by Scipio Aemilianus. The Romans pulled the Phoenician warships out into the harbor and burned them before the city, and went from house to house, capturing and enslaving the people. About 50,000 Carthaginians were sold into slavery. The city was set ablaze and razed to the ground, leaving only ruins and rubble. After the fall of Carthage, Rome annexed the majority of the Carthaginian colonies, including other North African locations such as Volubilis, Lixus, Chellah.
The legend that the city was sown with salt remains widely accepted despite a lack of evidence among ancient historical accounts; According to R.T. Ridley, the earliest such claim is attributable to B.L. Hallward's chapter in "Cambridge Ancient History", published in 1930. Ridley contended that Hallward's claim may have gained traction due to historical evidence of other salted-earth instances such as Abimelech's salting of Shechem in Judges 9:45. B.H. Warmington admitted he had repeated Hallward's error, but posited that the legend precedes 1930 and inspired repetitions of the practice. He also suggested that it is useful to understand how subsequent historical narratives have been framed and that the symbolic value of the legend is so great and enduring that it mitigates a deficiency of concrete evidence.
For many years but especially beginning in the 19th century, various texts claim that after defeating the city of Carthage in the Third Punic War (146 BC), the Roman general Scipio Aemilianus Africanus ordered the city be sacked, forced its surviving inhabitants into slavery, plowed it over and sowed it with salt. However, no ancient sources exist documenting the salting itself. The element of salting is therefore probably a later invention modeled on the Biblical story of Shechem. The ritual of symbolically drawing a plow over the site of a city is mentioned in ancient sources, but not in reference to Carthage specifically. When Pope Boniface VIII destroyed Palestrina in 1299, he issued a papal bull that it be plowed "following the old example of Carthage in Africa" and also salted. "I have run the plough over it, like the ancient Carthage of Africa, and I have had salt sown upon it..."
When Carthage fell, its nearby rival Utica, a Roman ally, was made capital of the region and replaced Carthage as the leading center of Punic trade and leadership. It had the advantageous position of being situated on the outlet of the Medjerda River, Tunisia's only river that flowed all year long. However, grain cultivation in the Tunisian mountains caused large amounts of silt to erode into the river. This silt accumulated in the harbor until it became useless, and Rome was forced to rebuild Carthage.
By 122 BC, Gaius Gracchus founded a short-lived colony, called "Colonia Iunonia", after the Latin name for the Punic goddess Tanit, "Iuno Caelestis". The purpose was to obtain arable lands for impoverished farmers. The Senate abolished the colony some time later, to undermine Gracchus' power.
After this ill-fated attempt, a new city of Carthage was built on the same land by Julius Caesar in the period from 49 to 44 BC, and by the first century, it had grown to be the second-largest city in the western half of the Roman Empire, with a peak population of 500,000. It was the center of the province of Africa, which was a major breadbasket of the Empire. Among its major monuments was an amphitheater.
Carthage also became a center of early Christianity (see Carthage (episcopal see)). In the first of a string of rather poorly reported councils at Carthage a few years later, no fewer than 70 bishops attended. Tertullian later broke with the mainstream that was increasingly represented in the West by the primacy of the Bishop of Rome, but a more serious rift among Christians was the Donatist controversy, which Augustine of Hippo spent much time and parchment arguing against. At the Council of Carthage (397), the biblical canon for the western Church was confirmed. The Christians at Carthage conducted persecutions against the pagans, during which the pagan temples, notably the famous Temple of Juno Caelesti, were destroyed.
The political fallout from the deep disaffection of African Christians is supposedly a crucial factor in the ease with which Carthage and the other centers were captured in the fifth century by Gaiseric, king of the Vandals, who defeated the Roman general Bonifacius and made the city the capital of the Vandal Kingdom. Gaiseric was considered a heretic, too, an Arian, and though Arians commonly despised Catholic Christians, a mere promise of toleration might have caused the city's population to accept him.
The Vandals during their conquest are said to have destroyed parts of Carthage by Victor Vitensis in "Historia Persecutionis Africanae Provincia" including various buildings and churches.
After a failed attempt to recapture the city in the fifth century, the Eastern Roman Empire finally subdued the Vandals in the Vandalic War in 533–534. Thereafter, the city became the seat of the praetorian prefecture of Africa, which was made into an exarchate during the emperor Maurice's reign, as was Ravenna on the Italian Peninsula. These two exarchates were the western bulwarks of the Byzantine Empire, all that remained of its power in the West. In the early seventh century Heraclius the Elder, the exarch of Carthage, overthrew the Byzantine emperor Phocas, whereupon his son Heraclius succeeded to the imperial throne.
The Roman Exarchate of Africa was not able to withstand the seventh-century Muslim conquest of the Maghreb. The Umayyad Caliphate under Abd al-Malik ibn Marwan in 686 sent a force led by Zuhayr ibn Qays, who won a battle over the Romans and Berbers led by King Kusaila of the Kingdom of Altava on the plain of Kairouan, but he could not follow that up. In 695, Hassan ibn al-Nu'man captured Carthage and advanced into the Atlas Mountains. An imperial fleet arrived and retook Carthage, but in 698, Hasan ibn al-Nu'man returned and defeated Emperor Tiberios III at the 698 Battle of Carthage. Roman imperial forces withdrew from all of Africa except Ceuta. Fearing that the Byzantine Empire might reconquer it, they decided to destroy Roman Carthage in a scorched earth policy and establish their headquarters somewhere else. Its walls were torn down, the water supply from its aqueducts cut off, the agricultural land was ravaged and its harbors made unusable.
The destruction of the Exarchate of Africa marked a permanent end to the Byzantine Empire's influence in the region.
It is visible from archaeological evidence, that the town of Carthage continued to be occupied. The neighborhood of Bjordi Djedid continued to be occupied. The Baths of Antoninus continued to function in the Arab period and the historian Al-Bakri stated that they were still in good condition. They also had production centers nearby. It is difficult to determine whether the continued habitation of some other buildings belonged to Late Byzantine or Early Arab period. The Bir Ftouha church might have continued to remain in use though it is not clear when it became uninhabited. Constantine the African was born in Carthage.
The Medina of Tunis, originally a Berber settlement, was established as the new regional center under the Umayyad Caliphate in the early 8th century. Under the Aghlabids, the people of Tunis revolted numerous times, but the city profited from economic improvements and quickly became the second most important in the kingdom. It was briefly the national capital, from the end of the reign of Ibrahim II in 902, until 909, when the Shi'ite Berbers took over Ifriqiya and founded the Fatimid Caliphate.
Carthage remained a residential see until the high medieval period, mentioned in
two letters of Pope Leo IX dated 1053, written in reply to consultations regarding a conflict between the bishops of Carthage and Gummi.
In each of the two letters, Pope Leo declares that, after the Bishop of Rome, the first archbishop and chief metropolitan of the whole of Africa is the bishop of Carthage.
Later, an archbishop of Carthage named Cyriacus was imprisoned by the Arab rulers because of an accusation by some Christians. Pope Gregory VII wrote him a letter of consolation, repeating the hopeful assurances of the primacy of the Church of Carthage, "whether the Church of Carthage should still lie desolate or rise again in glory".
By 1076, Cyriacus was set free, but there was only one other bishop in the province. These are the last of whom there is mention in that period of the history of the see.
The fortress of Carthage was used by the Muslims until Hafsid era and was captured by the Crusaders during the Eighth Crusade. The inhabitants of Carthage were slaughtered by the Crusaders after they took it, and it was used as a base of operations against the Hafsids. After repelling them, Muhammad I al-Mustansir decided to destroy Cathage's defenses completely to prevent a repeat.
Carthage is some east-northeast of Tunis; the settlements nearest to Carthage were the town of Sidi Bou Said to the north and the village of Le Kram to the south.
Sidi Bou Said was a village which had grown around the tomb of the eponymous sufi saint (d. 1231), which had been developed into a town under Ottoman rule in the 18th century. Le Kram was developed in the late 19th century under French administration as a settlement close to the port of La Goulette.
In 1881, Tunisia became a French protectorate, and in the same year Charles Lavigerie, who was archbishop of Algiers, became apostolic administrator of the vicariate of Tunis. In the following year, Lavigerie became a cardinal. He "saw himself as the reviver of the ancient Christian Church of Africa, the Church of Cyprian of Carthage", and, on 10 November 1884, was successful in his great ambition of having the metropolitan see of Carthage restored, with himself as its first archbishop. In line with the declaration of Pope Leo IX in 1053, Pope Leo XIII acknowledged the revived Archdiocese of Carthage as the primatial see of Africa and Lavigerie as primate.
The Acropolium of Carthage (Saint Louis Cathedral of Carthage) was erected on Byrsa hill in 1884.
The Danish consul Christian Tuxen Falbe conducted a first survey of the topography of the archaeological site (published in 1833).
Antiquarian interest was intensified following the publication of Flaubert's "Salammbô" in 1858. Charles Ernest Beulé performed some preliminary excavations of Roman remains on Byrsa hill in 1860. A more systematic survey of both Punic and Roman-era remains is due to Alfred Louis Delattre, who was sent to Tunis by cardinal Charles Lavigerie in 1875 on both an apostolic and an archaeological mission.
Audollent (1901, p. 203) cites Delattre and Lavigerie to the effect that in the 1880s, locals still knew the area of the ancient city under the name of "Cartagenna" (i.e. reflecting the Latin "n"-stem "Carthāgine").
Auguste Audollent divides the area of Roman Carthage into four quarters, "Cartagenna", "Dermèche", "Byrsa" and "La Malga". Cartagenna and Dermèche correspond with the lower city, including the site of Punic Carthage; Byrsa is associated with the upper city, which in Punic times was a walled citadel above the harbour; and "La Malga" is linked with the more remote parts of the upper city in Roman times.
French-led excavations at Carthage began in 1921, and from 1923 reported finds of a large quantity of urns containing a mixture of animal and children's bones. René Dussaud identified a 4th-century BC stela found in Carthage as depicting a child sacrifice.
A temple at Amman (1400–1250 BC) excavated and reported upon by J.B. Hennessy in 1966, shows the possibility of bestial and human sacrifice by fire. While evidence of child sacrifice in Canaan was the object of academic disagreement, with some scholars arguing that merely children's cemeteries had been unearthed in Carthage, the mixture of children's with animal bones as well as associated epigraphic evidence involving mention of "mlk" led some to believe that, at least in Carthage, child sacrifice was indeed common practice. However, though the animals were surely sacrificed, this does not entirely indicate that the infants were, and in fact the bones indicate the opposite. Rather, the animal sacrifice was likely done to, in some way, honour the deceased.
In 2016, an ancient Carthaginian individual, who was excavated from a Punic tomb in Byrsa Hill, was found to belong to the rare U5b2c1 maternal haplogroup. The Young Man of Byrsa specimen dates from the late 6th century BCE, and his lineage is believed to represent early gene flow from Iberia to the Maghreb.
In 1920, the first seaplane base was built on the Lake of Tunis for the seaplanes of Compagnie Aéronavale. The Tunis Airfield opened in 1938, serving around 5,800 passengers annually on the Paris-Tunis route.
During World War II, the airport was used by the United States Army Air Force Twelfth Air Force as a headquarters and command control base for the Italian Campaign of 1943.
Construction on the Tunis-Carthage Airport, which was fully funded by France, began in 1944, and in 1948 the airport become the main hub for Tunisair.
In the 1950s the Lycée Français de Carthage was established to serve French families in Carthage. In 1961 it was given to the Tunisian government as part of the Independence of Tunisia, so the nearby Collège Maurice Cailloux in La Marsa, previously an annex of the Lycée Français de Carthage, was renamed to the Lycée Français de La Marsa and began serving the "lycée" level. It is currently the Lycée Gustave Flaubert.
After Tunisian independence in 1956, the Tunis conurbation gradually extended around the airport, and Carthage (قرطاج " Qarṭāj") is now a suburb of Tunis, covering the area between Sidi Bou Said and Le Kram.
Its population as of January 2013 was estimated at 21,276,
mostly attracting the more wealthy residents. If Carthage is not the capital, it tends to be the political pole, a « place of emblematic power » according to Sophie Bessis, leaving to Tunis the economic and administrative roles. The Carthage Palace (the Tunisian presidential palace) is located in the coast.
The suburb has six train stations of the TGM line between Le Kram and Sidi Bou Said:
Carthage Salammbo (named for Salambo, the fictional daughter of Hamilcar), Carthage Byrsa (named for Byrsa hill), Carthage Dermech ("Dermèche"), Carthage Hannibal (named for Hannibal), Carthage Présidence (named for the Presidential Palace) and Carthage Amilcar (named for Hamilcar).
The scant remains of what was once a great city are reflected upon in Letitia Elizabeth Landon's poem, "Carthage", published in 1836 with quotes from Sir Grenville Temple's Journal.
The merchants of Carthage were in part heirs of the Mediterranean trade developed by Phoenicia, and so also heirs of the rivalry with Greek merchants. Business activity was accordingly both stimulated and challenged. Cyprus had been an early site of such commercial contests. The Phoenicians then had ventured into the western Mediterranean, founding trading posts, including Utica and Carthage. The Greeks followed, entering the western seas where the commercial rivalry continued. Eventually it would lead, especially in Sicily, to several centuries of intermittent war. Although Greek-made merchandise was generally considered superior in design, Carthage also produced trade goods in abundance. That Carthage came to function as a manufacturing colossus was shown during the Third Punic War with Rome. Carthage, which had previously disarmed, then was made to face the fatal Roman siege. The city "suddenly organised the manufacture of arms" with great skill and effectiveness. According to Strabo (63 BC – AD 21) in his "Geographica":
[Carthage] each day produced one hundred and forty finished shields, three hundred swords, five hundred spears, and one thousand missiles for the catapults... . Furthermore, [Carthage although surrounded by the Romans] built one hundred and twenty decked ships in two months... for old timber had been stored away in readiness, and a large number of skilled workmen, maintained at public expense.
The textiles industry in Carthage probably started in private homes, but the existence of professional weavers indicates that a sort of factory system later developed. Products included embroidery, carpets, and use of the purple murex dye (for which the Carthaginian isle of Djerba was famous). Metalworkers developed specialized skills, i.e., making various weapons for the armed forces, as well as domestic articles, such as knives, forks, scissors, mirrors, and razors (all articles found in tombs). Artwork in metals included vases and lamps in bronze, also bowls, and plates. Other products came from such crafts as the potters, the glassmakers, and the goldsmiths. Inscriptions on votive stele indicate that many were not slaves but 'free citizens'.
Phoenician and Punic merchant ventures were often run as a family enterprise, putting to work its members and its subordinate clients. Such family-run businesses might perform a variety of tasks: own and maintain the ships, providing the captain and crew; do the negotiations overseas, either by barter or buying and selling, of their own manufactured commodities and trade goods, and native products (metals, foodstuffs, etc.) to carry and trade elsewhere; and send their agents to stay at distant outposts in order to make lasting local contacts, and later to establish a warehouse of shipped goods for exchange, and eventually perhaps a settlement. Over generations, such activity might result in the creation of a wide-ranging network of trading operations. Ancillary would be the growth of reciprocity between different family firms, foreign and domestic.
State protection was extended to its sea traders by the Phoenician city of Tyre and later likewise by the daughter city-state of Carthage. , the well-regarded French historian of ancient North Africa, summarized the major principles guiding the civic rulers of Carthage with regard to its policies for trade and commerce:
Both the Phoenicians and the Cathaginians were well known in antiquity for their secrecy in general, and especially pertaining to commercial contacts and trade routes. Both cultures excelled in commercial dealings. Strabo (63BC-AD21) the Greek geographer wrote that before its fall (in 146 BC) Carthage enjoyed a population of 700,000, and directed an alliance of 300 cities. The Greek historian Polybius (c.203–120) referred to Carthage as "the wealthiest city in the world".
A "suffet" (possibly two) was elected by the citizens, and held office with no military power for a one-year term. Carthaginian generals marshalled mercenary armies and were separately elected. From about 550 to 450 the Magonid family monopolized the top military position; later the Barcid family acted similarly. Eventually it came to be that, after a war, the commanding general had to testify justifying his actions before a court of 104 judges.
Aristotle (384–322) discusses Carthage in his work, "Politica"; he begins: "The Carthaginians are also considered to have an excellent form of government." He briefly describes the city as a "mixed constitution", a political arrangement with cohabiting elements of monarchy, aristocracy, and democracy, i.e., a king (Gk: basileus), a council of elders (Gk: gerusia), and the people (Gk: demos). Later Polybius of Megalopolis (c.204–122, Greek) in his "Histories" would describe the Roman Republic in more detail as a mixed constitution in which the Consuls were the monarchy, the Senate the aristocracy, and the Assemblies the democracy.
Evidently Carthage also had an institution of elders who advised the Suffets, similar to a Greek "gerusia" or the Roman Senate. We do not have a Punic name for this body. At times its members would travel with an army general on campaign. Members also formed permanent committees. The institution had several hundred members drawn from the wealthiest class who held office for life. Vacancies were probably filled by recruitment from among the elite, i.e., by co-option. From among its members were selected the 104 Judges mentioned above. Later the 104 would come to evaluate not only army generals but other office holders as well. Aristotle regarded the 104 as most important; he compared it to the ephorate of Sparta with regard to control over security. In Hannibal's time, such a Judge held office for life. At some stage there also came to be independent self-perpetuating boards of five who filled vacancies and supervised (non-military) government administration.
Popular assemblies also existed at Carthage. When deadlocked the Suffets and the quasi-senatorial institution of elders might request the assembly to vote; also, assembly votes were requested in very crucial matters in order to achieve political consensus and popular coherence. The assembly members had no "legal" wealth or birth qualification. How its members were selected is unknown, e.g., whether by festival group or urban ward or another method.
The Greeks were favourably impressed by the constitution of Carthage; Aristotle had a separate study of it made which unfortunately is lost. In his "Politica" he states: "The government of Carthage is oligarchical, but they successfully escape the evils of oligarchy by enriching one portion of the people after another by sending them to their colonies." "[T]heir policy is to send some [poorer citizens] to their dependent towns, where they grow rich." Yet Aristotle continues, "[I]f any misfortune occurred, and the bulk of the subjects revolted, there would be no way of restoring peace by legal means." Aristotle remarked also:
Many of the Carthaginian institutions are excellent. The superiority of their constitution is proved by the fact that the common people remain loyal to the constitution; the Carthaginians have never had any rebellion worth speaking of, and have never been under the rule of a tyrant.
Here one may remember that the city-state of Carthage, who citizens were mainly "Libyphoenicians" (of Phoenician ancestry born in Africa), dominated and exploited an agricultural countryside composed mainly of native Berber sharecroppers and farmworkers, whose affiliations to Carthage were open to divergent possibilities. Beyond these more settled Berbers and the Punic farming towns and rural manors, lived the independent Berber tribes, who were mostly pastoralists.
In the brief, uneven review of government at Carthage found in his "Politica" Aristotle mentions several faults. Thus, "that the same person should hold many offices, which is a favorite practice among the Carthaginians." Aristotle disapproves, mentioning the flute-player and the shoemaker. Also, that "magistrates should be chosen not only for their merit but for their wealth." Aristotle's opinion is that focus on pursuit of wealth will lead to oligarchy and its evils.
[S]urely it is a bad thing that the greatest offices... should be bought. The law which allows this abuse makes wealth of more account than virtue, and the whole state becomes avaricious. For, whenever the chiefs of the state deem anything honorable, the other citizens are sure to follow their example; and, where virtue has not the first place, their aristocracy cannot be firmly established.
In Carthage the people seemed politically satisfied and submissive, according to the historian Warmington. They in their assemblies only rarely exercised the few opportunities given them to assent to state decisions. Popular influence over government appears not to have been an issue at Carthage. Being a commercial republic fielding a mercenary army, the people were not conscripted for military service, an experience which can foster the feel for popular political action. But perhaps this misunderstands the society; perhaps the people, whose values were based on small-group loyalty, felt themselves sufficiently connected to their city's leadership by the very integrity of the person-to-person linkage within their social fabric. Carthage was very stable; there were few openings for tyrants. Only after defeat by Rome devastated Punic imperial ambitions did the people of Carthage seem to question their governance and to show interest in political reform.
In 196, following the Second Punic War (218–201), Hannibal Barca, still greatly admired as a Barcid military leader, was elected suffet. When his reforms were blocked by a financial official about to become a judge for life, Hannibal rallied the populace against the 104 judges. He proposed a one-year term for the 104, as part of a major civic overhaul. Additionally, the reform included a restructuring of the city's revenues, and the fostering of trade and agriculture. The changes rather quickly resulted in a noticeable increase in prosperity. Yet his incorrigible political opponents cravenly went to Rome, to charge Hannibal with conspiracy, namely, plotting war against Rome in league with Antiochus the Hellenic ruler of Syria. Although the Roman Scipio Africanus resisted such manoeuvre, eventually intervention by Rome forced Hannibal to leave Carthage. Thus, corrupt city officials efficiently blocked Hannibal Barca in his efforts to reform the government of Carthage.
Mago (6th century) was King of Carthage; the head of state, war leader, and religious figurehead. His family was considered to possess a sacred quality. Mago's office was somewhat similar to that of a pharaoh, but although kept in a family it was not hereditary, it was limited by legal consent. Picard, accordingly, believes that the council of elders and the popular assembly are late institutions. Carthage was founded by the king of Tyre who had a royal monopoly on this trading venture. Thus it was the royal authority stemming from this traditional source of power that the King of Carthage possessed. Later, as other Phoenician ship companies entered the trading region, and so associated with the city-state, the King of Carthage had to keep order among a rich variety of powerful merchants in their negotiations among themselves and over risky commerce across the Mediterranean. Under these circumstance, the office of king began to be transformed. Yet it was not until the aristocrats of Carthage became wealthy owners of agricultural lands in Africa that a council of elders was institutionalized at Carthage.
Most ancient literature concerning Carthage comes from Greek and Roman sources as Carthage's own documents were destroyed by the Romans. Apart from inscriptions, hardly any Punic literature has survived, and none in its own language and script. A brief catalogue would include:
"[F]rom the Greek author Plutarch [(c. 46 – c. 120)] we learn of the 'sacred books' in Punic safeguarded by the city's temples. Few Punic texts survive, however." Once "the City Archives, the Annals, and the scribal lists of "suffets"" existed, but evidently these were destroyed in the horrific fires during the Roman capture of the city in 146 BC.
Yet some Punic books (Latin: "libri punici") from the libraries of Carthage reportedly did survive the fires. These works were apparently given by Roman authorities to the newly augmented Berber rulers. Over a century after the fall of Carthage, the Roman politician-turned-author Gaius Sallustius Crispus or Sallust (86–34) reported his having seen volumes written in Punic, which books were said to be once possessed by the Berber king, Hiempsal II (r. 88–81). By way of Berber informants and Punic translators, Sallust had used these surviving books to write his brief sketch of Berber affairs.
Probably some of Hiempsal II's "libri punici", that had escaped the fires that consumed Carthage in 146 BC, wound up later in the large royal library of his grandson Juba II (r.25 BC-AD 24). Juba II not only was a Berber king, and husband of Cleopatra's daughter, but also a scholar and author in Greek of no less than nine works. He wrote for the Mediterranean-wide audience then enjoying classical literature. The "libri punici" inherited from his grandfather surely became useful to him when composing his "Libyka", a work on North Africa written in Greek. Unfortunately, only fragments of "Libyka" survive, mostly from quotations made by other ancient authors. It may have been Juba II who 'discovered' the five-centuries-old 'log book' of Hanno the Navigator, called the "Periplus", among library documents saved from fallen Carthage.
In the end, however, most Punic writings that survived the destruction of Carthage "did not escape the immense wreckage in which so many of Antiquity's literary works perished." Accordingly, the long and continuous interactions between Punic citizens of Carthage and the Berber communities that surrounded the city have no local historian. Their political arrangements and periodic crises, their economic and work life, the cultural ties and social relations established and nourished (infrequently as kin), are not known to us directly from ancient Punic authors in written accounts. Neither side has left us their stories about life in Punic-era Carthage.
Regarding "Phoenician" writings, few remain and these seldom refer to Carthage. The more ancient and most informative are cuneiform tablets, ca. 1600–1185, from ancient Ugarit, located to the north of Phoenicia on the Syrian coast; it was a Canaanite city politically affiliated with the Hittites. The clay tablets tell of myths, epics, rituals, medical and administrative matters, and also correspondence. The highly valued works of Sanchuniathon, an ancient priest of Beirut, who reportedly wrote on Phoenician religion and the origins of civilization, are themselves completely lost, but some little content endures twice removed. Sanchuniathon was said to have lived in the 11th century, which is considered doubtful. Much later a "Phoenician History" by Philo of Byblos (64–141) reportedly existed, written in Greek, but only fragments of this work survive. An explanation proffered for why so few Phoenician works endured: early on (11th century) archives and records began to be kept on papyrus, which does not long survive in a moist coastal climate. Also, both Phoenicians and Carthaginians were well known for their secrecy.
Thus, of their ancient writings we have little of major interest left to us by Carthage, or by Phoenicia the country of origin of the city founders. "Of the various Phoenician and Punic compositions alluded to by the ancient classical authors, not a single work or even fragment has survived in its original idiom." "Indeed, not a single Phoenician manuscript has survived in the original [language] or in translation." We cannot therefore access directly the line of thought or the contour of their worldview as expressed in their own words, in their own voice. Ironically, it was the Phoenicians who "invented or at least perfected and transmitted a form of writing [the alphabet] that has influenced dozens of cultures including our own."
As noted, the celebrated ancient books on agriculture written by Mago of Carthage survives only via quotations in Latin from several later Roman works.

</doc>
<doc id="6556" url="https://en.wikipedia.org/wiki?curid=6556" title="Coprime integers">
Coprime integers

In number theory, two integers and are said to be relatively prime, mutually prime, or coprime if the only positive integer (factor) that divides both of them is 1. Consequently, any prime number that divides one of or does not divide the other. This is equivalent to their greatest common divisor (gcd) being 1. 
The numerator and denominator of a reduced fraction are coprime. 
The numbers 14 and 25 are coprime, since 1 is their only common divisor.
On the other hand, 14 and 21 are not coprime, because they are both divisible by 7. 
Standard notations for relatively prime integers and are: and . Graham, Knuth and Patashnik have proposed that the notation formula_1 be used to indicate that and are relatively prime and that the term "prime" be used instead of coprime (as in is "prime" to ).
A fast way to determine whether two numbers are coprime is given by the Euclidean algorithm and its faster variants such as binary GCD algorithm or Lehmer's GCD algorithm.
The number of integers coprime to a positive integer , between 1 and , is given by Euler's totient function, 
also known as Euler's phi function, .
A set of integers can also be called coprime if its elements share no common positive factor except 1. A stronger condition on a set of integers is pairwise coprime, which means that and are coprime for every pair of different integers in the set. The set } is coprime, but it is not pairwise coprime since 2 and 4 are not relatively prime.
The numbers 1 and −1 are the only integers coprime to every integer, and they are the only integers that are coprime with 0.
A number of conditions are equivalent to and being coprime:
As a consequence of the third point, if "a" and "b" are coprime and "br" ≡ "bs" (mod "a"), then "r" ≡ "s" (mod "a"). That is, we may "divide by "b"" when working modulo "a". Furthermore, if "b" and "b" are both coprime with "a", then so is their product "b""b" (i.e., modulo "a" it is a product of invertible elements, and therefore invertible); this also follows from the first point by Euclid's lemma, which states that if a prime number "p" divides a product "bc", then "p" divides at least one of the factors "b", "c".
As a consequence of the first point, if "a" and "b" are coprime, then so are any powers "a" and "b".
If "a" and "b" are coprime and "a" divides the product "bc", then "a" divides "c". This can be viewed as a generalization of Euclid's lemma.
The two integers "a" and "b" are coprime if and only if the point with coordinates ("a", "b") in a Cartesian coordinate system is "visible" from the origin (0,0), in the sense that there is no point with integer coordinates on the line segment between the origin and ("a", "b"). (See figure 1.)
In a sense that can be made precise, the probability that two randomly chosen integers are coprime is 6/π (see pi), which is about 61%. See below.
Two natural numbers "a" and "b" are coprime if and only if the numbers 2 − 1 and 2 − 1 are coprime. As a generalization of this, following easily from the Euclidean algorithm in base "n" > 1:
A set of integers "S" = {"a", "a", ... "a"} can also be called "coprime" or "setwise coprime" if the greatest common divisor of all the elements of the set is 1. For example, the integers 6, 10, 15 are coprime because 1 is the only positive integer that divides all of them.
If every pair in a set of integers is coprime, then the set is said to be "pairwise coprime" (or "pairwise relatively prime", "mutually coprime" or "mutually relatively prime"). Pairwise coprimality is a stronger condition than setwise coprimality; every pairwise coprime finite set is also setwise coprime, but the reverse is not true. For example, the integers 4, 5, 6 are (setwise) coprime (because the only positive integer dividing "all" of them is 1), but they are not "pairwise" coprime (because gcd(4, 6) = 2).
The concept of pairwise coprimality is important as a hypothesis in many results in number theory, such as the Chinese remainder theorem.
It is possible for an infinite set of integers to be pairwise coprime. Notable examples include the set of all prime numbers, the set of elements in Sylvester's sequence, and the set of all Fermat numbers.
Two ideals "A" and "B" in the commutative ring "R" are called coprime (or comaximal) if "A" + "B" = "R". This generalizes Bézout's identity: with this definition, two principal ideals ("a") and ("b") in the ring of integers Z are coprime if and only if "a" and "b" are coprime. If the ideals "A" and "B" of "R" are coprime, then "AB" = "A"∩"B"; furthermore, if "C" is a third ideal such that "A" contains "BC", then "A" contains "C". The Chinese remainder theorem can be generalized to any commutative ring, using coprime ideals.
Given two randomly chosen integers "a" and "b", it is reasonable to ask how likely it is that "a" and "b" are coprime. In this determination, it is convenient to use the characterization that "a" and "b" are coprime if and only if no prime number divides both of them (see Fundamental theorem of arithmetic).
Informally, the probability that any number is divisible by a prime (or in fact any integer) formula_3 is formula_4; for example, every 7th integer is divisible by 7. Hence the probability that two numbers are both divisible by "p" is formula_5, and the probability that at least one of them is not is formula_6. Any finite collection of divisibility events associated to distinct primes is mutually independent. For example, in the case of two events, a number is divisible by primes "p" and "q" if and only if it is divisible by "pq"; the latter event has probability 1/"pq". If one makes the heuristic assumption that such reasoning can be extended to infinitely many divisibility events, one is led to guess that the probability that two numbers are coprime is given by a product over all primes,
Here "ζ" refers to the Riemann zeta function, the identity relating the product over primes to "ζ"(2) is an example of an Euler product, and the evaluation of "ζ"(2) as "π"/6 is the Basel problem, solved by Leonhard Euler in 1735.
There is no way to choose a positive integer at random so that each positive integer occurs with equal probability, but statements about "randomly chosen integers" such as the ones above can be formalized by using the notion of "natural density". For each positive integer "N", let "P" be the probability that two randomly chosen numbers in formula_8 are coprime. Although "P" will never equal formula_9 exactly, with work one can show that in the limit as formula_10, the probability formula_11 approaches formula_9.
More generally, the probability of "k" randomly chosen integers being coprime is formula_13.
All pairs of positive coprime numbers formula_14 (with formula_15) can be arranged in two disjoint complete ternary trees, one tree starting from formula_16 (for even-odd and odd-even pairs), and the other tree starting from formula_17 (for odd-odd pairs). The children of each vertex formula_18 are generated as follows:
This scheme is exhaustive and non-redundant with no invalid members.

</doc>
