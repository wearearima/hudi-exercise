<doc id="1354" url="https://en.wikipedia.org/wiki?curid=1354" title="Andes">
Andes

The Andes, Andes Mountains or Andean Mountains () are the longest continental mountain range in the world, forming a continuous highland along the western edge of South America. The range is long, wide (widest between 18° south and 20° south latitude), and has an average height of about . The Andes extend from north to south through seven South American countries: Venezuela, Colombia, Ecuador, Peru, Bolivia, Chile, and Argentina.
Along their length, the Andes are split into several ranges, separated by intermediate depressions. The Andes are the location of several high plateaus—some of which host major cities such as Quito, Bogotá, Cali, Arequipa, Medellín, Bucaramanga, Sucre, Mérida and La Paz. The Altiplano plateau is the world's second-highest after the Tibetan plateau. These ranges are in turn grouped into three major divisions based on climate: the Tropical Andes, the Dry Andes, and the Wet Andes.
The Andes Mountains are the highest mountain range outside Asia. The highest mountain outside Asia, Argentina's Mount Aconcagua, rises to an elevation of about above sea level. The peak of Chimborazo in the Ecuadorian Andes is farther from the Earth's center than any other location on the Earth's surface, due to the equatorial bulge resulting from the Earth's rotation. The world's highest volcanoes are in the Andes, including Ojos del Salado on the Chile-Argentina border, which rises to .
The Andes are also part of the American Cordillera, a chain of mountain ranges (cordillera) that consists of an almost continuous sequence of mountain ranges that form the western "backbone" of North America, Central America, South America and Antarctica.
The etymology of the word "Andes" has been debated. The majority consensus is that it derives from the Quechua word , which means "east" as in "Antisuyu" (Quechua for "east region"), one of the four regions of the Inca Empire.
The term "cordillera" comes from the Spanish word "cordel", meaning "rope", and is used as a descriptive name for several contiguous sections of the Andes, as well as the entire Andean range, and the combined mountain chain along the western part of the North and South American continents.
The Andes can be divided into three sections:
The Leeward Antilles islands Aruba, Bonaire, and Curaçao, which lie in the Caribbean Sea off the coast of Venezuela, were formerly thought to represent the submerged peaks of the extreme northern edge of the Andes range, but ongoing geological studies indicate that such a simplification does not do justice to the complex tectonic boundary between the South American and Caribbean plates.
The Andes are a Mesozoic–Tertiary orogenic belt of mountains along the Pacific Ring of Fire, a zone of volcanic activity that encompasses the Pacific rim of the Americas as well as the Asia-Pacific region. The Andes are the result of tectonic plate processes, caused by the subduction of oceanic crust beneath the South American Plate. It is the result of a convergent plate boundary between the Nazca Plate and the South American Plate. The main cause of the rise of the Andes is the compression of the western rim of the South American Plate due to the subduction of the Nazca Plate and the Antarctic Plate. To the east, the Andes range is bounded by several sedimentary basins, such as Orinoco, Amazon Basin, Madre de Dios and Gran Chaco, that separate the Andes from the ancient cratons in eastern South America. In the south, the Andes share a long boundary with the former Patagonia Terrane. To the west, the Andes end at the Pacific Ocean, although the Peru-Chile trench can be considered their ultimate western limit. From a geographical approach, the Andes are considered to have their western boundaries marked by the appearance of coastal lowlands and a less rugged topography. The Andes Mountains also contain large quantities of iron ore located in many mountains within the range.
The Andean orogen has a series of bends or oroclines. The Bolivian Orocline is a seaward concave bending in the coast of South America and the Andes Mountains at about 18° S. At this point, the orientation of the Andes turns from Northwest in Peru to South in Chile and Argentina. The Andean segment north and south of the Orocline have been rotated 15° to 20° counter clockwise and clockwise respectively. The Bolivian Orocline area overlaps with the area of maximum width of the Altiplano Plateau and according to Isacks (1988) the Orocline is related to crustal shortening. The specific point at 18° S where the coastline bends is known as the "Arica Elbow". Further south lies the Maipo Orocline a more subtle Orocline between 30° S and 38°S with a seaward-concave break in trend at 33° S. Near the southern tip of the Andes lies the Patagonian Orocline.
The western rim of the South American Plate has been the place of several pre-Andean orogenies since at least the late Proterozoic and early Paleozoic, when several terranes and microcontinents collided and amalgamated with the ancient cratons of eastern South America, by then the South American part of Gondwana.
The formation of the modern Andes began with the events of the Triassic when Pangaea began the break up that resulted in developing several rifts. The development continued through the Jurassic Period. It was during the Cretaceous Period that the Andes began to take their present form, by the uplifting, faulting and folding of sedimentary and metamorphic rocks of the ancient cratons to the east. The rise of the Andes has not been constant, as different regions have had different degrees of tectonic stress, uplift, and erosion.
Tectonic forces above the subduction zone along the entire west coast of South America where the Nazca Plate and a part of the Antarctic Plate are sliding beneath the South American Plate continue to produce an ongoing orogenic event resulting in minor to major earthquakes and volcanic eruptions to this day. In the extreme south, a major transform fault separates Tierra del Fuego from the small Scotia Plate. Across the wide Drake Passage lie the mountains of the Antarctic Peninsula south of the Scotia Plate which appear to be a continuation of the Andes chain.
The regions immediately east of the Andes experience a series of changes resulting from the Andean orogeny. Parts of the Sunsás Orogen in Amazonian craton disappeared from the surface of earth being overridden by the Andes.
The Sierras de Córdoba, where the effects of the ancient Pampean orogeny can be observed, owe their modern uplift and relief to the Andean orogeny in the Tertiary. Further south in southern Patagonia the onset of the Andean orogeny caused the Magallanes Basin to evolve from being an extensional back-arc basin in the Mesozoic to being a compressional foreland basin in the Cenozoic.
The Andes range has many active volcanoes distributed in four volcanic zones separated by areas of inactivity. The Andean volcanism is a result of subduction of the Nazca Plate and Antarctic Plate underneath the South American Plate. The belt is subdivided into four main volcanic zones that are separated from each other by volcanic gaps. The volcanoes of the belt are diverse in terms of activity style, products and morphology. While some differences can be explained by which volcanic zone a volcano belongs to, there are significant differences inside volcanic zones and even between neighbouring volcanoes. Despite being a type location for calc-alkalic and subduction volcanism, the Andean Volcanic Belt has a large range of volcano-tectonic settings, such as rift systems and extensional zones, transpressional faults, subduction of mid-ocean ridges and seamount chains apart from a large range of crustal thicknesses and magma ascent paths, and different amount of crustal assimilations.
The Andes Mountains host large ore and salt deposits and some of their eastern fold and thrust belt acts as traps for commercially exploitable amounts of hydrocarbons. In the forelands of the Atacama Desert some of the largest porphyry copper mineralizations occurs making Chile and Peru the first and second largest exporters of copper in the world. Porphyry copper in the western slopes of the Andes has been generated by hydrothermal fluids (mostly water) during the cooling of plutons or volcanic systems. The porphyry mineralization further benefited from the dry climate that let them largely out of the disturbing actions of meteoric water. The dry climate in the central western Andes has also led to the creation of extensive saltpeter deposits which were extensively mined until the invention of synthetic nitrates. Yet another result of the dry climate are the salars of Atacama and Uyuni, the first one being the largest source of lithium today and the second the world's largest reserve of the element. Early Mesozoic and Neogene plutonism in Bolivia's Cordillera Central created the Bolivian tin belt as well as the famous, now depleted, deposits of Cerro Rico de Potosí.
The climate in the Andes varies greatly depending on latitude, altitude, and proximity to the sea. Temperature, atmospheric pressure and humidity decrease in higher elevations. The southern section is rainy and cool, the central section is dry. The northern Andes are typically rainy and warm, with an average temperature of in Colombia. The climate is known to change drastically in rather short distances. Rainforests exist just kilometres away from the snow-covered peak Cotopaxi. The mountains have a large effect on the temperatures of nearby areas. The snow line depends on the location. It is at between in the tropical Ecuadorian, Colombian, Venezuelan, and northern Peruvian Andes, rising to in the drier mountains of southern Peru south to northern Chile south to about 30°S before descending to on Aconcagua at 32°S, at 40°S, at 50°S, and only in Tierra del Fuego at 55°S; from 50°S, several of the larger glaciers descend to sea level.
The Andes of Chile and Argentina can be divided in two climatic and glaciological zones: the Dry Andes and the Wet Andes. Since the Dry Andes extend from the latitudes of Atacama Desert to the area of Maule River, precipitation is more sporadic and there are strong temperature oscillations. The line of equilibrium may shift drastically over short periods of time, leaving a whole glacier in the ablation area or in the accumulation area.
In the high Andes of central Chile and Mendoza Province, rock glaciers are larger and more common than glaciers; this is due to the high exposure to solar radiation.
Though precipitation increases with the height, there are semiarid conditions in the nearly highest mountains of the Andes. This dry steppe climate is considered to be typical of the subtropical position at 32–34° S. The valley bottoms have no woods, just dwarf scrub. The largest glaciers, as e.g. the Plomo glacier and the Horcones glaciers, do not even reach in length and have an only insignificant ice thickness. At glacial times, however, c. 20,000 years ago, the glaciers were over ten times longer. On the east side of this section of the Mendozina Andes, they flowed down to and on the west side to about above sea level. The massifs of Cerro Aconcagua (), Cerro Tupungato () and Nevado Juncal () are tens of kilometres away from each other and were connected by a joint ice stream network. The Andes' dendritic glacier arms, i.e. components of valley glaciers, were up to long, over thick and overspanned a vertical distance of . The climatic glacier snowline (ELA) was lowered from to at glacial times.
The Andean region cuts across several natural and floristic regions due to its extension from Caribbean Venezuela to cold, windy and wet Cape Horn passing through the hyperarid Atacama Desert. Rainforests and tropical dry forests used to encircle much of the northern Andes but are now greatly diminished, especially in the Chocó and inter-Andean valleys of Colombia. Opposite of the humid Andean slopes are the relatively dry Andean slopes in most of western Peru, Chile and Argentina. Along with several Interandean Valles, they are typically dominated by deciduous woodland, shrub and xeric vegetation, reaching the extreme in the slopes near the virtually lifeless Atacama Desert.
About 30,000 species of vascular plants live in the Andes, with roughly half being endemic to the region, surpassing the diversity of any other hotspot. The small tree "Cinchona pubescens", a source of quinine which is used to treat malaria, is found widely in the Andes as far south as Bolivia. Other important crops that originated from the Andes are tobacco and potatoes. The high-altitude "Polylepis" forests and woodlands are found in the Andean areas of Colombia, Ecuador, Peru, Bolivia and Chile. These trees, by locals referred to as Queñua, Yagual and other names, can be found at altitudes of above sea level. It remains unclear if the patchy distribution of these forests and woodlands is natural, or the result of clearing which began during the Incan period. Regardless, in modern times the clearance has accelerated, and the trees are now considered to be highly endangered, with some believing that as little as 10% of the original woodland remains.
The Andes are rich in fauna: With almost 1,000 species, of which roughly 2/3 are endemic to the region, the Andes are the most important region in the world for amphibians.
The diversity of animals in the Andes is high, with almost 600 species of mammals (13% endemic), more than 1,700 species of birds (about 1/3 endemic), more than 600 species of reptile (about 45% endemic), and almost 400 species of fish (about 1/3 endemic).
The vicuña and guanaco can be found living in the Altiplano, while the closely related domesticated llama and alpaca are widely kept by locals as pack animals and for their meat and wool. The crepuscular (active during dawn and dusk) chinchillas, two threatened members of the rodent order, inhabit the Andes' alpine regions. The Andean condor, the largest bird of its kind in the Western Hemisphere, occurs throughout much of the Andes but generally in very low densities. Other animals found in the relatively open habitats of the high Andes include the huemul, cougar, foxes in the genus "Pseudalopex", and, for birds, certain species of tinamous (notably members of the genus "Nothoprocta"), Andean goose, giant coot, flamingos (mainly associated with hypersaline lakes), lesser rhea, Andean flicker, diademed sandpiper-plover, miners, sierra-finches and diuca-finches.
Lake Titicaca hosts several endemics, among them the highly endangered Titicaca flightless grebe and Titicaca water frog. A few species of hummingbirds, notably some hillstars, can be seen at altitudes above , but far higher diversities can be found at lower altitudes, especially in the humid Andean forests ("cloud forests") growing on slopes in Colombia, Ecuador, Peru, Bolivia and far northwestern Argentina. These forest-types, which includes the Yungas and parts of the Chocó, are very rich in flora and fauna, although few large mammals exist, exceptions being the threatened mountain tapir, spectacled bear and yellow-tailed woolly monkey.
Birds of humid Andean forests include mountain-toucans, quetzals and the Andean cock-of-the-rock, while mixed species flocks dominated by tanagers and furnariids commonly are seen – in contrast to several vocal but typically cryptic species of wrens, tapaculos and antpittas.
A number of species such as the royal cinclodes and white-browed tit-spinetail are associated with "Polylepis", and consequently also threatened.
The Andes Mountains form a north–south axis of cultural influences. A long series of cultural development culminated in the expansion of the Inca civilization and Inca Empire in the central Andes during the 15th century. The Incas formed this civilization through imperialistic militarism as well as careful and meticulous governmental management. The government sponsored the construction of aqueducts and roads in addition to preexisting installations. Some of these constructions are still in existence today.
Devastated by European diseases to which they had no immunity and civil wars, in 1532 the Incas were defeated by an alliance composed of tens of thousands of allies from nations they had subjugated (e.g. Huancas, Chachapoyas, Cañaris) and a small army of 180 Spaniards led by Francisco Pizarro. One of the few Inca sites the Spanish never found in their conquest was Machu Picchu, which lay hidden on a peak on the eastern edge of the Andes where they descend to the Amazon. The main surviving languages of the Andean peoples are those of the Quechua and Aymara language families. Woodbine Parish and Joseph Barclay Pentland surveyed a large part of the Bolivian Andes from 1826 to 1827.
In modern times, the largest cities in the Andes are Bogotá, with a population of about eight million, and Santiago, Medellín, and Cali. Lima is a coastal city adjacent to the Andes and is the largest city of all Andean countries. It is the seat of the Andean Community of Nations.
La Paz, Bolivia's seat of government, is the highest capital city in the world, at an elevation of approximately . Parts of the La Paz conurbation, including the city of El Alto, extend up to .
Other cities in or near the Andes include Bariloche, Catamarca, Jujuy, Mendoza, Salta, San Juan, and Tucumán in Argentina; Calama and Rancagua in Chile; Cochabamba, Oruro, Potosí, Sucre, Sacaba, Tarija, and Yacuiba in Bolivia; Arequipa, Cajamarca, Cusco, Huancayo, Huánuco, Huaraz, Juliaca, and Puno in Peru; Ambato, Cuenca, Ibarra, Loja, Quito, Riobamba and Tulcán in Ecuador; Armenia, Cúcuta, Bucaramanga, Duitama, Ibagué, Ipiales, Manizales, Palmira, Pasto, Pereira, Popayán, Sogamoso, Tunja, and Villavicencio in Colombia; and Barquisimeto, La Grita, Mérida, San Cristóbal, Tovar, Trujillo, and Valera in Venezuela. The cities of Caracas, Valencia, and Maracay are in the Venezuelan Coastal Range, which is a debatable extension of the Andes at the northern extremity of South America.
Cities and large towns are connected with asphalt-paved roads, while smaller towns are often connected by dirt roads, which may require a four-wheel-drive vehicle.
The rough terrain has historically put the costs of building highways and railroads that cross the Andes out of reach of most neighboring countries, even with modern civil engineering practices. For example, the main crossover of the Andes between Argentina and Chile is still accomplished through the Paso Internacional Los Libertadores. Only recently the ends of some highways that came rather close to one another from the east and the west have been connected. Much of the transportation of passengers is done via aircraft.
However, there is one railroad that connects Chile with Peru via the Andes, and there are others that make the same connection via southern Bolivia. See railroad maps of that region.
There are multiple highways in Bolivia that cross the Andes. Some of these were built during a period of war between Bolivia and Paraguay, in order to transport Bolivian troops and their supplies to the war front in the lowlands of southeastern Bolivia and western Paraguay.
For decades, Chile claimed ownership of land on the eastern side of the Andes. However, these claims were given up in about 1870 during the War of the Pacific between Chile, the allied Bolivia and Peru, in a diplomatic deal to keep Peru out of the war. The Chilean Army and Chilean Navy defeated the combined forces of Bolivia and Peru, and Chile took over Bolivia's only province on the Pacific Coast, some land from Peru that was returned to Peru decades later. Bolivia has been a completely landlocked country ever since. It mostly uses seaports in eastern Argentina and Uruguay for international trade because its diplomatic relations with Chile have been suspended since 1978.
Because of the tortuous terrain in places, villages and towns in the mountains—to which travel via motorized vehicles is of little use—are still located in the high Andes of Chile, Bolivia, Peru, and Ecuador. Locally, the relatives of the camel, the llama, and the alpaca continue to carry out important uses as pack animals, but this use has generally diminished in modern times. Donkeys, mules, and horses are also useful.
The ancient peoples of the Andes such as the Incas have practiced irrigation techniques for over 6,000 years. Because of the mountain slopes, terracing has been a common practice. Terracing, however, was only extensively employed after Incan imperial expansions to fuel their expanding realm. The potato holds a very important role as an internally consumed staple crop. Maize was also an important crop for these people, and was used for the production of chicha, important to Andean native people. Currently, tobacco, cotton and coffee are the main export crops. Coca, despite eradication programmes in some countries, remains an important crop for legal local use in a mildly stimulating herbal tea, and, both controversially and illegally, for the production of cocaine.
In unirrigated land, pasture is the most common type of land use. In the rainy season (summer), part of the rangeland is used for cropping (mainly potatoes, barley, broad beans and wheat).
Irrigation is helpful in advancing the sowing data of the summer crops which guarantees an early yield in the period of food shortage. Also, by early sowing, maize can be cultivated higher up in the mountains (up to ). In addition it makes cropping in the dry season (winter) possible and allows the cultivation of frost resistant vegetable crops like onion and carrot.
The Andes rose to fame for their mineral wealth during the Spanish conquest of South America. Although Andean Amerindian peoples crafted ceremonial jewelry of gold and other metals, the mineralizations of the Andes were first mined on a large scale after the Spanish arrival. Potosí in present-day Bolivia and Cerro de Pasco in Peru was one of the principal mines of the Spanish Empire in the New World. Río de la Plata and Argentina derive their names from the silver of Potosí.
Currently, mining in the Andes of Chile and Peru places these countries as the first and third major producers of copper in the world. Peru also contains the 4th largest goldmine in the world: the Yanacocha. The Bolivian Andes produce principally tin although historically silver mining had a huge impact on the economy of 17th century Europe.
There is a long history of mining in the Andes, from the Spanish silver mines in Potosí in the 16th century to the vast current porphyry copper deposits of Chuquicamata and Escondida in Chile and Toquepala in Peru. Other metals including iron, gold, and tin in addition to non-metallic resources are important.
This list contains some of the major peaks in the Andes mountain range. The highest peak is Aconcagua of Argentina (see below).

</doc>
<doc id="1356" url="https://en.wikipedia.org/wiki?curid=1356" title="Ancylopoda">
Ancylopoda

Ancylopoda is a group of browsing, herbivorous, mammals in the Perissodactyla that show long, curved and cleft claws. Morphological evidence indicates the Ancylopoda diverged from the tapirs, rhinoceroses and horses (Euperissodactyla) after the Brontotheria, however earlier authorities such as Osborn sometimes considered the Ancylopoda to be outside Perissodactyla or, as was popular more recently, to be related to Brontotheria.
"Macrotherium", which is typically from the middle Miocene of Sansan, in Gers, France, may indicate a distinct genus. Limb-bones resembling those of Macrotherium, but relatively stouter, have been described from the Pliocene beds of Attica and Samos as "Ancylotherium". In the Americas, the names "Morothorium" and "Moropus" have been applied to similar bones, in the belief that they indicated Xenarthrans. "Macrotherium magnum" must have been an animal of about nine feet in length.
The South American genus "Homalodotherium" is sometimes placed in the Ancylopoda, but arguments against this have been given by Professor H. F. Osborn, who considers that the Ancylopoda are directly descended from the Condylarthra.

</doc>
<doc id="1358" url="https://en.wikipedia.org/wiki?curid=1358" title="Anchor">
Anchor

An anchor is a device, normally made of metal, used to connect a vessel to the bed of a body of water to prevent the craft from drifting due to wind or current. The word derives from Latin "ancora", which itself comes from the Greek ἄγκυρα ("ankura").
Anchors can either be temporary or permanent. Permanent anchors are used in the creation of a mooring, and are rarely moved; a specialist service is normally needed to move or maintain them. Vessels carry one or more temporary anchors, which may be of different designs and weights.
A sea anchor is a drag device, not in contact with the seabed, used to minimise drift of a vessel relative to the water. A drogue is a drag device used to slow or help steer a vessel running before a storm in a following or overtaking sea, or when crossing a bar in a breaking sea.
Anchors achieve holding power either by "hooking" into the seabed, or sheer mass, or a combination of the two. Permanent moorings use large masses (commonly a block or slab of concrete) resting on the seabed. Semi-permanent mooring anchors (such as mushroom anchors) and large ship's anchors derive a significant portion of their holding power from their mass, while also hooking or embedding in the bottom. Modern anchors for smaller vessels have metal "flukes" which hook on to rocks on the bottom or bury themselves in soft seabed.
The vessel is attached to the anchor by the "rode" (commonly called "cable" when made of rope, and made of chain in larger vessels), or a combination of these. The ratio of the length of rode to the water depth is known as the scope; generally, the rode should be between 5 and 10 times the depth to the seabed, giving a scope of 5:1 or 10:1; the larger the number, the shallower the angle is between the cable and the seafloor, and the less upwards force is acting on the anchor. A 10:1 scope gives the greatest holding power, but also allows for much more drifting due to the longer amount of cable paid out. Anchoring with sufficient scope and/or heavy chain rode brings the direction of strain close to parallel with the seabed. This is particularly important for light, modern anchors designed to bury in the bottom, where scopes of 5:1 to 7:1 are common, whereas heavy anchors and moorings can use a scope of 3:1, or less. Some modern anchors, such as the Ultra will hold with a scope of 3:1; but, unless the anchorage is crowded, a longer scope will always reduce shock stresses.
Since all anchors that embed themselves in the bottom require the strain to be along the seabed, anchors can be broken out of the bottom by shortening the rope until the vessel is directly above the anchor; at this point the anchor chain is "up and down", in naval parlance. If necessary, motoring slowly around the location of the anchor also helps dislodge it. Anchors are sometimes fitted with a tripping line attached to the crown, by which they can be unhooked from rocks or coral.
The term "aweigh" describes an anchor when it is hanging on the rope and is not resting on the bottom. This is linked to the term "to weigh anchor", meaning to lift the anchor from the sea bed, allowing the ship or boat to move. An anchor is described as "aweigh" when it has been broken out of the bottom and is being hauled up to be "stowed". "Aweigh" should not be confused with "under way", which describes a vessel which is not "moored" to a dock or "anchored", whether or not the vessel is moving through the water.
Holding ground is the area of sea floor which holds an anchor, and thus the attached ship or boat. Different types of anchor are designed to hold in different types of holding ground. Some bottom materials hold better than others; for instance, hard sand holds well, shell very poorly. Holding ground may be fouled with obstacles. An anchorage location may be chosen for its holding ground. In poor holding ground, only the weight of an anchor matters; in good holding ground, it is able to dig in, and the holding power can be significantly higher.
The earliest anchors were probably rocks, and many rock anchors have been found dating from at least the Bronze Age. Pre-European Maori waka (canoes) used one or more hollowed stones, tied with flax ropes, as anchors. Many modern moorings still rely on a large rock as the primary element of their design. However, using pure mass to resist the forces of a storm only works well as a permanent mooring; a large enough rock would be nearly impossible to move to a new location.
The ancient Greeks used baskets of stones, large sacks filled with sand, and wooden logs filled with lead. According to Apollonius Rhodius and Stephen of Byzantium, anchors were formed of stone, and Athenaeus states that they were also sometimes made of wood. Such anchors held the vessel merely by their weight and by their friction along the bottom.
Iron was afterwards introduced for the construction of anchors, and an improvement was made by forming them with teeth, or "flukes", to fasten themselves into the bottom. This is the iconic anchor shape most familiar to non-sailors.
This form has been used since antiquity. The Roman Nemi ships of the 1st century AD used this form. The Viking Ladby ship (probably 10th century) used a fluked anchor of this type, made entirely of iron.
The Admiralty Pattern anchor, or simply "Admiralty", also known as a "Fisherman", consists of a central shank with a ring or shackle for attaching the rode (the rope, chain, or cable connecting the ship and the anchor). At the other end of the shank there are two arms, carrying the flukes, while the stock is mounted to the shackle end, at ninety degrees to the arms. When the anchor lands on the bottom, it will generally fall over with the arms parallel to the seabed. As a strain comes onto the rode, the stock will dig into the bottom, canting the anchor until one of the flukes catches and digs into the bottom.
The Admiralty Anchor is an entirely independent reinvention of a classical design, as seen in one of the Nemi ship anchors. This basic design remained unchanged for centuries, with the most significant changes being to the overall proportions, and a move from stocks made of wood to iron stocks in the late 1830s and early 1840s.
Since one fluke always protrudes up from the set anchor, there is a great tendency of the rode to foul the anchor as the vessel swings due to wind or current shifts. When this happens, the anchor may be pulled out of the bottom, and in some cases may need to be hauled up to be re-set. In the mid-19th century, numerous modifications were attempted to alleviate these problems, as well as improve holding power, including one-armed mooring anchors. The most successful of these "patent anchors", the Trotman Anchor, introduced a pivot at the centre of the crown where the arms join the shank, allowing the "idle" upper arm to fold against the shank. When deployed the lower arm may fold against the shank tilting the tip of the fluke upwards, so each fluke has a tripping palm at its base, to hook on the bottom as the folded arm drags along the seabed, which unfolds the downward oriented arm until the tip of the fluke can engage the bottom.
Handling and storage of these anchors requires special equipment and procedures. Once the anchor is hauled up to the hawsepipe, the ring end is hoisted up to the end of a timber projecting from the bow known as the cathead. The crown of the anchor is then hauled up with a heavy tackle until one fluke can be hooked over the rail. This is known as "catting and fishing" the anchor. Before dropping the anchor, the fishing process is reversed, and the anchor is dropped from the end of the cathead.
The stockless anchor, patented in England in 1821, represented the first significant departure in anchor design in centuries. Though their holding-power-to-weight ratio is significantly lower than admiralty pattern anchors, their ease of handling and stowage aboard large ships led to almost universal adoption. In contrast to the elaborate stowage procedures for earlier anchors, stockless anchors are simply hauled up until they rest with the shank inside the hawsepipes, and the flukes against the hull (or inside a recess in the hull).
While there are numerous variations, stockless anchors consist of a set of heavy flukes connected by a pivot or ball and socket joint to a shank. Cast into the crown of the anchor is a set of tripping palms, projections that drag on the bottom, forcing the main flukes to dig in.
Until the mid-20th century, anchors for smaller vessels were either scaled-down versions of admiralty anchors, or simple grapnels. As new designs with greater holding-power-to-weight ratios, a great variety of anchor designs has emerged. Many of these designs are still under patent, and other types are best known by their original trademarked names.
A traditional design, the grapnel is merely a shank with four or more tines. It has a benefit in that, no matter how it reaches the bottom, one or more tines will be aimed to set. In coral, or rock, it is often able to set quickly by hooking into the structure, but may be more difficult to retrieve. A grapnel is often quite light, and may have additional uses as a tool to recover gear lost overboard. Its weight also makes it relatively easy to move and carry, however its shape is generally not very compact and it may be awkward to stow unless a collapsing model is used.
Grapnels rarely have enough fluke area to develop much hold in sand, clay, or mud. It is not unknown for the anchor to foul on its own rode, or to foul the tines with refuse from the bottom, preventing it from digging in. On the other hand, it is quite possible for this anchor to find such a good hook that, without a trip line from the crown, it is impossible to retrieve.
Designed by yacht designer L. Francis Herreshoff, this is essentially the same pattern as an admiralty anchor, albeit with small diamond-shaped flukes or palms. The novelty of the design lay in the means by which it could be broken down into three pieces for stowage. In use, it still presents all the issues of the admiralty pattern anchor.
Originally designed as a lightweight anchor for seaplanes, this design consists of two plough-like blades mounted to a shank, with a folding stock crossing through the crown of the anchor.
Many manufacturers produce a plough-type anchor, so-named after its resemblance to an agricultural plough. All such anchors are copied from the original CQR "secure", a 1933 design patented in the UK by mathematician Geoffrey Ingram Taylor.
Plough anchors stow conveniently in a roller at the bow, and have been popular with cruising sailors and private boaters. Ploughs are generally good in all types of seafloor, though not exceptional in any. Contrary to popular belief, the CQR's hinged shank is not to allow the anchor to turn with direction changes rather than breaking out, but actually to prevent the shank's weight from disrupting the fluke's orientation while setting. The hinge can wear out and may trap a sailor's fingers. Some later plough anchors have a rigid shank, such as the Lewmar's "Delta".
A plough anchor has a fundamental flaw: like it namesake, the agricultural plough, it will dig in but then tends to break out back to the surface. Plough anchors sometimes have difficulty setting at all, and instead skip across the seafloor. By contrast, modern efficient anchors tend to be "spade" types that dig ever deeper.
The Delta was developed in the 1980s for commercialization by British marine manufacturer Simpson–Lawrence. It is a plough anchor with a rigid, arched shank. It is described as "self-launching" because it can be dropped from a bow roller simply by paying out the rode, without manual assistance.
American Richard Danforth invented the Danforth pattern in the 1940s for use aboard landing craft. It uses a stock at the crown to which two large flat triangular flukes are attached. The stock is hinged so the flukes can orient toward the bottom (and on some designs may be adjusted for an optimal angle depending on the bottom type). Tripping palms at the crown act to tip the flukes into the seabed. The design is a burying variety, and once well set can develop high resistance. Its lightweight and compact flat design make it easy to retrieve and relatively easy to store; some anchor rollers and hawsepipes can accommodate a fluke-style anchor.
A Danforth will not usually penetrate or hold in gravel or weeds. In boulders and coral it may hold by acting as a hook. If there is much current, or if the vessel is moving while dropping the anchor, it may "kite" or "skate" over the bottom due to the large fluke area acting as a sail or wing.
The FOB HP anchor designed in Brittany in the 1970s is a Danforth variant designed to give increased holding through its use of rounded flukes setting at a 30° angle.
The Fortress is an American aluminum alloy Danforth variant which can be disassembled for storage and it features an adjustable 32° and 45° shank/fluke angle to improve holding capability in common sea bottoms such as hard sand and soft mud. This anchor performed well in a 1989 US Naval Sea Systems Command (NAVSEA) test. and in an August 2014 holding power test that was conducted in the soft mud bottoms of the Chesapeake Bay.
This claw-shaped anchor was designed by Peter Bruce from the Isle of Man in the 1970s. Bruce gained his early reputation from the production of large-scale commercial anchors for ships and fixed installations such as oil rigs. The Bruce and its copies, known generically as "claws", have been adopted on smaller boats (partly because they stow easily on a bow roller) but they are most effective in larger sizes. It was intended to address some of the problems of the only general-purpose option then available, the plough. Claw-types do not always set quickly in most seabeds, but they have the reputation of not breaking out with tide or wind changes, instead slowly turning in the bottom to align with the force.
Bruce anchors can have difficulty penetrating weedy bottoms and grass. They offer a fairly low holding-power-to-weight ratio and generally have to be oversized to compete with newer types. On the other hand, they have a reasonable reputation in boulder seafloors, and they perform relatively well with low rode scopes. They cannot be used with hawsepipes.
In recent years there has been significant progress in anchor design. Primarily designed to set very quickly, then generate high holding power, these new generation anchors (mostly proprietary inventions still under patent) are becoming popular with users of small to medium-sized vessels.
These are used where the vessel is permanently or semi-permanently sited, for example in the case of lightvessels or channel marker buoys. The anchor needs to hold the vessel in all weathers, including the most severe storm, but needs to be lifted only occasionally, at most – for example, only if the vessel is to be towed into port for maintenance. An alternative to using an anchor under these circumstances, especially if the anchor need never be lifted at all, may be to use a pile driven into the seabed.
Permanent anchors come in a wide range of types and have no standard form. A slab of rock with an iron staple in it to attach a chain to would serve the purpose, as would any dense object of appropriate weight (for instance, an engine block). Modern moorings may be anchored by augers, which look and act very much like oversized screws drilled into the seabed, or by barbed metal beams pounded in (or even driven in with explosives) like pilings, or by a variety of other non-mass means of getting a grip on the bottom. One method of building a mooring is to use three or more conventional anchors laid out with short lengths of chain attached to a swivel, so no matter which direction the vessel moves, one or more anchors will be aligned to resist the force.
The mushroom anchor is suitable where the seabed is composed of silt or fine sand. It was invented by Robert Stevenson, for use by an 82-ton converted fishing boat, "Pharos", which was used as a lightvessel between 1807 and 1810 near to Bell Rock whilst the lighthouse was being constructed. It was equipped with a 1.5-ton example.
It is shaped like an inverted mushroom, the head becoming buried in the silt. A counterweight is often provided at the other end of the shank to lay it down before it becomes buried.
A mushroom anchor will normally sink in the silt to the point where it has displaced its own weight in bottom material, thus greatly increasing its holding power. These anchors are only suitable for a silt or mud bottom, since they rely upon suction and cohesion of the bottom material, which rocky or coarse sand bottoms lack. The holding power of this anchor is at best about twice its weight until it becomes buried, when it can be as much as ten times its weight. They are available in sizes from about 5 kg up to several tons.
This is an anchor which relies solely on being a heavy weight. It is usually just a large block of concrete or stone at the end of the chain. Its holding power is defined by its weight underwater (i.e. taking its buoyancy into account) regardless of the type of seabed, although suction can increase this if it becomes buried. Consequently, deadweight anchors are used where mushroom anchors are unsuitable, for example in rock, gravel or coarse sand. An advantage of a deadweight anchor over a mushroom is that if it does become dragged, then it continues to provide its original holding force. The disadvantage of using deadweight anchors in conditions where a mushroom anchor could be used is that it needs to be around ten times the weight of the equivalent mushroom anchor.
Auger anchors can be used to anchor permanent moorings, floating docks, fish farms, etc. These anchors, which have one or more slightly pitched self-drilling threads, must be screwed into the seabed with the use of a tool, so require access to the bottom, either at low tide or by use of a diver. Hence they can be difficult to install in deep water without special equipment.
Weight for weight, augers have a higher holding than other permanent designs, and so can be cheap and relatively easily installed, although difficult to set in extremely soft mud.
There is a need in the oil-and-gas industry to resist large anchoring forces when laying pipelines and for drilling vessels. These anchors are installed and removed using a support tug and pennant/pendant wire. Some examples are the Stevin range supplied by Vrijhof Ankers. Large plate anchors such as the Stevmanta are used for permanent moorings.
The elements of anchoring gear include the anchor, the cable (also called a "rode"), the method of attaching the two together, the method of attaching the cable to the ship, charts, and a method of learning the depth of the water.
Vessels may carry a number of anchors: "bower anchors" (formerly known as "sheet anchors" ) are the main anchors used by a vessel and normally carried at the bow of the vessel. A "kedge anchor" is a light anchor used for warping an anchor, also known as "kedging", or more commonly on yachts for mooring quickly or in benign conditions. A "stream anchor", which is usually heavier than a "kedge anchor", can be used for kedging or warping in addition to temporary mooring and restraining stern movement in tidal conditions or in waters where vessel movement needs to be restricted, such as rivers and channels. A "Killick anchor" is a small, possibly improvised, anchor.
Charts are vital to good anchoring. Knowing the location of potential dangers, as well as being useful in estimating the effects of weather and tide in the anchorage, is essential in choosing a good place to drop the hook. One can get by without referring to charts, but they are an important tool and a part of good anchoring gear, and a skilled mariner would not choose to anchor without them.
The depth of water is necessary for determining "scope", which is the ratio of length of cable to the depth measured from the highest point (usually the anchor roller or bow chock) to the seabed. For example, if the water is deep, and the anchor roller is above the water, the scope is the ratio between the amount of cable let out and . For this reason it is important to have a reliable and accurate method of measuring the depth of water.
The anchor rode (or "cable") that connects the anchor to the vessel is made up of chain, sometime with rope ("warp"). Large ships will use only chain rode, whereas, to save weight, smaller boats will use a rope/chain combination. All anchors should have some chain rode; chain is heavy but it resists abrasion from coral, sharp rocks, or shellfish beds, whereas a rope warp is susceptible to abrasion. A combination rode should be arranged so that the rope element should be suspended in the water (and not in contact with the sea bed).
Being strong and elastic, nylon rope is very suitable as an anchor warp. Polyester (Terylene) is stronger but less elastic than nylon. Both ropes sink, so they avoid fouling other craft in crowded anchorages and do not absorb much water. Neither breaks down quickly in sunlight. Polypropylene, "polyprop", is not suited to warps as it floats and is much weaker than nylon and barely stronger than natural fibres. Polyprop breaks down in sunlight and becomes hard and unpleasant to handle. Natural fibres such as manila or hemp are still used in developing nations but absorb much water, are relatively weak and rot. They do give good grip and are often very cheap.
All anchors should have chain at least equal to the boat's length. Some skippers prefer an all chain warp for added security in coral waters. Boats less than 8 m typically use 6 mm galvanized chain. 8–14 m craft use 9 mm chain and over 14 m use 12 mm chain. The chain should be shackled to the warp through a steel eye or spliced to the chain using a chain splice. The shackle pin should be securely wired. Either galvanized or stainless steel is suitable for eyes and shackles, galvanised steel being the stronger of the two. Larger yachts may add swivels to the rode. These should not be connected to the anchor itself, but should be somewhere in the chain. Most modern stainless steel swivels will pass easily over windlass gypsies and through hawseholes.
In moderate conditions the ratio of warp to water depth should be 4:1. In rougher conditions it should be up to twice this with the extra length giving more stretch to resist the anchor breaking out. There is little benefit in having a scope of more than 8:1.
The basic anchoring consists of determining the location, dropping the anchor, laying out the scope, setting the hook, and assessing where the vessel ends up. The ship will seek a location which is sufficiently protected; has suitable holding ground, enough depth at low tide and enough room for the boat to swing.
The location to drop the anchor should be approached from down wind or down current, whichever is stronger. As the chosen spot is approached, the vessel should be stopped or even beginning to drift back. The anchor should be lowered quickly but under control until it is on the bottom (see anchor windlass). The vessel should continue to drift back, and the cable should be veered out under control so it will be relatively straight.
Once the desired scope is laid out, the vessel should be gently forced astern, usually using the auxiliary motor but possibly by backing a sail. A hand on the anchor line may telegraph a series of jerks and jolts, indicating the anchor is dragging, or a smooth tension indicative of digging in. As the anchor begins to dig in and resist backward force, the engine may be throttled up to get a thorough set. If the anchor continues to drag, or sets after having dragged too far, it should be retrieved and moved back to the desired position (or another location chosen.)
There are techniques of anchoring to limit the swing of a vessel if the anchorage has limited room:
Lowering a concentrated, heavy weight down the anchor line – rope or chain – directly in front of the bow to the seabed behaves like a heavy chain rode and lowers the angle of pull on the anchor. If the weight is suspended off the seabed it acts as a spring or shock absorber to dampen the sudden actions that are normally transmitted to the anchor and can cause it to dislodge and drag. In light conditions, a kellet will reduce the swing of the vessel considerably. In heavier conditions these effects disappear as the rode becomes straightened and the weight ineffective. Known as an "anchor chum weight" or "angel" in the UK.
Using two anchors set approximately 45° apart, or wider angles up to 90°, from the bow is a strong mooring for facing into strong winds. To set anchors in this way, first one anchor is set in the normal fashion. Then, taking in on the first cable as the boat is motored into the wind and letting slack while drifting back, a second anchor is set approximately a half-scope away from the first on a line perpendicular to the wind. After this second anchor is set, the scope on the first is taken up until the vessel is lying between the two anchors and the load is taken equally on each cable.
This moor also to some degree limits the range of a vessel's swing to a narrower oval. Care should be taken that other vessels will not swing down on the boat due to the limited swing range.
(Not to be mistaken with the "Bahamian moor", below.) In the "bow and stern" technique, an anchor is set off each the bow and the stern, which can severely limit a vessel's swing range and also align it to steady wind, current or wave conditions. One method of accomplishing this moor is to set a bow anchor normally, then drop back to the limit of the bow cable (or to double the desired scope, e.g. 8:1 if the eventual scope should be 4:1, 10:1 if the eventual scope should be 5:1, etc.) to lower a stern anchor. By taking up on the bow cable the stern anchor can be set. After both anchors are set, tension is taken up on both cables to limit the swing or to align the vessel.
Similar to the above, a "Bahamian moor" is used to sharply limit the swing range of a vessel, but allows it to swing to a current. One of the primary characteristics of this technique is the use of a swivel as follows: the first anchor is set normally, and the vessel drops back to the limit of anchor cable. A second anchor is attached to the end of the anchor cable, and is dropped and set. A swivel is attached to the middle of the anchor cable, and the vessel connected to that.
The vessel will now swing in the middle of two anchors, which is acceptable in strong reversing currents, but a wind perpendicular to the current may break out the anchors, as they are not aligned for this load.
Also known as "tandem anchoring", in this technique two anchors are deployed in line with each other, on the same rode. With the foremost anchor reducing the load on the aft-most, this technique can develop great holding power and may be appropriate in "ultimate storm" circumstances. It does not limit swinging range, and might not be suitable in some circumstances. There are complications, and the technique requires careful preparation and a level of skill and experience above that required for a single anchor.
"Kedging" or "warping" is a technique for moving or turning a ship by using a relatively light anchor.
In yachts, a kedge anchor is an anchor carried in addition to the main, or bower anchors, and usually stowed aft. Every yacht should carry at least two anchors – the main or "bower" anchor and a second lighter "kedge" anchor. It is used occasionally when it is necessary to limit the turning circle as the yacht swings when it is anchored, such as in a very narrow river or a deep pool in an otherwise shallow area. Kedge anchors are sometimes used to recover vessels that have run aground.
For ships, a kedge may be dropped while a ship is underway, or carried out in a suitable direction by a tender or ship's boat to enable the ship to be winched off if aground or swung into a particular heading, or even to be held steady against a tidal or other stream.
Historically, it was of particular relevance to sailing warships which used them to outmaneuver opponents when the wind had dropped but might be used by any vessel in confined, shoal water to place it in a more desirable position, provided she had enough manpower.
Club hauling is an archaic technique. When a vessel is in a narrow channel or on a lee shore so that there is no room to tack the vessel in a conventional manner, an anchor attached to the lee quarter may be dropped from the lee bow. This is deployed when the vessel is head to wind and has lost headway. As the vessel gathers sternway the strain on the cable pivots the vessel around what is now the weather quarter turning the vessel onto the other tack. The anchor is then normally cut away, as it cannot be recovered.
An anchor frequently appears on the flags and coats of arms of institutions involved with the sea, both naval and commercial, as well as of port cities and seacoast regions and provinces in various countries. There also exists in heraldry the "Anchored Cross", or Mariner's Cross, a stylized cross in the shape of an anchor. The symbol can be used to signify 'fresh start' or 'hope'. The New Testament refers to the Christian's hope as "an anchor of the soul" (). The Mariner's Cross is also referred to as St. Clement's Cross, in reference to the way this saint was killed (being tied to an anchor and thrown from a boat into the Black Sea in 102). Anchored crosses are occasionally a feature of coats of arms in which context they are referred to by the heraldic terms "anchry" or "ancre".
In 1887, the Delta Gamma Fraternity adopted the anchor as its badge to signify hope.
The Unicode anchor (Miscellaneous Symbols) is represented by: ⚓.

</doc>
<doc id="1359" url="https://en.wikipedia.org/wiki?curid=1359" title="Anbar (town)">
Anbar (town)

Anbar (, ,) also known by its original ancient name, Peroz-Shapur, was an ancient and medieval town in central Iraq. It played a role in the Roman–Persian Wars of the 3rd–4th centuries, and briefly became the capital of the Abbasid Caliphate before the founding of Baghdad in 762. It remained a moderately prosperous town through the 10th century, but quickly declined thereafter. As a local administrative centre, it survived until the 14th century, but was later abandoned.
Its ruins are near modern Fallujah. The city gives its name to the Al-Anbar Governorate.
The city is located on the left bank of the Middle Euphrates, at the junction with the Nahr Isa canal, the first of the navigable canals that link the Euphrates to the River Tigris to the east. The origins of the city are unknown, but ancient, perhaps dating to the Babylonian era and even earlier: the local artificial mound of Tell Aswad dates to .
The town was originally known as Misiche (Greek: ), Mesiche (), or Massice ( mšyk; mšyk). As a major crossing point of the Euphrates, and occupying the northernmost point of the complex irrigation network of the Sawad, the town was of considerable strategic significance. As the western gate to central Mesopotamia, it was fortified by the Sasanian ruler Shapur I () to shield his capital, Ctesiphon, from the Roman Empire. After his decisive defeat of the Roman emperor Gordian III at the Battle of Misiche in 244, Shapur renamed the town to Peroz-Shapur ("Pērōz-Šāpūr" or "Pērōz-Šābuhr", from , meaning "victorious Shapur"; in ; in ). It became known as Pirisapora or Bersabora () to the Greeks and Romans.
The city was fortified by a double wall, possibly through the use of Roman prisoner labour; it was sacked and burned after an agreement with its garrison in March 363 by the Roman emperor Julian during his invasion of the Sasanian Empire. It was rebuilt by Shapur II. By 420, it is attested as a bishopric, both for the Church of the East and for the Syriac Orthodox Church. The town's garrison was Persian, but it also contained sizeable Arab and Jewish populations. Anbar was adjacent or identical to the Babylonian Jewish center of Nehardea (), and lies a short distance from the present-day town of Fallujah, formerly the Babylonian Jewish center of Pumbedita ().
The city fell to the Rashidun Caliphate in July 633, after a fiercely fought siege. The Arabs retained the name ("Fīrūz Shābūr") for the surrounding district, but the town itself became known as Anbar (Middle Persian word for "granary" or "storehouse") from the granaries in its citadel, a name that had appeared already during the 6th century. According to Baladhuri, the third mosque to be built in Iraq was erected in the city by Sa'd ibn Abi Waqqas. Ibn Abi Waqqas initially considered Anbar as a candidate for the location of one of the first Muslim garrison towns, but the fever and fleas endemic in the area persuaded him otherwise.
According to medieval Arabic sources, most of the inhabitants of the town migrated north to found the city of Hdatta south of Mosul. The famous governor al-Hajjaj ibn Yusuf cleared the canals of the city.
Abu'l-Abbas as-Saffah (), the founder of the Abbasid Caliphate, made it his capital in 752, constructing a new town half a "farsakh" () to the north for his Khurasani troops. There he died and was buried at the palace he had built. His successor, al-Mansur (), remained in the city until the founding of Baghdad in 762. The Abbasids also dug the great Nahr Isa canal to the south of the city, which carried water and commerce east to Baghdad. Thee Nahr al-Saqlawiyya or Nahr al-Qarma canal, which branches off from the Euphrates to the west of the city, is sometimes erroneously held to be the Nahr Isa, but it is more likely that it is to be identified with the pre-Islamic Nahr al-Rufayl.
It continued to be a place of much importance throughout the Abbasid period. Caliph Harun al-Rashid () stayed at the town in 799 and in 803. The town's prosperity was founded on agricultural activities, but also on trade between Iraq ans Syria. The town was still prosperous in the early 9th century, but the decline of Abbasid authority during the later 9th century exposed it to Bedouin attacks in 882 and 899. In 927, the Qarmatians under Abu Tahir al-Jannabi sacked the city, and the devastation was compounded by another Bedouin attack two years later. The town's decline accelerated after that: while the early 10th-century geographer Istakhri still calls the town modest but populous, with the ruins of the buildings of as-Saffah still visible, Ibn Hawqal and al-Maqdisi, who wrote a generation later, attest to its decline, and the diminution of its population.
The town was sacked again in 1262 by the Mongols under Kerboka. The Ilkhanids retained Anbar as an administrative centre, a role it retained until the first half of the 14th century; the Ilkhanid minister Shams al-Din Juvayni had a canal dug from the city to Najaf, and the city was surrounded by a wall of sun-dried bricks.
Anbar used to host an Assyrian community from the fifth century: the town was the seat of a bishopric of the Church of the East. The names of fourteen of its bishops of the period 486–1074 are known, three of whom became Chaldean Patriarchs of Babylon.
Anbar is listed by the Catholic Church as a titular see of the Chaldean Catholic Church, established as titular bishopric in 1980.
It has had the following incumbents:
It is now entirely deserted, occupied only by mounds of ruins, whose great number indicate the city's former importance. Its ruins are northwest of Fallujah, with a circumference of some . The remains include traces of the late medieval wall, a square fortification, and the early Islamic mosque. 

</doc>
<doc id="1360" url="https://en.wikipedia.org/wiki?curid=1360" title="Anazarbus">
Anazarbus

Anazarbus (, medieval Ain Zarba; modern Anavarza; ) was an ancient Cilician city. Under the late Roman Empire, it was the capital of Cilicia Secunda. Roman emperor Justin I rebuilt the city in 527 after a strong earthquake hit it. It was destroyed in 1374 by the forces of Mamluk Empire, after their conquest of Armenia.
It was situated in Anatolia in modern Turkey, in the present Çukurova (or classical Aleian plain) about 15 km west of the main stream of the present Ceyhan River (or classical Pyramus river) and near its tributary the Sempas Su.
A lofty isolated ridge formed its acropolis. Though some of the masonry in the ruins is certainly pre-Roman, the Suda's identification of it with Cyinda, famous as a treasure city in the wars of Eumenes of Cardia, cannot be accepted in the face of Strabo's express location of Cyinda in western Cilicia.
It was founded by Assyrians. It was situated on the Pyramus. According to the "Suda", the original name of the place was Cyinda or Kyinda or Quinda (); that it was next called Diocaesarea. How the city obtained the name Anazarbus (Ἀνάζαρβος) or Anazarba (Ἀνάζαρβα), as it was also known, is a matter of conjecture. According to Stephanus of Byzantium, after the city was destroyed by an earthquake, the emperor Nerva sent thither one Anazarbus, a man of senatorial rank, who rebuilt the city, and gave to it his own name. This account cannot be accurate, as Valesius remarks, for it was called Anazarbus in Pliny's time. Dioscorides is called a native of Anazarbus; but the period of Dioscorides is not certain. It was also the home of the poet Oppian. Its later name was Caesarea ad Anazarbum, and there are many medals of the place in which it is both named Anazarbus and Caesarea at or under Anazarbus. On the division of Cilicia it became the chief place of the Roman province of Cilicia Secunda, with the title of Metropolis. It suffered dreadfully from an earthquake both in the time of Eastern Roman emperor Justinian I, and, still more, in the reign of his successor Justin I. After Justinian rebuilt the place, it was renamed Justinianopolis or Ioustinianoupolis (Ἰουστινιανούπολις). Rebuilt by Justin I after the earthquake in the 6th century, it became Justinopolis or Ioustinoupolis (Ἰουστινούπολις) (525); but the old name persisted, and when Thoros I, king of Lesser Armenia, made it his capital early in the 12th century, it was known as Anazarva.
Its great natural strength and situation, not far from the mouth of the Sis pass, and near the great road which debouched from the Cilician Gates, made Anazarbus play a considerable part in the struggles between the Eastern Roman Empire and the early Muslim invaders. It had been rebuilt by Harun al-Rashid in 796, refortified at great expense by the Hamdanid Sayf al-Dawla (mid-10th century) and again destroyed in 962 by Nikephoros II Phokas.
In late 1097 or early 1098 it was captured by the armies of the First Crusade and was incorporated into Bohemond's Principality of Antioch. The Crusaders are probably responsible for the construction of an impressive donjon atop the center of the outcrop. Most of the remaining fortifications, including the curtain walls, massive horse-shaped towers, undercrofts, cisterns, and free-standing structures date from the Armenian periods of occupation, which began with the arrival of the Rubenid Baron T‛oros I, . The site briefly exchanged hands between the Greeks and Armenians, until it was formally part of the Armenian Kingdom of Cilicia. Within the fortress are two Armenian chapels and the magnificent (but severely damaged) three-aisle church built by T‛oros I to celebrate his conquests. The church was once surrounded by a continuous, well-executed dedicatory inscription in Armenian.
The Mamluk Empire of Egypt finally destroyed the city in 1374.
The present wall of the lower city is of late construction. It encloses a mass of ruins conspicuous in which are a fine triumphal arch, the colonnades of two streets, a gymnasium, etc. A stadium and a theatre lie outside the walls to the south. The remains of the acropolis fortifications are very interesting, including roads and ditches hewn in the rock. There are no notable structures in the upper town. For picturesqueness the site is not equaled in Cilicia, and it is worthwhile to trace the three fine aqueducts to their sources. A necropolis on the escarpment to the south of the curtain wall can also be seen complete with signs of illegal modern excavations.
A visit in December 2002 showed that the three aqueducts mentioned above have been nearly completely destroyed. Only small, isolated sections are left standing with the largest portion lying in a pile of rubble that stretches the length of where the aqueducts once stood. A powerful earthquake that struck the area in 1945 is thought to be responsible for the destruction.
A modest Turkish farming village (Dilekkaya) lies to the southwest of the ancient city. A small outdoor museum with some of the artifacts collected in the area can be viewed for a small fee. Also nearby are some beautiful mosaics discovered in a farmers field. Inquire at the museum for a viewing.
Anazarbus/Anavarsa was one of a chain of Armenian fortifications stretching through Cilicia. The castle of Sis (modern Kozan, Adana) lies to the north while Tumlu Castle and Yilankale are to the south, and the fortresses of Amouda and Sarvandikar are to the east.
In 2013, excavations uncovered the first known colonnaded double-lane road of the ancient world, 34 meters wide and 2700 meters long, also uncovered the ruins of a church and a bathhouse.
In 2017, archaeologists discovered a limestone statue of the goddess Hygieia and the god Eros. The statue is thought to date to the third or fourth century B.C.
Anazarbus was the capital and so also from 553 (the date of the Second Council of Constantinople) the metropolitan see of the Late Roman province of Cilicia Secunda.
In the 4th century, one of the bishops of Anazarbus was Athanasius, a "consistent expounder of the theology of Arius." His theological opponent, Athanasius of Alexandria, in "De Synodis" 17, 1 refers to Anazarbus as Ναζαρβῶν.
Maximin of Anazarbus attended the Council of Chalcedon.
A 6th century "Notitia Episcopatuum" indicates that it had as suffragan sees Epiphania, Alexandria Minor, Irenopolis, Flavias, Castabala and Aegeae. Rhosus was also subject to Anazarbus, but after the 6th century was made exempt, and Mopsuestia was raised to the rank of autcephalous metropolitan see, though without suffragans.
The titular archbishopric was revived in the 18th century as a see of the Latin Catholic church, Anazarbus.
It is vacant, having had the following incumbents, generally of the highest (Metropolitan) rank, "with an episcopal (lowest rank) exception :
In the 19th century, an Armenian Catholic titular bishopric of Anazarbus (of the Armenians) (Anazarbus degli Armeniin Curiate Italian) was established.
It was a suppressed in 1933, having had a single incumbent, of the intermediary (archiepiscopal) rank :

</doc>
<doc id="1361" url="https://en.wikipedia.org/wiki?curid=1361" title="Anagram">
Anagram

An anagram is a word or phrase formed by rearranging the letters of a different word or phrase, typically using all the original letters exactly once. For example, the word "anagram" can be rearranged into "nag a ram", or the word "binary" into "brainy" or the word "adobe" into "abode".
The original word or phrase is known as the "subject" of the anagram. Any word or phrase that exactly reproduces the letters in another order is an anagram. Someone who creates anagrams may be called an "anagrammatist", and the goal of a serious or skilled anagrammatist is to produce anagrams that reflect or comment on their subject.
Anagrams may be created as a commentary on the subject. They may be a parody, a criticism or satire. For example:
An anagram may also be a synonym of the original word. For example:
An anagram that has a meaning opposed to that of the original word or phrase is called an "antigram". For example:
They can sometimes change from a proper noun or personal name into an appropriate sentence:
They can change part of speech, such as the adjective "silent" to the verb "listen".
"Anagrams" itself can be anagrammatized as "Ars magna" (Latin, 'the great art').
Anagrams can be traced back to the time of the Ancient Greeks, and were then known as "Themuru" or changing, which was to find the hidden and mystical meaning in names.
They were popular throughout Europe during the Middle Ages, for example with the poet and composer Guillaume de Machaut. They are said to go back at least to the Greek poet Lycophron, in the third century BCE; but this relies on an account of Lycophron given by John Tzetzes in the 12th century.
Anagrams in Latin were considered witty over many centuries. "Est vir qui adest", explained below, was cited as the example in Samuel Johnson's "A Dictionary of the English Language". They became hugely popular in the Early Modern period, especially in Germany.
Any historical material on anagrams must always be interpreted in terms of the assumptions and spellings that were current for the language in question. In particular, spelling in English only slowly became fixed. There were attempts to regulate anagram formation, an important one in English being that of George Puttenham's "Of the Anagram or Posy Transposed" in "The Art of English Poesie" (1589).
As a literary game when Latin was the common property of the literate, Latin anagrams were prominent. Two examples are the change of "Ave Maria, gratia plena, Dominus tecum" (Latin: Hail Mary, full of grace, the Lord [is] with you) into "Virgo serena, pia, munda et immaculata" (Latin: Serene virgin, pious, clean and spotless), and the anagrammatic answer to Pilate's question, "Quid est veritas?" (Latin: What is truth?), namely, "Est vir qui adest" (Latin: It is the man who is here). The origins of these are not documented.
Latin continued to influence letter values (such as I = J, U = V and W = VV). There was an ongoing tradition of allowing anagrams to be "perfect" if the letters were all used once, but allowing for these interchanges. This can be seen in a popular Latin anagram against the Jesuits: "Societas Jesu" turned into "Vitiosa seces" (Latin: Cut off the wicked things). Puttenham, in the time of Elizabeth I, wished to start from "Elissabet Anglorum Regina" (Latin: Elizabeth Queen of the English), to obtain "Multa regnabis ense gloria" (Latin: By thy sword shalt thou reign in great renown); he explains carefully that H is "a note of aspiration only and no letter", and that Z in Greek or Hebrew is a mere SS. The rules were not completely fixed in the 17th century. William Camden in his "Remains" commented, singling out some letters—Æ, K, W, and Z—not found in the classical Roman alphabet:
When it comes to the 17th century and anagrams in English or other languages, there is a great deal of documented evidence of learned interest. The lawyer Thomas Egerton was praised through the anagram "gestat honorem" ('he carries honor'); the physician George Ent took the anagrammatic motto "genio surget" ('he rises through spirit/genius'), which requires his first name as "Georgius". James I's courtiers discovered in "James Stuart" "a just master", and converted "Charles James Stuart" into "Claims Arthur's seat" (even at that point in time, the letters I and J were more-or-less interchangeable). Walter Quin, tutor to the future Charles I, worked hard on multilingual anagrams on the name of father James. A notorious murder scandal, the Overbury case, threw up two imperfect anagrams that were aided by typically loose spelling and were recorded by Simonds D'Ewes: "Francis Howard" (for Frances Carr, Countess of Somerset, her maiden name spelled in a variant) became "Car findes a whore", with the letters E hardly counted, and the victim Thomas Overbury, as "Thomas Overburie", was written as "O! O! a busie murther" (an old form of "murder"), with a V counted as U.
William Drummond of Hawthornden, in an essay "On the Character of a Perfect Anagram", tried to lay down rules for permissible substitutions (such as S standing for Z) and letter omissions. William Camden provided a definition of "Anagrammatisme" as "a dissolution of a name truly written into his letters, as his elements, and a new connection of it by artificial transposition, without addition, subtraction or change of any letter, into different words, making some perfect sense appliable (i.e., applicable) to the person named." Dryden in "MacFlecknoe" disdainfully called the pastime the "torturing of one poor word ten thousand ways".
"Eleanor Audeley", wife of Sir John Davies, is said to have been brought before the High Commission in 1634 for extravagances, stimulated by the discovery that her name could be transposed to "Reveale, O Daniel", and to have been laughed out of court by another anagram submitted by Sir John Lambe, the dean of the Arches, "Dame Eleanor Davies", "Never soe mad a ladie".
An example from France was a flattering anagram for Cardinal Richelieu, comparing him to Hercules or at least one of his hands (Hercules being a kingly symbol), where "Armand de Richelieu" became "Ardue main d'Hercule" ("difficult hand of Hercules").
Examples from the 19th century are the transposition of "Horatio Nelson" into "Honor est a Nilo" (Latin: Honor is from the Nile); and of "Florence Nightingale" into "Flit on, cheering angel". The Victorian love of anagramming as recreation is alluded to by the mathematician Augustus De Morgan using his own name as example; "Great Gun, do us a sum!" is attributed to his son William De Morgan, but a family friend John Thomas Graves was prolific, and a manuscript with over 2,800 has been preserved.
With the advent of surrealism as a poetic movement, anagrams regained the artistic respect they had had in the Baroque period. The German poet Unica Zürn, who made extensive use of anagram techniques, came to regard obsession with anagrams as a "dangerous fever", because it created isolation of the author. The surrealist leader André Breton coined the anagram "Avida Dollars" for Salvador Dalí, to tarnish his reputation by the implication of commercialism.
While anagramming is certainly a recreation first, there are ways in which anagrams are put to use, and these can be more serious, or at least not quite frivolous and formless. For example, psychologists use anagram-oriented tests, often called "anagram solution tasks", to assess the implicit memory of young adults and adults alike.
Natural philosophers (astronomers and others) of the 17th century transposed their discoveries into Latin anagrams, to establish their priority. In this way they laid claim to new discoveries, before their results were ready for publication.
Galileo used ' for ' (Latin: I have observed the most distant planet to have a triple form) for discovering the rings of Saturn in 1610. Galileo announced his discovery that Venus had phases like the Moon in the form ' (Latin: These immature ones have already been read in vain by me -oy), that is, when rearranged, ' (Latin: The Mother of Loves [= Venus] imitates the figures of Cynthia [= the moon]). In both cases, Johannes Kepler had solved the anagrams incorrectly, assuming they were talking about the Moons of Mars (') and a red spot on Jupiter ('), respectively. By coincidence, he turned out to be right about the actual objects existing.
In 1656, Christiaan Huygens, using a better telescope than those available to Galileo, figured that Galileo's earlier observations of Saturn actually meant it had a ring (Galileo's tools were only sufficient to see it as bumps) and, like Galileo, had published an anagram, '. Upon confirming his observations, three years later he revealed it to mean ' (Latin: It [Saturn] is surrounded by a thin, flat, ring, nowhere touching, inclined to the ecliptic).
When Robert Hooke discovered Hooke's law in 1660, he first published it in anagram form, ', for ' (Latin: as the extension, so the force).
In a related use, from 1975, British naturalist Sir Peter Scott coined the scientific term ' (Greek: The monster (or wonder) of Ness with the diamond-shaped fin) for the apocryphal Loch Ness Monster. Shortly afterwards, several London newspapers pointed out that ' anagrams into "Monster hoax by Sir Peter S". However, Robert Rines, who previously made two underwater photographs allegedly showing the monster, countered that they can also be arranged into "Yes, both pix are monsters, R".
Anagrams are connected to pseudonyms, by the fact that they may conceal or reveal, or operate somewhere in between like a mask that can establish identity. For example, Jim Morrison used an anagram of his name in The Doors song "L.A. Woman", calling himself "Mr. Mojo Risin'". The use of anagrams and fabricated personal names may be to circumvent restrictions on the use of real names, as happened in the 18th century when Edward Cave wanted to get around restrictions imposed on the reporting of the House of Commons. In a genre such as farce or parody, anagrams as names may be used for pointed and satiric effect.
Pseudonyms adopted by authors are sometimes transposed forms of their names; thus "Calvinus" becomes "Alcuinus" (here V = U) or "François Rabelais" = "Alcofribas Nasier". The name "Voltaire" of François Marie Arouet fits this pattern, and is allowed to be an anagram of "Arouet, l[e] j[eune]" (U = V, J = I) that is, "Arouet the younger". Other examples include:
Several of these are "imperfect anagrams", letters having been left out in some cases for the sake of easy pronunciation.
Anagrams used for titles afford scope for some types of wit. Examples:
In Hebrew, the name "Gernot Zippe" (גרנוט ציפה), the inventor of the Zippe-type centrifuge, is an anagram of the word "centrifuge" (צנטריפוגה).
Anagrams are in themselves a recreational activity, but they also make up part of many other games, puzzles and game shows. The Jumble is a puzzle found in many newspapers in the United States requiring the unscrambling of letters to find the solution. Cryptic crossword puzzles frequently use anagrammatic clues, usually indicating that they are anagrams by the inclusion of a descriptive term like "confused" or "in disarray". An example would be "Businessman burst into tears (9 letters)". The solution, "stationer", is an anagram of "into tears", the letters of which have "burst" out of their original arrangement to form the name of a type of "businessman".
Numerous other games and contests involve some element of anagram formation as a basic skill. Some examples:
Multiple anagramming is a technique used to solve some kinds of cryptograms, such as a permutation cipher, a transposition cipher, and the Jefferson disk. Solutions may be computationally found using a Jumble algorithm.
Sometimes, it is possible to "see" anagrams in words, unaided by tools, though the more letters involved the more difficult this becomes. Anagram dictionaries could also be used. Computer programs, known as "anagram servers" "anagram solvers" or "anagrammers", offer a much faster route to creating anagrams, and a large number of these programs are available on the Internet.
The program or server carries out an exhaustive search of a database of words, to produce a list containing every possible combination of words or phrases from the input word or phrase using a jumble algorithm. Some programs (such as "Lexpert") restrict to one-word answers. Many anagram servers (for example, The Words Oracle) can control the search results, by excluding or including certain words, limiting the number or length of words in each anagram, or limiting the number of results. Anagram solvers are often banned from online anagram games. The disadvantage of computer anagram solvers, especially when applied to multi-word anagrams, is their poor understanding of the meaning of the words they are manipulating. They usually cannot filter out meaningful or appropriate anagrams from large numbers of nonsensical word combinations. Some servers attempt to improve on this using statistical techniques that try to combine only words that appear together often. This approach provides only limited success since it fails to recognize ironic and humorous combinations.
Some anagrammatists indicate the method they used. Anagrams constructed without aid of a computer are noted as having been done "manually" or "by hand"; those made by utilizing a computer may be noted "by machine" or "by computer", or may indicate the name of the computer program (using "Anagram Genius").
There are also a few "natural" instances: English words unconsciously created by switching letters around. The French "chaise longue" ("long chair") became the American "chaise lounge" by metathesis (transposition of letters and/or sounds). It has also been speculated that the English "curd" comes from the Latin "crudus" ("raw"). Similarly, the ancient English word for bird was "brid".
The French king Louis XIII had a man named Thomas Billen appointed as his Royal Anagrammatist with an annual salary of 1200 pounds. Among contemporary anagrammers, Anu Garg, the founder of Wordsmith.org, created the Internet Anagram Server in 1994. He is also the founder and editor of satirical anagram-based newspaper The Anagram Times. Mike Keith has anagrammed the complete text of "Moby Dick". He, along with Richard Brodie, has published "The Anagrammed Bible" that includes anagrammed version of many books of the Bible. Popular television personality Dick Cavett is known for his anagrams of famous celebrities such as Alec Guinness and Spiro Agnew.
An animated anagram displays the letters of a word or phrase moving into their new positions. Animations can be created manually, or with software.

</doc>
<doc id="1362" url="https://en.wikipedia.org/wiki?curid=1362" title="Anadyr (river)">
Anadyr (river)

The Anadyr () is a river in the far northeast Siberia which flows into the Gulf of Anadyr of the Bering Sea and drains much of the interior of Chukotka Autonomous Okrug. Its basin corresponds to the Anadyrsky District of Chukotka.
The Anadyr is long and has a basin of . It is frozen from October to late May and has a maximum flow in June with the snowmelt. It is navigable in small boats for about to near Markovo. West of Markovo it is in the Anadyr Highlands (moderate mountains and valleys with a few trees) and east of Markovo it moves into the Anadyr Lowlands (very flat treeless tundra with lakes and bogs). The drop from Markovo to the sea is less than .
It rises at about 67°N latitude and 171°E longitude in the Anadyr Highlands, near the headwaters of the Maly Anyuy, flows southwest receiving the waters of the rivers Yablon and Yeropol, turns east and passes Markvovo and the old site of Anadyrsk, turns north and east and receives the Mayn from the south, thereby encircling the Lebediny Zakaznik, turns northeast to receive the Belaya from the north in the Parapol-Belsky Lowlands, then past Ust-Belaya it turns southeast into the Anadyr Lowlands past the Ust-Tanyurer Zakaznik and receives the Tanyurer from the north. At Lake Krasnoye, it turns east and flows into the Onemen Bay of the Anadyr Estuary. If the Onemen Bay is considered part of the river, it also receives the Velikaya from the south and the Kanchalan from the north.
Its basin is surrounded by (north) Amguema and Palyavaam, (northwest) Bolshoy Anyuy and the Oloy Kolyma basin) and (southwest) Penzhina.
In 1648 Semyon Dezhnev reached the mouth of the Anadyr after being shipwrecked on the coast. In 1649 he went upriver and built winter quarters at Anadyrsk. For the next 100 years the Anadyr was the main route from the Arctic to the Pacific and Kamchatka. In the 18th century, the Anadyr was described by the polar explorer Dmitry Laptev.
The country through which it passes is thinly populated, and is dominated by tundra, with a rich variety of plant life. Much of the region has beautiful landscapes, dominated by often spectacular, rugged mountains. For nine months of the year the ground is covered with snow, and the frozen rivers become navigable roads. George Kennan, an American working on the Western Union Telegraph Expedition in the late 1860s, found that dog sled travel on the lower Anadyr was limited by lack of firewood.
Reindeer, upon which the local inhabitants subsisted, were once found in considerable numbers, but the domestic reindeer population has collapsed dramatically since the reorganization and privatization of state-run collective farms beginning in 1992. As herds of domestic reindeer have declined, herds of wild caribou have increased.
There are ten species of salmon inhabiting the Anadyr river basin. Every year, on the last Sunday in April, there is an ice fishing competition in the frozen estuarine waters of the Anadyr's mouth. This festival is locally known as Korfest.
The area is a summering place for a number of migratory birds including brent geese, Eurasian wigeons, and the pintails of California.

</doc>
<doc id="1363" url="https://en.wikipedia.org/wiki?curid=1363" title="André-Marie Ampère">
André-Marie Ampère

André-Marie Ampère (; ; 20 January 177510 June 1836) was a French physicist and mathematician who was one of the founders of the science of classical electromagnetism, which he referred to as "electrodynamics". He is also the inventor of numerous applications, such as the solenoid (a term coined by him) and the electrical telegraph. An autodidact, Ampère was a member of the French Academy of Sciences and professor at the École polytechnique and the Collège de France.
The SI unit of measurement of electric current, the ampere, is named after him. His name is also one of the 72 names inscribed on the Eiffel Tower.
André-Marie Ampère was born on 20 January 1775 to Jean-Jacques Ampère a prosperous businessman, and Jeanne Antoinette Desutières-Sarcey Ampère, during the height of the French Enlightenment. He spent his childhood and adolescence at the family property at Poleymieux-au-Mont-d'Or near Lyon. Jean-Jacques Ampère, a successful merchant, was an admirer of the philosophy of Jean-Jacques Rousseau, whose theories of education (as outlined in his treatise Émile) were the basis of Ampère's education. Rousseau believed that young boys should avoid formal schooling and pursue instead an "education direct from nature." Ampère's father actualized this ideal by allowing his son to educate himself within the walls of his well-stocked library. French Enlightenment masterpieces such as Georges-Louis Leclerc, comte de Buffon's "Histoire naturelle, générale et particulière" (begun in 1749) and Denis Diderot and Jean le Rond d'Alembert's "Encyclopédie" (volumes added between 1751 and 1772) thus became Ampère's schoolmasters. The young Ampère, however, soon resumed his Latin lessons, which enabled him to master the works of Leonhard Euler and Daniel Bernoulli.
In addition, Ampère used his access to the latest books to begin teaching himself advanced mathematics at age 12. In later life Ampère claimed that he knew as much about, mathematics and science when he was eighteen as ever he knew; but, a polymath, his reading embraced history, travels, poetry, philosophy, and the natural sciences. His mother was a devout woman, so Ampère was also initiated into the Catholic faith along with Enlightenment science. The French Revolution (1789–99) that began during his youth was also influential: Ampère's father was called into public service by the new revolutionary government, becoming a justice of the peace in a small town near Lyon. When the Jacobin faction seized control of the Revolutionary government in 1792, his father Jean-Jacques Ampère resisted the new political tides, and he was guillotined on 24 November 1793, as part of the Jacobin purges of the period.
In 1796 Ampère met Julie Carron, and in 1799 they were married. André-Marie Ampère took his first regular job in 1799 as a mathematics teacher, which gave him the financial security to marry Carron and father his first child, Jean-Jacques (named after his father), the next year. (Jean-Jacques Ampère eventually achieved his own fame as a scholar of languages.) Ampère's maturation corresponded with the transition to the Napoleonic regime in France, and the young father and teacher found new opportunities for success within the technocratic structures favoured by the new French First Consul. In 1802 Ampère was appointed a professor of physics and chemistry at the École Centrale in Bourg-en-Bresse, leaving his ailing wife and infant son Jean-Jacques Antoine Ampère in Lyon. He used his time in Bourg to research mathematics, producing "Considérations sur la théorie mathématique de jeu" (1802; "Considerations on the Mathematical Theory of Games"), a treatise on mathematical probability that he sent to the Paris Academy of Sciences in 1803.
After the death of his wife in July 1803, Ampère moved to Paris, where he began a tutoring post at the new École Polytechnique in 1804. Despite his lack of formal qualifications, Ampère was appointed a professor of mathematics at the school in 1809. As well as holding positions at this school until 1828, in 1819 and 1820 Ampère offered courses in philosophy and astronomy, respectively, at the University of Paris, and in 1824 he was elected to the prestigious chair in experimental physics at the Collège de France. In 1814 Ampère was invited to join the class of mathematicians in the new "Institut Impérial", the umbrella under which the reformed state Academy of Sciences would sit.
Ampère engaged in a diverse array of scientific inquiries during the years leading up to his election to the academy—writing papers and engaging in topics from mathematics and philosophy to chemistry and astronomy, which was customary among the leading scientific intellectuals of the day. Ampère claimed that "at eighteen years he found three culminating points in his life, his First Communion, the reading of Antoine Leonard Thomas's "Eulogy of Descartes", and the Taking of the Bastille. On the day of his wife's death he wrote two verses from the Psalms, and the prayer, 'O Lord, God of Mercy, unite me in Heaven with those whom you have permitted me to love on earth.' In times of duress he would take refuge in the reading of the Bible and the Fathers of the Church."
For a time he took into his family the young student Frédéric Ozanam (1813–1853), one of the founders of the Conference of Charity, later known as the Society of Saint Vincent de Paul. Through Ampère, Ozanam had contact with leaders of the neo-Catholic movement, such as François-René de Chateaubriand, Jean-Baptiste Henri Lacordaire, and Charles Forbes René de Montalembert. Ozanam was beatified by Pope John Paul II in 1998.
In September 1820, Ampère's friend and eventual eulogist François Arago showed the members of the French Academy of Sciences the surprising discovery of Danish physicist Hans Christian Ørsted that a magnetic needle is deflected by an adjacent electric current. Ampère began developing a mathematical and physical theory to understand the relationship between electricity and magnetism. Furthering Ørsted's experimental work, Ampère showed that two parallel wires carrying electric currents attract or repel each other, depending on whether the currents flow in the same or opposite directions, respectively - this laid the foundation of electrodynamics. He also applied mathematics in generalizing physical laws from these experimental results. The most important of these was the principle that came to be called Ampère's law, which states that the mutual action of two lengths of current-carrying wire is proportional to their lengths and to the intensities of their currents. Ampère also applied this same principle to magnetism, showing the harmony between his law and French physicist Charles Augustin de Coulomb's law of magnetic action. Ampère's devotion to, and skill with, experimental techniques anchored his science within the emerging fields of experimental physics.
Ampère also provided a physical understanding of the electromagnetic relationship, theorizing the existence of an "electrodynamic molecule" (the forerunner of the idea of the electron) that served as the component element of both electricity and magnetism. Using this physical explanation of electromagnetic motion, Ampère developed a physical account of electromagnetic phenomena that was both empirically demonstrable and mathematically predictive. In 1827 Ampère published his magnum opus, "Mémoire sur la théorie mathématique des phénomènes électrodynamiques uniquement déduite de l’experience" (Memoir on the Mathematical Theory of Electrodynamic Phenomena, Uniquely Deduced from Experience), the work that coined the name of his new science, "electrodynamics", and became known ever after as its founding treatise.
In 1827 Ampère was elected a Foreign Member of the Royal Society and in 1828, a foreign member of the Royal Swedish Academy of Science.
In recognition of his contribution to the creation of modern electrical science, an international convention, signed at the 1881 International Exposition of Electricity, established the ampere as a standard unit of electrical measurement, along with the coulomb, volt, ohm, and watt, which are named, respectively, after Ampère's contemporaries Charles-Augustin de Coulomb of France, Alessandro Volta of Italy, Georg Ohm of Germany, and James Watt of Scotland. Ampère's name is one of the 72 names inscribed on the Eiffel Tower.
Several items are named after Ampère; many streets and squares, schools, a Lyon metro station, a mountain on the moon and an electric ferry in Norway.
Partial translations:
Complete translations:

</doc>
<doc id="1365" url="https://en.wikipedia.org/wiki?curid=1365" title="Ammonia">
Ammonia

Ammonia is a compound of nitrogen and hydrogen with the formula NH. A stable binary hydride, and the simplest pnictogen hydride, ammonia is a colourless gas with a characteristic pungent smell. It is a common nitrogenous waste, particularly among aquatic organisms, and it contributes significantly to the nutritional needs of terrestrial organisms by serving as a precursor to food and fertilizers. Ammonia, either directly or indirectly, is also a building block for the synthesis of many pharmaceutical products and is used in many commercial cleaning products. It is mainly collected by downward displacement of both air and water.
Although common in nature—both terrestrially and in the outer planets of the Solar System—and in wide use, ammonia is both caustic and hazardous in its concentrated form. It is classified as an extremely hazardous substance in the United States, and is subject to strict reporting requirements by facilities which produce, store, or use it in significant quantities.
The global industrial production of ammonia in 2018 was 175 million tonnes, with no significant change relative to the 2013 global industrial production of 175 million tonnes. Industrial ammonia is sold either as ammonia liquor (usually 28% ammonia in water) or as pressurized or refrigerated anhydrous liquid ammonia transported in tank cars or cylinders.
NH boils at at a pressure of one atmosphere, so the liquid must be stored under pressure or at low temperature. Household ammonia or ammonium hydroxide is a solution of NH in water. The concentration of such solutions is measured in units of the Baumé scale (density), with 26 degrees Baumé (about 30% (by weight) ammonia at ) being the typical high-concentration commercial product.
Pliny, in Book XXXI of his Natural History, refers to a salt produced in the Roman province of Cyrenaica named "hammoniacum", so called because of its proximity to the nearby Temple of Jupiter Amun (Greek Ἄμμων "Ammon"). However, the description Pliny gives of the salt does not conform to the properties of ammonium chloride. According to Herbert Hoover's commentary in his English translation of Georgius Agricola's "De re metallica", it is likely to have been common sea salt. In any case, that salt ultimately gave ammonia and ammonium compounds their name.
Ammonia is a chemical found in trace quantities in nature, being produced from nitrogenous animal and vegetable matter. Ammonia and ammonium salts are also found in small quantities in rainwater, whereas ammonium chloride (sal ammoniac), and ammonium sulfate are found in volcanic districts; crystals of ammonium bicarbonate have been found in Patagonia guano. The kidneys secrete ammonia to neutralize excess acid. Ammonium salts are found distributed through fertile soil and in seawater.
Ammonia is also found throughout the Solar System on Mars, Jupiter, Saturn, Uranus, Neptune, and Pluto, among other places: on smaller, icy bodies such as Pluto, ammonia can act as a geologically important antifreeze, as a mixture of water and ammonia can have a melting point as low as if the ammonia concentration is high enough and thus allow such bodies to retain internal oceans and active geology at a far lower temperature than would be possible with water alone. Substances containing ammonia, or those that are similar to it, are called "ammoniacal".
Ammonia is a colourless gas with a characteristically pungent smell. It is lighter than air, its density being 0.589 times that of air. It is easily liquefied due to the strong hydrogen bonding between molecules; the liquid boils at , and freezes to white crystals at .
Ammonia may be conveniently deodorized by reacting it with either sodium bicarbonate or acetic acid. Both of these reactions form an odourless ammonium salt.
The ammonia molecule has a trigonal pyramidal shape as predicted by the valence shell electron pair repulsion theory (VSEPR theory) with an experimentally determined bond angle of 106.7°. The central nitrogen atom has five outer electrons with an additional electron from each hydrogen atom. This gives a total of eight electrons, or four electron pairs that are arranged tetrahedrally. Three of these electron pairs are used as bond pairs, which leaves one lone pair of electrons. The lone pair repels more strongly than bond pairs, therefore the bond angle is not 109.5°, as expected for a regular tetrahedral arrangement, but 106.7°. This shape gives the molecule a dipole moment and makes it polar. The molecule's polarity, and especially, its ability to form hydrogen bonds, makes ammonia highly miscible with water. The lone pair makes ammonia a base, a proton acceptor. Ammonia is moderately basic; a 1.0 M aqueous solution has a pH of 11.6, and if a strong acid is added to such a solution until the solution is neutral (pH = 7), 99.4% of the ammonia molecules are protonated. Temperature and salinity also affect the proportion of NH. The latter has the shape of a regular tetrahedron and is isoelectronic with methane.
The ammonia molecule readily undergoes nitrogen inversion at room temperature; a useful analogy is an umbrella turning itself inside out in a strong wind. The energy barrier to this inversion is 24.7 kJ/mol, and the resonance frequency is 23.79 GHz, corresponding to microwave radiation of a wavelength of 1.260 cm. The absorption at this frequency was the first microwave spectrum to be observed.
One of the most characteristic properties of ammonia is its basicity. Ammonia is considered to be a weak base. It combines with acids to form salts; thus with hydrochloric acid it forms ammonium chloride (sal ammoniac); with nitric acid, ammonium nitrate, etc. Perfectly dry ammonia will not combine with perfectly dry hydrogen chloride; moisture is necessary to bring about the reaction. As a demonstration experiment, opened bottles of concentrated ammonia and hydrochloric acid produce clouds of ammonium chloride, which seem to appear "out of nothing" as the salt forms where the two diffusing clouds of molecules meet, somewhere between the two bottles.
The salts produced by the action of ammonia on acids are known as the and all contain the ammonium ion (NH).
Although ammonia is well known as a weak base, it can also act as an extremely weak acid. It is a protic substance and is capable of formation of amides (which contain the NH ion). For example, lithium dissolves in liquid ammonia to give a solution of lithium amide:
Like water, ammonia undergoes molecular autoionisation to form its acid and base conjugates:
Ammonia often functions as a weak base, so it has some buffering ability. Shifts in pH will cause more or fewer ammonium cations () and amide anions () to be present in solution. At standard pressure and temperature, K=[][] = 10
The combustion of ammonia to nitrogen and water is exothermic:
The standard enthalpy change of combustion, Δ"H"°, expressed per mole of ammonia and with condensation of the water formed, is −382.81 kJ/mol. Dinitrogen is the thermodynamic product of combustion: all nitrogen oxides are unstable with respect to N and O, which is the principle behind the catalytic converter. Nitrogen oxides can be formed as kinetic products in the presence of appropriate catalysts, a reaction of great industrial importance in the production of nitric acid:
A subsequent reaction leads to NO:
The combustion of ammonia in air is very difficult in the absence of a catalyst (such as platinum gauze or warm chromium(III) oxide), due to the relatively low heat of combustion, a lower laminar burning velocity, high auto-ignition temperature, high heat of vaporization, and a narrow flammability range. However, recent studies have shown that efficient and stable combustion of ammonia can be achieved using swirl combustors, thereby rekindling research interest in ammonia as a fuel for thermal power production. The flammable range of ammonia in dry air is 15.15%-27.35% and in 100% relative humidity air is 15.95%-26.55%. For studying the kinetics of ammonia combustion a detailed reliable reaction mechanism is required, however knowledge about ammonia chemical kinetics during combustion process has been challenging.
In organic chemistry, ammonia can act as a nucleophile in substitution reactions. Amines can be formed by the reaction of ammonia with alkyl halides, although the resulting -NH group is also nucleophilic and secondary and tertiary amines are often formed as byproducts. An excess of ammonia helps minimise multiple substitution and neutralises the hydrogen halide formed. Methylamine is prepared commercially by the reaction of ammonia with chloromethane, and the reaction of ammonia with 2-bromopropanoic acid has been used to prepare racemic alanine in 70% yield. Ethanolamine is prepared by a ring-opening reaction with ethylene oxide: the reaction is sometimes allowed to go further to produce diethanolamine and triethanolamine.
Amides can be prepared by the reaction of ammonia with carboxylic acid derivatives. Acyl chlorides are the most reactive, but the ammonia must be present in at least a twofold excess to neutralise the hydrogen chloride formed. Esters and anhydrides also react with ammonia to form amides. Ammonium salts of carboxylic acids can be dehydrated to amides so long as there are no thermally sensitive groups present: temperatures of 150–200 °C are required.
The hydrogen in ammonia is susceptible to replacement by myriad substituents. When heated with sodium it converts to sodamide, NaNH. With chlorine, monochloramine is formed.
Pentavalent ammonia is known as λ-amine or, more commonly, ammonium hydride. This crystalline solid is only stable under high pressure and decomposes back into trivalent ammonia and hydrogen gas at normal conditions. This substance was once investigated as a possible solid rocket fuel in 1966.
Ammonia can act as a ligand in transition metal complexes. It is a pure σ-donor, in the middle of the spectrochemical series, and shows intermediate hard-soft behaviour (see also ECW model). Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots. For historical reasons, ammonia is named ammine in the nomenclature of coordination compounds. Some notable ammine complexes include tetraamminediaquacopper(II) ([Cu(NH)(HO)]), a dark blue complex formed by adding ammonia to a solution of copper(II) salts. Tetraamminediaquacopper(II) hydroxide is known as Schweizer's reagent, and has the remarkable ability to dissolve cellulose. Diamminesilver(I) ([Ag(NH)]) is the active species in Tollens' reagent. Formation of this complex can also help to distinguish between precipitates of the different silver halides: silver chloride (AgCl) is soluble in dilute (2M) ammonia solution, silver bromide (AgBr) is only soluble in concentrated ammonia solution, whereas silver iodide (AgI) is insoluble in aqueous ammonia.
Ammine complexes of chromium(III) were known in the late 19th century, and formed the basis of Alfred Werner's revolutionary theory on the structure of coordination compounds. Werner noted only two isomers ("fac"- and "mer"-) of the complex [CrCl(NH)] could be formed, and concluded the ligands must be arranged around the metal ion at the vertices of an octahedron. This proposal has since been confirmed by X-ray crystallography.
An ammine ligand bound to a metal ion is markedly more acidic than a free ammonia molecule, although deprotonation in aqueous solution is still rare. One example is the Calomel reaction, where the resulting amidomercury(II) compound is highly insoluble.
Ammonia forms 1:1 adducts with a variety of Lewis acids such as I, phenol, and Al(CH). Ammonia is a hard base and its E & C parameters are E = 2.31 and C = 2.04. Its relative donor strength toward a series of acids, versus other Lewis bases, can be illustrated by C-B plots.
Ammonia and ammonium salts can be readily detected, in very minute traces, by the addition of Nessler's solution, which gives a distinct yellow colouration in the presence of the slightest trace of ammonia or ammonium salts. The amount of ammonia in ammonium salts can be estimated quantitatively by distillation of the salts with sodium or potassium hydroxide, the ammonia evolved being absorbed in a known volume of standard sulfuric acid and the excess of acid then determined volumetrically; or the ammonia may be absorbed in hydrochloric acid and the ammonium chloride so formed precipitated as ammonium hexachloroplatinate, (NH)PtCl.
Sulfur sticks are burnt to detect small leaks in industrial ammonia refrigeration systems. Larger quantities can be detected by warming the salts with a caustic alkali or with quicklime, when the characteristic smell of ammonia will be at once apparent. Ammonia is an irritant and irritation increases with concentration; the permissible exposure limit is 25 ppm, and lethal above 500 ppm. Higher concentrations are hardly detected by conventional detectors, the type of detector is chosen according to the sensitivity required (e.g. semiconductor, catalytic, electrochemical). Holographic sensors have been proposed for detecting concentrations up to 12.5% in volume.
Ammoniacal nitrogen (NH-N) is a measure commonly used for testing the quantity of ammonium ions, derived naturally from ammonia, and returned to ammonia via organic processes, in water or waste liquids. It is a measure used mainly for quantifying values in waste treatment and water purification systems, as well as a measure of the health of natural and man-made water reserves. It is measured in units of mg/L (milligram per litre).
The ancient Greek historian Herodotus mentioned that there were outcrops of salt in an area of Libya that was inhabited by a people called the "Ammonians" (now: the Siwa oasis in northwestern Egypt, where salt lakes still exist). The Greek geographer Strabo also mentioned the salt from this region. However, the ancient authors Dioscorides, Apicius, Arrian, Synesius, and Aëtius of Amida described this salt as forming clear crystals that could be used for cooking and that were essentially rock salt. "Hammoniacus sal" appears in the writings of Pliny, although it is not known whether the term is identical with the more modern sal ammoniac (ammonium chloride).
The fermentation of urine by bacteria produces a solution of ammonia; hence fermented urine was used in Classical Antiquity to wash cloth and clothing, to remove hair from hides in preparation for tanning, to serve as a mordant in dying cloth, and to remove rust from iron.
In the form of sal ammoniac "(نشادر, nushadir)", ammonia was important to the Muslim alchemists as early as the 8th century, first mentioned by the Persian-Arab chemist Jābir ibn Hayyān, and to the European alchemists since the 13th century, being mentioned by Albertus Magnus. It was also used by dyers in the Middle Ages in the form of fermented urine to alter the colour of vegetable dyes. In the 15th century, Basilius Valentinus showed that ammonia could be obtained by the action of alkalis on sal ammoniac. At a later period, when sal ammoniac was obtained by distilling the hooves and horns of oxen and neutralizing the resulting carbonate with hydrochloric acid, the name "spirit of hartshorn" was applied to ammonia.
Gaseous ammonia was first isolated by Joseph Black in 1756 by reacting "sal ammoniac" (Ammonium Chloride) with "calcined magnesia" (Magnesium Oxide). It was isolated again by Peter Woulfe in 1767, by Carl Wilhelm Scheele in 1770 and by Joseph Priestley in 1773 and was termed by him "alkaline air". Eleven years later in 1785, Claude Louis Berthollet ascertained its composition.
The Haber–Bosch process to produce ammonia from the nitrogen in the air was developed by Fritz Haber and Carl Bosch in 1909 and patented in 1910. It was first used on an industrial scale in Germany during World War I, following the allied blockade that cut off the supply of nitrates from Chile. The ammonia was used to produce explosives to sustain war efforts.
Before the availability of natural gas, hydrogen as a precursor to ammonia production was produced via the electrolysis of water or using the chloralkali process.
With the advent of the steel industry in the 20th century, ammonia became a byproduct of the production of coking coal.
In the US as of 2019, approximately 88% of ammonia was used as fertilizers either as its salts, solutions or anhydrously. When applied to soil, it helps provide increased yields of crops such as maize and wheat. 30% of agricultural nitrogen applied in the US is in the form of anhydrous ammonia and worldwide 110 million tonnes are applied each year.
Ammonia is directly or indirectly the precursor to most nitrogen-containing compounds. Virtually all synthetic nitrogen compounds are derived from ammonia. An important derivative is nitric acid. This key material is generated via the Ostwald process by oxidation of ammonia with air over a platinum catalyst at , ≈9 atm. Nitric oxide is an intermediate in this conversion:
Nitric acid is used for the production of fertilizers, explosives, and many organonitrogen compounds.
Ammonia is also used to make the following compounds:
Ammonia can also be used to make compounds in reactions which are not specifically named. Examples of such compounds include: ammonium perchlorate, ammonium nitrate, formamide, dinitrogen tetroxide, alprazolam, ethanolamine, ethyl carbamate, hexamethylenetetramine, and ammonium bicarbonate.
Household ammonia is a solution of NH in water, and is used as a general purpose cleaner for many surfaces. Because ammonia results in a relatively streak-free shine, one of its most common uses is to clean glass, porcelain and stainless steel. It is also frequently used for cleaning ovens and soaking items to loosen baked-on grime. Household ammonia ranges in concentration by weight from 5 to 10% ammonia. United States manufacturers of cleaning products are required to provide the product's material safety data sheet which lists the concentration used.
Solutions of ammonia ranging from 16% to 25% are used in the fermentation industry as a source of nitrogen for microorganisms and to adjust pH during fermentation.
As early as in 1895, it was known that ammonia was "strongly antiseptic ... it requires 1.4 grams per litre to preserve beef tea." In one study, anhydrous ammonia destroyed 99.999% of zoonotic bacteria in 3 types of animal feed, but not silage. Anhydrous ammonia is currently used commercially to reduce or eliminate microbial contamination of beef.
Lean finely textured beef (popularly known as "pink slime") in the beef industry is made from fatty beef trimmings (c. 50–70% fat) by removing the fat using heat and centrifugation, then treating it with ammonia to kill "E. coli". The process was deemed effective and safe by the US Department of Agriculture based on a study that found that the treatment reduces "E. coli" to undetectable levels. There have been safety concerns about the process as well as consumer complaints about the taste and smell of beef treated at optimal levels of ammonia. The level of ammonia in any final product has not come close to toxic levels to humans.
Because of ammonia's vaporization properties, it is a useful refrigerant. It was commonly used before the popularisation of chlorofluorocarbons (Freons). Anhydrous ammonia is widely used in industrial refrigeration applications and hockey rinks because of its high energy efficiency and low cost. It suffers from the disadvantage of toxicity, and requiring corrosion resistant components, which restricts its domestic and small-scale use. Along with its use in modern vapor-compression refrigeration it is used in a mixture along with hydrogen and water in absorption refrigerators. The Kalina cycle, which is of growing importance to geothermal power plants, depends on the wide boiling range of the ammonia–water mixture. Ammonia coolant is also used in the S1 radiator aboard the International Space Station in two loops which are used to regulate the internal temperature and enable temperature dependent experiments.
The potential importance of ammonia as a refrigerant has increased with the discovery that vented CFCs and HFCs are extremely potent and stable greenhouse gases. The contribution to the greenhouse effect of CFCs and HFCs in current use, if vented, would match that of all CO in the atmosphere.
Ammonia is used to scrub SO from the burning of fossil fuels, and the resulting product is converted to ammonium sulfate for use as fertilizer. Ammonia neutralizes the nitrogen oxide (NO) pollutants emitted by diesel engines. This technology, called SCR (selective catalytic reduction), relies on a vanadia-based catalyst.
Ammonia may be used to mitigate gaseous spills of phosgene.
The raw energy density of liquid ammonia is 11.5 MJ/L, which is about a third that of diesel. There is the opportunity to convert ammonia back to hydrogen, where it can be used to power hydrogen fuel cells or directly within high-temperature fuel cells. The conversion of ammonia to hydrogen via the sodium amide process, either for combustion or as fuel for a proton exchange membrane fuel cell, is possible. Conversion to hydrogen would allow the storage of hydrogen at nearly 18 wt% compared to ≈5% for gaseous hydrogen under pressure.
Ammonia engines or ammonia motors, using ammonia as a working fluid, have been proposed and occasionally used. The principle is similar to that used in a fireless locomotive, but with ammonia as the working fluid, instead of steam or compressed air. Ammonia engines were used experimentally in the 19th century by Goldsworthy Gurney in the UK and the St. Charles Avenue Streetcar line in New Orleans in the 1870s and 1880s, and during World War II ammonia was used to power buses in Belgium.
Ammonia is sometimes proposed as a practical alternative to fossil fuel for internal combustion engines. Its high octane rating of 120 and low flame temperature allows the use of high compression ratios without a penalty of high NOx production. Since ammonia contains no carbon, its combustion cannot produce carbon dioxide, carbon monoxide, hydrocarbons, or soot.
Even though ammonia production currently creates 1.8% of global CO2 emissions, a 2020 Royal Society report claims that "green" ammonia can be produced by using low-carbon hydrogen (blue hydrogen and green hydrogen). Total decarbonization of ammonia production and the accomplishment of net-zero targets are possible by 2050. 
However ammonia cannot be easily used in existing Otto cycle engines because of its very narrow flammability range, and there are also other barriers to widespread automobile usage. In terms of raw ammonia supplies, plants would have to be built to increase production levels, requiring significant capital and energy sources. Although it is the second most produced chemical (after sulfuric acid), the scale of ammonia production is a small fraction of world petroleum usage. It could be manufactured from renewable energy sources, as well as coal or nuclear power. The 60 MW Rjukan dam in Telemark, Norway produced ammonia for many years from 1913, providing fertilizer for much of Europe.
Despite this, several tests have been done. In 1981, a Canadian company converted a 1981 Chevrolet Impala to operate using ammonia as fuel. In 2007, a University of Michigan pickup powered by ammonia drove from Detroit to San Francisco as part of a demonstration, requiring only one fill-up in Wyoming.
Compared to hydrogen as a fuel, ammonia is much more energy efficient, and could be produced, stored, and delivered at a much lower cost than hydrogen which must be kept compressed as a cryogenic liquid.
Rocket engines have also been fueled by ammonia. The Reaction Motors XLR99 rocket engine that powered the hypersonic research aircraft used liquid ammonia. Although not as powerful as other fuels, it left no soot in the reusable rocket engine, and its density approximately matches the density of the oxidizer, liquid oxygen, which simplified the aircraft's design.
In early August 2018, scientists from Australia's Commonwealth Scientific and Industrial Research Organisation (CSIRO) announced the success of developing a process to release hydrogen from ammonia and harvest that at ultra-high purity as a fuel for cars. This uses a special membrane. Two demonstration fuel cell vehicles have the technology, a Hyundai Nexo and Toyota Mirai.
In 2020, Saudi Arabia shipped forty metric tons of liquid "blue ammonia" to Japan for use as a fuel. It was produced as a by-product by petrochemical industries, and can be burned without giving off greenhouse gases. Its energy density by volume is nearly double that of liquid hydrogen. If the process of creating it can be scaled up via purely renewable resources, producing green ammonia, it could make a major difference in avoiding climate change.
Ammonia, as the vapor released by smelling salts, has found significant use as a respiratory stimulant. Ammonia is commonly used in the illegal manufacture of methamphetamine through a Birch reduction. The Birch method of making methamphetamine is dangerous because the alkali metal and liquid ammonia are both extremely reactive, and the temperature of liquid ammonia makes it susceptible to explosive boiling when reactants are added.
Liquid ammonia is used for treatment of cotton materials, giving properties like mercerisation, using alkalis. In particular, it is used for prewashing of wool.
At standard temperature and pressure, ammonia is less dense than atmosphere and has approximately 45-48% of the lifting power of hydrogen or helium. Ammonia has sometimes been used to fill weather balloons as a lifting gas. Because of its relatively high boiling point (compared to helium and hydrogen), ammonia could potentially be refrigerated and liquefied aboard an airship to reduce lift and add ballast (and returned to a gas to add lift and reduce ballast).
Ammonia has been used to darken quartersawn white oak in Arts & Crafts and Mission-style furniture. Ammonia fumes react with the natural tannins in the wood and cause it to change colours.
The U.S. Occupational Safety and Health Administration (OSHA) has set a 15-minute exposure limit for gaseous ammonia of 35 ppm by volume in the environmental air and an 8-hour exposure limit of 25 ppm by volume. The National Institute for Occupational Safety and Health (NIOSH) recently reduced the IDLH (Immediately Dangerous to Life and Health, the level to which a healthy worker can be exposed for 30 minutes without suffering irreversible health effects) from 500 to 300 based on recent more conservative interpretations of original research in 1943. Other organizations have varying exposure levels. U.S. Navy Standards [U.S. Bureau of Ships 1962] maximum allowable concentrations (MACs): continuous exposure (60 days): 25 ppm / 1 hour: 400 ppm. Ammonia vapour has a sharp, irritating, pungent odour that acts as a warning of potentially dangerous exposure. The average odour threshold is 5 ppm, well below any danger or damage. Exposure to very high concentrations of gaseous ammonia can result in lung damage and death. Ammonia is regulated in the United States as a non-flammable gas, but it meets the definition of a material that is toxic by inhalation and requires a hazardous safety permit when transported in quantities greater than 13,248 L (3,500 gallons). 
Liquid ammonia is dangerous because it is hygroscopic and because it can cause caustic burns. See for more information.
The toxicity of ammonia solutions does not usually cause problems for humans and other mammals, as a specific mechanism exists to prevent its build-up in the bloodstream. Ammonia is converted to carbamoyl phosphate by the enzyme carbamoyl phosphate synthetase, and then enters the urea cycle to be either incorporated into amino acids or excreted in the urine. Fish and amphibians lack this mechanism, as they can usually eliminate ammonia from their bodies by direct excretion. Ammonia even at dilute concentrations is highly toxic to aquatic animals, and for this reason it is classified as "dangerous for the environment".
Ammonia is a constituent of tobacco smoke.
Ammonia is present in coking wastewater streams, as a liquid by-product of the production of coke from coal. In some cases, the ammonia is discharged to the marine environment where it acts as a pollutant. The Whyalla steelworks in South Australia is one example of a coke-producing facility which discharges ammonia into marine waters.
Ammonia toxicity is believed to be a cause of otherwise unexplained losses in fish hatcheries. Excess ammonia may accumulate and cause alteration of metabolism or increases in the body pH of the exposed organism. Tolerance varies among fish species. At lower concentrations, around 0.05 mg/L, un-ionised ammonia is harmful to fish species and can result in poor growth and feed conversion rates, reduced fecundity and fertility and increase stress and susceptibility to bacterial infections and diseases. Exposed to excess ammonia, fish may suffer loss of equilibrium, hyper-excitability, increased respiratory activity and oxygen uptake and increased heart rate. At concentrations exceeding 2.0 mg/L, ammonia causes gill and tissue damage, extreme lethargy, convulsions, coma, and death. Experiments have shown that the lethal concentration for a variety of fish species ranges from 0.2 to 2.0 mg/l.
During winter, when reduced feeds are administered to aquaculture stock, ammonia levels can be higher. Lower ambient temperatures reduce the rate of algal photosynthesis so less ammonia is removed by any algae present. Within an aquaculture environment, especially at large scale, there is no fast-acting remedy to elevated ammonia levels. Prevention rather than correction is recommended to reduce harm to farmed fish and in open water systems, the surrounding environment.
Similar to propane, anhydrous ammonia boils below room temperature when at atmospheric pressure. A storage vessel capable of is suitable to contain the liquid. Ammonia is used in numerous different industrial application requiring carbon or stainless steel storage vessels. Ammonia with at least 0.2 percent by weight water content is not corrosive to carbon steel. NH3 carbon steel construction storage tanks with 0.2 percent by weight or more of water could last more than 50 years in service. Ammonium compounds should never be allowed to come in contact with bases (unless in an intended and contained reaction), as dangerous quantities of ammonia gas could be released.
Solutions of ammonia (5–10% by weight) are used as household cleaners, particularly for glass. These solutions are irritating to the eyes and mucous membranes (respiratory and digestive tracts), and to a lesser extent the skin. Caution should be used that the chemical is never mixed into any liquid containing bleach, as a toxic gas may result. Mixing with chlorine-containing products or strong oxidants, such as household bleach, can generate chloramines.
The hazards of ammonia solutions depend on the concentration: "dilute" ammonia solutions are usually 5–10% by weight (<5.62 mol/L); "concentrated" solutions are usually prepared at >25% by weight. A 25% (by weight) solution has a density of 0.907 g/cm, and a solution that has a lower density will be more concentrated. The European Union classification of ammonia solutions is given in the table.
The ammonia vapour from concentrated ammonia solutions is severely irritating to the eyes and the respiratory tract, and these solutions should only be handled in a fume hood. Saturated ("0.880" – see #Properties) solutions can develop a significant pressure inside a closed bottle in warm weather, and the bottle should be opened with care; this is not usually a problem for 25% ("0.900") solutions.
Ammonia solutions should not be mixed with halogens, as toxic and/or explosive products are formed. Prolonged contact of ammonia solutions with silver, mercury or iodide salts can also lead to explosive products: such mixtures are often formed in qualitative inorganic analysis, and should be lightly acidified but not concentrated (<6% w/v) before disposal once the test is completed.
Anhydrous ammonia is classified as toxic (T) and dangerous for the environment (N). The gas is flammable (autoignition temperature: 651 °C) and can form explosive mixtures with air (16–25%). The permissible exposure limit (PEL) in the United States is 50 ppm (35 mg/m), while the IDLH concentration is estimated at 300 ppm. Repeated exposure to ammonia lowers the sensitivity to the smell of the gas: normally the odour is detectable at concentrations of less than 50 ppm, but desensitised individuals may not detect it even at concentrations of 100 ppm. Anhydrous ammonia corrodes copper- and zinc-containing alloys, and so brass fittings should not be used for handling the gas. Liquid ammonia can also attack rubber and certain plastics.
Ammonia reacts violently with the halogens. Nitrogen triiodide, a primary high explosive, is formed when ammonia comes in contact with iodine. Ammonia causes the explosive polymerisation of ethylene oxide. It also forms explosive fulminating compounds with compounds of gold, silver, mercury, germanium or tellurium, and with stibine. Violent reactions have also been reported with acetaldehyde, hypochlorite solutions, potassium ferricyanide and peroxides.
Ammonia is one of the most produced inorganic chemicals, with global production reported at 175 million tonnes in 2018. China accounted for 28.5% of that, followed by Russia at 10.3%, the United States at 9.1%, and India at 6.7%.
Before the start of World War I, most ammonia was obtained by the dry distillation of nitrogenous vegetable and animal waste products, including camel dung, where it was distilled by the reduction of nitrous acid and nitrites with hydrogen; in addition, it was produced by the distillation of coal, and also by the decomposition of ammonium salts by alkaline hydroxides such as quicklime:
For small scale laboratory synthesis, one can heat urea and calcium hydroxide:
Mass production of ammonia mostly uses the Haber–Bosch process, a gas phase reaction between hydrogen (H) and nitrogen (N) at a moderately-elevated temperature (450 °C) and high pressure ():
This reaction is both exothermic and results in decreased entropy, meaning that the reaction is favoured at lower temperatures and higher pressures. This makes it difficult and expensive to achieve, as lower temperatures result in slower reaction kinetics (hence a slower reaction rate) and high pressure requires high-strength pressure vessels that aren't weakened by hydrogen embrittlement. In addition, diatomic nitrogen is bound together by an exceptionally strong triple bond, which makes it rather inert. Both the yield and efficiency of the Haber-Bosch Process are low, meaning that ammonia produced must be continuously separated and extracted for the reaction to proceed at an appreciable pace. Combined with the energy needed to produce hydrogen and purified atmospheric nitrogen, ammonia production is a very energy-intensive process, consuming 1 to 2% of global energy, 3% of global carbon emissions, and 3 to 5% of natural gas consumption.
Liquid ammonia is the best-known and most widely studied nonaqueous ionising solvent. Its most conspicuous property is its ability to dissolve alkali metals to form highly coloured, electrically conductive solutions containing solvated electrons. Apart from these remarkable solutions, much of the chemistry in liquid ammonia can be classified by analogy with related reactions in aqueous solutions. Comparison of the physical properties of NH with those of water shows NH has the lower melting point, boiling point, density, viscosity, dielectric constant and electrical conductivity; this is due at least in part to the weaker hydrogen bonding in NH and because such bonding cannot form cross-linked networks, since each NH molecule has only one lone pair of electrons compared with two for each HO molecule. The ionic self-dissociation constant of liquid NH at −50 °C is about 10.
Liquid ammonia is an ionising solvent, although less so than water, and dissolves a range of ionic compounds, including many nitrates, nitrites, cyanides, thiocyanates, metal cyclopentadienyl complexes and metal bis(trimethylsilyl)amides. Most ammonium salts are soluble and act as acids in liquid ammonia solutions. The solubility of halide salts increases from fluoride to iodide. A saturated solution of ammonium nitrate (Divers' solution, named after Edward Divers) contains 0.83 mol solute per mole of ammonia and has a vapour pressure of less than 1 bar even at .
Liquid ammonia will dissolve all of the alkali metals and other electropositive metals such as Ca, Sr, Ba, Eu, and Yb (also Mg using an electrolytic process). At low concentrations (<0.06 mol/L), deep blue solutions are formed: these contain metal cations and solvated electrons, free electrons that are surrounded by a cage of ammonia molecules.
These solutions are very useful as strong reducing agents. At higher concentrations, the solutions are metallic in appearance and in electrical conductivity. At low temperatures, the two types of solution can coexist as phases.
The range of thermodynamic stability of liquid ammonia solutions is very narrow, as the potential for oxidation to dinitrogen, "E"° (N + 6NH + 6e ⇌ 8NH), is only +0.04 V. In practice, both oxidation to dinitrogen and reduction to dihydrogen are slow. This is particularly true of reducing solutions: the solutions of the alkali metals mentioned above are stable for several days, slowly decomposing to the metal amide and dihydrogen. Most studies involving liquid ammonia solutions are done in reducing conditions; although oxidation of liquid ammonia is usually slow, there is still a risk of explosion, particularly if transition metal ions are present as possible catalysts.
Ammonia is both a metabolic waste and a metabolic input throughout the biosphere. It is an important source of nitrogen for living systems. Although atmospheric nitrogen abounds (more than 75%), few living creatures are capable of using this atmospheric nitrogen in its diatomic form, N gas. Therefore, nitrogen fixation is required for the synthesis of amino acids, which are the building blocks of protein. Some plants rely on ammonia and other nitrogenous wastes incorporated into the soil by decaying matter. Others, such as nitrogen-fixing legumes, benefit from symbiotic relationships with rhizobia that create ammonia from atmospheric nitrogen.
In certain organisms, ammonia is produced from atmospheric nitrogen by enzymes called nitrogenases. The overall process is called nitrogen fixation. Intense effort has been directed toward understanding the mechanism of biological nitrogen fixation; the scientific interest in this problem is motivated by the unusual structure of the active site of the enzyme, which consists of an FeMoS ensemble.
Ammonia is also a metabolic product of amino acid deamination catalyzed by enzymes such as glutamate dehydrogenase 1. Ammonia excretion is common in aquatic animals. In humans, it is quickly converted to urea, which is much less toxic, particularly less basic. This urea is a major component of the dry weight of urine. Most reptiles, birds, insects, and snails excrete uric acid solely as nitrogenous waste.
Ammonia also plays a role in both normal and abnormal animal physiology. It is biosynthesised through normal amino acid metabolism and is toxic in high concentrations. The liver converts ammonia to urea through a series of reactions known as the urea cycle. Liver dysfunction, such as that seen in cirrhosis, may lead to elevated amounts of ammonia in the blood (hyperammonemia). Likewise, defects in the enzymes responsible for the urea cycle, such as ornithine transcarbamylase, lead to hyperammonemia. Hyperammonemia contributes to the confusion and coma of hepatic encephalopathy, as well as the neurologic disease common in people with urea cycle defects and organic acidurias.
Ammonia is important for normal animal acid/base balance. After formation of ammonium from glutamine, α-ketoglutarate may be degraded to produce two molecules of bicarbonate, which are then available as buffers for dietary acids. Ammonium is excreted in the urine, resulting in net acid loss. Ammonia may itself diffuse across the renal tubules, combine with a hydrogen ion, and thus allow for further acid excretion.
Ammonium ions are a toxic waste product of metabolism in animals. In fish and aquatic invertebrates, it is excreted directly into the water. In mammals, sharks, and amphibians, it is converted in the urea cycle to urea, because it is less toxic and can be stored more efficiently. In birds, reptiles, and terrestrial snails, metabolic ammonium is converted into uric acid, which is solid, and can therefore be excreted with minimal water loss.
Ammonia has been detected in the atmospheres of the giant planets, including Jupiter, along with other gases like methane, hydrogen, and helium. The interior of Saturn may include frozen crystals of ammonia. It is naturally found on Deimos and Phobos – the two moons of Mars.
Ammonia was first detected in interstellar space in 1968, based on microwave emissions from the direction of the galactic core. This was the first polyatomic molecule to be so detected.
The sensitivity of the molecule to a broad range of excitations and the ease with which it can be observed in a number of regions has made ammonia one of the most important molecules for studies of molecular clouds. The relative intensity of the ammonia lines can be used to measure the temperature of the emitting medium.
The following isotopic species of ammonia have been detected:
The detection of triply deuterated ammonia was considered a surprise as deuterium is relatively scarce. It is thought that the low-temperature conditions allow this molecule to survive and accumulate.
Since its interstellar discovery, NH has proved to be an invaluable spectroscopic tool in the study of the interstellar medium. With a large number of transitions sensitive to a wide range of excitation conditions, NH has been widely astronomically detected – its detection has been reported in hundreds of journal articles. Listed below is a sample of journal articles that highlights the range of detectors that have been used to identify ammonia.
The study of interstellar ammonia has been important to a number of areas of research in the last few decades. Some of these are delineated below and primarily involve using ammonia as an interstellar thermometer.
The interstellar abundance for ammonia has been measured for a variety of environments. The [NH]/[H] ratio has been estimated to range from 10 in small dark clouds up to 10 in the dense core of the Orion Molecular Cloud Complex. Although a total of 18 total production routes have been proposed, the principal formation mechanism for interstellar NH is the reaction:
The rate constant, "k", of this reaction depends on the temperature of the environment, with a value of 5.2×10 at 10 K. The rate constant was calculated from the formula . For the primary formation reaction, and . Assuming an NH abundance of 3×10 and an electron abundance of 10 typical of molecular clouds, the formation will proceed at a rate of in a molecular cloud of total density .
All other proposed formation reactions have rate constants of between 2 and 13 orders of magnitude smaller, making their contribution to the abundance of ammonia relatively insignificant. As an example of the minor contribution other formation reactions play, the reaction:
has a rate constant of 2.2. Assuming H densities of 10 and [NH]/[H] ratio of 10, this reaction proceeds at a rate of 2.2, more than 3 orders of magnitude slower than the primary reaction above.
Some of the other possible formation reactions are:
There are 113 total proposed reactions leading to the destruction of NH. Of these, 39 were tabulated in extensive tables of the chemistry among C, N, and O compounds. A review of interstellar ammonia cites the following reactions as the principal dissociation mechanisms:
with rate constants of 4.39×10 and 2.2×10, respectively. The above equations (, ) run at a rate of 8.8×10 and 4.4×10, respectively. These calculations assumed the given rate constants and abundances of [NH]/[H] = 10, [H]/[H] = 2×10, [HCO]/[H] = 2×10, and total densities of "n" = 10, typical of cold, dense, molecular clouds. Clearly, between these two primary reactions, equation () is the dominant destruction reaction, with a rate ≈10,000 times faster than equation (). This is due to the relatively high abundance of H.
Radio observations of NH from the Effelsberg 100-m Radio Telescope reveal that the ammonia line is separated into two components – a background ridge and an unresolved core. The background corresponds well with the locations previously detected CO. The 25 m Chilbolton telescope in England detected radio signatures of ammonia in H II regions, HNHO masers, H-H objects, and other objects associated with star formation. A comparison of emission line widths indicates that turbulent or systematic velocities do not increase in the central cores of molecular clouds.
Microwave radiation from ammonia was observed in several galactic objects including W3(OH), Orion A, W43, W51, and five sources in the galactic centre. The high detection rate indicates that this is a common molecule in the interstellar medium and that high-density regions are common in the galaxy.
VLA observations of NH in seven regions with high-velocity gaseous outflows revealed condensations of less than 0.1 pc in L1551, S140, and Cepheus A. Three individual condensations were detected in Cepheus A, one of them with a highly elongated shape. They may play an important role in creating the bipolar outflow in the region.
Extragalactic ammonia was imaged using the VLA in IC 342. The hot gas has temperatures above 70 K, which was inferred from ammonia line ratios and appears to be closely associated with the innermost portions of the nuclear bar seen in CO. NH was also monitored by VLA toward a sample of four galactic ultracompact HII regions: G9.62+0.19, G10.47+0.03, G29.96-0.02, and G31.41+0.31. Based upon temperature and density diagnostics, it is concluded that in general such clumps are probably the sites of massive star formation in an early evolutionary phase prior to the development of an ultracompact HII region.
Absorption at 2.97 micrometres due to solid ammonia was recorded from interstellar grains in the Becklin-Neugebauer Object and probably in NGC 2264-IR as well. This detection helped explain the physical shape of previously poorly understood and related ice absorption lines.
A spectrum of the disk of Jupiter was obtained from the Kuiper Airborne Observatory, covering the 100 to 300 cm spectral range. Analysis of the spectrum provides information on global mean properties of ammonia gas and an ammonia ice haze.
A total of 149 dark cloud positions were surveyed for evidence of 'dense cores' by using the (J,K) = (1,1) rotating inversion line of NH. In general, the cores are not spherically shaped, with aspect ratios ranging from 1.1 to 4.4. It is also found that cores with stars have broader lines than cores without stars.
Ammonia has been detected in the Draco Nebula and in one or possibly two molecular clouds, which are associated with the high-latitude galactic infrared cirrus. The finding is significant because they may represent the birthplaces for the Population I metallicity B-type stars in the galactic halo that could have been borne in the galactic disk.
By balancing and stimulated emission with spontaneous emission, it is possible to construct a relation between excitation temperature and density. Moreover, since the transitional levels of ammonia can be approximated by a 2-level system at low temperatures, this calculation is fairly simple. This premise can be applied to dark clouds, regions suspected of having extremely low temperatures and possible sites for future star formation. Detections of ammonia in dark clouds show very narrow lines—indicative not only of low temperatures, but also of a low level of inner-cloud turbulence. Line ratio calculations provide a measurement of cloud temperature that is independent of previous CO observations. The ammonia observations were consistent with CO measurements of rotation temperatures of ≈10 K. With this, densities can be determined, and have been calculated to range between 10 and 10 cm in dark clouds. Mapping of NH gives typical clouds sizes of 0.1 pc and masses near 1 solar mass. These cold, dense cores are the sites of future star formation.
Ultra-compact HII regions are among the best tracers of high-mass star formation. The dense material surrounding UCHII regions is likely primarily molecular. Since a complete study of massive star formation necessarily involves the cloud from which the star formed, ammonia is an invaluable tool in understanding this surrounding molecular material. Since this molecular material can be spatially resolved, it is possible to constrain the heating/ionising sources, temperatures, masses, and sizes of the regions. Doppler-shifted velocity components allow for the separation of distinct regions of molecular gas that can trace outflows and hot cores originating from forming stars.
Ammonia has been detected in external galaxies, and by simultaneously measuring several lines, it is possible to directly measure the gas temperature in these galaxies. Line ratios imply that gas temperatures are warm (≈50 K), originating from dense clouds with sizes of tens of pc. This picture is consistent with the picture within our Milky Way galaxy—hot dense molecular cores form around newly forming stars embedded in larger clouds of molecular material on the scale of several hundred pc (giant molecular clouds; GMCs).

</doc>
<doc id="1366" url="https://en.wikipedia.org/wiki?curid=1366" title="Amethyst">
Amethyst

Amethyst is a violet variety of quartz. The name comes from the Koine Greek αμέθυστος "amethystos" from α- "a-", "not" and μεθύσκω (Ancient Greek) / μεθώ (Modern Greek), "intoxicate", a reference to the belief that the stone protected its owner from drunkenness. The ancient Greeks wore amethyst and carved drinking vessels from it in the belief that it would prevent intoxication.
Amethyst is a semiprecious stone that is often used in jewelry and is the traditional birthstone for February.
Amethyst is a purple variety of quartz (SiO) and owes its violet color to irradiation, impurities of iron and in some cases other transition metals, and the presence of other trace elements, which result in complex crystal lattice substitutions. The hardness of the mineral is the same as quartz, thus making it suitable for use in jewelry.
Amethyst occurs in primary hues from a light pinkish violet color to a deep purple color. Amethyst may exhibit one or both secondary hues, red and blue. High quality amethyst can be found in Siberia, Sri Lanka, Brazil, Uruguay, and the far East. The ideal grade is called "Deep Siberian" and has a primary purple hue of around 75–80%, with 15–20% blue and (depending on the light source) red secondary hues. ‘Rose de France’ is defined by its markedly light shade of the purple, reminiscent of a lavender/lilac shade. These pale colors were once considered undesirable but have recently become popular due to intensive marketing.
Green quartz is sometimes incorrectly called green amethyst, which is a misnomer and not an appropriate name for the material, the proper terminology being prasiolite. Other names for green quartz are vermarine or lime citrine.
Of very variable intensity, the color of amethyst is often laid out in stripes parallel to the final faces of the crystal. One aspect in the art of lapidary involves correctly cutting the stone to place the color in a way that makes the tone of the finished gem homogeneous. Often, the fact that sometimes only a thin surface layer of violet color is present in the stone or that the color is not homogeneous makes for a difficult cutting. It can even cut crystal quartz, which is one of Earth’s sharpest gems.
The color of amethyst has been demonstrated to result from substitution by irradiation of trivalent iron (Fe) for silicon in the structure, in the presence of trace elements of large ionic radius, and, to a certain extent, the amethyst color can naturally result from displacement of transition elements even if the iron concentration is low. Natural amethyst is dichroic in reddish violet and bluish violet, but when heated, turns yellow-orange, yellow-brown, or dark brownish and may resemble citrine, but loses its dichroism, unlike genuine citrine. When partially heated, amethyst can result in ametrine.
Amethyst can fade in tone if overexposed to light sources and can be artificially darkened with adequate irradiation. It does not fluoresce under either short-wave or long-wave UV light.
Amethyst is produced in abundance from the state of Minas Gerais in Brazil where it occurs in large geodes within volcanic rocks. Many of the hollow agates of southwestern Brazil and Uruguay contain a crop of amethyst crystals in the interior. Artigas, Uruguay and neighboring Brazilian state Rio Grande do Sul are large world producers exceeding in quantity Minas Gerais, as well as Mato Grosso, Espirito Santo, Bahia, and Ceará states, all amethyst producers of importance in Brazil.
It is also found and mined in South Korea. The largest opencast amethyst vein in the world is in Maissau, Lower Austria. Much fine amethyst comes from Russia, especially from near Mursinka in the Ekaterinburg district, where it occurs in drusy cavities in granitic rocks. Many localities in south India yield amethyst. One of the largest global amethyst producers is Zambia in southern Africa with an annual production of about 1000 tons.
Amethyst occurs at many localities in the United States. Among these may be mentioned: the Mazatzal Mountain region in Gila and Maricopa Counties, Arizona; Red Feather Lakes, near Fort Collins, Colorado; Amethyst Mountain, Texas; Yellowstone National Park; Delaware County, Pennsylvania; Haywood County, North Carolina; Deer Hill and Stow, Maine and in the Lake Superior region of Minnesota, Wisconsin and Michigan. Amethyst is relatively common in the Canadian provinces of Ontario and Nova Scotia. The largest amethyst mine in North America is located in Thunder Bay, Ontario.
Amethyst is the official state gemstone of South Carolina. Several South Carolina amethysts are on display at the Smithsonian Museum of Natural History.
Amethyst was used as a gemstone by the ancient Egyptians and was largely employed in antiquity for intaglio engraved gems.
The Greeks believed amethyst gems could prevent intoxication, while medieval European soldiers wore amethyst amulets as protection in battle in the belief that amethysts heal people and keep them cool-headed. Beads of amethyst were found in Anglo-Saxon graves in England. Anglican bishops wear an episcopal ring often set with an amethyst, an allusion to the description of the Apostles as "not drunk" at Pentecost in Acts 2:15.
A large geode, or "amethyst-grotto", from near Santa Cruz in southern Brazil was presented at a 1902 exhibition in Düsseldorf, Germany.
In the 19th century, the color of amethyst was attributed to the presence of manganese. However, since it can be greatly altered and even discharged by heat, the color was believed by some authorities to be from an organic source. Ferric thiocyanate has been suggested, and sulfur was said to have been detected in the mineral.
Synthetic (laboratory-grown) amethyst is produced by a synthesis method called hydrothermal growth, which grows the crystals inside a high-pressure autoclave.
Synthetic amethyst is made to imitate the best quality amethyst. Its chemical and physical properties are the same as that of natural amethyst and it can not be differentiated with absolute certainty without advanced gemmological testing (which is often cost-prohibitive). One test based on "Brazil law twinning" (a form of quartz twinning where right and left hand quartz structures are combined in a single crystal) can be used to identify most synthetic amethyst rather easily. It is possible to synthesize twinned amethyst, but this type is not available in large quantities in the market.
Single-crystal quartz is very desirable in the industry, particularly for keeping the regular vibrations necessary for quartz movements in watches and clocks, which is where a lot of synthetic quartz is used.
Treated amethyst is produced by gamma ray, X-ray or electron beam irradiation of clear quartz (rock crystal) which has been first doped with ferric impurities. Exposure to heat partially cancels the irradiation effects and amethyst generally becomes yellow or even green. Much of the citrine, cairngorm, or yellow quartz of jewelry is said to be merely "burnt amethyst".
The Greek word "amethystos" may be translated as "not drunken", from Greek "a-", "not" + , "intoxicated". Amethyst was considered to be a strong antidote against drunkenness, which is why wine goblets were often carved from it. In his poem "L'Amethyste, ou les Amours de Bacchus et d'Amethyste" (Amethyst or the loves of Bacchus and Amethyste), the French poet Remy Belleau (1528–1577) invented a myth in which Bacchus, the god of intoxication, of wine, and grapes was pursuing a maiden named Amethyste, who refused his affections. Amethyste prayed to the gods to remain chaste, a prayer which the chaste goddess Diana answered, transforming her into a white stone. Humbled by Amethyste's desire to remain chaste, Bacchus poured wine over the stone as an offering, dyeing the crystals purple.
Variations of the story include that Dionysus had been insulted by a mortal and swore to slay the next mortal who crossed his path, creating fierce tigers to carry out his wrath. The mortal turned out to be a beautiful young woman, Amethystos, who was on her way to pay tribute to Artemis. Her life was spared by Artemis, who transformed the maiden into a statue of pure crystalline quartz to protect her from the brutal claws. Dionysus wept tears of wine in remorse for his action at the sight of the beautiful statue. The god's tears then stained the quartz purple.
This myth and its variations are not found in classical sources. However, the titan Rhea does present Dionysus with an amethyst stone to preserve the wine-drinker's sanity in historical text.
Tibetans consider amethyst sacred to the Buddha and make prayer beads from it. Amethyst is considered the birthstone of February. In the Middle Ages, it was considered a symbol of royalty and used to decorate English regalia. In the Old World, amethyst was considered one of the Cardinal gems, in that it was one of the five gemstones considered precious above all others, until large deposits were found in Brazil.
Up until the 18th century, amethyst was included in the cardinal, or most valuable, gemstones (along with diamond, sapphire, ruby, and emerald). However, since the discovery of extensive deposits in locations such as Brazil, it has lost most of its value.
Collectors look for depth of color, possibly with red flashes if cut conventionally. As amethyst is readily available in large structures the value of the gem is not primarily defined by carat weight; this is different from most gemstones where the carat weight exponentially increases the value of the stone. The biggest factor in the value of amethyst is the color displayed.
The highest-grade amethyst (called "Deep Russian") is exceptionally rare and therefore, when one is found, its value is dependent on the demand of collectors. It is, however, still orders of magnitude cheaper than the highest-grade sapphires or rubies.

</doc>
<doc id="1367" url="https://en.wikipedia.org/wiki?curid=1367" title="Albertosaurus">
Albertosaurus

Albertosaurus (; meaning "Alberta lizard") is a genus of tyrannosaurid theropod dinosaurs that lived in western North America during the Late Cretaceous Period, about 70 million years ago. The type species, "A. sarcophagus", was apparently restricted in range to the modern-day Canadian province of Alberta, after which the genus is named, although an indeterminate species ("cf. "Albertosaurus" sp.") has been discovered in the Corral de Enmedio and Packard Formations in Mexico. Scientists disagree on the content of the genus, with some recognizing "Gorgosaurus libratus" as a second species.
As a tyrannosaurid, "Albertosaurus" was a bipedal predator with tiny, two-fingered hands and a massive head that had dozens of large, sharp teeth. It may have been at the top of the food chain in its local ecosystem. While "Albertosaurus" was large for a theropod, it was much smaller than its larger and more famous relative "Tyrannosaurus rex", growing and possibly weighing or less.
Since the first discovery in 1884, fossils of more than 30 individuals have been recovered, providing scientists with a more detailed knowledge of "Albertosaurus" anatomy than is available for most other tyrannosaurids. The discovery of 26 individuals at one site provides evidence of pack behaviour and allows studies of ontogeny and population biology, which are impossible with lesser-known dinosaurs.
"Albertosaurus" was larger than most tyrannosaurids, but smaller than "Tarbosaurus" and "Tyrannosaurus". Typical "Albertosaurus" adults measured up to long, while rare individuals of great age could grow to be over long. Several independent mass estimates, obtained by different methods, suggest that an adult "Albertosaurus" weighed between 1.3 tonnes and 2.5 tonnes (2.8 tons). In 2016 Molina-Pérez and Larramendi estimated the (CMN 5600) specimen at 9.7 meters (32 ft) and 4 tonnes (4.4 short tons).
"Albertosaurus" shared a similar body appearance with all other tyrannosaurids. Typically for a theropod, "Albertosaurus" was bipedal and balanced the heavy head and torso with a long tail. However, tyrannosaurid forelimbs were extremely small for their body size and retained only two digits. The hind limbs were long and ended in a four-toed foot on which the first digit, called the hallux, was short and did not reach the ground. The third digit was longer than the rest. "Albertosaurus" may have been able to reach walking speeds of 14−21 km/hour (8−13 mi/hour). At least for the younger individuals, a high running speed is plausible.
Two skin impressions from "Albertosaurus" are known, both showing scales. One patch is found with some gastralic ribs and the impression of a long, unknown bone, indicating that the patch is from the belly. The scales are pebbly and gradually become larger and somewhat hexagonal in shape. Also preserved are two larger feature scales, placed 4.5 cm apart from each other. Another skin impression is from an unknown part of the body. These scales are small, diamond-shaped and arranged in rows.
The massive skull of "Albertosaurus", which was perched on a short, S-shaped neck, was about long in the largest adults. Wide openings in the skull (fenestrae) reduced the weight of the head while also providing space for muscle attachment and sensory organs. Its long jaws contained, both sides combined, 58 or more banana-shaped teeth; larger tyrannosaurids possessed fewer teeth; "Gorgosaurus" had more at 62. Unlike most theropods, "Albertosaurus" and other tyrannosaurids were heterodont, with teeth of different forms depending on their position in the mouth. The premaxillary teeth at the tip of the upper jaw, four per side, were much smaller than the rest, more closely packed, and D-shaped in cross section. Like with "Tyrannosaurus", the maxillary (cheek) teeth of "Albertosaurus" were adapted in general form to resist lateral forces exerted by a struggling prey. The bite force of "Albertosaurus" was less formidable, however, with the maximum force, by the hind teeth, reaching 3,413 Newtons. Above the eyes were short bony crests that may have been brightly coloured in life and used in courtship to attract a mate.
William Abler observed in 2001 that "Albertosaurus" tooth serrations resemble a crack in the tooth ending in a round void called an ampulla. Tyrannosaurid teeth were used as holdfasts for pulling flesh off a body, so when a tyrannosaur pulled back on a piece of meat, the tension could cause a purely crack-like serration to spread through the tooth. However, the presence of the ampulla distributed these forces over a larger surface area, and lessened the risk of damage to the tooth under strain. The presence of incisions ending in voids has parallels in human engineering. Guitar makers use incisions ending in voids to, as Abler describes, "impart alternating regions of flexibility and rigidity" to wood they work. The use of a drill to create an "ampulla" of sorts and prevent the propagation of cracks through material is also used to protect aircraft surfaces. Abler demonstrated that a plexiglass bar with incisions called "kerfs" and drilled holes was more than 25% stronger than one with only regularly placed incisions. Unlike tyrannosaurs, ancient predators like phytosaurs and "Dimetrodon" had no adaptations to prevent the crack-like serrations of their teeth from spreading when subjected to the forces of feeding.
"Albertosaurus" was named by Henry Fairfield Osborn in a one-page note at the end of his 1905 description of "Tyrannosaurus rex". The name honours Alberta, the Canadian province established the same year, in which the first remains were found. The generic name also incorporates the Greek term "σαυρος"/"sauros" ("lizard"), the most common suffix in dinosaur names. The type species is "Albertosaurus sarcophagus"; the specific name is derived from Ancient Greek σαρκοφάγος ("sarkophagos") meaning "flesh-eating" and having the same etymology as the funeral container with which it shares its name: a combination of the Greek words σαρξ/' ("flesh") and φαγειν/' ("to eat"). More than 30 specimens of all ages are known to science.
The type specimen is a partial skull, collected in the summer of 1884 from an outcrop of the Horseshoe Canyon Formation alongside the Red Deer River, in Alberta. This specimen, found on June 9, 1884, was recovered by an expedition of the Geological Survey of Canada, led by the famous geologist Joseph Burr Tyrrell. Due to a lack of specialised equipment the almost complete skull could only be partially secured. In 1889, Tyrrell's colleague Thomas Chesmer Weston found an incomplete smaller skull associated with some skeletal material at a location nearby. The two skulls were assigned to the preexisting species "Laelaps incrassatus" by Edward Drinker Cope in 1892, although the name "Laelaps" was preoccupied by a genus of mite and had been changed to "Dryptosaurus" in 1877 by Othniel Charles Marsh. Cope refused to recognize the new name created by his archrival Marsh. However, Lawrence Lambe used the name "Dryptosaurus incrassatus" instead of "Laelaps incrassatus" when he described the remains in detail in 1903 and 1904, a combination first coined by Oliver Perry Hay in 1902. Shortly later, Osborn pointed out that "D. incrassatus" was based on generic tyrannosaurid teeth, so the two Horseshoe Canyon skulls could not be confidently referred to that species. The Horseshoe Canyon skulls also differed markedly from the remains of "D. aquilunguis", type species of "Dryptosaurus", so Osborn created the new name "Albertosaurus sarcophagus" for them in 1905. He did not describe the remains in any great detail, citing Lambe's complete description the year before. Both specimens (the holotype CMN 5600 and the paratype CMN 5601) are stored in the Canadian Museum of Nature in Ottawa. By the early twenty-first century, some concerns had arisen that, due to the damaged state of the holotype, "Albertosaurus" might be a "nomen dubium", a "dubious name" that could only be used for the type specimen itself because other fossils could not reliably be assigned to it. However, in 2010, Thomas Carr established that the holotype, the paratype and comparable later finds all shared a single common unique trait or autapomorphy: the possession of an enlarged pneumatic opening in the back rim of the side of the palatine bone, proving that "Albertosaurus" was a valid taxon.
On 11 August 1910, American paleontologist Barnum Brown discovered the remains of a large group of "Albertosaurus" at another quarry alongside the Red Deer River. Because of the large number of bones and the limited time available, Brown's party did not collect every specimen, but made sure to collect remains from all of the individuals that they could identify in the bonebed. Among the bones deposited in the American Museum of Natural History collections in New York City are seven sets of right metatarsals, along with two isolated toe bones that did not match any of the metatarsals in size. This indicated the presence of at least nine individuals in the quarry. Palaeontologist Philip J. Currie of the Royal Tyrrell Museum of Palaeontology rediscovered the bonebed in 1997 and resumed fieldwork at the site, which is now located inside Dry Island Buffalo Jump Provincial Park. Further excavation from 1997 to 2005 turned up the remains of 13 more individuals of various ages, including a diminutive two-year-old and a very old individual estimated at over in length. None of these individuals are known from complete skeletons, and most are represented by remains in both museums. Excavations continued until 2008, when the minimum number of individuals present had been established at 12, on the basis of preserved elements that occur only once in a skeleton, and at 26 if mirrored elements were counted when differing in size due to ontogeny. A total of 1,128 "Albertosaurus" bones had been secured, the largest concentration of large theropod fossils known from the Cretaceous.
In 1911, Barnum Brown, during the second year of American Museum of Natural History operations in Alberta, uncovered a fragmentary partial "Albertosaurus" skull at the Red Deer River near Tolman Bridge, specimen AMNH 5222.
William Parks described a new species in 1928, "Albertosaurus arctunguis", based on a partial skeleton lacking the skull excavated by Gus Lindblad and Ralph Hornell near the Red Deer River in 1923, but this species has been considered identical to "A. sarcophagus" since 1970. Parks' specimen (ROM 807) is housed in the Royal Ontario Museum in Toronto.
Between 1926 and 1972, no "Albertosaurus" fossils were found at all; but, since the seventies, there has been a steady increase in the known material. Apart from the Dry Island bonebed, six more skulls and skeletons have since been discovered in Alberta and are housed in various Canadian museums: specimens RTMP 81.010.001, found in 1978 by amateur paleontologist Maurice Stefanuk; RTMP 85.098.001, found by Stefanuk on 16 June 1985; RTMP 86.64.001 (December 1985); RTMP 86.205.001 (1986); RTMP 97.058.0001 (1996); and CMN 11315. However, due to vandalism and accidents, no undamaged and complete skulls could be secured among these finds. Fossils have also been reported from the American states of Montana, New Mexico, Wyoming, and Missouri, but these probably do not represent "A. sarcophagus" and may not even belong to the genus "Albertosaurus".
Two specimens from ("cf "Albertosaurus" ".sp") have been found in Mexico (Packard Formation and Corral de Enmedio Formation).
In 1913, paleontologist Charles H. Sternberg recovered another tyrannosaurid skeleton from the slightly older Dinosaur Park Formation in Alberta. Lawrence Lambe named this dinosaur "Gorgosaurus libratus" in 1914. Other specimens were later found in Alberta and the US state of Montana. Finding, largely due to a lack of good "Albertosaurus" skull material, no significant differences to separate the two taxa, Dale Russell declared the name "Gorgosaurus" a junior synonym of "Albertosaurus", which had been named first, and "G. libratus" was renamed "Albertosaurus libratus" in 1970. A species distinction was maintained because of the age difference. This addition extended the temporal range of the genus "Albertosaurus" backwards by several million years and its geographic range southwards by hundreds of kilometres.
In 2003, Philip J. Currie, benefiting from much more extensive finds and a general increase in anatomical knowledge of theropods, compared several tyrannosaurid skulls and came to the conclusion that the two species are more distinct than previously thought. The decision to use one or two genera is rather arbitrary, as the two species are sister taxa, more closely related to each other than to any other species. Recognizing this, Currie nevertheless recommended that "Albertosaurus" and "Gorgosaurus" be retained as separate genera, as he concluded that they were no more similar than "Daspletosaurus" and "Tyrannosaurus", which are almost always separated. In addition, several albertosaurine specimens have been recovered from Alaska and New Mexico, and Currie suggested that the "Albertosaurus"-"Gorgosaurus" situation may be clarified once these are described fully. Most authors have followed Currie's recommendation, but some have not.
Apart from "A. sarcophagus", "A. arctunguis" and "A. libratus", several other species of "Albertosaurus" have been named. All of these are today seen as younger synonyms of other species or as "nomina dubia", and are not assigned to "Albertosaurus".
In 1930, Anatoly Nikolaevich Riabinin named "Albertosaurus pericolosus" based on a tooth from China, that probably belonged to "Tarbosaurus". In 1932, Friedrich von Huene renamed "Dryptosaurus incrassatus", not considered a "nomen dubium" by him, to "Albertosaurus incrassatus". Because he had identified "Gorgosaurus" with "Albertosaurus", in 1970, Russell also renamed "Gorgosaurus sternbergi" (Matthew & Brown 1922) into "Albertosaurus sternbergi" and "Gorgosaurus lancensis" (Gilmore 1946) into "Albertosaurus lancensis". The former species is today seen as a juvenile form of "Gorgosaurus libratus", the latter as either identical to "Tyrannosaurus" or representing a separate genus "Nanotyrannus". In 1988, Gregory S. Paul based "Albertosaurus megagracilis" on a small tyrannosaurid skeleton, specimen LACM 28345, from the Hell Creek Formation of Montana. It was renamed "Dinotyrannus" in 1995, but is now thought to represent a juvenile "Tyrannosaurus rex". Also in 1988, Paul renamed "Alectrosaurus olseni" (Gilmore 1933) into "Albertosaurus olseni"; this has found no general acceptance. In 1989, "Gorgosaurus novojilovi" (Maleev 1955) was renamed by Bryn Mader and Robert Bradley as "Albertosaurus novojilovi"; today this is seen as a synonym of "Tarbosaurus".
On two occasions, species based on valid "Albertosaurus" material were reassigned to a different genus: in 1922 William Diller Matthew renamed "A. sarcophagus" into "Deinodon sarcophagus" and in 1939 German paleontologist Oskar Kuhn renamed "A. arctunguis" into "Deinodon arctunguis".
"Albertosaurus" is a member of the theropod family Tyrannosauridae, in the subfamily Albertosaurinae. Its closest relative is the slightly older "Gorgosaurus libratus" (sometimes called "Albertosaurus libratus"; see below). These two species are the only described albertosaurines; other undescribed species may exist. Thomas Holtz found "Appalachiosaurus" to be an albertosaurine in 2004, but his more recent unpublished work locates it just outside Tyrannosauridae, in agreement with other authors.
The other major subfamily of tyrannosaurids is the Tyrannosaurinae, which includes "Daspletosaurus", "Tarbosaurus" and "Tyrannosaurus". Compared with these robust tyrannosaurines, albertosaurines had slender builds, with proportionately smaller skulls and longer bones of the lower leg (tibia) and feet (metatarsals and phalanges).
Below is the cladogram of the Tyrannosauridae based on the phylogenetic analysis conducted by Loewen "et al." in 2013.
Most age categories of "Albertosaurus" are represented in the fossil record. Using bone histology, the age of an individual animal at the time of death can often be determined, allowing growth rates to be estimated and compared with other species. The youngest known "Albertosaurus" is a two-year-old discovered in the Dry Island bonebed, which would have weighed about 50 kilograms (110 lb) and measured slightly more than in length. The specimen from the same quarry is the oldest and largest known, at 28 years of age. When specimens of intermediate age and size are plotted on a graph, an "S"-shaped growth curve results, with the most rapid growth occurring in a four-year period ending around the sixteenth year of life, a pattern also seen in other tyrannosaurids. The growth rate during this phase was per year, based on an adult 1.3 tonnes. Other studies have suggested higher adult weights; this would affect the magnitude of the growth rate, but not the overall pattern. Tyrannosaurids similar in size to "Albertosaurus" had similar growth rates, although the much larger "Tyrannosaurus rex" grew at almost five times this rate ( per year) at its peak. The end of the rapid growth phase suggests the onset of sexual maturity in "Albertosaurus", although growth continued at a slower rate throughout the animals' lives. Sexual maturation while still actively growing appears to be a shared trait among small and large dinosaurs as well as in large mammals such as humans and elephants. This pattern of relatively early sexual maturation differs strikingly from the pattern in birds, which delay their sexual maturity until after they have finished growing.
During growth, through thickening the tooth morphology changed so much that, had the association of young and adult skeletons on the Dry Island bonebed not proven they belonged to the same taxon, the teeth of juveniles would likely have been identified by statistical analysis as those of a different species.
Most known "Albertosaurus" individuals were aged 14 years or more at the time of death. Juvenile animals are rarely found as fossils for several reasons, mainly preservation bias, where the smaller bones of younger animals were less likely to be preserved by fossilization than the larger bones of adults, and collection bias, where smaller fossils are less likely to be noticed by collectors in the field. Young "Albertosaurus" are relatively large for juvenile animals, but their remains are still rare in the fossil record compared with adults. It has been suggested that this phenomenon is a consequence of life history, rather than bias, and that fossils of juvenile "Albertosaurus" are rare because they simply did not die as often as adults did.
A hypothesis of "Albertosaurus" life history postulates that hatchlings died in large numbers, but have not been preserved in the fossil record due to their small size and fragile construction. After just two years, juveniles were larger than any other predator in the region aside from adult "Albertosaurus", and more fleet of foot than most of their prey animals. This resulted in a dramatic decrease in their mortality rate and a corresponding rarity of fossil remains. Mortality rates doubled at age twelve, perhaps the result of the physiological demands of the rapid growth phase, and then doubled again with the onset of sexual maturity between the ages of fourteen and sixteen. This elevated mortality rate continued throughout adulthood, perhaps due to the high physiological demands of procreation, including stress and injuries received during intraspecific competition for mates and resources, and eventually, the ever-increasing effects of senescence. The higher mortality rate in adults may explain their more common preservation. Very large animals were rare because few individuals survived long enough to attain such sizes. High infant mortality rates, followed by reduced mortality among juveniles and a sudden increase in mortality after sexual maturity, with very few animals reaching maximum size, is a pattern observed in many modern large mammals, including elephants, African buffalo, and rhinoceros. The same pattern is also seen in other tyrannosaurids. The comparison with modern animals and other tyrannosaurids lends support to this life history hypothesis, but bias in the fossil record may still play a large role, especially since more than two-thirds of all "Albertosaurus" specimens are known from one locality.
The Dry Island bonebed discovered by Barnum Brown and his crew contains the remains of 26 "Albertosaurus", the most individuals found in one locality of any large Cretaceous theropod, and the second-most of any large theropod dinosaur behind the "Allosaurus" assemblage at the Cleveland-Lloyd Dinosaur Quarry in Utah. The group seems to be composed of one very old adult; eight adults between 17 and 23 years old; seven sub-adults undergoing their rapid growth phases at between 12 and 16 years old; and six juveniles between the ages of 2 and 11 years, who had not yet reached the growth phase.
The near-absence of herbivore remains and the similar state of preservation common to the many individuals at the "Albertosaurus" bonebed quarry led Currie to conclude that the locality was not a predator trap like the La Brea Tar Pits in California, and that all of the preserved animals died at the same time. Currie claims this as evidence of pack behaviour. Other scientists are skeptical, observing that the animals may have been driven together by drought, flood or for other reasons.
There is plentiful evidence for gregarious behaviour among herbivorous dinosaurs, including ceratopsians and hadrosaurs. However, only rarely are so many dinosaurian predators found at the same site. Small theropods like "Deinonychus" and "Coelophysis" have been found in aggregations, as have larger predators like "Allosaurus" and "Mapusaurus". There is some evidence of gregarious behaviour in other tyrannosaurids as well. Fragmentary remains of smaller individuals were found alongside "Sue", the "Tyrannosaurus" mounted in the Field Museum of Natural History in Chicago, and a bonebed in the Two Medicine Formation of Montana contains at least three specimens of "Daspletosaurus", preserved alongside several hadrosaurs. These findings may corroborate the evidence for social behaviour in "Albertosaurus", although some or all of the above localities may represent temporary or unnatural aggregations. Others have speculated that instead of social groups, at least some of these finds represent Komodo dragon-like mobbing of carcasses, where aggressive competition leads to some of the predators being killed and cannibalized.
Currie has also speculated on the pack-hunting habits of "Albertosaurus". The leg proportions of the smaller individuals were comparable to those of ornithomimids, which were probably among the fastest dinosaurs. Younger "Albertosaurus" were probably equally fleet-footed, or at least faster than their prey. Currie hypothesized that the younger members of the pack may have been responsible for driving their prey towards the adults, who were larger and more powerful, but also slower. Juveniles may also have had different lifestyles than adults, filling predator niches between the enormous adults and the smaller contemporaneous theropods, the largest of which were two orders of magnitude smaller than adult "Albertosaurus" in mass. A similar situation is observed in modern Komodo dragons, with hatchlings beginning life as small insectivores before growing to become the dominant predators on their islands. However, as the preservation of behaviour in the fossil record is exceedingly rare, these ideas cannot readily be tested. In 2010, Currie, though still favouring the hunting pack hypothesis, admitted that the concentration could have been brought about by other causes, such as a slowly rising water level during an extended flood.
In 2009, researchers hypothesized that smooth-edged holes found in the fossil jaws of tyrannosaurid dinosaurs such as "Albertosaurus" were caused by a parasite similar to "Trichomonas gallinae", which infects birds. They suggested that tyrannosaurids transmitted the infection by biting each other, and that the infection impaired their ability to eat food.
In 2001, Bruce Rothschild and others published a study examining evidence for stress fractures and tendon avulsions in theropod dinosaurs and the implications for their behavior. They found that only one of the 319 "Albertosaurus" foot bones checked for stress fractures actually had them and none of the four hand bones did. The scientists found that stress fractures were "significantly" less common in "Albertosaurus" than in the carnosaur "Allosaurus". ROM 807, the holotype of "A. arctunguis" (now referred to "A. sarcophagus"), had a deep hole in the iliac blade, although the describer of the species did not recognize this as pathological. The specimen also contains some exostosis on the fourth left metatarsal. In 1970, two of the five "Albertosaurus sarcophagus" specimens with humeri were reported by Dale Russel as having pathological damage to them.
In 2010, the health of the Dry Island "Albertosaurus" assembly was reported upon. Most specimens showed no sign of disease. On three phalanges of the foot strange bony spurs, consisting of abnormal ossifications of the tendons, so-called enthesophytes, were present, their cause unknown. Two ribs and a belly-rib showed signs of breaking and healing. One adult specimen had a left lower jaw showing a puncture wound and both healed and unhealed bite marks. The low number of abnormalities compares favourably with the health condition of a "Majungasaurus" population of which it in 2007 was established that 19% of individuals showed bone pathologies.
Most fossils of "Albertosaurus sarcophagus" are known from the upper Horseshoe Canyon Formation in Alberta. These younger units of this geologic formation date to the early Maastrichtian stage of the Late Cretaceous Period, 70 to 68 Ma (million years ago). Immediately below this formation is the Bearpaw Shale, a marine formation representing a section of the Western Interior Seaway. The seaway was receding as the climate cooled and sea levels subsided towards the end of the Cretaceous, exposing land that had previously been underwater. It was not a smooth process, however, and the seaway would periodically rise to cover parts of the region throughout Horseshoe Canyon before finally receding altogether in the years after. Due to the changing sea levels, many different environments are represented in the Horseshoe Canyon Formation, including offshore and near-shore marine habitats and coastal habitats like lagoons, estuaries and tidal flats. Numerous coal seams represent ancient peat swamps. Like most of the other vertebrate fossils from the formation, "Albertosaurus" remains are found in deposits laid down in the deltas and floodplains of large rivers during the later half of Horseshoe Canyon times.
The fauna of the Horseshoe Canyon Formation is well-known, as vertebrate fossils, including those of dinosaurs, are quite common. Sharks, rays, sturgeons, bowfins, gars and the gar-like "Aspidorhynchus" made up the fish fauna. Mammals included multituberculates and the marsupial "Didelphodon". The saltwater plesiosaur "Leurospondylus" has been found in marine sediments in the Horseshoe Canyon, while freshwater environments were populated by turtles, "Champsosaurus", and crocodilians like "Leidyosuchus" and "Stangerochampsa". Dinosaurs dominate the fauna, especially hadrosaurs, which make up half of all dinosaurs known, including the genera "Edmontosaurus", "Saurolophus" and "Hypacrosaurus". Ceratopsians and ornithomimids were also very common, together making up another third of the known fauna. Along with much rarer ankylosaurians and pachycephalosaurs, all of these animals would have been prey for a diverse array of carnivorous theropods, including troodontids, dromaeosaurids, and caenagnathids. Intermingled with the "Albertosaurus" remains of the Dry Island bonebed, the bones of the small theropod "Albertonykus" were found. Adult "Albertosaurus" were the apex predators in this environment, with intermediate niches possibly filled by juvenile albertosaurs.

</doc>
<doc id="1368" url="https://en.wikipedia.org/wiki?curid=1368" title="Assembly language">
Assembly language

In computer programming, assembly language (or assembler language), often abbreviated asm, is any low-level programming language in which there is a very strong correspondence between the instructions in the language and the architecture's machine code instructions. Because assembly depends on the machine code instructions, every assembly language is designed for exactly one specific computer architecture. Assembly language may also be called "symbolic machine code".
Assembly code is converted into executable machine code by a utility program referred to as an "assembler". The conversion process is referred to as "assembly", as in "assembling" the source code. Assembly language usually has one statement per machine instruction (1:1), but comments and statements that are assembler directives, macros, and symbolic labels of program and memory locations are often also supported.
The term "assembler" is generally attributed to Wilkes, Wheeler and Gill in their 1951 book "The preparation of programs for an electronic digital computer", who, however, used the term to mean "a program that assembles another program consisting of several sections into a single program".
Each assembly language is specific to a particular computer architecture and sometimes to an operating system. However, some assembly languages do not provide specific syntax for operating system calls, and most assembly languages can be used universally with any operating system, as the language provides access to all the real capabilities of the processor, upon which all system call mechanisms ultimately rest. In contrast to assembly languages, most high-level programming languages are generally portable across multiple architectures but require interpreting or compiling, a much more complicated task than assembling.
The computational step when an assembler is processing a program is called "assembly time".
Assembly language uses a mnemonic to represent each low-level machine instruction or opcode, typically also each architectural register, flag, etc. Many operations require one or more operands in order to form a complete instruction. Most assemblers permit named constants, registers, and labels for program and memory locations, and can calculate expressions for operands. Thus, the programmers are freed from tedious repetitive calculations and assembler programs are much more readable than machine code. Depending on the architecture, these elements may also be combined for specific instructions or addressing modes using offsets or other data as well as fixed addresses. Many assemblers offer additional mechanisms to facilitate program development, to control the assembly process, and to aid debugging.
An assembler program creates object code by translating combinations of mnemonics and syntax for operations and addressing modes into their numerical equivalents. This representation typically includes an "operation code" ("opcode") as well as other control bits and data. The assembler also calculates constant expressions and resolves symbolic names for memory locations and other entities. The use of symbolic references is a key feature of assemblers, saving tedious calculations and manual address updates after program modifications. Most assemblers also include macro facilities for performing textual substitution – e.g., to generate common short sequences of instructions as inline, instead of "called" subroutines.
Some assemblers may also be able to perform some simple types of instruction set-specific optimizations. One concrete example of this may be the ubiquitous x86 assemblers from various vendors. Called jump-sizing, most of them are able to perform jump-instruction replacements (long jumps replaced by short or relative jumps) in any number of passes, on request. Others may even do simple rearrangement or insertion of instructions, such as some assemblers for RISC architectures that can help optimize a sensible instruction scheduling to exploit the CPU pipeline as efficiently as possible.
Like early programming languages such as Fortran, Algol, Cobol and Lisp, assemblers have been available since the 1950s and the first generations of text based computer interfaces. However, assemblers came first as they are far simpler to write than compilers for high-level languages. This is because each mnemonic along with the addressing modes and operands of an instruction translates rather directly into the numeric representations of that particular instruction, without much context or analysis. There have also been several classes of translators and semi automatic code generators with properties similar to both assembly and high level languages, with Speedcode as perhaps one of the better known examples.
There may be several assemblers with different syntax for a particular CPU or instruction set architecture. For instance, an instruction to add memory data to a register in a x86-family processor might be codice_1, in original "Intel syntax", whereas this would be written codice_2 in the "AT&T syntax" used by the GNU Assembler. Despite different appearances, different syntactic forms generally generate the same numeric machine code. A single assembler may also have different modes in order to support variations in syntactic forms as well as their exact semantic interpretations (such as FASM-syntax, TASM-syntax, ideal mode, etc., in the special case of x86 assembly programming).
There are two types of assemblers based on how many passes through the source are needed (how many times the assembler reads the source) to produce the object file.
In both cases, the assembler must be able to determine the size of each instruction on the initial passes in order to calculate the addresses of subsequent symbols. This means that if the size of an operation referring to an operand defined later depends on the type or distance of the operand, the assembler will make a pessimistic estimate when first encountering the operation, and if necessary, pad it with one or more
"no-operation" instructions in a later pass or the errata. In an assembler with peephole optimization, addresses may be recalculated between passes to allow replacing pessimistic code with code tailored to the exact distance from the target.
The original reason for the use of one-pass assemblers was memory size and speed of assembly – often a second pass would require storing the symbol table in memory (to handle forward references), rewinding and rereading the program source on tape, or rereading a deck of cards or punched paper tape. Later computers with much larger memories (especially disc storage), had the space to perform all necessary processing without such re-reading. The advantage of the multi-pass assembler is that the absence of errata makes the linking process (or the program load if the assembler directly produces executable code) faster.
Example: in the following code snippet, a one-pass assembler would be able to determine the address of the backward reference BKWD when assembling statement S2, but would not be able to determine the address of the forward reference FWD when assembling the branch statement S1; indeed, FWD may be undefined. A two-pass assembler would determine both addresses in pass 1, so they would be known when generating code in pass 2.
More sophisticated high-level assemblers provide language abstractions such as:
See Language design below for more details.
A program written in assembly language consists of a series of mnemonic processor instructions and meta-statements (known variously as directives, pseudo-instructions, and pseudo-ops), comments and data. Assembly language instructions usually consist of an opcode mnemonic followed by a list of data, arguments or parameters. These are translated by an assembler into machine language instructions that can be loaded into memory and executed.
For example, the instruction below tells an x86/IA-32 processor to move an immediate 8-bit value into a register. The binary code for this instruction is 10110 followed by a 3-bit identifier for which register to use. The identifier for the "AL" register is 000, so the following machine code loads the "AL" register with the data 01100001.
This binary computer code can be made more human-readable by expressing it in hexadecimal as follows.
Here, codice_3 means 'Move a copy of the following value into "AL", and codice_4 is a hexadecimal representation of the value 01100001, which is 97 in decimal. Assembly language for the 8086 family provides the mnemonic MOV (an abbreviation of "move") for instructions such as this, so the machine code above can be written as follows in assembly language, complete with an explanatory comment if required, after the semicolon. This is much easier to read and to remember.
MOV AL, 61h ; Load AL with 97 decimal (61 hex)
In some assembly languages (including this one) the same mnemonic, such as MOV, may be used for a family of related instructions for loading, copying and moving data, whether these are immediate values, values in registers, or memory locations pointed to by values in registers or by immediate (a/k/a direct) addresses. Other assemblers may use separate opcode mnemonics such as L for "move memory to register", ST for "move register to memory", LR for "move register to register", MVI for "move immediate operand to memory", etc.
If the same mnemonic is used for different instructions, that means that the mnemonic corresponds to several different binary instruction codes, excluding data (e.g. the codice_5 in this example), depending on the operands that follow the mnemonic. For example, for the x86/IA-32 CPUs, the Intel assembly language syntax codice_6 represents an instruction that moves the contents of register "AH" into register "AL". The hexadecimal form of this instruction is:
The first byte, 88h, identifies a move between a byte-sized register and either another register or memory, and the second byte, E0h, is encoded (with three bit-fields) to specify that both operands are registers, the source is "AH", and the destination is "AL".
In a case like this where the same mnemonic can represent more than one binary instruction, the assembler determines which instruction to generate by examining the operands. In the first example, the operand codice_5 is a valid hexadecimal numeric constant and is not a valid register name, so only the codice_3 instruction can be applicable. In the second example, the operand codice_9 is a valid register name and not a valid numeric constant (hexadecimal, decimal, octal, or binary), so only the codice_10 instruction can be applicable.
Assembly languages are always designed so that this sort of unambiguousness is universally enforced by their syntax. For example, in the Intel x86 assembly language, a hexadecimal constant must start with a numeral digit, so that the hexadecimal number 'A' (equal to decimal ten) would be written as codice_11 or codice_12, not codice_9, specifically so that it cannot appear to be the name of register "AH". (The same rule also prevents ambiguity with the names of registers "BH", "CH", and "DH", as well as with any user-defined symbol that ends with the letter "H" and otherwise contains only characters that are hexadecimal digits, such as the word "BEACH".)
Returning to the original example, while the x86 opcode 10110000 (codice_3) copies an 8-bit value into the "AL" register, 10110001 (codice_15) moves it into "CL" and 10110010 (codice_16) does so into "DL". Assembly language examples for these follow.
MOV AL, 1h ; Load AL with immediate value 1
MOV CL, 2h ; Load CL with immediate value 2
MOV DL, 3h ; Load DL with immediate value 3
The syntax of MOV can also be more complex as the following examples show.
MOV EAX, [EBX] ; Move the 4 bytes in memory at the address contained in EBX into EAX
MOV [ESI+EAX], CL ; Move the contents of CL into the byte at address ESI+EAX
MOV DS, DX ; Move the contents of DX into segment register DS
In each case, the MOV mnemonic is translated directly into one of the opcodes 88-8C, 8E, A0-A3, B0-BF, C6 or C7 by an assembler, and the programmer normally does not have to know or remember which.
Transforming assembly language into machine code is the job of an assembler, and the reverse can at least partially be achieved by a disassembler. Unlike high-level languages, there is a one-to-one correspondence between many simple assembly statements and machine language instructions. However, in some cases, an assembler may provide "pseudoinstructions" (essentially macros) which expand into several machine language instructions to provide commonly needed functionality. For example, for a machine that lacks a "branch if greater or equal" instruction, an assembler may provide a pseudoinstruction that expands to the machine's "set if less than" and "branch if zero (on the result of the set instruction)". Most full-featured assemblers also provide a rich macro language (discussed below) which is used by vendors and programmers to generate more complex code and data sequences. Since the information about pseudoinstructions and macros defined in the assembler environment is not present in the object program, a disassembler cannot reconstruct the macro and pseudoinstruction invocations but can only disassemble the actual machine instructions that the assembler generated from those abstract assembly-language entities. Likewise, since comments in the assembly language source file are ignored by the assembler and have no effect on the object code it generates, a disassembler is always completely unable to recover source comments.
Each computer architecture has its own machine language. Computers differ in the number and type of operations they support, in the different sizes and numbers of registers, and in the representations of data in storage. While most general-purpose computers are able to carry out essentially the same functionality, the ways they do so differ; the corresponding assembly languages reflect these differences.
Multiple sets of mnemonics or assembly-language syntax may exist for a single instruction set, typically instantiated in different assembler programs. In these cases, the most popular one is usually that supplied by the CPU manufacturer and used in its documentation.
Two examples of CPUs that have two different sets of mnemonics are the Intel 8080 family and the Intel 8086/8088. Because Intel claimed copyright on its assembly language mnemonics (on each page of their documentation published in the 1970s and early 1980s, at least), some companies that independently produced CPUs compatible with Intel instruction sets invented their own mnemonics. The Zilog Z80 CPU, an enhancement of the Intel 8080A, supports all the 8080A instructions plus many more; Zilog invented an entirely new assembly language, not only for the new instructions but also for all of the 8080A instructions. For example, where Intel uses the mnemonics "MOV", "MVI", "LDA", "STA", "LXI", "LDAX", "STAX", "LHLD", and "SHLD" for various data transfer instructions, the Z80 assembly language uses the mnemonic "LD" for all of them. A similar case is the NEC V20 and V30 CPUs, enhanced copies of the Intel 8086 and 8088, respectively. Like Zilog with the Z80, NEC invented new mnemonics for all of the 8086 and 8088 instructions, to avoid accusations of infringement of Intel's copyright. (It is questionable whether such copyrights can be valid, and later CPU companies such as AMD and Cyrix republished Intel's x86/IA-32 instruction mnemonics exactly with neither permission nor legal penalty.) It is doubtful whether in practice many people who programmed the V20 and V30 actually wrote in NEC's assembly language rather than Intel's; since any two assembly languages for the same instruction set architecture are isomorphic (somewhat like English and Pig Latin), there is no requirement to use a manufacturer's own published assembly language with that manufacturer's products.
There is a large degree of diversity in the way the authors of assemblers categorize statements and in the nomenclature that they use. In particular, some describe anything other than a machine mnemonic or extended mnemonic as a pseudo-operation (pseudo-op). A typical assembly language consists of 3 types of instruction statements that are used to define program operations:
Instructions (statements) in assembly language are generally very simple, unlike those in high-level languages. Generally, a mnemonic is a symbolic name for a single executable machine language instruction (an opcode), and there is at least one opcode mnemonic defined for each machine language instruction. Each instruction typically consists of an "operation" or "opcode" plus zero or more "operands". Most instructions refer to a single value or a pair of values. Operands can be immediate (value coded in the instruction itself), registers specified in the instruction or implied, or the addresses of data located elsewhere in storage. This is determined by the underlying processor architecture: the assembler merely reflects how this architecture works. "Extended mnemonics" are often used to specify a combination of an opcode with a specific operand, e.g., the System/360 assemblers use as an extended mnemonic for with a mask of 15 and ("NO OPeration" – do nothing for one step) for with a mask of 0.
"Extended mnemonics" are often used to support specialized uses of instructions, often for purposes not obvious from the instruction name. For example, many CPU's do not have an explicit NOP instruction, but do have instructions that can be used for the purpose. In 8086 CPUs the instruction is used for , with being a pseudo-opcode to encode the instruction . Some disassemblers recognize this and will decode the instruction as . Similarly, IBM assemblers for System/360 and System/370 use the extended mnemonics and for and with zero masks. For the SPARC architecture, these are known as "synthetic instructions".
Some assemblers also support simple built-in macro-instructions that generate two or more machine instructions. For instance, with some Z80 assemblers the instruction is recognized to generate followed by . These are sometimes known as "pseudo-opcodes".
Mnemonics are arbitrary symbols; in 1985 the IEEE published Standard 694 for a uniform set of mnemonics to be used by all assemblers. The standard has since been withdrawn.
There are instructions used to define data elements to hold data and variables. They define the type of data, the length and the alignment of data. These instructions can also define whether the data is available to outside programs (programs assembled separately) or only to the program in which the data section is defined. Some assemblers classify these as pseudo-ops.
Assembly directives, also called pseudo-opcodes, pseudo-operations or pseudo-ops, are commands given to an assembler "directing it to perform operations other than assembling instructions". Directives affect how the assembler operates and "may affect the object code, the symbol table, the listing file, and the values of internal assembler parameters". Sometimes the term "pseudo-opcode" is reserved for directives that generate object code, such as those that generate data.
The names of pseudo-ops often start with a dot to distinguish them from machine instructions. Pseudo-ops can make the assembly of the program dependent on parameters input by a programmer, so that one program can be assembled in different ways, perhaps for different applications. Or, a pseudo-op can be used to manipulate presentation of a program to make it easier to read and maintain. Another common use of pseudo-ops is to reserve storage areas for run-time data and optionally initialize their contents to known values.
Symbolic assemblers let programmers associate arbitrary names ("labels" or "symbols") with memory locations and various constants. Usually, every constant and variable is given a name so instructions can reference those locations by name, thus promoting self-documenting code. In executable code, the name of each subroutine is associated with its entry point, so any calls to a subroutine can use its name. Inside subroutines, GOTO destinations are given labels. Some assemblers support "local symbols" which are often lexically distinct from normal symbols (e.g., the use of "10$" as a GOTO destination).
Some assemblers, such as NASM, provide flexible symbol management, letting programmers manage different namespaces, automatically calculate offsets within data structures, and assign labels that refer to literal values or the result of simple computations performed by the assembler. Labels can also be used to initialize constants and variables with relocatable addresses.
Assembly languages, like most other computer languages, allow comments to be added to program source code that will be ignored during assembly. Judicious commenting is essential in assembly language programs, as the meaning and purpose of a sequence of binary machine instructions can be difficult to determine. The "raw" (uncommented) assembly language generated by compilers or disassemblers is quite difficult to read when changes must be made.
Many assemblers support "predefined macros", and others support "programmer-defined" (and repeatedly re-definable) macros involving sequences of text lines in which variables and constants are embedded. The macro definition is most commonly a mixture of assembler statements, e.g., directives, symbolic machine instructions, and templates for assembler statements. This sequence of text lines may include opcodes or directives. Once a macro has been defined its name may be used in place of a mnemonic. When the assembler processes such a statement, it replaces the statement with the text lines associated with that macro, then processes them as if they existed in the source code file (including, in some assemblers, expansion of any macros existing in the replacement text). Macros in this sense date to IBM autocoders of the 1950s.
In assembly language, the term "macro" represents a more comprehensive concept than it does in some other contexts, such as the pre-processor in the C programming language, where its #define directive typically is used to create short single line macros. Assembler macro instructions, like macros in PL/I and some other languages, can be lengthy "programs" by themselves, executed by interpretation by the assembler during assembly.
Since macros can have 'short' names but expand to several or indeed many lines of code, they can be used to make assembly language programs appear to be far shorter, requiring fewer lines of source code, as with higher level languages. They can also be used to add higher levels of structure to assembly programs, optionally introduce embedded debugging code via parameters and other similar features.
Macro assemblers often allow macros to take parameters. Some assemblers include quite sophisticated macro languages, incorporating such high-level language elements as optional parameters, symbolic variables, conditionals, string manipulation, and arithmetic operations, all usable during the execution of a given macro, and allowing macros to save context or exchange information. Thus a macro might generate numerous assembly language instructions or data definitions, based on the macro arguments. This could be used to generate record-style data structures or "unrolled" loops, for example, or could generate entire algorithms based on complex parameters. For instance, a "sort" macro could accept the specification of a complex sort key and generate code crafted for that specific key, not needing the run-time tests that would be required for a general procedure interpreting the specification. An organization using assembly language that has been heavily extended using such a macro suite can be considered to be working in a higher-level language since such programmers are not working with a computer's lowest-level conceptual elements. Underlining this point, macros were used to implement an early virtual machine in SNOBOL4 (1967), which was written in the SNOBOL Implementation Language (SIL), an assembly language for a virtual machine. The target machine would translate this to its native code using a macro assembler. This allowed a high degree of portability for the time.
Macros were used to customize large scale software systems for specific customers in the mainframe era and were also used by customer personnel to satisfy their employers' needs by making specific versions of manufacturer operating systems. This was done, for example, by systems programmers working with IBM's Conversational Monitor System / Virtual Machine (VM/CMS) and with IBM's "real time transaction processing" add-ons, Customer Information Control System CICS, and ACP/TPF, the airline/financial system that began in the 1970s and still runs many large computer reservation systems (CRS) and credit card systems today.
It is also possible to use solely the macro processing abilities of an assembler to generate code written in completely different languages, for example, to generate a version of a program in COBOL using a pure macro assembler program containing lines of COBOL code inside assembly time operators instructing the assembler to generate arbitrary code. IBM OS/360 uses macros to perform system generation. The user specifies options by coding a series of assembler macros. Assembling these macros generates a job stream to build the system, including job control language and utility control statements.
This is because, as was realized in the 1960s, the concept of "macro processing" is independent of the concept of "assembly", the former being in modern terms more word processing, text processing, than generating object code. The concept of macro processing appeared, and appears, in the C programming language, which supports "preprocessor instructions" to set variables, and make conditional tests on their values. Unlike certain previous macro processors inside assemblers, the C preprocessor is not Turing-complete because it lacks the ability to either loop or "go to", the latter allowing programs to loop.
Despite the power of macro processing, it fell into disuse in many high level languages (major exceptions being C, C++ and PL/I) while remaining a perennial for assemblers.
Macro parameter substitution is strictly by name: at macro processing time, the value of a parameter is textually substituted for its name. The most famous class of bugs resulting was the use of a parameter that itself was an expression and not a simple name when the macro writer expected a name. In the macro:
the intention was that the caller would provide the name of a variable, and the "global" variable or constant b would be used to multiply "a". If foo is called with the parameter codice_17, the macro expansion of codice_18 occurs. To avoid any possible ambiguity, users of macro processors can parenthesize formal parameters inside macro definitions, or callers can parenthesize the input parameters.
Packages of macros have been written providing structured programming elements to encode execution flow. The earliest example of this approach was in the Concept-14 macro set, originally proposed by Harlan Mills (March 1970), and implemented by Marvin Kessler at IBM's Federal Systems Division, which provided IF/ELSE/ENDIF and similar control flow blocks for OS/360 assembler programs. This was a way to reduce or eliminate the use of GOTO operations in assembly code, one of the main factors causing spaghetti code in assembly language. This approach was widely accepted in the early 1980s (the latter days of large-scale assembly language use).
A curious design was A-natural, a "stream-oriented" assembler for 8080/Z80, processors from Whitesmiths Ltd. (developers of the Unix-like Idris operating system, and what was reported to be the first commercial C compiler). The language was classified as an assembler because it worked with raw machine elements such as opcodes, registers, and memory references; but it incorporated an expression syntax to indicate execution order. Parentheses and other special symbols, along with block-oriented structured programming constructs, controlled the sequence of the generated instructions. A-natural was built as the object language of a C compiler, rather than for hand-coding, but its logical syntax won some fans.
There has been little apparent demand for more sophisticated assemblers since the decline of large-scale assembly language development. In spite of that, they are still being developed and applied in cases where resource constraints or peculiarities in the target system's architecture prevent the effective use of higher-level languages.
Assemblers with a strong macro engine allow structured programming via macros, such as the switch macro provided with the Masm32 package (this code is a complete program):
include \masm32\include\masm32rt.inc ; use the Masm32 library
.code
demomain:
end demomain
Assembly languages were not available at the time when the stored-program computer was introduced. Kathleen Booth "is credited with inventing assembly language" based on theoretical work she began in 1947, while working on the ARC2 at Birkbeck, University of London following consultation by Andrew Booth (later her husband) with mathematician John von Neumann and physicist Herman Goldstine at the Institute for Advanced Study.
In late 1948, the Electronic Delay Storage Automatic Calculator (EDSAC) had an assembler (named "initial orders") integrated into its bootstrap program. It used one-letter mnemonics developed by David Wheeler, who is credited by the IEEE Computer Society as the creator of the first "assembler". Reports on the EDSAC introduced the term "assembly" for the process of combining fields into an instruction word. SOAP (Symbolic Optimal Assembly Program) was an assembly language for the IBM 650 computer written by Stan Poley in 1955.
Assembly languages eliminate much of the error-prone, tedious, and time-consuming first-generation programming needed with the earliest computers, freeing programmers from tedium such as remembering numeric codes and calculating addresses. They were once widely used for all sorts of programming. However, by the 1980s (1990s on microcomputers), their use had largely been supplanted by higher-level languages, in the search for improved programming productivity. Today, assembly language is still used for direct hardware manipulation, access to specialized processor instructions, or to address critical performance issues. Typical uses are device drivers, low-level embedded systems, and real-time systems.
Historically, numerous programs have been written entirely in assembly language. The Burroughs MCP (1961) was the first computer for which an operating system was not developed entirely in assembly language; it was written in Executive Systems Problem Oriented Language (ESPOL), an Algol dialect. Many commercial applications were written in assembly language as well, including a large amount of the IBM mainframe software written by large corporations. COBOL, FORTRAN and some PL/I eventually displaced much of this work, although a number of large organizations retained assembly-language application infrastructures well into the 1990s.
Most early microcomputers relied on hand-coded assembly language, including most operating systems and large applications. This was because these systems had severe resource constraints, imposed idiosyncratic memory and display architectures, and provided limited, buggy system services. Perhaps more important was the lack of first-class high-level language compilers suitable for microcomputer use. A psychological factor may have also played a role: the first generation of microcomputer programmers retained a hobbyist, "wires and pliers" attitude.
In a more commercial context, the biggest reasons for using assembly language were minimal bloat (size), minimal overhead, greater speed, and reliability.
Typical examples of large assembly language programs from this time are IBM PC DOS operating systems, the Turbo Pascal compiler and early applications such as the spreadsheet program Lotus 1-2-3. Assembly language was used to get the best performance out of the Sega Saturn, a console that was notoriously challenging to develop and program games for. The 1993 arcade game "NBA Jam" is another example.
Assembly language has long been the primary development language for many popular home computers of the 1980s and 1990s (such as the MSX, Sinclair ZX Spectrum, Commodore 64, Commodore Amiga, and Atari ST). This was in large part because interpreted BASIC dialects on these systems offered insufficient execution speed, as well as insufficient facilities to take full advantage of the available hardware on these systems. Some systems even have an integrated development environment (IDE) with highly advanced debugging and macro facilities. Some compilers available for the Radio Shack TRS-80 and its successors had the capability to combine inline assembly source with high-level program statements. Upon compilation, a built-in assembler produced inline machine code.
There have always been debates over the usefulness and performance of assembly language relative to high-level languages. 
Although assembly language has specific niche uses where it is important (see below), there are other tools for optimization.
, the TIOBE index of programming language popularity ranks assembly language at 11, ahead of Visual Basic, for example. Assembler can be used to optimize for speed or optimize for size. In the case of speed optimization, modern optimizing compilers are claimed to render high-level languages into code that can run as fast as hand-written assembly, despite the counter-examples that can be found. The complexity of modern processors and memory sub-systems makes effective optimization increasingly difficult for compilers, as well as for assembly programmers. Moreover, increasing processor performance has meant that most CPUs sit idle most of the time, with delays caused by predictable bottlenecks such as cache misses, I/O operations and paging. This has made raw code execution speed a non-issue for many programmers.
There are some situations in which developers might choose to use assembly language:
Assembly language is still taught in most computer science and electronic engineering programs. Although few programmers today regularly work with assembly language as a tool, the underlying concepts remain important. Such fundamental topics as binary arithmetic, memory allocation, stack processing, character set encoding, interrupt processing, and compiler design would be hard to study in detail without a grasp of how a computer operates at the hardware level. Since a computer's behavior is fundamentally defined by its instruction set, the logical way to learn such concepts is to study an assembly language. Most modern computers have similar instruction sets. Therefore, studying a single assembly language is sufficient to learn: I) the basic concepts; II) to recognize situations where the use of assembly language might be appropriate; and III) to see how efficient executable code can be created from high-level languages.

</doc>
<doc id="1369" url="https://en.wikipedia.org/wiki?curid=1369" title="Ambrosia">
Ambrosia

In the ancient Greek myths, ambrosia (, ) is the food or drink of the Greek gods, often depicted as conferring longevity or immortality upon whoever consumed it. It was brought to the gods in Olympus by doves and served by either Hebe or Ganymede at the heavenly feast.
"Ambrosia" is sometimes depicted in ancient art as distributed by a nymph labeled with that name and a nurse of Dionysus. In the myth of Lycurgus, the king attacked Ambrosia and Dionysus' entourage, causing the god to drive Lycurgus insane.
Ambrosia is very closely related to the gods' other form of sustenance, "nectar". The two terms may not have originally been distinguished; though in Homer's poems nectar is usually the drink and ambrosia the food of the gods; it was with ambrosia Hera "cleansed all defilement from her lovely flesh", and with ambrosia Athena prepared Penelope in her sleep, so that when she appeared for the final time before her suitors, the effects of years had been stripped away, and they were inflamed with passion at the sight of her. On the other hand, in Alcman, nectar is the food, and in Sappho and Anaxandrides, ambrosia is the drink. A character in Aristophanes' "Knights" says, "I dreamed the goddess poured ambrosia over your head—out of a ladle." Both descriptions could be correct, as ambrosia could be a liquid considered a food (such as honey).
The consumption of ambrosia was typically reserved for divine beings. Upon his assumption into immortality on Olympus, Heracles is given ambrosia by Athena, while the hero Tydeus is denied the same thing when the goddess discovers him eating human brains. In one version of the myth of Tantalus, part of Tantalus' crime is that after tasting ambrosia himself, he attempts to steal some to give to other mortals. Those who consume ambrosia typically have ichor, not blood, in their veins.
Both nectar and ambrosia are fragrant, and may be used as perfume: in the "Odyssey" Menelaus and his men are disguised as seals in untanned seal skins, "...and the deadly smell of the seal skins vexed us sore; but the goddess saved us; she brought ambrosia and put it under our nostrils." Homer speaks of ambrosial raiment, ambrosial locks of hair, even the gods' ambrosial sandals.
Among later writers, ambrosia has been so often used with generic meanings of "delightful liquid" that such late writers as Athenaeus, Paulus and Dioscurides employ it as a technical terms in contexts of cookery, medicine, and botany. Pliny used the term in connection with different plants, as did early herbalists.
Additionally, some modern ethnomycologists, such as Danny Staples, identify ambrosia with the hallucinogenic mushroom "Amanita muscaria": "...it was the food of the gods, their ambrosia, and nectar was the pressed sap of its juices", Staples asserts.
W. H. Roscher thinks that both nectar and ambrosia were kinds of honey, in which case their power of conferring immortality would be due to the supposed healing and cleansing powers of honey, and because fermented honey (mead) preceded wine as an entheogen in the Aegean world; on some Minoan seals, goddesses were represented with bee faces (compare Merope and Melissa).
The concept of an immortality drink is attested in at least two ancient Indo-European languages: Greek and Sanskrit. The Greek ἀμβροσία ("ambrosia") is semantically linked to the Sanskrit ("amṛta") as both words denote a drink or food that gods use to achieve immortality. The two words appear to be derived from the same Indo-European form *"ṇ-mṛ-tós", "un-dying" ("n-": negative prefix from which the prefix "a-" in both Greek and Sanskrit are derived; "mṛ": zero grade of *"mer-", "to die"; and "-to-": adjectival suffix). A semantically similar etymology exists for nectar, the beverage of the gods (Greek: νέκταρ "néktar") presumed to be a compound of the PIE roots "*nek-", "death", and "-*tar", "overcoming".
Lycurgus, king of Thrace, forbade the cult of Dionysus, whom he drove from Thrace, and attacked the gods' entourage when they celebrated the god. Among them was Ambrosia, who turned herself into a grapevine to hide from his wrath. Dionysus, enraged by the king's actions, drove him mad. In his fit of insanity he killed his son, whom he mistook for a stock of ivy, and then himself.

</doc>
<doc id="1370" url="https://en.wikipedia.org/wiki?curid=1370" title="Ambrose">
Ambrose

Ambrose (born Aurelius Ambrosius; c. 340 – 397), venerated as Saint Ambrose, was the Bishop of Milan, a theologian, and one of the most influential ecclesiastical figures of the 4th century.
Ambrose was serving as the Roman governor of Aemilia-Liguria in Milan when he was unexpectedly made Bishop of Milan in 374 by popular acclamation. As bishop, he took a firm position against Arianism and attempted to mediate the conflict between the emperor Theodosius I and the usurper Magnus Maximus. Tradition credits Ambrose with promoting "antiphonal chant", a style of chanting in which one side of the choir responds alternately to the other, as well as with composing "Veni redemptor gentium", an Advent hymn. He also had notable influence on Augustine of Hippo (354-430).
Western Christianity identified Ambrose as one of its four traditional Doctors of the Church. He is considered a saint by the Catholic Church, Eastern Orthodox Church, Anglican Communion, and various Lutheran denominations, and venerated as the patron saint of Milan.
Ambrose was born into a Roman Christian family about 340 and was raised in Gallia Belgica, the capital of which was Augusta Treverorum. His father is sometimes identified with Aurelius Ambrosius, a praetorian prefect of Gaul; but some scholars identify his father as an official named Uranius who received an imperial constitution dated 3 February 339 (addressed in a brief extract from one of the three emperors ruling in 339, Constantine II, Constantius II, or Constans, in the "Codex Theodosianus", book XI.5).
His mother was a woman of intellect and piety and a member of the Roman family "Aurelii Symmachi," and thus Ambrose was cousin of the orator Quintus Aurelius Symmachus. He was the youngest of three children, who included Marcellina and Satyrus (who is the subject of Ambrose's "De excessu fratris Satyri"), also venerated as saints. There is a legend that as an infant, a swarm of bees settled on his face while he lay in his cradle, leaving behind a drop of honey. His father considered this a sign of his future eloquence and honeyed tongue. For this reason, bees and beehives often appear in the saint's symbology.
About the year 354 Ambrosius, the father, died, whereupon the family moved to Rome. There he studied literature, law, and rhetoric. He then followed in his father's footsteps and entered public service. Praetorian Prefect Sextus Claudius Petronius Probus first gave him a place in the council and then in about 372 made him governor of Liguria and Emilia, with headquarters at Milan. In 286 Diocletian had moved the capital of the Western Roman Empire from Rome to Mediolanum (Milan).
Ambrose was the Governor of Aemilia-Liguria in northern Italy until 374, when he became the Bishop of Milan. Ambrose was a very popular political figure, and since he had been the Governor in the effective capital in the Roman West, he was a recognizable figure in the court of Valentinian I.
In the late 4th century there was a deep conflict in the diocese of Milan between the Nicene Church and Arians. In 374 the bishop of Milan, Auxentius, an Arian, died, and the Arians challenged the succession. Ambrose went to the church where the election was to take place, to prevent an uproar, which was probable in this crisis. His address was interrupted by a call, "Ambrose, bishop!", which was taken up by the whole assembly.
Ambrose was known to be Nicene Christian in belief, but also acceptable to Arians due to the charity shown in theological matters in this regard. At first he energetically refused the office, for which he was in no way prepared: Ambrose was neither baptized nor formally trained in theology. Upon his appointment, Ambrose fled to a colleague's home seeking to hide. Upon receiving a letter from the Emperor Gratian praising the appropriateness of Rome appointing individuals evidently worthy of holy positions, Ambrose's host gave him up. Within a week, he was baptized, ordained and duly consecrated bishop of Milan.
As bishop, he immediately adopted an ascetic lifestyle, apportioned his money to the poor, donating all of his land, making only provision for his sister Marcellina (who had become a nun). This raised his popularity even further, giving him considerable political leverage over even the emperor. Upon the unexpected appointment of Ambrose to the episcopate, his brother Satyrus resigned a prefecture in order to move to Milan, where he took over managing the diocese's temporal affairs.
In 383 Gratian was assassinated at Lyon, France, and Paulinus of Nola, who had served as governor of Campania, went to Milan to attend the school of Ambrose.
Ambrose studied theology with Simplician, a presbyter of Rome. Using to his advantage his excellent knowledge of Greek, which was then rare in the West, he studied the Old Testament and Greek authors like Philo, Origen, Athanasius, and Basil of Caesarea, with whom he was also exchanging letters. He applied this knowledge as preacher, concentrating especially on exegesis of the Old Testament, and his rhetorical abilities impressed Augustine of Hippo, who hitherto had thought poorly of Christian preachers.
In the confrontation with Arians, Ambrose sought to theologically refute their propositions, which were contrary to the Nicene creed and thus to the officially defined orthodoxy. The Arians appealed to many high level leaders and clergy in both the Western and Eastern empires. Although the western Emperor Gratian supported orthodoxy, the younger Valentinian II, who became his colleague in the Empire, adhered to the Arian creed. Ambrose did not sway the young prince's position. In the East, Emperor Theodosius I likewise professed the Nicene creed; but there were many adherents of Arianism throughout his dominions, especially among the higher clergy.
In this contested state of religious opinion, two leaders of the Arians, bishops Palladius of Ratiaria and Secundianus of Singidunum, confident of numbers, prevailed upon Gratian to call a general council from all parts of the empire. This request appeared so equitable that he complied without hesitation. However, Ambrose feared the consequences and prevailed upon the emperor to have the matter determined by a council of the Western bishops. Accordingly, a synod composed of thirty-two bishops was held at Aquileia in the year 381. Ambrose was elected president and Palladius, being called upon to defend his opinions, declined. A vote was then taken and Palladius and his associate Secundianus were deposed from their episcopal offices.
Nevertheless, the increasing strength of the Arians proved a formidable task for Ambrose. In 385 or 386 the emperor and his mother Justina, along with a considerable number of clergy and laity, especially military, professed Arianism. They demanded two churches in Milan, one in the city (the Basilica of the Apostles), the other in the suburbs (St Victor's), be allocated to the Arians. Ambrose refused and was required to answer for his conduct before the council. He went, his eloquence in defense of the Church reportedly overawing the ministers of Valentinian, so he was permitted to retire without making the surrender of the churches. The day following, when he was performing divine service in the basilica, the prefect of the city came to persuade him to give up at least the Portian basilica in the suburbs. As he still refused, certain deans or officers of the court were sent to take possession of the Portian basilica, by hanging up in it imperial escutcheons to prepare for the arrival of the emperor and his mother at the ensuing festival of Easter.
In spite of Imperial opposition, Ambrose declared, "If you demand my person, I am ready to submit: carry me to prison or to death, I will not resist; but I will never betray the church of Christ. I will not call upon the people to succour me; I will die at the foot of the altar rather than desert it. The tumult of the people I will not encourage: but God alone can appease it."
In 386 Justina and Valentinian received the Arian bishop Auxentius the younger, and Ambrose was again ordered to hand over a church in Milan for Arian usage. Ambrose and his congregation barricaded themselves inside the church, and the imperial order was rescinded.
The imperial court was displeased with the religious principles of Ambrose, however his aid was soon solicited by the Emperor. When Magnus Maximus usurped the supreme power in Gaul, and was meditating a descent upon Italy, Valentinian sent Ambrose to dissuade him from the undertaking, and the embassy was successful.
A second later embassy was unsuccessful. The enemy entered Italy and Milan was taken. Justina and her son fled but Ambrose remained at his post and did good service to many of the sufferers by causing the plate of the church to be melted for their relief.
Theodosius I, the emperor of the East, espoused the cause of Justina, and regained the kingdom. Theodosius was excommunicated by Ambrose for the massacre of 7,000 people at Thessalonica in 390, after the murder of the Roman governor there by rioters. Ambrose told Theodosius to imitate David in his repentance as he had imitated him in guilt, and he readmitted the emperor to the Eucharist only after several months of penance. This shows the strong position of a bishop in the western part of the empire, even when facing a strong emperor. The controversy of John Chrysostom with a much weaker emperor a few years later in Constantinople led to a crushing defeat of the bishop.
In 392, after the death of Valentinian II and the fall of Eugenius, Ambrose supplicated the emperor for the pardon of those who had supported Eugenius after Theodosius was eventually victorious.
In his treatise on Abraham, Ambrose warns against intermarriage with pagans, Jews, or heretics. In 388, Emperor Theodosius the Great was informed that a crowd of Christians, led by their bishop, had destroyed the synagogue at Callinicum on the Euphrates. He ordered the synagogue rebuilt at the expense of the bishop, but Ambrose persuaded Theodosius to retreat from this position. He wrote to the Emperor, pointing out that he was thereby "exposing the bishop to the danger of either acting against the truth or of death"; in the letter "the reasons given for the imperial rescript are met, especially by the plea that the Jews had burnt many churches". Ambrose, referring to a prior incident where Magnus Maximus issued an edict censuring Christians in Rome for burning down a Jewish synagogue, warned Theodosius that the people in turn exclaimed "the emperor has become a Jew", implying that if Theodosius attempted to apply the law to protect his Jewish subjects he'd be viewed similarly. In the course of the letter Ambrose speaks of the clemency that the emperor had shown with regard to the many houses of wealthy people and churches that had been destroyed by unruly mobs, with many then still not restored and then adds: "There is, then, no adequate cause for such a commotion, that the people should be so severely punished for the burning of a building, and much less since it is the burning of a synagogue, a home of unbelief, a house of impiety, a receptacle of folly, which God Himself has condemned. For thus we read, where the Lord our God speaks by the mouth of the prophet Jeremiah: 'And I will do to this house, which is called by My Name, wherein ye trust, and to the place which I gave to you and to your fathers, as I have done to Shiloh, and I will cast you forth from My sight, as I cast forth your brethren, the whole seed of Ephraim. And do not thou pray for that people, and do not thou ask mercy for them, and do not come near Me on their behalf, for I will not hear thee. Or seest thou not what they do in the cities of Judah?' God forbids intercession to be made for those." Yet, Ambrose did not oppose punishing those who were directly responsible for destroying the synagogue.
In his exposition of Psalm 1, Ambrose says: "Virtues without faith are leaves, flourishing in appearance, but unproductive. How many pagans have mercy and sobriety but no fruit, because they do not attain their purpose! The leaves speedily fall at the wind's breath. Some Jews exhibit purity of life and much diligence and love of study, but bear no fruit and live like leaves."
Under his influence, emperors Gratian, Valentinian II and Theodosius I carried on a persecution of paganism; Theodosius issued the 391 "Theodosian decrees," which with increasing intensity outlawed pagan practices.The Altar of Victory was removed by Gratian. Ambrose prevailed upon Gratian, Valentinian and Theodosius to reject requests to restore the altar.
In April 393 Arbogast, "magister militum" of the West and his puppet Emperor Eugenius, marched into Italy to consolidate their position in regard to Theodosius I and his son, Honorius, whom Theodosius had appointed Augustus to govern the western portion of the empire. Arbogast and Eugenius courted Ambrose's support by very obliging letters; but before they arrived at Milan, he had retired to Bologna, where he assisted at the translation of the relics of Saints Vitalis and Agricola. From there he went to Florence, where he remained until Eugenius withdrew from Milan to meet Theodosius in the Battle of the Frigidus in early September 394.
Soon after acquiring the undisputed possession of the Roman Empire, Theodosius died at Milan in 395, and two years later (4 April 397) Ambrose also died. He was succeeded as bishop of Milan by Simplician. Ambrose's body may still be viewed in the church of Saint Ambrogio in Milan, where it has been continuously venerated – along with the bodies identified in his time as being those of Saints Gervase and Protase.
Many circumstances in the history of Ambrose are characteristic of the general spirit of the times. The chief causes of his victory over his opponents were his great popularity and the reverence paid to the episcopal character at that period. He used several indirect means to obtain and support his authority with the people.
It was his custom to comment severely in his preaching on the public characters of his times; and he introduced popular reforms in the order and manner of public worship. It is alleged, too, that at a time when the influence of Ambrose required vigorous support, he was admonished in a dream to search for, and found under the pavement of the church, the remains of two martyrs, Gervasius and Protasius. The saints, although they would have had to have been hundreds of years old, looked as if they had just died. The applause of the people was mingled with the derision of the court party.
Ambrose joins Augustine, Jerome, and Gregory the Great as one of the Latin Doctors of the Church. Theologians compare him with Hilary, who they claim fell short of Ambrose's administrative excellence but demonstrated greater theological ability. He succeeded as a theologian despite his juridical training and his comparatively late handling of Biblical and doctrinal subjects.
Ambrose's intense episcopal consciousness furthered the growing doctrine of the Church and its sacerdotal ministry, while the prevalent asceticism of the day, continuing the Stoic and Ciceronian training of his youth, enabled him to promulgate a lofty standard of Christian ethics. Thus we have the "De officiis ministrorum", "De viduis", "De virginitate" and "De paenitentia".
Ambrose displayed a kind of liturgical flexibility that kept in mind that liturgy was a tool to serve people in worshiping God, and ought not to become a rigid entity that is invariable from place to place. His advice to Augustine of Hippo on this point was to follow local liturgical custom. "When I am at Rome, I fast on a Saturday; when I am at Milan, I do not. Follow the custom of the church where you are." Thus Ambrose refused to be drawn into a false conflict over which particular local church had the "right" liturgical form where there was no substantial problem. His advice has remained in the English language as the saying, "When in Rome, do as the Romans do."
One interpretation of Ambrose's writings is that he was a Christian universalist. It has been noted that Ambrose's theology was significantly influenced by that of Origen and Didymus the Blind, two other early Christian universalists. One quotation cited in favor of this belief is:
One could interpret this passage as being another example of the mainstream Christian belief in a general resurrection (that both those in heaven and in hell undergo a bodily resurrection), or an allusion to purgatory (that some destined for heaven must first undergo a phase of purification). Several other works by Ambrose clearly teach the mainstream view of salvation. For example: "The Jews feared to believe in manhood taken up into God, "and therefore have lost the grace of redemption", because they reject that on which salvation depends."
He was also interested in the condition of contemporary Italian society. Ambrose considered the poor not a distinct group of outsiders, but a part of the united, solidary people. Giving to the poor was not to be considered an act of generosity towards the fringes of society but a repayment of resources that God had originally bestowed on everyone equally and that the rich had usurped.
The theological treatises of Ambrose of Milan would come to influence Popes Damasus, Siricius and Leo XIII. Central to Ambrose is the virginity of Mary and her role as Mother of God.
Ambrose viewed celibacy as superior to marriage and saw Mary as the model of virginity.
In matters of exegesis he is, like Hilary, an Alexandrian. In dogma he follows Basil of Caesarea and other Greek authors, but nevertheless gives a distinctly Western cast to the speculations of which he treats. This is particularly manifest in the weightier emphasis which he lays upon human sin and divine grace, and in the place which he assigns to faith in the individual Christian life.
Ambrose is traditionally credited but not actually known to have composed any of the repertory of Ambrosian chant also known simply as "antiphonal chant", a method of chanting where one side of the choir alternately responds to the other. (The later pope Gregory I the Great is not known to have composed any Gregorian chant, the plainsong or "Romish chant".) However, Ambrosian chant was named in his honor due to his contributions to the music of the Church; he is credited with introducing hymnody from the Eastern Church into the West.
Catching the impulse from Hilary of Arles and confirmed in it by the success of Arian psalmody, Ambrose composed several original hymns as well, four of which still survive, along with music which may not have changed too much from the original melodies. Each of these hymns has eight, four-line stanzas and is written in strict iambic tetrameter (that is 4 × 2 syllables, each iamb being two syllables). Marked by dignified simplicity, they served as a fruitful model for later times.
In his writings, Ambrose refers only to the performance of psalms, in which solo singing of psalm verses alternated with a congregational refrain called an "antiphon".
Saint Ambrose was also traditionally credited with composing the hymn "Te Deum", which he is said to have composed when he baptised Saint Augustine of Hippo, his celebrated convert.
Ambrose was Bishop of Milan at the time of Augustine's conversion, and is mentioned in Augustine's "Confessions". It is commonly understood in the Christian Tradition that Ambrose baptized Augustine.
In a passage of Augustine's "Confessions" in which Augustine wonders why he could not share his burden with Ambrose, he comments: "Ambrose himself I esteemed a happy man, as the world counted happiness, because great personages held him in honor. Only his celibacy appeared to me a painful burden."
In this same passage of Augustine's "Confessions" is an anecdote which bears on the history of reading:
This is a celebrated passage in modern scholarly discussion. The practice of reading to oneself without vocalizing the text was less common in antiquity than it has since become. In a culture that set a high value on oratory and public performances of all kinds, in which the production of books was very labor-intensive, the majority of the population was illiterate, and where those with the leisure to enjoy literary works also had slaves to read for them, written texts were more likely to be seen as scripts for recitation than as vehicles of silent reflection. However, there is also evidence that silent reading did occur in antiquity and that it was not generally regarded as unusual.
Latin
English translations
Several of Ambrose's works have recently been published in the bilingual Latin-German "Fontes Christiani" series (currently edited by Brepols).
Several religious brotherhoods which have sprung up in and around Milan at various times since the 14th century have been called Ambrosians. Their connection to Ambrose is tenuous

</doc>
<doc id="1371" url="https://en.wikipedia.org/wiki?curid=1371" title="Ambracia">
Ambracia

Ambracia (; , occasionally , "Ampracia") was a city of ancient Greece on the site of modern Arta. It was captured by the Corinthians in 625 BC and was situated about from the Ambracian Gulf, on a bend of the navigable river Arachthos (or Aratthus), in the midst of a fertile wooded plain.
It was founded between 650 and 625 BC by Gorgus, son of the Corinthian tyrant Cypselus, at which time its economy was based on farmlands, fishing, timber for shipbuilding, and the exportation of the produce of Epirus. After the expulsion of Gorgus's son Periander its government developed into a strong democracy. The early policy of Ambracia was determined by its loyalty to Corinth (for which it probably served as an entrepot in the Epirus trade), and its consequent aversion to Corcyra (as Ambracia participated on the Corinthian side at the Battle of Sybota, which took place in 433 BC between the rebellious Corinthian colony of Corcyra (modern Corfu) and Corinth).
Ambraciot politics featured many frontier disputes with the Amphilochians and Acarnanians. Hence it took a prominent part in the Peloponnesian War until the crushing defeat at Idomene (426), which crippled its resources.
In the 4th century BC it continued its traditional policy, but in 338 was besieged by Philip II of Macedon. With the assistance of Corinth and Athens, it escaped complete domination at Philip's hands, but was nevertheless forced to accept a Macedonian garrison. In 294 BC, after forty-three years of semi-autonomy under Macedonian suzerainty, Ambracia was given by the son of Cassander to Pyrrhus, king of Epirus, who made it his capital, and adorned it with palace, temples and theatres. In the wars of Philip V of Macedon and the Epirotes against the Aetolian League (220–205) Ambracia passed from one alliance to the other, but ultimately joined the latter confederacy. During the struggle of the Aetolians against Rome, it stood a stubborn siege, including the first known use of poison gas against the Romans' siege tunnels.
Ambracia was captured and plundered by Marcus Fulvius Nobilior in 189 BC, after which it was declared by Rome a "free city", and gradually fell into insignificance. The foundation by Augustus of Nicopolis, into which the remaining inhabitants were drafted, left the site desolate. In Byzantine times a new settlement took its place under the name of Arta. Some fragmentary walls of large, well-dressed blocks near this latter town indicate the early prosperity of Ambracia.
Attribution:

</doc>
<doc id="1372" url="https://en.wikipedia.org/wiki?curid=1372" title="Amber">
Amber

Amber is fossilized tree resin that has been appreciated for its color and natural beauty since Neolithic times. Much valued from antiquity to the present as a gemstone, amber is made into a variety of decorative objects. Amber is used in jewelry. It has also been used as a healing agent in folk medicine.
There are five classes of amber, defined on the basis of their chemical constituents. Because it originates as a soft, sticky tree resin, amber sometimes contains animal and plant material as inclusions. Amber occurring in coal seams is also called resinite, and the term "ambrite" is applied to that found specifically within New Zealand coal seams.
The English word "amber" derives from Arabic (cognate with Middle Persian "ambar") via Middle Latin "ambar" and Middle French "ambre". The word was adopted in Middle English in the 14th century as referring to what is now known as "ambergris" ("ambre gris" or "grey amber"), a solid waxy substance derived from the sperm whale. 
In the Romance languages, the sense of the word had come to be extended to Baltic amber (fossil resin) from as early as the late 13th century. At first called white or yellow amber ("ambre jaune"), this meaning was adopted in English by the early 15th century. As the use of ambergris waned, this became the main sense of the word.
The two substances ("yellow amber" and "grey amber") conceivably became associated or confused because they both were found washed up on beaches. Ambergris is less dense than water and floats, whereas amber is too dense to float, though less dense than stone.
The classical names for amber, Latin "electrum" and Ancient Greek ("ēlektron"), are connected to a term ἠλέκτωρ ("ēlektōr") meaning "beaming Sun". According to myth, when Phaëton son of Helios (the Sun) was killed, his mourning sisters became poplar trees, and their tears became "elektron", amber. The word "elektron" gave rise to the words "electric, electricity", and their relatives because of amber's ability to bear a charge of static electricity.
Theophrastus discussed amber in the 4th century BC, as did Pytheas (c. 330 BC), whose work "On the Ocean" is lost, but was referenced by Pliny the Elder (23 to 79 AD), according to whose "The Natural History" (in what is also the earliest known mention of the name "Germania"):
Earlier Pliny says that Pytheas refers to a large island - three days' sail from the Scythian coast and called Balcia by Xenophon of Lampsacus (author of a fanciful travel book in Greek) - as "Basilia" - a name generally equated with "Abalus". Given the presence of amber, the island could have been Heligoland, Zealand, the shores of Bay of Gdańsk, the Sambia Peninsula or the Curonian Lagoon, which were historically the richest sources of amber in northern Europe.
It is assumed that there were well-established trade routes for amber connecting the Baltic with the Mediterranean (known as the "Amber Road"). Pliny states explicitly that the Germans exported amber to Pannonia, from where the Veneti distributed it onwards.
The ancient Italic peoples of southern Italy used to work amber; the National Archaeological Museum of Siritide (Museo Archeologico Nazionale della Siritide) at Policoro in the province of Matera (Basilicata) displays important surviving examples.
Amber used in antiquity as at Mycenae and in the prehistory of the Mediterranean comes from deposits of Sicily.
Pliny also cites the opinion of Nicias ( 470–413 BC), according to whom amber Besides the fanciful explanations according to which amber is "produced by the Sun", Pliny cites opinions that are well aware of its origin in tree resin, citing the native Latin name of "succinum" ("sūcinum", from "sucus" "juice"). In Book 37, section XI of "Natural History", Pliny wrote:
He also states that amber is also found in Egypt and in India, and he even refers to the electrostatic properties of amber, by saying that "in Syria the women make the whorls of their spindles of this substance, and give it the name of "harpax" [from ἁρπάζω, "to drag"] from the circumstance that it attracts leaves towards it, chaff, and the light fringe of tissues".
Pliny says that the German name of amber was "glæsum", "for which reason the Romans, when Germanicus Caesar commanded the fleet in those parts, gave to one of these islands the name of Glæsaria, which by the barbarians was known as Austeravia". This is confirmed by the recorded Old High German word "glas" and by the Old English word "glær" for "amber" (compare "glass").
In Middle Low German, amber was known as "berne-, barn-, börnstēn" (with etymological roots related to "burn" and to "stone"). The Low German term became dominant also in High German by the 18th century, thus modern German "Bernstein" besides Dutch "barnsteen".
In the Baltic languages, the Lithuanian term for amber is "gintaras" and the Latvian "dzintars". These words, and the Slavic "jantar" and Hungarian "gyanta" ('resin'), are thought to originate from Phoenician "jainitar" ("sea-resin").
Amber has a long history of use in China, with the first written record from 200 BC.
Early in the nineteenth century, the first reports of amber found in North America came from discoveries in New Jersey along Crosswicks Creek near Trenton, at Camden, and near Woodbury.
Amber is heterogeneous in composition, but consists of several resinous bodies more or less soluble in alcohol, ether and chloroform, associated with an insoluble bituminous substance. Amber is a macromolecule by free radical polymerization of several precursors in the labdane family, e.g. communic acid, cummunol, and biformene. These labdanes are diterpenes (CH) and trienes, equipping the organic skeleton with three alkene groups for polymerization. As amber matures over the years, more polymerization takes place as well as isomerization reactions, crosslinking and cyclization.
Heated above , amber decomposes, yielding an oil of amber, and leaves a black residue which is known as "amber colophony", or "amber pitch"; when dissolved in oil of turpentine or in linseed oil this forms "amber varnish" or "amber lac".
Molecular polymerization, resulting from high pressures and temperatures produced by overlying sediment, transforms the resin first into copal. Sustained heat and pressure drives off terpenes and results in the formation of amber.
For this to happen, the resin must be resistant to decay. Many trees produce resin, but in the majority of cases this deposit is broken down by physical and biological processes. Exposure to sunlight, rain, microorganisms (such as bacteria and fungi), and extreme temperatures tends to disintegrate the resin. For the resin to survive long enough to become amber, it must be resistant to such forces or be produced under conditions that exclude them.
Fossil resins from Europe fall into two categories, the famous Baltic ambers and another that resembles the "Agathis" group. Fossil resins from the Americas and Africa are closely related to the modern genus "Hymenaea", while Baltic ambers are thought to be fossil resins from family Sciadopityaceae plants that once lived in north Europe.
Most amber has a hardness between 2.0 and 2.5 on the Mohs scale, a refractive index of 1.5–1.6, a specific gravity between 1.06 and 1.10, and a melting point of 250–300 °C.
The abnormal development of resin in living trees ("succinosis") can result in the formation of amber. Impurities are quite often present, especially when the resin dropped onto the ground, so the material may be useless except for varnish-making. Such impure amber is called "firniss".
Such inclusion of other substances can cause amber to have an unexpected color. Pyrites may give a bluish color. "Bony amber" owes its cloudy opacity to numerous tiny bubbles inside the resin. However, so-called "black amber" is really only a kind of jet.
In darkly clouded and even opaque amber, inclusions can be imaged using high-energy, high-contrast, high-resolution X-rays.
Amber is globally distributed, mainly in rocks of Cretaceous age or younger.
Historically, the coast west of Königsberg in Prussia was the world's leading source of amber. The first mentions of amber deposits here date back to the 12th century. About 90% of the world's extractable amber is still located in that area, which became the Kaliningrad Oblast of Russia in 1946.
Pieces of amber torn from the seafloor are cast up by the waves and collected by hand, dredging, or diving. Elsewhere, amber is mined, both in open works and underground galleries. Then nodules of "blue earth" have to be removed and an opaque crust must be cleaned off, which can be done in revolving barrels containing sand and water. Erosion removes this crust from sea-worn amber.
Dominican amber is mined through bell pitting, which is dangerous due to the risk of tunnel collapse. Another important source of amber is Kachin State in northern Myanmar, which has been a major source of amber in China for at least 1800 years. Contemporary mining of this deposit has attracted attention for unsafe working conditions and its role in funding internal conflict in the country. Amber from the Rivne Oblast of Ukraine, referred to as Rovno amber, is mined illegally by organised crime groups, who deforest the surrounding areas and pump water into the sediments to extract the amber, causing severe environmental deterioration.
The Vienna amber factories, which use pale amber to manufacture pipes and other smoking tools, turn it on a lathe and polish it with whitening and water or with rotten stone and oil. The final luster is given by friction with flannel.
When gradually heated in an oil-bath, amber becomes soft and flexible. Two pieces of amber may be united by smearing the surfaces with linseed oil, heating them, and then pressing them together while hot. Cloudy amber may be clarified in an oil-bath, as the oil fills the numerous pores to which the turbidity is due.
Small fragments, formerly thrown away or used only for varnish, are now used on a large scale in the formation of "ambroid" or "pressed amber". The pieces are carefully heated with exclusion of air and then compressed into a uniform mass by intense hydraulic pressure, the softened amber being forced through holes in a metal plate. The product is extensively used for the production of cheap jewelry and articles for smoking. This pressed amber yields brilliant interference colors in polarized light.
Amber has often been imitated by other resins like copal and kauri gum, as well as by celluloid and even glass. Baltic amber is sometimes colored artificially, but also called "true amber".
Amber occurs in a range of different colors. As well as the usual yellow-orange-brown that is associated with the color "amber", amber itself can range from a whitish color through a pale lemon yellow, to brown and almost black. Other uncommon colors include red amber (sometimes known as "cherry amber"), green amber, and even blue amber, which is rare and highly sought after.
Yellow amber is a hard fossil resin from evergreen trees, and despite the name it can be translucent, yellow, orange, or brown colored. Known to the Iranians by the Pahlavi compound word kah-ruba (from kah "straw" plus rubay "attract, snatch", referring to its electrical properties), which entered Arabic as kahraba' or kahraba (which later became the Arabic word for electricity, كهرباء "kahrabā'"), it too was called amber in Europe (Old French and Middle English ambre). Found along the southern shore of the Baltic Sea, yellow amber reached the Middle East and western Europe via trade. Its coastal acquisition may have been one reason yellow amber came to be designated by the same term as ambergris. Moreover, like ambergris, the resin could be burned as an incense. The resin's most popular use was, however, for ornamentation—easily cut and polished, it could be transformed into beautiful jewelry.
Much of the most highly prized amber is transparent, in contrast to the very common cloudy amber and opaque amber. Opaque amber contains numerous minute bubbles. This kind of amber is known as "bony amber".
Although all Dominican amber is fluorescent, the rarest Dominican amber is blue amber. It turns blue in natural sunlight and any other partially or wholly ultraviolet light source. In long-wave UV light it has a very strong reflection, almost white. Only about is found per year, which makes it valuable and expensive.
Sometimes amber retains the form of drops and stalactites, just as it exuded from the ducts and receptacles of the injured trees. It is thought that, in addition to exuding onto the surface of the tree, amber resin also originally flowed into hollow cavities or cracks within trees, thereby leading to the development of large lumps of amber of irregular form.
Amber can be classified into several forms. Most fundamentally, there are two types of plant resin with the potential for fossilization. Terpenoids, produced by conifers and angiosperms, consist of ring structures formed of isoprene (CH) units. Phenolic resins are today only produced by angiosperms, and tend to serve functional uses. The extinct medullosans produced a third type of resin, which is often found as amber within their veins. The composition of resins is highly variable; each species produces a unique blend of chemicals which can be identified by the use of pyrolysis–gas chromatography–mass spectrometry. The overall chemical and structural composition is used to divide ambers into five classes. There is also a separate classification of amber gemstones, according to the way of production.
This class is by far the most abundant. It comprises labdatriene carboxylic acids such as communic or ozic acids. It is further split into three sub-classes. Classes Ia and Ib utilize regular labdanoid diterpenes (e.g. communic acid, communol, biformenes), while Ic uses "enantio" labdanoids (ozic acid, ozol, "enantio" biformenes).
Class Ia includes "Succinite" (= 'normal' Baltic amber) and "Glessite". They have a communic acid base, and they also include much succinic acid.
Baltic amber yields on dry distillation succinic acid, the proportion varying from about 3% to 8%, and being greatest in the pale opaque or "bony" varieties. The aromatic and irritating fumes emitted by burning amber are mainly due to this acid. Baltic amber is distinguished by its yield of succinic acid, hence the name "succinite". Succinite has a hardness between 2 and 3, which is rather greater than that of many other fossil resins. Its specific gravity varies from 1.05 to 1.10. It can be distinguished from other ambers via IR spectroscopy due to a specific carbonyl absorption peak. IR spectroscopy can detect the relative age of an amber sample. Succinic acid may not be an original component of amber, but rather a degradation product of abietic acid.
Like class Ia ambers, these are based on communic acid; however, they lack succinic acid.
This class is mainly based on "enantio"-labdatrienonic acids, such as ozic and zanzibaric acids. Its most familiar representative is Dominican amber.
Dominican amber differentiates itself from Baltic amber by being mostly transparent and often containing a higher number of fossil inclusions. This has enabled the detailed reconstruction of the ecosystem of a long-vanished tropical forest. Resin from the extinct species "Hymenaea protera" is the source of Dominican amber and probably of most amber found in the tropics. It is not "succinite" but "retinite".
These ambers are formed from resins with a sesquiterpenoid base, such as cadinene.
These ambers are polystyrenes.
Class IV is something of a wastebasket; its ambers are not polymerized, but mainly consist of cedrene-based sesquiterpenoids.
Class V resins are considered to be produced by a pine or pine relative. They comprise a mixture of diterpinoid resins and "n"-alkyl compounds. Their main variety is "Highgate copalite".
The oldest amber recovered dates to the Upper Carboniferous period (). Its chemical composition makes it difficult to match the amber to its producers – it is most similar to the resins produced by flowering plants; however, there are no flowering plant fossils known from before the Cretaceous, and they were not common until the Late Cretaceous. Amber becomes abundant long after the Carboniferous, in the Early Cretaceous, , when it is found in association with insects. The oldest amber with arthropod inclusions comes from the Late Triassic (late Carnian c. 230 Ma) of Italy, where two microscopic (0.2-0.1 mm) mites, "Triasacarus" and "Ampezzoa" and a poorly preserved nematoceran fly were found in mm sized droplets of amber. The oldest amber with significant numbers of arthropod inclusions comes from Lebanon. This amber, referred to as Lebanese amber, is roughly 125–135 million years old, is considered of high scientific value, providing evidence of some of the oldest sampled ecosystems.
In Lebanon, more than 450 outcrops of Lower Cretaceous amber were discovered by Dany Azar, a Lebanese paleontologist and entomologist. Among these outcrops, 20 have yielded biological inclusions comprising the oldest representatives of several recent families of terrestrial arthropods. Even older, Jurassic amber has been found recently in Lebanon as well. Many remarkable insects and spiders were recently discovered in the amber of Jordan including the oldest zorapterans, clerid beetles, umenocoleid roaches, and achiliid planthoppers.
The most important amber from the Cretaceous is the Burmese amber from the Hukawng Valley in northern Myanmar, and the only commercially exploited Cretaceous amber. Uranium–lead dating of zircon crystals associated with the deposit have given an estimated depositional age of approximately 99 Ma. Over 1300 species have been described from the amber, with over 300 in 2019 alone.
Baltic amber or succinite (historically documented as Prussian amber) is found as irregular nodules in marine glauconitic sand, known as "blue earth", occurring in Upper Eocene strata of Sambia in Prussia (in historical sources also referred to as "Glaesaria"). After 1945, this territory around Königsberg was turned into Kaliningrad Oblast, Russia, where amber is now systematically mined.
It appears, however, to have been partly derived from older Eocene deposits and it occurs also as a derivative phase in later formations, such as glacial drift. Relics of an abundant flora occur as inclusions trapped within the amber while the resin was yet fresh, suggesting relations with the flora of Eastern Asia and the southern part of North America. Heinrich Göppert named the common amber-yielding pine of the Baltic forests "Pinites succiniter", but as the wood does not seem to differ from that of the existing genus it has been also called "Pinus succinifera". It is improbable, however, that the production of amber was limited to a single species; and indeed a large number of conifers belonging to different genera are represented in the amber-flora.
Amber is a unique preservational mode, preserving otherwise unfossilizable parts of organisms; as such it is helpful in the reconstruction of ecosystems as well as organisms; the chemical composition of the resin, however, is of limited utility in reconstructing the phylogenetic affinity of the resin producer.
Amber sometimes contains animals or plant matter that became caught in the resin as it was secreted. Insects, spiders and even their webs, annelids, frogs, crustaceans, bacteria and amoebae, marine microfossils, wood, flowers and fruit, hair, feathers and other small organisms have been recovered in Cretaceous ambers (deposited c. ).
The preservation of prehistoric organisms in amber forms a key plot point in Michael Crichton's 1990 novel "Jurassic Park" and the 1993 movie adaptation by Steven Spielberg. In the story, scientists are able to extract the preserved blood of dinosaurs from prehistoric mosquitoes trapped in amber, from which they genetically clone living dinosaurs. Scientifically this is as yet impossible, since no amber with fossilized mosquitoes has ever yielded preserved blood. Amber is, however, conducive to preserving DNA, since it dehydrates and thus stabilizes organisms trapped inside. One projection in 1999 estimated that DNA trapped in amber could last up to 100 million years, far beyond most estimates of around 1 million years in the most ideal conditions, although a later 2013 study was unable to extract DNA from insects trapped in much more recent Holocene copal.
Amber has been used since prehistory (Solutrean) in the manufacture of jewelry and ornaments, and also in folk medicine.
Amber has been used as jewelry since the Stone Age, from 13,000 years ago. Amber ornaments have been found in Mycenaean tombs and elsewhere across Europe. To this day it is used in the manufacture of smoking and glassblowing mouthpieces. Amber's place in culture and tradition lends it a tourism value; Palanga Amber Museum is dedicated to the fossilized resin.
Amber has long been used in folk medicine for its purported healing properties. Amber and extracts were used from the time of Hippocrates in ancient Greece for a wide variety of treatments through the Middle Ages and up until the early twentieth century. Traditional Chinese medicine uses amber to "tranquilize the mind".
Amber necklaces are a traditional European remedy for colic or teething pain due to the purported analgesic properties of succinic acid, although there is no evidence that this is an effective remedy or delivery method. The American Academy of Pediatrics and the FDA have warned strongly against their use, as they present both a choking and a strangulation hazard.
In ancient China, it was customary to burn amber during large festivities. If amber is heated under the right conditions, oil of amber is produced, and in past times this was combined carefully with nitric acid to create "artificial musk" – a resin with a peculiar musky odor. Although when burned, amber does give off a characteristic "pinewood" fragrance, modern products, such as perfume, do not normally use actual amber due to the fact that fossilized amber produces very little scent. In perfumery, scents referred to as "amber" are often created and patented
to emulate the opulent golden warmth of the fossil.
The modern name for amber is thought to come from the Arabic word, ambar, meaning ambergris. Ambergris is the waxy aromatic substance created in the intestines of sperm whales and was used in making perfumes both in ancient times as well as modern.
The scent of amber was originally derived from emulating the scent of ambergris and/or the plant resin labdanum, but due to the endangered species status of the sperm whale the scent of amber is now largely derived from labdanum. The term "amber" is loosely used to describe a scent that is warm, musky, rich and honey-like, and also somewhat earthy. It can be synthetically created or derived from natural resins. When derived from natural resins it is most often created out of labdanum. Benzoin is usually part of the recipe. Vanilla and cloves are sometimes used to enhance the aroma.
"Amber" perfumes may be created using combinations of labdanum, benzoin resin, copal (itself a type of tree resin used in incense manufacture), vanilla, Dammara resin and/or synthetic materials.
Young resins, these are used as imitations:
Plastics, these are used as imitations:

</doc>
<doc id="1373" url="https://en.wikipedia.org/wiki?curid=1373" title="Amalaric">
Amalaric


</doc>
<doc id="1374" url="https://en.wikipedia.org/wiki?curid=1374" title="Alphorn">
Alphorn

The alphorn or alpenhorn or alpine horn is a labrophone, consisting of a straight several-meter-long wooden natural horn of conical bore, with a wooden cup-shaped mouthpiece. It is used by mountain dwellers in the Swiss Alps, Austrian Alps, Bavarian Alps in Germany, French Alps, and elsewhere. Similar wooden horns were used for communication in most mountainous regions of Europe, from the Alps to the Carpathians. Alphorns are today used as musical instruments.
For a long time, scholars believed that the alphorn had been derived from the Roman-Etruscan lituus, because of their resemblance in shape, and because of the word "liti", meaning Alphorn in the dialect of Obwalden. There is no documented evidence for this theory, however, and, the word "liti" was probably borrowed from 16th–18th century writings in Latin, where the word "lituus" could describe various wind instruments, such as the horn, the crumhorn, or the cornett. Swiss naturalist Conrad Gesner used the words "lituum alpinum" for the first known detailed description of the alphorn in his "De raris et admirandis herbis" in 1555. The oldest known document using the German word "Alphorn" is a page from a 1527 account book from the former Cistercian abbey St. Urban near Pfaffnau mentioning the payment of two Batzen for an itinerant alphorn player from the Valais.
17th–19th century collections of alpine myths and legends suggest that alphorn-like instruments had frequently been used as signal instruments in village communities since medieval times or earlier, sometimes substituting for the lack of church bells. Surviving artifacts, dating back to as far as ca. AD 1400, include wooden labrophones in their stretched form, like the alphorn, or coiled versions, such as the "Büchel" and the "Allgäuisches Waldhorn" or "Ackerhorn". The alphorn's exact origins remain indeterminate, and the ubiquity of horn-like signal instruments in valleys throughout Europe may indicate a long history of cross influences regarding their construction and usage.
The alphorn is carved from solid softwood, generally spruce but sometimes pine. In former times the alphorn maker would find a tree bent at the base in the shape of an alphorn, but modern makers piece the wood together at the base. A cup-shaped mouthpiece carved out of a block of hard wood is added and the instrument is complete.
An alphorn made at Rigi-Kulm, Schwyz, and now in the Victoria and Albert Museum, measures in length and has a straight tube. The Swiss alphorn varies in shape according to the locality, being curved near the bell in the Bernese Oberland. Michael Praetorius mentions an alphorn-like instrument under the name of Hölzern Trummet (wooden trumpet) in "Syntagma Musicum" (Wittenberg, 1615–1619; Pl. VIII).
The alphorn has no lateral openings and therefore gives the pure natural harmonic series of the open pipe. The notes of the natural harmonic series overlap, but do not exactly correspond, to notes found in the familiar chromatic scale in standard Western equal temperament. Most prominently within the alphorn's range, the 7th and 11th harmonics are particularly noticeable, because they fall between adjacent notes in the chromatic scale.
Accomplished alphornists often command a range of nearly three octaves, consisting of the 2nd through the 16th notes of the harmonic series. The availability of the higher tones is due in part to the relatively small diameter of the bore of the mouthpiece and tubing in relation to the overall length of the horn.
The well-known "Ranz des Vaches" (score; audio) is a traditional Swiss melody often heard on the alphorn. The song describes the time of bringing the cows to the high country at cheese making time. Rossini introduced the "Ranz des Vaches" into his masterpiece "William Tell," along with many other delightful melodies scattered throughout the opera in vocal and instrumental parts that are well-suited to the alphorn. Brahms wrote to Clara Schumann that the inspiration for the dramatic entry of the horn in the introduction to the last movement of his First Symphony was an alphorn melody he heard while vacationing in the Rigi area of Switzerland. For Clara's birthday in 1868 Brahms sent her a greeting that was to be sung with the melody.
Among music composed for the alphorn:

</doc>
<doc id="1376" url="https://en.wikipedia.org/wiki?curid=1376" title="Army">
Army

An army (from Latin "arma" "arms, weapons" via Old French "armée", "armed" [feminine]), ground force or land force is a fighting force that fights primarily on land. In the broadest sense, it is the land-based military branch, service branch or armed service of a nation or state. It may also include aviation assets by possessing an army aviation component. Within a national military force, the word army may also mean a field army.
In some countries, such as France and China, the term "army", especially in its plural form "armies", has the broader meaning of armed forces as a whole, while retaining the colloquial sense of land forces. To differentiate the colloquial army from the formal concept of military force, the term is qualified, for example in France the land force is called "Armée de terre", meaning Land Army, and the air force is called "Armée de l'Air", meaning Air Army. The naval force, although not using the term "army", is also included in the broad sense of the term "armies" — thus the French Navy is an integral component of the collective French Armies (French Armed Forces) under the Ministry of the Armies. A similar pattern is seen in China, with the People's Liberation Army (PLA) being the overall military, the "actual army" being the PLA Ground Force, and so forth for the PLA Air Force, the PLA Navy, and other branches.
The current largest army in the world, by number of active troops, is the PLA Ground Force of China with 1,600,000 active troops and 510,000 reserve personnel followed by the Indian Army with 1,237,117 active troops and 960,000 reserve personnel.
By convention, irregular military is understood in contrast to regular armies which grew slowly from personal bodyguards or elite militia. Regular in this case refers to standardized doctrines, uniforms, organizations, etc. Regular military can also refer to full-time status (standing army), versus reserve or part-time personnel. Other distinctions may separate statutory forces (established under laws such as the National Defence Act), from de facto "non-statutory" forces such as some guerrilla and revolutionary armies. Armies may also be expeditionary (designed for overseas or international deployment) or fencible (designed for – or restricted to – homeland defence)
India's armies were among the first in the world. The first recorded battle, the Battle of the Ten Kings, happened when a Hindu Aryan king named Sudas defeated an alliance of ten kings and their supportive chieftains. During the Iron Age, the Maurya and Nanda Empires had the largest armies in the world, the peak being approximately over 600,000 Infantry, 30,000 Cavalry, 8,000 War-Chariots and 9,000 War Elephants not including tributary state allies. In the Gupta age, large armies of longbowmen were recruited to fight off invading horse archer armies. Elephants, pikemen and cavalry were other featured troops.
In Rajput times, the main piece of equipment was iron or chain-mail armour, a round shield, either a curved blade or a straight-sword, a chakra disc and a katar dagger.
The states of China raised armies for at least 1000 years before the Spring and Autumn Annals. By the Warring States period, the crossbow had been perfected enough to become a military secret, with bronze bolts which could pierce any armor. Thus any political power of a state rested on the armies and their organization. China underwent political consolidation of the states of Han (韓), Wei (魏), Chu (楚), Yan (燕), Zhao (趙) and Qi (齊), until by 221 BCE, Qin Shi Huang (秦始皇帝), the first emperor of the Qin dynasty, attained absolute power. This first emperor of China could command the creation of a Terracotta Army to guard his tomb in the city of Xi'an (西安), as well as a realignment of the Great Wall of China to strengthen his empire against insurrection, invasion and incursion.
Sun Tzu's "The Art of War" remains one of China's Seven Military Classics, even though it is two thousand years old. Since no political figure could exist without an army, measures were taken to ensure only the most capable leaders could control the armies. Civil bureaucracies (士大夫) arose to control the productive power of the states, and their military power.
The Spartan Army was one of the earliest known professional armies. Boys were sent to a barracks at the age of seven or eight to train for becoming a soldier. At the age of thirty they were released from the barracks and allowed to marry and have a family. After that, men devoted their lives to war until their retirement at the age of 60. Unlike other civilizations, whose armies had to disband during the planting and harvest seasons, the Spartan serfs or "helots", did the manual labor.
This allowed the Spartans to field a full-time army with a campaign season that lasted all year. The Spartan Army was largely composed of hoplites, equipped with arms and armor nearly identical to each other. Each hoplite bore the Spartan emblem and a scarlet uniform. The main pieces of this armor were a round shield, a spear and a helmet.
The Roman Army had its origins in the citizen army of the Republic, which was staffed by citizens serving mandatory duty for Rome. Reforms turned the army into a professional organization which was still largely filled by citizens, but these citizens served continuously for 25 years before being discharged.
The Romans were also noted for making use of auxiliary troops, non-Romans who served with the legions and filled roles that the traditional Roman military could not fill effectively, such as light skirmish troops and heavy cavalry. After their service in the army they were made citizens of Rome and then their children were citizens also. They were also given land and money to settle in Rome. In the Late Roman Empire, these auxiliary troops, along with foreign mercenaries, became the core of the Roman Army; moreover, by the time of the Late Roman Empire tribes such as the Visigoths were paid to serve as mercenaries.
In the earliest Middle Ages it was the obligation of every aristocrat to respond to the call to battle with his own equipment, archers, and infantry. This decentralized system was necessary due to the social order of the time, but could lead to motley forces with variable training, equipment and abilities. The more resources the noble had access to, the better his troops would be.
Initially, the words "knight" and "noble" were used interchangeably as there was not generally a distinction between them. While the nobility did fight upon horseback, they were also supported by lower class citizens – and mercenaries and criminals – whose only purpose was participating in warfare because, most often than not, they held brief employment during their lord's engagement. As the Middle Ages progressed and feudalism developed in a legitimate social and economic system, knights started to develop into their own class with a minor caveat: they were still in debt to their lord. No longer primarily driven by economic need, the newly established vassal class were, instead, driven by fealty and chivalry.
As central governments grew in power, a return to the citizen armies of the classical period also began, as central levies of the peasantry began to be the central recruiting tool. England was one of the most centralized states in the Middle Ages, and the armies that fought in the Hundred Years' War were, predominantly, composed of paid professionals.
In theory, every Englishman had an obligation to serve for forty days. Forty days was not long enough for a campaign, especially one on the continent.
Thus the scutage was introduced, whereby most Englishmen paid to escape their service and this money was used to create a permanent army. However, almost all high medieval armies in Europe were composed of a great deal of paid core troops, and there was a large mercenary market in Europe from at least the early 12th century.
As the Middle Ages progressed in Italy, Italian cities began to rely mostly on mercenaries to do their fighting rather than the militias that had dominated the early and high medieval period in this region. These would be groups of career soldiers who would be paid a set rate. Mercenaries tended to be effective soldiers, especially in combination with standing forces, but in Italy they came to dominate the armies of the city states. This made them considerably less reliable than a standing army. Mercenary-on-mercenary warfare in Italy also led to relatively bloodless campaigns which relied as much on maneuver as on battles.
In 1439 the French legislature, known as the Estates General (French: "états généraux"), passed laws that restricted military recruitment and training to the king alone. There was a new tax to be raised known as the "taille" that was to provide funding for a new Royal army. The mercenary companies were given a choice of either joining the Royal army as "compagnies d'ordonnance" on a permanent basis, or being hunted down and destroyed if they refused. France gained a total standing army of around 6,000 men, which was sent out to gradually eliminate the remaining mercenaries who insisted on operating on their own. The new standing army had a more disciplined and professional approach to warfare than its predecessors. The reforms of the 1440s, eventually led to the French victory at Castillon in 1453, and the conclusion of the Hundred Years' War. By 1450 the companies were divided into the field army, known as the "grande ordonnance" and the garrison force known as the "petite ordonnance".
First nation states lacked the funds needed to maintain standing forces, so they tended to hire mercenaries to serve in their armies during wartime. Such mercenaries typically formed at the ends of periods of conflict, when men-at-arms were no longer needed by their respective governments.
The veteran soldiers thus looked for other forms of employment, often becoming mercenaries. Free Companies would often specialize in forms of combat that required longer periods of training that was not available in the form of a mobilized militia.
As late as the 1650s, most troops were mercenaries. However, after the 17th century, most states invested in better disciplined and more politically reliable permanent troops. For a time mercenaries became important as trainers and administrators, but soon these tasks were also taken by the state. The massive size of these armies required a large supporting force of administrators.
The newly centralized states were forced to set up vast organized bureaucracies to manage these armies, which some historians argue is the basis of the modern bureaucratic state. The combination of increased taxes and increased centralisation of government functions caused a series of revolts across Europe such as the Fronde in France and the English Civil War.
In many countries, the resolution of this conflict was the rise of absolute monarchy. Only in England and the Netherlands did representative government evolve as an alternative. From the late 17th century, states learned how to finance wars through long term low interest loans from national banking institutions. The first state to master this process was the Dutch Republic. This transformation in the armies of Europe had great social impact. The defense of the state now rested on the commoners, not on the aristocrats.
However, aristocrats continued to monopolise the officer corps of almost all early modern armies, including their high command. Moreover, popular revolts almost always failed unless they had the support and patronage of the noble or gentry classes. The new armies, because of their vast expense, were also dependent on taxation and the commercial classes who also began to demand a greater role in society. The great commercial powers of the Dutch and English matched much larger states in military might.
As any man could be quickly trained in the use of a musket, it became far easier to form massive armies. The inaccuracy of the weapons necessitated large groups of massed soldiers. This led to a rapid swelling of the size of armies. For the first time huge masses of the population could enter combat, rather than just the highly skilled professionals.
It has been argued that the drawing of men from across the nation into an organized corps helped breed national unity and patriotism, and during this period the modern notion of the nation state was born. However, this would only become apparent after the French Revolutionary Wars. At this time, the "levée en masse" and conscription would become the defining paradigm of modern warfare.
Before then, however, most national armies were in fact composed of many nationalities. In Spain armies were recruited from all the Spanish European territories including Spain, Italy, Wallonia (Walloon Guards) and Germany. The French recruited some soldiers from Germany, Switzerland as well as from Piedmont. Britain recruited Hessian and Hanovrian troops until the late 18th century. Irish Catholics made careers for themselves in the armies of many Catholic European states.
Prior to the English Civil War in England, the monarch maintained a personal bodyguard of Yeomen of the Guard and the Honourable Corps of Gentlemen at Arms, or "gentlemen pensioners", and a few locally raised companies to garrison important places such as Berwick on Tweed or Portsmouth (or Calais before it was recaptured by France in 1558).
Troops for foreign expeditions were raised upon an "ad hoc" basis. Noblemen and professional regular soldiers were commissioned by the monarch to supply troops, raising their quotas by indenture from a variety of sources. On January 26, 1661 Charles II issued the Royal Warrant that created the genesis of what would become the British Army, although the Scottish and English Armies would remain two separate organizations until the unification of England and Scotland in 1707. The small force was represented by only a few regiments.
After the American Revolutionary War the Continental Army was quickly disbanded as part of the Americans' distrust of standing armies, and irregular state militias became the sole ground army of the United States, with the exception of one battery of artillery guarding West Point's arsenal. Then First American Regiment was established in 1784. However, because of continuing conflict with Native Americans, it was soon realized that it was necessary to field a trained standing army. The first of these, the Legion of the United States, was established in 1791.
Until 1733 the common soldiers of Prussian Army consisted largely of peasantry recruited or impressed from Brandenburg–Prussia, leading many to flee to neighboring countries. To halt this trend, Frederick William I divided Prussia into regimental cantons. Every youth was required to serve as a soldier in these recruitment districts for three months each year; this met agrarian needs and added extra troops to bolster the regular ranks.
Russian tsars before Peter I of Russia maintained professional hereditary musketeer corps (streltsy in Russian) that were highly unreliable and undisciplined. In times of war the armed forces were augmented by peasants. Peter I introduced a modern regular army built on German model, but with a new aspect: officers not necessarily from nobility, as talented commoners were given promotions that eventually included a noble title at the attainment of an officer's rank. Conscription of peasants and townspeople was based on quota system, per settlement. Initially it was based on the number of households, later it was based on the population numbers. The term of service in the 18th century was for life. In 1793 it was reduced to 25 years. In 1834 it was reduced to 20 years plus 5 years in reserve and in 1855 to 12 years plus 3 years of reserve.
The first Ottoman standing army were Janissaries. They replaced forces that mostly comprised tribal warriors ("ghazis") whose loyalty and morale could not always be trusted. The first Janissary units were formed from prisoners of war and slaves, probably as a result of the sultan taking his traditional one-fifth share of his army's booty in kind rather than cash.
From the 1380s onwards, their ranks were filled under the "devşirme" system, where feudal dues were paid by service to the sultan. The "recruits" were mostly Christian youths, reminiscent of mamluks.
China organized the Manchu people into the Eight Banner system in the early 17th century. Defected Ming armies formed the Green Standard Army. These troops enlisted voluntarily and for long terms of service.
Conscription allowed the French Republic to form the "Grande Armée", what Napoleon Bonaparte called "the nation in arms", which successfully battled European professional armies.
Conscription, particularly when the conscripts are being sent to foreign wars that do not directly affect the security of the nation, has historically been highly politically contentious in democracies.
Canada also had a political dispute over conscription during World War II. Similarly, mass protests against conscription to fight the Vietnam War occurred in several countries in the late 1960s.
In developed nations, the increasing emphasis on technological firepower and better-trained fighting forces, the sheer unlikelihood of a conventional military assault on most developed nations, as well as memories of the contentiousness of the Vietnam War experience, make mass conscription unlikely in the foreseeable future.
Russia, as well as many other nations, retains mainly a conscript army. There is also a very rare "citizen army" as used in Switzerland (see Military of Switzerland).
Western armies are usually subdivided as follows:
A field army is composed of a headquarters, army troops, a variable number of corps, typically between three and four, and a variable number of divisions, also between three and four. A battle is influenced at the Field Army level by transferring divisions and reinforcements from one corps to another to increase the pressure on the enemy at a critical point. Field armies are controlled by a general or lieutenant general.
A particular army can be named or numbered to distinguish it from military land forces in general. For example, the First United States Army and the Army of Northern Virginia. In the British Army it is normal to spell out the ordinal number of an army (e.g. First Army), whereas lower formations use figures (e.g. 1st Division).
Armies (as well as army groups and theaters) are large formations which vary significantly between armed forces in size, composition, and scope of responsibility.
In the Soviet Red Army and the Soviet Air Force, "Armies" could vary in size, but were subordinate to an Army Group-sized "front" in wartime. In peacetime, a Soviet army was usually subordinate to a military district. Viktor Suvorov's "Inside the Soviet Army" describes how Cold War era Soviet military districts were actually composed of a front headquarters and a military district headquarters co-located for administration and deception ('maskirovika') reasons.

</doc>
<doc id="1380" url="https://en.wikipedia.org/wiki?curid=1380" title="Alligatoridae">
Alligatoridae

The family Alligatoridae of crocodylians includes alligators and caimans.
The superfamily Alligatoroidea includes all crocodilians (fossil and extant) that are more closely related to the American alligator than to either the Nile crocodile or the gharial.
This superfamily is thought to have split from the crocodile-gharial lineage in the late Cretaceous, about 87 million years ago. "Leidyosuchus" of Alberta is the earliest known genus. Fossil alligatoroids have been found throughout Eurasia as land bridges across both the North Atlantic and the Bering Strait have connected North America to Eurasia during the Cretaceous, Paleogene, and Neogene periods. Alligators and caimans split in North America during the early Tertiary or late Cretaceous (about 53 million to about 65 million years ago) and the latter reached South America by the Paleogene, before the closure of the Isthmus of Panama during the Neogene period. The Chinese alligator split from the American alligator about 33 million years ago and likely descended from a lineage that crossed the Bering land bridge during the Neogene. The modern American alligator is well represented in the fossil record of the Pleistocene. The alligator's full mitochondrial genome was sequenced in the 1990s and it suggests the animal evolved at a rate similar to mammals and greater than birds and most cold-blooded vertebrates. The full genome, published in 2014, suggests that the alligator evolved much more slowly than mammals and birds.
The lineage including alligators proper (Alligatorinae) occurs in the fluvial deposits of the age of the Upper Chalk in Europe, where they did not die out until the Pliocene age. The true alligators are today represented by two species, "A. mississippiensis" in the southeastern United States, which can grow to 15 ft (4.6 m) and weigh 1000 lbs (453 kg) and the small "A. sinensis" in the Yangtze River, China, which grows to an average of 5 ft (1.5 m). Their name derives from the Spanish "el lagarto", which means "the lizard".
In Central and South America, the alligator family is represented by six species of the subfamily Caimaninae, which differ from the alligator by the absence of a bony septum between the nostrils, and having ventral armour composed of overlapping bony scutes, each of which is formed of two parts united by a suture. Besides the three species in "Caiman", the smooth-fronted caimans in genus "Paleosuchus" and the black caiman in "Melanosuchus" are described. Caimans tend to be more agile and crocodile-like in their movements, and have longer, sharper teeth than alligators.
"C. crocodilus", the spectacled caiman, has the widest distribution, from southern Mexico to the northern half of Argentina, and grows to a modest size of about . The largest is the near-threatened "Melanosuchus niger", the "jacaré-açu" or large or black caiman of the Amazon River basin. Black caimans grow to , with the largest recorded size . The black caiman and American alligator are the only members of the alligator family that pose the same danger to humans as the larger species of the crocodile family.
Although caimans have not been studied in depth, scientists have learned their mating cycles (previously thought to be spontaneous or year-round) are linked to the rainfall cycles and the river levels, which increases chances of survival for their offspring.

</doc>
<doc id="1383" url="https://en.wikipedia.org/wiki?curid=1383" title="Alder">
Alder

Alder is the common name of a genus of flowering plants, Alnus, belonging to the birch family Betulaceae. The genus comprises about 35 species of monoecious trees and shrubs, a few reaching a large size, distributed throughout the north temperate zone with a few species extending into Central America, as well as the northern and southern Andes.
The common name "alder" evolved from the Old English word "alor", which in turn is derived from Proto-Germanic root "aliso". The generic name "Alnus" is the equivalent Latin name (which is also the source for "Alamo", the Spanish term for "poplar").
With a few exceptions, alders are deciduous, and the leaves are alternate, simple, and serrated. The flowers are catkins with elongate male catkins on the same plant as shorter female catkins, often before leaves appear; they are mainly wind-pollinated, but also visited by bees to a small extent. These trees differ from the birches ("Betula", another genus in the family) in that the female catkins are woody and do not disintegrate at maturity, opening to release the seeds in a similar manner to many conifer cones.
The largest species are red alder ("A. rubra") on the west coast of North America, and black alder ("A. glutinosa"), native to most of Europe and widely introduced elsewhere, both reaching over 30 m. By contrast, the widespread "Alnus alnobetula" (green alder) is rarely more than a 5-m-tall shrub.
Alders are commonly found near streams, rivers, and wetlands. Sometimes where the prevalence of alders is particularly prominent these are called alder carrs. In the Pacific Northwest of North America, the white alder (Alnus rhombifolia) unlike other northwest alders, has an affinity for warm, dry climates, where it grows along watercourses, such as along the lower Columbia River east of the Cascades and the Snake River, including Hells Canyon.
Alder leaves and sometimes catkins are used as food by numerous butterflies and moths.
"A. glutinosa" and "A. viridis" are classed as environmental weeds in New Zealand. Alder leaves and especially the roots are important to the ecosystem because they enrich the soil with nitrogen and other nutrients.
Alder is particularly noted for its important symbiotic relationship with "Frankia alni", an actinomycete, filamentous, nitrogen-fixing bacterium. This bacterium is found in root nodules, which may be as large as a human fist, with many small lobes, and light brown in colour. The bacterium absorbs nitrogen from the air and makes it available to the tree. Alder, in turn, provides the bacterium with sugars, which it produces through photosynthesis. As a result of this mutually beneficial relationship, alder improves the fertility of the soil where it grows, and as a pioneer species, it helps provide additional nitrogen for the successional species which follow.
Because of its abundance, red alder delivers large amounts of nitrogen to enrich forest soils. Red alder stands have been found to supply between 120 and 290 pounds of nitrogen per acre (130 to 320 kg per ha) annually to the soil. From Alaska to Oregon, "Alnus viridis" subsp. "sinuata" ("A. sinuata", Sitka Alder or Slide Alder), characteristically pioneer fresh, gravelly sites at the foot of retreating glaciers. Studies show that Sitka alder, a more shrubby variety of alder, adds nitrogen to the soil at an average of 55 pounds per acre (60 kg per ha) per year, helping convert the sterile glacial terrain to soil capable of supporting a conifer forest. Alders are common among the first species to colonize disturbed areas from floods, windstorms, fires, landslides, etc. Alder groves themselves often serve as natural firebreaks since these broad-leaved trees are much less flammable than conifers. Their foliage and leaf litter does not carry a fire well, and their thin bark is sufficiently resistant to protect them from light surface fires. In addition, the light weight of alder seeds (650,000 per pound, or 1.5 million per kg) allows for easy dispersal by the wind. Although it outgrows coastal Douglas-fir for the first 25 years, it is very shade intolerant and seldom lives more than 100 years. Red alder is the Pacific Northwest's largest alder and the most plentiful and commercially important broad-leaved tree in the coastal Northwest. Groves of red alder 10 to 20 inches (25 to 50 cm) in diameter intermingle with young Douglas-fir forests west of the Cascades, attaining a maximum height of 100 to 110 feet (30 to 33 m) in about sixty years and then lose vigor as heart rot sets in. Alders largely help create conditions favorable for giant conifers that replace them.
Alder roots are parasitized by northern groundcone.
The catkins of some alder species have a degree of edibility, and may be rich in protein. Reported to have a bitter and unpleasant taste, they are more useful for survival purposes. The wood of certain alder species is often used to smoke various food items such as coffee, salmon, and other seafood.
Most of the pilings that form the foundation of Venice were made from alder trees.
Alder bark contains the anti-inflammatory salicin, which is metabolized into salicylic acid in the body. Some Native American cultures use red alder bark ("Alnus rubra") to treat poison oak, insect bites, and skin irritations. Blackfeet Indians have traditionally used an infusion made from the bark of red alder to treat lymphatic disorders and tuberculosis. Recent clinical studies have verified that red alder contains betulin and lupeol, compounds shown to be effective against a variety of tumors.
The inner bark of the alder, as well as red osier dogwood, or chokecherry, is used by some Indigenous peoples of the Americas in smoking mixtures, known as "kinnikinnick", to improve the taste of the bearberry leaf.
Alder is illustrated in the coat of arms for the Austrian town of Grossarl.
Electric guitars, most notably those manufactured by the Fender Musical Instruments Corporation, have been built with alder bodies since the 1950s. Alder is appreciated for its tone that is claimed to be tight and evenly balanced, especially when compared to mahogany, and has been adopted by many electric guitar manufacturers.
As a hardwood, alder is used in making furniture, cabinets, and other woodworking products. For example, in the television series "Northern Exposure" season 3 episode "Things Become Extinct" (1992), Native American Ira Wingfeather makes duck flutes out of alder tree branches while Ed Chigliak films.
Ermanno Olmi's movie "The Tree Of Wooden Clogs" ("L' Albero Degli Zoccoli," 1978) refers in its title to alder, typically used to make clogs as in this movie's plot. 
Alder bark and wood (like oak and sweet chestnut) contain tannin and are traditionally used to tan leather.
A red dye can also be extracted from the outer bark, and a yellow dye from the inner bark.
The genus is divided into three subgenera:
Subgenus "Alnus": Trees with stalked shoot buds, male and female catkins produced in autumn (fall) but stay closed over winter, pollinating in late winter or early spring, about 15–25 species, including:
Subgenus "Clethropsis". Trees or shrubs with stalked shoot buds, male and female catkins produced in autumn (fall) and expanding and pollinating then, three species:
Subgenus "Alnobetula". Shrubs with shoot buds not stalked, male and female catkins produced in late spring (after leaves appear) and expanding and pollinating then, one to four species:

</doc>
<doc id="1384" url="https://en.wikipedia.org/wiki?curid=1384" title="Amos Bronson Alcott">
Amos Bronson Alcott

Amos Bronson Alcott (; November 29, 1799March 4, 1888) was an American teacher, writer, philosopher, and reformer. As an educator, Alcott pioneered new ways of interacting with young students, focusing on a conversational style, and avoided traditional punishment. He hoped to perfect the human spirit and, to that end, advocated a vegan diet before the term was coined. He was also an abolitionist and an advocate for women's rights.
Born in Wolcott, Connecticut in 1799, Alcott had only minimal formal schooling before attempting a career as a traveling salesman. Worried about how the itinerant life might have a negative impact on his soul, he turned to teaching. His innovative methods, however, were controversial, and he rarely stayed in one place very long. His most well-known teaching position was at the Temple School in Boston. His experience there was turned into two books: "Records of a School" and "Conversations with Children on the Gospels". Alcott became friends with Ralph Waldo Emerson and became a major figure in transcendentalism. His writings on behalf of that movement, however, are heavily criticized for being incoherent. Based on his ideas for human perfection, Alcott founded Fruitlands, a transcendentalist experiment in community living. The project was short-lived and failed after seven months. Alcott continued to struggle financially for most of his life. Nevertheless, he continued focusing on educational projects and opened a new school at the end of his life in 1879. He died in 1888.
Alcott married Abby May in 1830 and they eventually had four surviving children, all daughters. Their second was Louisa May, who fictionalized her experience with the family in her novel "Little Women" in 1868.
A native New Englander, Amos Bronson Alcott was born in Wolcott, Connecticut (then recently renamed from "Farmingbury") on November 29, 1799. His parents were Joseph Chatfield Alcott and Anna Bronson Alcott. The family home was in an area known as Spindle Hill, and his father, Joseph Alcox, traced his ancestry to colonial-era settlers in eastern Massachusetts. The family originally spelled their name "Alcock", later changed to "Alcocke" then "Alcox". Amos Bronson, the oldest of eight children, later changed the spelling to "Alcott" and dropped his first name.
At age six, young Bronson began his formal education in a one-room schoolhouse in the center of town but learned how to read at home with the help of his mother. The school taught only reading, writing, and spelling and he left this school at the age of 10. At age 13, his uncle, Reverend Tillotson Bronson, invited Alcott into his home in Cheshire, Connecticut, to be educated and prepared for college. Bronson gave it up after only a month and was self-educated from then on. He was not particularly social and his only close friend was his neighbor and second cousin William Alcott, with whom he shared books and ideas. Bronson Alcott later reflected on his childhood at Spindle Hill: "It kept me pure... I dwelt amidst the hills... God spoke to me while I walked the fields." Starting at age 15, he took a job working for clockmaker Seth Thomas in the nearby town of Plymouth.
At age 17, Alcott passed the exam for a teaching certificate but had trouble finding work as a teacher. Instead, he left home and became a traveling salesman in the American South, peddling books and merchandise. He hoped the job would earn him enough money to support his parents, "to make their cares, and burdens less... and get them free from debt", though he soon spent most of his earnings on a new suit. At first, he thought it an acceptable occupation but soon worried about his spiritual well-being. In March 1823, Alcott wrote to his brother: "Peddling is a hard place to serve God, but a capital one to serve Mammon." Near the end of his life, he fictionalized this experience in his book, "New Connecticut", originally circulated only among friends before its publication in 1881.
By the summer of 1823, Alcott returned to Connecticut in debt to his father, who bailed him out after his last two unsuccessful sales trips. He took a job as a schoolteacher in Cheshire with the help of his Uncle Tillotson. He quickly set about reforming the school. He added backs to the benches on which students sat, improved lighting and heating, de-emphasized rote learning, and provided individual slates to each student—paid for by himself. Alcott had been influenced by educational philosophy of the Swiss pedagogue Johann Heinrich Pestalozzi and even renamed his school "The Cheshire Pestalozzi School". His style attracted the attention of Samuel Joseph May, who introduced Alcott to his sister Abby May. She called him, "an intelligent, philosophic, modest man" and found his views on education "very attractive". Locals in Cheshire were less supportive and became suspicious of his methods. Many students left and were enrolled in the local common school or a recently re-opened private school for boys. On November 6, 1827, Alcott started teaching in Bristol, Connecticut, still using the same methods he used in Cheshire, but opposition from the community surfaced quickly; he was unemployed by March 1828. He moved to Boston on April 24, 1828, and was immediately impressed, referring to the city as a place "where the light of the sun of righteousness has risen". He opened the Salem Street Infant School two months later on June 23. Abby May applied as his teaching assistant; instead, the couple were engaged, without consent of the family. They were married at King's Chapel on May 22, 1830; he was 30 years old and she was 29. Her brother conducted the ceremony and a modest reception followed at her father's house. After their marriage the Alcotts moved to 12 Franklin Street in Boston, a boarding house run by a Mrs. Newall. Around this time, Alcott also first expressed his public disdain for slavery. In November 1830, he and William Lloyd Garrison founded what he later called a "preliminary Anti-Slavery Society", though he differed from Garrison as a nonresistant. Alcott became a member of the Boston Vigilance Committee.
Attendance at Alcott's school was falling when a wealthy Quaker named Reuben Haines III proposed that he and educator William Russell start a new school in Pennsylvania, associated with the Germantown Academy. Alcott accepted and he and his newly pregnant wife set forth on December 14. The school was established in Germantown and the Alcotts were offered a rent-free home by Haines. Alcott and Russell were initially concerned that the area would not be conducive to their progressive approach to education and considered establishing the school in nearby Philadelphia instead. Unsuccessful, they went back to Germantown, though the rent-free home was no longer available and the Alcotts instead had to rent rooms in a boarding-house. It was there that their first child, a daughter they named Anna Bronson Alcott, was born on March 16, 1831, after 36 hours of labor. By the fall of that year, their benefactor Haines died suddenly and the Alcotts again suffered financial difficulty. "We hardly earn the bread", wrote Abby May to her brother, "[and] the butter we have to think about."
The couple's only son was born on April 6, 1839, but lived only a few minutes. The mother recorded: "Gave birth to a fine boy full grown perfectly formed but not living". It was in Germantown that the couple's second daughter was born. Louisa May Alcott was born on her father's birthday, November 29, 1832, at a half-hour past midnight. Bronson described her as "a very fine healthful child, much more so than Anna was at birth". The Germantown school, however, was faltering; soon only eight pupils remained. Their benefactor Haines died before Louisa's birth. He had helped recruit students and even paid tuition for some of them. As Abby wrote, his death "has prostrated all our hopes here". On April 10, 1833, the family moved to Philadelphia, where Alcott ran a day school. As usual, Alcott's methods were controversial; a former student later referred to him as "the most eccentric man who ever took on himself to train and form the youthful mind." Alcott began to believe Boston was the best place for his ideas to flourish. He contacted theologian William Ellery Channing for support. Channing approved of Alcott's methods and promised to help find students to enroll, including his daughter Mary. Channing also secured aid from Justice Lemuel Shaw and Boston mayor Josiah Quincy, Jr.
On September 22, 1834, Alcott opened a school of about 30 students, mostly from wealthy families. It was named the Temple School because classes were held at the Masonic Temple on Tremont Street in Boston. His assistant was Elizabeth Palmer Peabody, later replaced by Margaret Fuller. Mary Peabody Mann served as a French instructor for a time. The school was briefly famous, and then infamous, because of his original methods. Before 1830, writing (except in higher education) equated to rote drills in the rules of grammar, spelling, vocabulary, penmanship and transcription of adult texts. However, in that decade, progressive reformers such as Alcott, influenced by Pestalozzi as well as Friedrich Fröbel and Johann Friedrich Herbart, began to advocate writing about subjects from students' personal experiences. Reformers debated against beginning instruction with rules and were in favor of helping students learn to write by expressing the personal meaning of events within their own lives. Alcott's plan was to develop self-instruction on the basis of self-analysis, with an emphasis on conversation and questioning rather than lecturing and drill, which were prevalent in the U.S. classrooms of the time. Alongside writing and reading, he gave lessons in "spiritual culture", which included interpretation of the Gospels, and advocated "object teaching" in writing instruction. He even went so far as to decorate his schoolroom with visual elements he thought would inspire learning: paintings, books, comfortable furniture, and busts or portraits of Plato, Socrates, Jesus, and William Ellery Channing.
During this time, the Alcotts had another child. Born on June 24, 1835, she was named Elizabeth Peabody Alcott in honor of the teaching assistant at the Temple School. By age three, however, her mother changed her name to Elizabeth "Sewall" Alcott, after her own mother.
In July 1835, Peabody published her account as an assistant to the Temple School as "Record of a School: Exemplifying the General Principles of Spiritual Culture". While working on a second book, Alcott and Peabody had a falling out and "Conversations with Children on the Gospels" was prepared with help from Peabody's sister Sophia, published at the end of December 1836. Alcott's methods were not well received; many found his conversations on the Gospels close to blasphemous. For example, he asked students to question if Biblical miracles were literal and suggested that all people are part of God. In the "Boston Daily Advertiser", Nathan Hale criticized Alcott's "flippant and off hand conversation" about serious topics from the Virgin birth of Jesus to circumcision. Joseph T. Buckingham called Alcott "either insane or half-witted" and "an ignorant and presuming charlatan". The book did not sell well; a Boston lawyer bought 750 copies to use as waste paper.
The temple school was widely denounced in the press. Reverend James Freeman Clarke was one of Alcott's few supporters and defended him against the harsh response from Boston periodicals. Alcott was rejected by most public opinion and, by the summer of 1837, he had only 11 students left and no assistant after Margaret Fuller moved to Providence, Rhode Island. The controversy had caused many parents to remove their children and, as the school closed, Alcott became increasingly financially desperate. Remaining steadfast to his pedagogy, a forerunner of progressive and democratic schooling, he alienated parents in a later "parlor school" by admitting an African American child to the class, whom he then refused to expel in the face of protests.
Beginning in 1836, Alcott's membership in the Transcendental Club put him in such company as Ralph Waldo Emerson, Orestes Brownson and Theodore Parker. He became a member with the club's second meeting and hosted their third. A biographer of Emerson described the group as "the occasional meetings of a changing body of liberal thinkers, agreeing in nothing but their liberality". Frederic Henry Hedge wrote of the group's nature: "There was no club in the strict sense... only occasional meetings of like-minded men and women". Alcott preferred the term "Symposium" for their group.
In late April 1840, Alcott moved to the town of Concord urged by Emerson. He rented a home for $50 a year within walking distance of Emerson's house; he named it Dove Cottage, though they also called it Concordia Cottage. A supporter of Alcott's philosophies, Emerson offered to help with his writing, which proved a difficult task. After several revisions, for example, he deemed the essay "Psyche" (Alcott's account of how he educated his daughters) unpublishable. Alcott also wrote a series patterned after the work of German writer Johann Wolfgang von Goethe which were eventually published in the Transcendentalists' journal, "The Dial". Emerson wrote to Margaret Fuller, then editor, that they might "pass muster & even pass for just & great". He was wrong. Alcott's so-called "Orphic Sayings" were widely mocked for being silly and unintelligible; Fuller herself disliked them, but did not want to hurt Alcott's feelings. In the first issue, for example, he wrote:
On July 26, 1840, Abby May gave birth again. Originally referred to as Baby for several months, she was eventually named Abby May after her mother. As a teenager, she changed the spelling of her name to "Abbie" before choosing to use only "May".
With financial support from Emerson, Alcott left Concord on May 8, 1842, to a visit to England, leaving his brother Junius with his family. He met two admirers, Charles Lane and Henry C. Wright. The two men were leaders of Alcott House, an experimental school based on Alcott's methods from the Temple School located about ten miles outside London. The school's founder, James Pierpont Greaves, had only recently died but Alcott was invited to stay there for a week. Alcott persuaded them to come to the United States with him; Lane and his son moved into the Alcott house and helped with family chores. Persuaded in part by Lane's abolitionist views, Alcott took a stand against the John Tyler administration's plan to annex Texas as a slave territory and refused to pay his poll tax. Abby May wrote in her journal on January 17, 1843, "A day of some excitement, as Mr. Alcott refused to pay his town tax... After waiting some time to be committed [to jail], he was told it was paid by a friend. Thus we were spared the affliction of his absence and the triumph of suffering for his principles." The annual poll tax was only $1.50. The incident inspired Henry David Thoreau, whose similar protest led to a night in jail and his essay "Civil Disobedience". Around this time, the Alcott family set up a sort of domestic post office to curb potential domestic tension. Abby May described her idea: "I thought it would afford a daily opportunity for the children, indeed all of us, to interchange thought and sentiment".
Lane and Alcott collaborated on a major expansion of their educational theories into a Utopian society. Alcott, however, was still in debt and could not purchase the land needed for their planned community. In a letter, Lane wrote, "I do not see anyone to act the money part but myself." In May 1843, he purchased a farm in Harvard, Massachusetts. Up front, he paid $1,500 of the total $1,800 value of the property; the rest was meant to be paid by the Alcotts over a two-year period. They moved to the farm on June 1 and optimistically named it "Fruitlands" despite only ten old apple trees on the property. In July, Alcott announced their plans in "The Dial": "We have made an arrangement with the proprietor of an estate of about a hundred acres, which liberates this tract from human ownership".
Their goal was to regain access to Eden by finding the correct formula for perfect living, following specific rules governing agriculture, diet, and reproduction. In order to achieve this, they removed themselves from the economy as much as possible and lived independently; unlike a similar project named Brook Farm, the participants at Fruitlands avoided interaction with local communities. Calling themselves a "consociate family", they agreed to follow a strict vegetarian diet and to till the land without the use of animal labor. After some difficulty, they relented and allowed some cattle to be "enslaved". They also banned coffee, tea, alcoholic drinks, milk, and warm bathwater. They only ate "aspiring vegetables"—those which grew upward—and refused those that grew downward like potatoes. As Alcott had published earlier, "Our wine is water,—flesh, bread;—drugs, fruits." For clothing, they prohibited leather because animals were killed for it, as well as cotton, silk, and wool, because they were products of slave labor. Alcott had high expectations but was often away when the community most needed him as he attempted to recruit more members.
The experimental community was never successful, partly because most of the land was not arable. Alcott lamented, "None of us were prepared to actualize practically the ideal life of which we dreamed. So we fell apart". Its founders were often away as well; in the middle of harvesting, they left for a lecture tour through Providence, Rhode Island, New York City, and New Haven, Connecticut. In its seven months, only 13 people joined, included the Alcotts and Lanes. Other than Abby May and her daughters, only one other woman joined, Ann Page. One rumor is that Page was asked to leave after eating a fish tail with a neighbor. Lane believed Alcott had misled him into thinking enough people would join the enterprise and developed a strong dislike for the nuclear family. He quit the project and moved to a nearby Shaker family with his son. After Lane's departure, Alcott fell into a depression and could not speak or eat for three days. Abby May thought Lane purposely sabotaged her family. She wrote to her brother, "All Mr. Lane's efforts have been to disunite us. But Mr. Alcott's ... paternal instincts were too strong for him." When the final payment on the farm was owed, Sam May refused to cover his brother-in-law's debts, as he often did, possibly at Abby May's suggestion. The experiment failed, the Alcotts had to leave Fruitlands.
The members of the Alcott family were not happy with their Fruitlands experience. At one point, Abby May threatened that she and their daughters would move elsewhere, leaving Bronson behind. Louisa May Alcott, who was ten years old at the time, later wrote of the experience in "Transcendental Wild Oats" (1873): "The band of brothers began by spading garden and field; but a few days of it lessened their ardor amazingly."
In January 1844, Alcott moved his family to Still River, a village within Harvard but, on March 1, 1845, the family returned to Concord to live in a home they named "The Hillside" (later renamed "The Wayside" by Nathaniel Hawthorne). Both Emerson and Sam May assisted in securing the home for the Alcotts. While living in the home, Louisa began writing in earnest and was given her own room. She later said her years at the home "were the happiest years" of her life; many of the incidents in her novel "Little Women" (1868) are based on this period. Alcott renovated the property, moving a barn and painting the home a rusty olive color, as well as tending to over six acres of land. On May 23, 1845, Abby May was granted a sum from her father's estate which was put into a trust fund, granting minor financial security. That summer, Bronson Alcott let Henry David Thoreau borrow his ax to prepare his home at Walden Pond.
The Alcotts hosted a steady stream of visitors at The Hillside, including fugitive slaves, which they hosted in secret as a station of the Underground Railroad. Alcott's opposition to slavery also fueled his opposition to the Mexican–American War which began in 1846. He considered the war a blatant attempt to extend slavery and asked if the country was made up of "a people bent on conquest, on getting the golden treasures of Mexico into our hands, and of subjugating foreign peoples?"
In 1848, Abby May insisted they leave Concord, which she called "cold, heartless, brainless, soulless". The Alcott family put The Hillside up for rent and moved to Boston. There, next door to Peabody's book store on West Street, Bronson Alcott hosted a series based on the "Conversations" model by Margaret Fuller called "A Course on the Conversations on Man—his History, Resources, and Expectations". Participants, both men and women, were charged three dollars to attend or five dollars for all seven lectures. In March 1853, Alcott was invited to teach fifteen students at Harvard Divinity School in an extracurricular, non-credit course.
Alcott and his family moved back to Concord after 1857, where he and his family lived in the Orchard House until 1877. In 1860, Alcott was named superintendent of Concord Schools.
Alcott voted in a presidential election for the first time in 1860. In his journal for November 6, 1860, he wrote: "At Town House, and cast my vote for Lincoln and the Republican candidates generally—the first vote I ever cast for a President and State officers." Alcott was an abolitionist and a friend of the more radical William Lloyd Garrison. He had attended a rally led by Wendell Phillips on behalf of 17-year-old Thomas Sims, a fugitive slave on trial in Boston. Alcott was one of several who attempted to storm the courthouse; when gunshots were heard, he was the only one who stood his ground, though the effort was unsuccessful. He had also stood his ground in a protest against the trial of Anthony Burns. A group had broken down the door of the Boston courthouse but guards beat them back. Alcott stood forward and asked the leader of the group, Thomas Wentworth Higginson, "Why are we not within?" He then walked calmly into the courthouse, was threatened with a gun, and turned back, "but without hastening a step", according to Higginson.
In 1862, Louisa moved to Washington, D.C. to volunteer as a nurse. On January 14, 1863, the Alcotts received a telegram that Louisa was sick; Bronson immediately went to bring her home, briefly meeting Abraham Lincoln while there. Louisa turned her experience into the book "Hospital Sketches". Her father wrote of it, "I see nothing in the way of a good appreciation of Louisa's merits as a woman and a writer."
Henry David Thoreau died on May 6, 1862, likely from an illness he caught from Alcott two years earlier. 
At Emerson's request, Alcott helped arrange Thoreau's funeral, which was held at First Parish Sanctuary in Concord, despite Thoreau having disavowed membership in the church when he was in his early twenties. Emerson wrote a eulogy, and Alcott helped plan the preparations. Only two years later, neighbor Nathaniel Hawthorne died as well. Alcott served as a pallbearer along with Louis Agassiz, James Thomas Fields, Oliver Wendell Holmes, Sr., Henry Wadsworth Longfellow, and others. With Hawthorne's death, Alcott worried that few of the Concord notables remained. He recorded in his journal: "Fair figures one by one are fading from sight." The next year, Lincoln was assassinated, which Alcott called "appalling news".
In 1868, Alcott met with publisher Thomas Niles, an admirer of "Hospital Sketches". Alcott asked Niles if he would publish a book of short stories by his daughter; instead, he suggested she write a book about girls. Louisa May was not interested initially but agreed to try. "They want a book of 200 pages or more", Alcott told his daughter. The result was "Little Women", published later that year. The book, which fictionalized the Alcott family during the girls' coming-of-age years, recast the father figure as a chaplain, away from home at the front in the Civil War.
Alcott spoke, as opportunity arose, before the "lyceums" then common in various parts of the United States, or addressed groups of hearers as they invited him. These "conversations" as he called them, were more or less informal talks on a great range of topics, spiritual, aesthetic and practical, in which he emphasized the ideas of the school of American Transcendentalists led by Emerson, who was always his supporter and discreet admirer. He often discussed Platonic philosophy, the illumination of the mind and soul by direct communion with Spirit; upon the spiritual and poetic monitions of external nature; and upon the benefit to man of a serene mood and a simple way of life.
Alcott's published books, all from late in his life, include "Tablets" (1868), "Concord Days" (1872), "New Connecticut" (1881), and "Sonnets and Canzonets" (1882). Louisa May attended to her father's needs in his final years. She purchased a house for her sister Anna which had been the last home of Henry David Thoreau, now known as the Thoreau-Alcott House. Louisa and her parents moved in with Anna as well.
After the death of his wife Abby May on November 25, 1877, Alcott never returned to Orchard House, too heartbroken to live there. He and Louisa May collaborated on a memoir and went over her papers, letters, and journals. "My heart bleeds with the memories of those days", he wrote, "and even long years, of cheerless anxiety and hopeless dependence." Louisa noted her father had become "restless with his anchor gone". They gave up on the memoir project and Louisa burned many of her mother's papers.
On January 19, 1879, Alcott and Franklin Benjamin Sanborn wrote a prospectus for a new school which they distributed to potentially interested people throughout the country. The result was the Concord School of Philosophy and Literature, which held its first session in 1879 in Alcott's study in the Orchard House. In 1880 the school moved to the Hillside Chapel, a building next to the house, where he held conversations and, over the course of successive summers, as he entered his eighties, invited others to give lectures on themes in philosophy, religion and letters. The school, considered one of the first formal adult education centers in America, was also attended by foreign scholars. It continued for nine years.
In April 1882, Alcott's friend and benefactor Ralph Waldo Emerson was sick and bedridden. After visiting him, Alcott wrote, "Concord will be shorn of its human splendor when he withdraws behind the cloud." Emerson died the next day. Alcott himself moved out of Concord for his final years, settling at 10 Louisburg Square in Boston beginning in 1885.
As he was bedridden at the end of his life, Alcott's daughter Louisa May came to visit him at Louisburg on March 1, 1888. He said to her, "I am going "up. Come with me"." She responded, "I wish I could." He died three days later on March 4; Louisa May died only two days after her father.
Alcott was fundamentally and philosophically opposed to corporal punishment as a means of disciplining his students. Instead, beginning at the Temple School, he would appoint a daily student superintendent. When that student observed an infraction, he or she reported it to the rest of the class and, as a whole, they deliberated on punishment. At times, Alcott offered his own hand for an offending student to strike, saying that any failing was the teacher's responsibility. The shame and guilt this method induced, he believed, was far superior to the fear instilled by corporal punishment; when he used physical "correction" he required that the students be unanimously in support of its application, even including the student to be punished.
The most detailed discussion of his theories on education is in an essay, "Observations on the Principles and Methods of Infant Instruction". Alcott believed that early education must draw out "unpremeditated thoughts and feelings of the child" and emphasized that infancy should primarily focus on enjoyment. He noted that learning was not about the acquisition of facts but the development of a reflective state of mind.
Alcott's ideas as an educator were controversial. Writer Harriet Martineau, for example, wrote dubiously that, "the master presupposes his little pupils possessed of all truth; and that his business is to bring it out into expression". Even so, his ideas helped to found one of the first adult education centers in America, and provided the foundation for future generations of liberal education. Many of Alcott's educational principles are still used in classrooms today, including "teach by encouragement", art education, music education, acting exercises, learning through experience, risk-taking in the classroom, tolerance in schools, physical education/recess, and early childhood education. The teachings of William Ellery Channing a few years earlier had also laid the groundwork for the work of most of the Concord Transcendentalists.
The Concord School of Philosophy, which closed following Alcott's death in 1888, was reopened almost 90 years later in the 1970s. It has continued functioning with a Summer Conversational Series in its original building at Orchard House, now run by the Louisa May Alcott Memorial Association.
While many of Alcott's ideas continue to be perceived as being on the liberal/radical edge, they are still common themes in society, including vegetarian/veganism, sustainable living, and temperance/self-control. Alcott described his sustenance as a "Pythagorean diet": meat, eggs, butter, cheese, and milk were excluded and drinking was confined to well water. Alcott believed that diet held the key to human perfection and connected physical well-being to mental improvement. He further viewed a perfection of nature to the spirit and, in a sense, predicted modern environmentalism by condemning pollution and encouraging humankind's role in sustaining ecology.
Alcott's philosophical teachings have been criticized as inconsistent, hazy or abrupt. He formulated no system of philosophy, and shows the influence of Plato, German mysticism, and Immanuel Kant as filtered through the writings of Samuel Taylor Coleridge. Margaret Fuller referred to Alcott as "a philosopher of the balmy times of ancient Greece—a man whom the worldlings of Boston hold in as much horror as the worldlings of Athens held Socrates." In his later years, Alcott related a story from his boyhood: during a total solar eclipse, he threw rocks at the sky until he fell and dislocated his shoulder. He reflected that the event was a prophecy that he would be "tilting at the sun and always catching the fall".
Like Emerson, Alcott was always optimistic, idealistic, and individualistic in thinking. Writer James Russell Lowell referred to Alcott in his poem "Studies for Two Heads" as "an angel with clipped wings". Even so, Emerson noted that Alcott's brilliant conversational ability did not translate into good writing. "When he sits down to write," Emerson wrote, "all his genius leaves him; he gives you the shells and throws away the kernel of his thought." His "Orphic Sayings", published in "The Dial", became famous for their hilarity as dense, pretentious, and meaningless. In New York, for example, "The Knickerbocker" published a parody titled "Gastric Sayings" in November 1840. A writer for the "Boston Post" referred to Alcott's "Orphic Sayings" as "a train of fifteen railroad cars with one passenger".
Modern critics often fault Alcott for not being able to financially support his family. Alcott himself worried about his own prospects as a young man, once writing to his mother that he was "still at my old trade—hoping." Alcott held his principles above his well-being. Shortly before his marriage, for example, his future father-in-law Colonel Joseph May helped him find a job teaching at a school in Boston run by the Society of Free Enquirers, followers of Robert Owen, for a lucrative $1,000 to $1,200 annual salary. He refused it because he did not agree with their beliefs, writing, "I shall have nothing to do with them."
From the other perspective, Alcott's unique teaching ideas created an environment which produced two famous daughters in different fields in a time when women were not commonly encouraged to have independent careers.

</doc>
<doc id="1386" url="https://en.wikipedia.org/wiki?curid=1386" title="Arachnophobia">
Arachnophobia

Arachnophobia is an intense and irrational fear of spiders and other arachnids such as scorpions.
Treatment is typically by exposure therapy, where the person is presented with pictures of spiders or the spiders themselves.
People with arachnophobia tend to feel uneasy in any area they believe could harbour spiders or that has visible signs of their presence, such as webs. If arachnophobes see a spider, they may not enter the general vicinity until they have overcome the panic attack that is often associated with their phobia. Some people run away, scream, cry, have emotional outbursts, experience trouble breathing, sweat, have increased heart rates, or even faint when they come in contact with an area near spiders or their webs. In some extreme cases, even a picture or a realistic drawing of a spider can trigger intense fear.
Arachnophobia may be an exaggerated form of an instinctive response that helped early humans to survive or a cultural phenomenon that is most common in predominantly European societies.
An evolutionary reason for the phobia remains unresolved. One view, especially held in evolutionary psychology, is that the presence of venomous spiders led to the evolution of a fear of spiders, or made acquisition of a fear of spiders especially easy. Like all traits, there is variability in the intensity of fear of spiders, and those with more intense fears are classified as phobic. Being relatively small, spiders do not fit the usual criterion for a threat in the animal kingdom where size is a factor, but they can have medically significant venom. However, a phobia is an irrational fear as opposed to a rational fear.
By ensuring that their surroundings were free from spiders, arachnophobes would have had a reduced risk of being bitten in ancestral environments, giving them a slight advantage over non-arachnophobes in terms of survival. However, having a disproportionate fear of spiders in comparison to other, potentially dangerous creatures present during "Homo sapiens"' environment of evolutionary adaptiveness may have had drawbacks.
In "The Handbook of the Emotions" (1993), psychologist Arne Öhman studied pairing an unconditioned stimulus with evolutionarily-relevant fear-response neutral stimuli (snakes and spiders) versus evolutionarily-irrelevant fear-response neutral stimuli (mushrooms, flowers, and physical representation of polyhedra) on human subjects and found that ophidiophobia and arachnophobia required only one pairing to develop a conditioned response while mycophobia, anthophobia, and phobias of physical representations of polyhedra required multiple pairings and went extinct without continued conditioning while the conditioned ophidiophobia and arachnophobia were permanent. Psychiatrists Isaac Marks and Randolph M. Nesse and evolutionary biologist George C. Williams have noted that people with systematically deficient responses to various adaptive phobias (e.g. arachnophobia, ophidiophobia, basophobia) are more temperamentally careless and more likely to end up in potentially fatal accidents and have proposed that such deficient phobia should be classified as "hypophobia" due to its selfish genetic consequences.
A 2001 study found that people could detect images of spiders among images of flowers and mushrooms more quickly than they could detect images of flowers or mushrooms among images of spiders. The researchers suggested that this was because fast response to spiders was more relevant to human evolution.
An alternative view is that the dangers, such as from spiders, are overrated and not sufficient to influence evolution. Instead, inheriting phobias would have restrictive and debilitating effects upon survival, rather than being an aid. For some communities such as in Papua New Guinea and Cambodia spiders are included in traditional foods. This suggests arachnophobia may be a cultural, rather than genetic trait.
The fear of spiders can be treated by any of the general techniques suggested for specific phobias. The first line of treatment is systematic desensitization – also known as exposure therapy. Before engaging in systematic desensitization, it is common to train the individual with arachnophobia in relaxation techniques, which will help keep the patient calm. Systematic desensitization can be done in vivo (with live spiders) or by getting the individual to imagine situations involving spiders, then modelling interaction with spiders for the person affected and eventually interacting with real spiders. This technique can be effective in just one session, although it generally takes more time.
Recent advances in technology have enabled the use of virtual or augmented reality spiders for use in therapy. These techniques have proven to be effective. It has been suggested that exposure to short clips from the "Spider-Man" movies may help to reduce an individual's arachnophobia.
Arachnophobia affects 3.5 to 6.1 percent of the global population.

</doc>
<doc id="1387" url="https://en.wikipedia.org/wiki?curid=1387" title="Alabaster">
Alabaster

Alabaster is a mineral or rock that is soft, often used for carving, and is processed for plaster powder. Archaeologists and the stone processing industry use the word differently from geologists. The former use it in a wider sense that includes varieties of two different minerals: the fine-grained massive type of gypsum and the fine-grained banded type of calcite. Geologists define alabaster only as the gypsum type. Chemically, gypsum is a hydrous sulfate of calcium, while calcite is a carbonate of calcium.
Both types of alabaster have similar properties. They are usually lightly colored, translucent, and soft stones. They have been used throughout history primarily for carving decorative artifacts.
The calcite type is also denominated "onyx-marble", "Egyptian alabaster", and "Oriental alabaster" and is geologically described as either a compact banded travertine or "a stalagmitic limestone marked with patterns of swirling bands of cream and brown". "Onyx-marble" is a traditional, but geologically inaccurate, name because both onyx and marble have geological definitions that are distinct from even the broadest definition of "alabaster".
In general, ancient alabaster is calcite in the wider Middle East, including Egypt and Mesopotamia, while it is gypsum in medieval Europe. Modern alabaster is probably calcite but may be either. Both are easy to work and slightly soluble in water. They have been used for making a variety of indoor artwork and carving, and they will not survive long outdoors.
The two kinds are readily distinguished by their different hardnesses: gypsum alabaster is so soft that a fingernail scratches it (Mohs hardness 1.5 to 2), while calcite cannot be scratched in this way (Mohs hardness 3), although it yields to a knife. Moreover, calcite alabaster, being a carbonate, effervesces when treated with hydrochloric acid, while gypsum alabaster remains almost unaffected.
The origin of "alabaster" is in Middle English through Old French ""alabastre", in turn derived from Latin "alabaster", and that from Greek "ἀλάβαστρος" ("alabastros") or "ἀλάβαστος" ("alabastos"). The Greek words denoted a vase of alabaster.
The name may be derived further from ancient Egyptian "a-labaste"", which refers to vessels of the Egyptian goddess Bast. She was represented as a lioness and frequently depicted as such in figures placed atop these alabaster vessels. Ancient Roman authors, Pliny the Elder and Ptolemy, wrote that the stone used for ointment jars called "alabastra" came from a region of Egypt known as Alabastron or Alabastrites.
The purest alabaster is a snow-white material of fine uniform grain, but it often is associated with an oxide of iron, which produces brown clouding and veining in the stone. The coarser varieties of gypsum alabaster are converted by calcination into plaster of Paris, and are sometimes known as "plaster stone".
The softness of alabaster enables it to be carved readily into elaborate forms, but its solubility in water renders it unsuitable for outdoor work. If alabaster with a smooth, polished surface is washed with dishwashing liquid, it will become rough, dull and whiter, losing most of its translucency and lustre. The finer kinds of alabaster are employed largely as an ornamental stone, especially for ecclesiastical decoration and for the rails of staircases and halls.
Alabaster is mined and then sold in blocks to alabaster workshops. There they are cut to the needed size ("squaring"), and then are processed in different techniques: turned on a lathe for round shapes, carved into three-dimensional sculptures, chiselled to produce low relief figures or decoration; and then given an elaborate finish that reveals its transparency, colour, and texture.
In order to diminish the translucency of the alabaster and to produce an opacity suggestive of true marble, the statues are immersed in a bath of water and heated gradually—nearly to the boiling point—an operation requiring great care, because if the temperature is not regulated carefully, the stone acquires a dead-white, chalky appearance. The effect of heating appears to be a partial dehydration of the gypsum. If properly treated, it very closely resembles true marble and is known as "marmo di Castellina".
Alabaster is a porous stone and can be "dyed" into any colour or shade, a technique used for centuries. For this the stone needs to be fully immersed in various pigmentary solutions and heated to a specific temperature. The technique can be used to disguise alabaster. In this way a very misleading imitation of coral that is called "alabaster coral" is produced.
Typically only one type is sculpted in any particular cultural environment, but sometimes both have been worked to make similar pieces in the same place and time. This was the case with small flasks of the alabastron type made in Cyprus from the Bronze Age into the Classical period.
When cut in thin sheets, alabaster is translucent enough to be used for small windows. It was used for this purpose in Byzantine churches and later in medieval ones, especially in Italy. Large sheets of Aragonese gypsum alabaster are used extensively in the contemporary Cathedral of Our Lady of the Angels, which was dedicated in 2002 by the Los Angeles, California Archdiocese. The cathedral incorporates special cooling to prevent the panes from overheating and turning opaque. The ancients used the calcite type, while the modern Los Angeles cathedral is using gypsum alabaster. There are also multiple examples of alabaster windows in ordinary village churches and monasteries in northern Spain.
Calcite alabaster, harder than the gypsum variety, was the kind primarily used in ancient Egypt and the wider Middle East (but not Assyrian palace reliefs), and is also used in modern times. It is found as either a stalagmitic deposit from the floor and walls of limestone caverns, or as a kind of travertine, similarly deposited in springs of calcareous water. Its deposition in successive layers gives rise to the banded appearance that the marble often shows on cross-section, from which its name is derived: onyx-marble or alabaster-onyx, or sometimes simply (and wrongly) as onyx.
Egyptian alabaster has been worked extensively near Suez and Assiut.
This stone variety is the "alabaster" of the ancient Egyptians and Bible and is often termed "Oriental alabaster", since the early examples came from the Far East. The Greek name "alabastrites" is said to be derived from the town of Alabastron in Egypt, where the stone was quarried. The locality probably owed its name to the mineral; the origin of the mineral name is obscure (though see above).
The "Oriental" alabaster was highly esteemed for making small perfume bottles or ointment vases called alabastra; the vessel name has been suggested as a possible source of the mineral name. In Egypt, craftsmen used alabaster for canopic jars and various other sacred and sepulchral objects. A sarcophagus discovered in the tomb of Seti I near Thebes is on display in Sir John Soane's Museum, London; it is carved in a single block of translucent calcite alabaster from Alabastron.
Algerian onyx-marble has been quarried largely in the province of Oran.
In Mexico, there are famous deposits of a delicate green variety at La Pedrara, in the district of Tecali, near Puebla. Onyx-marble occurs also in the district of Tehuacán and at several localities in the US including California, Arizona, Utah, Colorado and Virginia.
Gypsum alabaster is the softer of the two varieties, the other being calcite alabaster. It was used primarily in medieval Europe, and is also used in modern times.
"Mosul marble" is a kind of gypsum alabaster found in the north of modern Iraq, which was used for the Assyrian palace reliefs of the 9th to 7th centuries BC; these are the largest type of alabaster sculptures to have been regularly made. The relief is very low and the carving detailed, but large rooms were lined with continuous compositions on slabs around high. The "Lion Hunt of Ashurbanipal" and military Lachish reliefs, both 7th century and in the British Museum, are some of the best known.
Gypsum alabaster was widely used for small sculpture for indoor use in the ancient world, especially in ancient Egypt and Mesopotamia. Fine detail could be obtained in a material with an attractive finish without iron or steel tools. Alabaster was used for vessels dedicated for use in the cult of the deity Bast in the culture of the ancient Egyptians, and thousands of gypsum alabaster artifacts dating to the late 4th millennium BC also have been found in Tell Brak (present day Nagar), in Syria.
In Mesopotamia, gypsum alabaster was the material of choice for figures of deities and devotees in temples, as in a figure believed to represent the deity Abu dating to the first half of the 3rd millennium BC and currently kept in New York.
Much of the world's alabaster extraction is performed in the centre of the Ebro Valley in Aragon, Spain, which has the world's largest known exploitable deposits.
According to a brochure published by the Aragon government, alabaster has elsewhere either been depleted, or its extraction is so difficult that it has almost been abandoned or is carried out at a very high cost.
There are two separate sites in Aragon, both are located in Tertiary basins.
The most important site is the Fuentes-Azaila area, in the Tertiary Ebro Basin.
The other is the Calatayud-Teruel Basin, which divides the Iberian Range in two main sectors (NW and SE).
The abundance of Aragonese alabaster was crucial for its use in architecture, sculpture and decoration.
There is no record of likely use by pre-Roman cultures, so perhaps the first ones to use alabaster in Aragon were the Romans, who produced vessels from alabaster following the Greek and Egyptian models.
It seems that since the reconstruction of the Roman Wall in Zaragoza in the 3rd century AD with alabaster, the use of this material became common in building for centuries.
Muslim Saraqusta (today, Zaragoza) was also called "Medina Albaida", the White City, due to the appearance of its alabaster walls and palaces, which stood out among gardens, groves and orchards by the Ebro and Huerva Rivers.
The oldest remains in the Aljafería Palace, together with other interesting elements like capitals, reliefs and inscriptions, were made using alabaster, but it was during the artistic and economic blossoming of the Renaissance that Aragonese alabaster reached its golden age.
In the 16th century sculptors in Aragon chose alabaster for their best works. They were adept at exploiting its lighting qualities and generally speaking the finished art pieces retained their natural color.
In Europe, the centre of the alabaster trade today is Florence, Italy. Tuscan alabaster occurs in nodular masses embedded in limestone, interstratified with marls of Miocene and Pliocene age. The mineral is worked largely by means of underground galleries, in the district of Volterra. Several varieties are recognized—veined, spotted, clouded, agatiform, and others. The finest kind, obtained principally from Castellina, is sent to Florence for figure-sculpture, while the common kinds are carved locally, into vases, lights, and various ornamental objects. These items are objects of extensive trade, especially in Florence, Pisa, and Livorno.
In the 3rd century BC the Etruscans used the alabaster of Tuscany from the area of modern-day Volterra to produce funeral urns, possibly taught by Greek artists. During the Middle Ages the craft of alabaster was almost completely forgotten. A revival started in the mid-16th century, and until the beginning of the 17th century alabaster work was strictly artistic and did not expand to form a large industry.
In the 17th and 18th centuries production of artistic, high-quality Renaissance-style artifacts stopped altogether, being replaced by less sophisticated, cheaper items better suited for large-scale production and commerce. The new industry prospered, but the reduced need of skilled craftsmen left only few still working. The 19th century brought a boom to the industry, largely due to the "traveling artisans" who went and offered their wares to the palaces of Europe, as well as to America and the East.
In the 19th century new processing technology was also introduced, allowing for the production of custom-made, unique pieces, as well as the combination of alabaster with other materials. Apart from the newly developed craft, artistic work became again possible, chiefly by Volterran sculptor Albino Funaioli. After a short slump, the industry was revived again by the sale of mass-produced mannerist Expressionist sculptures, and was further enhanced in the 1920s by a new branch creating ceiling and wall lamps in the Art Deco style and culminating in the participation at the 1925 International Exposition of Modern Industrial and Decorative Arts from Paris. Important names from the evolution of alabaster use after World War II are Volterran Umberto Borgna, the "first alabaster designer", and later on the architect and industrial designer Angelo Mangiarotti.
Gypsum alabaster is a common mineral, which occurs in England in the Keuper marls of the Midlands, especially at Chellaston in Derbyshire, at Fauld in Staffordshire, and near Newark in Nottinghamshire. Deposits at all of these localities have been worked extensively.
In the 14th and 15th centuries its carving into small statues and sets of relief panels for altarpieces was a valuable local industry in Nottingham, as well as a major English export. These were usually painted, or partly painted. It was also used for the effigies, often life size, on tomb monuments, as the typical recumbent position suited the material's lack of strength, and it was cheaper and easier to work than good marble. After the English Reformation the making of altarpiece sets was discontinued, but funerary monument work in reliefs and statues continued.
Besides examples of these carvings still in Britain (especially at the Nottingham Castle Museum, British Museum, and Victoria and Albert Museum), trade in mineral alabaster (rather than just the antiques trade) has scattered examples in the material that may be found as far afield as the Musée de Cluny, Spain, and Scandinavia.
Alabaster also is found, although in smaller quantity, at Watchet in Somerset, near Penarth in Glamorganshire, and elsewhere. In Cumbria it occurs largely in the New Red rocks, but at a lower geological horizon. The alabaster of Nottinghamshire and Derbyshire is found in thick nodular beds or "floors" in spheroidal masses known as "balls" or "bowls" and in smaller lenticular masses termed "cakes". At Chellaston, where the local alabaster is known as "Patrick", it has been worked into ornaments under the name of "Derbyshire spar"―a term more properly applied to fluorspar.
"Black alabaster" is a rare anhydrite form of the gypsum-based mineral. This black form is found in only three veins in the world, one each in United States, Italy, and China.
Alabaster Caverns State Park, near Freedom, Oklahoma is home to a natural gypsum cave in which much of the gypsum is in the form of alabaster. There are several types of alabaster found at the site, including pink, white, and the rare black alabaster.
Chronological list of examples:

</doc>
<doc id="1389" url="https://en.wikipedia.org/wiki?curid=1389" title="Ahab">
Ahab

Ahab (; ; "Achaáb"; ) was the seventh king of Israel, the son and successor of King Omri and the husband of Jezebel of Sidon, according to the Hebrew Bible. The Hebrew Bible presents Ahab as a wicked king, particularly for condoning Jezebel's influence on religious policies and his principal role behind Naboth's arbitrary execution.
The existence of Ahab is historically supported outside the Bible. Shalmaneser III of Assyria documented in 853 BC that he defeated an alliance of a dozen kings in the Battle of Qarqar; one of these was Ahab. He is also mentioned on the inscriptions of the Mesha Stele.
Ahab became king of Israel in the thirty-eighth year of King Asa of Judah, and reigned for twenty-two years, according to 1 Kings. William F. Albright dated his reign to 869–850 BC, while Edwin R. Thiele offered the dates 874–853 BC. Most recently, Michael Coogan has dated Ahab's reign to 871–852 BCE.
King Omri, Ahab's father and founder of the short-lived Omri dynasty, seems to have been a successful military leader; he is reported in the text of the Moabite Mesha Stele to have "oppressed Moab for many days." During Ahab's reign, Moab, which had been conquered by his father, remained tributary. Ahab was allied by marriage with Jehoshaphat, who was king of Judah. Only with Aram-Damascus is he believed to have had strained relations.
Ahab married Jezebel, the daughter of the King of Tyre. tells the story of Ahab and Jezebel, and indicates that Jezebel was a dominant influence on Ahab, persuading him to abandon Yahweh and establish the religion of Baal in Israel. Ahab lived in Samaria, the royal capital established by Omri, and built a temple and altar to Baal there. These actions were said to have led to severe consequences for Israel, including a drought that lasted for several years and Jezebel's fanatical religious persecution of the prophets of Yahweh, which Ahab condoned. His reputation was so negative that in 1 Kings 16:34, the author attributed to his reign the deaths of Abiram and Segub, the sons of Hiel of Bethel, caused by their father's invocation of Joshua's curse several centuries ago. Ahab was succeeded by Ahaziah and Jehoram, who reigned over Israel until Jehu's revolt of 842 BCE.
The Battle of Qarqar is mentioned in extra-biblical records, and was perhaps at Apamea, where Shalmaneser III of Assyria fought a great confederation of princes from Cilicia, Northern Syria, Israel, Ammon, and the tribes of the Syrian desert (853 BC), including Ahab the Israelite ("A-ha-ab-bu Sir-'a-la-a-a") and Hadadezer ("Adad-'idri").
Ahab's contribution was estimated at 2000 chariots and 10,000 men. In reality, however, the number of chariots in Ahab's forces was probably closer to a number in the hundreds (based upon archaeological excavations of the area and the foundations of stables that have been found). If, however, the numbers are referring to allies it could possibly include forces from Tyre, Judah, Edom, and Moab. The Assyrian king claimed a victory, but his immediate return and subsequent expeditions in 849 BC and 846 BC against a similar but unspecified coalition seem to show that he met with no lasting success. However, according to the Hebrew Bible, Ahab with 7000 troops had previously overthrown Ben-hadad and his thirty-two kings, who had come to lay siege to Samaria, and in the following year obtained a decisive victory over him at Aphek, probably in the Sharon plain at Antipatris (1 Kings 20). A treaty was made whereby Ben-hadad restored the cities which his father had taken from Ahab's father, and trading facilities between Damascus and Samaria were granted.
Jezreel has been identified as Ahab's fortified chariot and cavalry base.
In the Biblical text, Ahab has five important encounters with prophets:
Three years later, war broke out east of the Jordan River, and Ahab with Jehoshaphat of Judah went to recover Ramoth-Gilead from the Arameans. During this battle, Ahab disguised himself, but he was mortally wounded by an unaimed arrow (1 Kings 22). The Hebrew Bible says that dogs licked his blood, according to the prophecy of Elijah. But the Septuagint adds that pigs also licked his blood, symbolically making him unclean to the Israelites, who abstained from pork. Ahab was succeeded by his sons, Ahaziah and Jehoram.
Jezebel's death, however, was more dramatic than Ahab's. As recorded in 2 Kings 9:30-34, Jezebel was confronted by Jehu who had her servants throw her out the window, causing her death.
1 Kings 16:29 through 22:40 contains the narrative of Ahab's reign. His reign was slightly more emphasised upon than the previous kings, due to his blatant trivialization of the "sins of Jeroboam", which the previous kings of Israel were plagued by, and his subsequent marriage with a pagan princess, the nationwide institution of Baal worship, the persecution of Yahweh's prophets and Naboth's shocking murder. These offenses and atrocities elicited prophetic denunciation from figures such as Elijah and Micaiah. Indeed, he is referred to by the author of Kings as being "more evil than all the kings before him".
Nonetheless, there were achievements that the author took note of, including his ability to fortify numerous Israelite cities and build an ivory palace (1 Kings 22:39). Adherents of the Yahwist religion found their principal champion in Elijah. His denunciation of the royal dynasty of Israel and his emphatic insistence on the worship of Yahweh and Yahweh alone, illustrated by the contest between Yahweh and Baal on Mount Carmel (1 Kings 18), form the keynote to a period which culminated in the accession of Jehu, an event in which Elijah's chosen disciple Elisha was the leading figure and the Omride Dynasty was brutally defeated.
One of the three or four wicked kings of Israel singled out by tradition as being excluded from the future world of bliss (Sanh. x. 2; Tosef., Sanh. xii. 11). Midrash Konen places him in the fifth department of Gehenna, as having the heathen under his charge. Though held up as a warning to sinners, Ahab is also described as displaying noble traits of character (Sanh. 102b; Yer. Sanh. xi. 29b). Talmudic literature represents him as an enthusiastic idolater who left no hilltop in Palestine without an idol before which he bowed, and to which he or his wife, Jezebel, brought his weight in gold as a daily offering. So defiant in his apostasy was he that he had inscribed on all the doors of the city of Samaria the words, "Ahab hath abjured the living God of Israel." Nevertheless, he paid great respect to the representatives of learning, "to the Torah given in twenty-two letters," for which reason he was permitted to reign for twenty-two successive years. He generously supported the students of the Law out of his royal treasury, in consequence of which half his sins were forgiven him. A type of worldliness (Ber. 61b), the Crœsus of his time, he was, according to ancient tradition (Meg. 11a), ruler over the whole world. Two hundred and thirty subject kings had initiated a rebellion; but he brought their sons as hostages to Samaria and Jerusalem. All the latter turned from idolaters into worshipers of the God of Israel (Tanna debe Eliyahu, i. 9). Each of his seventy sons had an ivory palace built for him. Since, however, it was Ahab's idolatrous wife who was the chief instigator of his crimes (B. M. 59a), some of the ancient teachers gave him the same position in the world to come as a sinner who had repented (Sanh. 104b, Num. R. xiv). Like Manasseh, he was made a type of repentance (I Kings, xxi. 29). Accordingly, he is described as undergoing fasts and penances for a long time; praying thrice a day to God for forgiveness, until his prayer was heard (PirḲe R. El. xliii). Hence, the name of Ahab in the list of wicked kings was changed to Ahaz (Yer. Sanh. x. 28b; Tanna debe Eliyahu Rabba ix, Zuṭṭa xxiv.).
Pseudo-Epiphanius ("Opera," ii. 245) makes Micah an Ephraimite. Confounding him with Micaiah, son of Imlah (I Kings xxii. 8 et seq.), he states that Micah, for his inauspicious prophecy, was killed by order of Ahab through being thrown from a precipice, and was buried at Morathi (Maroth?; Mic. i. 12), near the cemetery of Enakim (Ένακεὶμ Septuagint rendering of ; ib. i. 10). According to "Gelilot Ereẓ Yisrael" (quoted in "Seder ha-Dorot," i. 118, Warsaw, 1889), Micah was buried in Chesil, a town in southern Judah (Josh. xv. 30). Naboth's soul was the lying spirit that was permitted to deceive Ahab to his death.

</doc>
<doc id="1391" url="https://en.wikipedia.org/wiki?curid=1391" title="ASIC (disambiguation)">
ASIC (disambiguation)

In the realm of electronic technology, ASIC stands for "application-specific integrated circuit".
An ASIC is an integrated circuit developed for a particular use; as opposed to a general-purpose integrated circuit.
ASIC may also refer to:

</doc>
<doc id="1392" url="https://en.wikipedia.org/wiki?curid=1392" title="Dasyproctidae">
Dasyproctidae

Dasyproctidae is a family of large South American rodents, comprising the agoutis and acouchis. Their fur is a reddish or dark colour above, with a paler underside. They are herbivorous, often feeding on ripe fruit that falls from trees. They live in burrows, and, like squirrels, will bury some of their food for later use.
Dasyproctids exist in Central and South America, which are the tropical parts of the New World. The fossil record of this family can be traced back to the Late Oligocene (Deseadan in the SALMA classification).
As with all rodents, members of this family have incisors, pre-molars, and molars, but no canines. The cheek teeth are hypsodont and flat-crowned.
Fossil taxa follow McKenna and Bell, with modifications following Kramarz.
The pacas (genus "Cuniculus") are placed by some authorities in Dasyproctidae, but molecular studies have demonstrated they do not form a monophyletic group.

</doc>
<doc id="1394" url="https://en.wikipedia.org/wiki?curid=1394" title="Algol">
Algol

Algol , designated Beta Persei (β Persei, abbreviated Beta Per, β Per), known colloquially as the Demon Star, is a bright multiple star in the constellation of Perseus and one of the first non-nova variable stars to be discovered.
Algol is a three-star system, consisting of Beta Persei Aa1, Aa2, and Ab – in which the hot luminous primary β Persei Aa1 and the larger, but cooler and fainter, β Persei Aa2 regularly pass in front of each other, causing eclipses. Thus Algol's magnitude is usually near-constant at 2.1, but regularly dips to 3.4 every 2.86 days during the roughly 10-hour-long partial eclipses. The secondary eclipse when the brighter primary star occults the fainter secondary is very shallow and can only be detected photoelectrically.
Algol gives its name to its class of eclipsing variable, known as Algol variables.
An Ancient Egyptian Calendar of Lucky and Unlucky Days composed some 3,200 years ago is claimed to be the oldest historical documentation of the discovery of Algol.
The association of Algol with a demon-like creature (Gorgon in the Greek tradition, ghoul in the Arabic tradition) suggests that its variability was known long before the 17th century, but there is still no indisputable evidence for this. The Arabic astronomer al-Sufi said nothing about any variability of the star in his "Book of Fixed Stars" published c.964.
The variability of Algol was noted in 1667 by Italian astronomer Geminiano Montanari, but the periodic nature of its variations in brightness was not recognized until more than a century later, when the British amateur astronomer John Goodricke also proposed a mechanism for the star's variability. In May 1783, he presented his findings to the Royal Society, suggesting that the periodic variability was caused by a dark body passing in front of the star (or else that the star itself has a darker region that is periodically turned toward the Earth). For his report he was awarded the Copley Medal.
In 1881, the Harvard astronomer Edward Charles Pickering presented evidence that Algol was actually an eclipsing binary. This was confirmed a few years later, in 1889, when the Potsdam astronomer Hermann Carl Vogel found periodic doppler shifts in the spectrum of Algol, inferring variations in the radial velocity of this binary system. Thus Algol became one of the first known spectroscopic binaries. Joel Stebbins at the University of Illinois Observatory used an early selenium cell photometer to produce the first-ever photoelectric study of a variable star. The light curve revealed the second minimum and the reflection effect between the two stars.
Some difficulties in explaining the observed spectroscopic features led to the conjecture that a third star may be present in the system; four decades later this conjecture was found to be correct.
Listed are the first eclipse dates and times of each month; all times in UT. 
β Persei Aa2 eclipses β Persei Aa1 every 2.867321 days (2 days 20 hours 49 min); therefore keep adding that much to each date and time to get the following eclipses. For example, the Jan 2, 20h, eclipse will yield consecutive eclipse times on Jan 5, 17h, then Jan 8, 16h, then Jan 11, 13h, etc. (all times approximate).
Algol is a multiple-star system with three confirmed and two suspected stellar components. From the point of view of the Earth, Algol Aa1 and Algol Aa2 form an eclipsing binary because their orbital plane contains the line of sight to the Earth. The eclipsing binary pair is separated by only 0.062 astronomical units (au) from each other, whereas the third star in the system (Algol Ab) is at an average distance of 2.69 au from the pair, and the mutual orbital period of the trio is 681 Earth days. The total mass of the system is about 5.8 solar masses, and the mass ratios of Aa1, Aa2, and Ab are about 4.5 to 1 to 2.
The three components of the bright triple star used to be, and still sometimes are, referred to as β Per A, B, and C. The Washington Double Star Catalog lists them as Aa1, Aa2, and Ab, with two very faint stars B and C about one arcmin distant. A further five faint stars are also listed as companions.
Studies of Algol led to the Algol paradox in the theory of stellar evolution: although components of a binary star form at the same time, and massive stars evolve much faster than the less massive stars, the more massive component Algol Aa1 is still in the main sequence, but the less massive Algol Aa2 is a subgiant star at a later evolutionary stage. The paradox can be solved by mass transfer: when the more massive star became a subgiant, it filled its Roche lobe, and most of the mass was transferred to the other star, which is still in the main sequence. In some binaries similar to Algol, a gas flow can be seen. The gas flow between the primary and secondary stars in Algol has been imaged using Doppler Tomography.
This system also exhibits x-ray and radio wave flares. The x-ray flares are thought to be caused by the magnetic fields of the A and B components interacting with the mass transfer. The radio-wave flares might be created by magnetic cycles similar to those of sunspots, but because the magnetic fields of these stars are up to ten times stronger than the field of the Sun, these radio flares are more powerful and more persistent. The secondary component was identified as the radio emitting source in Algol using Very-long-baseline interferometry by Lestrade and co-authors.
Magnetic activity cycles in the chromospherically active secondary component induce changes in its radius of gyration that have been linked to recurrent orbital period variations on the order of  ≈ 10 via the Applegate mechanism. Mass transfer between the components is small in the Algol system but could be a significant source of period change in other Algol-type binaries.
Algol is about 92.8 light-years from the Sun, but about 7.3 million years ago it passed within 9.8 light-years of the Solar System and its apparent magnitude was about −2.5, which is considerably brighter than the star Sirius is today. Because the total mass of the Algol system is about 5.8 solar masses, at the closest approach this might have given enough gravity to perturb the Oort cloud of the Solar System somewhat and hence increase the number of comets entering the inner Solar System. However, the actual increase in net cometary collisions is thought to have been quite small.
"Beta Persei" is the star's Bayer designation. The name "Algol" derives from Arabic "raʾs al-ghūl" : head ("raʾs") of the ogre ("al-ghūl") (see "ghoul"). The English name Demon Star was taken from the Arabic name. In 2016, the International Astronomical Union organized a Working Group on Star Names (WGSN) to catalog and standardize proper names for stars. The WGSN's first bulletin of July 2016 included a table of the first two batches of names approved by the WGSN; which included "Algol" for this star. It is so entered on the IAU Catalog of Star Names.
In Hebrew folklore, Algol was called "Rōsh ha Sāṭān" or "Satan's Head", as stated by Edmund Chilmead, who called it "Divels head" or "Rosch hassatan". A Latin name for Algol from the 16th century was "Caput Larvae" or "the Spectre's Head". Hipparchus and Pliny made this a separate, though connected, constellation.
In Chinese, (), meaning "Mausoleum", refers to an asterism consisting of β Persei, 9 Persei, τ Persei, ι Persei, κ Persei, ρ Persei, 16 Persei and 12 Persei. Consequently, the Chinese name for β Persei itself is (, English: The Fifth Star of Mausoleum.). According to R.H. Allen the star bore the grim name of "Tseih She" (), meaning "Piled up Corpses" but this appears to be a misidentification, and "Dié Shī" is correctly π Persei, which is inside the Mausoleum.
Historically, the star has received a strong association with bloody violence across a wide variety of cultures. In the "Tetrabiblos", the 2nd-century astrological text of the Alexandrian astronomer Ptolemy, Algol is referred to as "the Gorgon of Perseus" and associated with death by decapitation: a theme which mirrors the myth of the hero Perseus's victory over the snake-haired Gorgon Medusa. Astrologically, Algol is considered one of the unluckiest stars in the sky, and was listed as one of the 15 Behenian stars.

</doc>
<doc id="1395" url="https://en.wikipedia.org/wiki?curid=1395" title="Amazing Grace">
Amazing Grace

"Amazing Grace" is a Christian hymn published in 1779, with words written in 1772 by the English poet and Anglican clergyman John Newton (1725–1807).
Newton wrote the words from personal experience. He grew up without any particular religious conviction, but his life's path was formed by a variety of twists and coincidences that were often put into motion by others' reactions to what they took as his recalcitrant insubordination. 
He was pressed (conscripted) into service in the Royal Navy. After leaving the service, he became involved in the Atlantic slave trade. In 1748, a violent storm battered his vessel off the coast of County Donegal, Ireland, so severely that he called out to God for mercy. This moment marked his spiritual conversion but he continued slave trading until 1754 or 1755, when he ended his seafaring altogether. He began studying Christian theology and later became an abolitionist.
Ordained in the Church of England in 1764, Newton became curate of Olney, Buckinghamshire, where he began to write hymns with poet William Cowper. "Amazing Grace" was written to illustrate a sermon on New Year's Day of 1773. It is unknown if there was any music accompanying the verses; it may have been chanted by the congregation. It debuted in print in 1779 in Newton and Cowper's "Olney Hymns" but settled into relative obscurity in England. In the United States, "Amazing Grace" became a popular song used by Baptist and Methodist preachers as part of their evangelizing, especially in the South, during the Second Great Awakening of the early 19th century. It has been associated with more than 20 melodies. In 1835, American composer William Walker set it to the tune known as "New Britain" in a shape note format. This is the version most frequently sung today.
With the message that forgiveness and redemption are possible regardless of sins committed and that the soul can be delivered from despair through the mercy of God, "Amazing Grace" is one of the most recognisable songs in the English-speaking world. Author Gilbert Chase writes that it is "without a doubt the most famous of all the folk hymns". Jonathan Aitken, a Newton biographer, estimates that the song is performed about 10 million times annually. It has had particular influence in folk music, and has become an emblematic black spiritual. Its universal message has been a significant factor in its crossover into secular music. "Amazing Grace" became newly popular during a revival of folk music in the US during the 1960s, and it has been recorded thousands of times during and since the 20th century.
According to the "Dictionary of American Hymnology", "Amazing Grace" is John Newton's spiritual autobiography in verse.
In 1725, Newton was born in Wapping, a district in London near the Thames. His father was a shipping merchant who was brought up as a Catholic but had Protestant sympathies, and his mother was a devout Independent, unaffiliated with the Anglican Church. She had intended Newton to become a clergyman, but she died of tuberculosis when he was six years old. For the next few years, while his father was at sea Newton was raised by his emotionally distant stepmother. He was also sent to boarding school, where he was mistreated. At the age of eleven, he joined his father on a ship as an apprentice; his seagoing career would be marked by headstrong disobedience.
As a youth, Newton began a pattern of coming very close to death, examining his relationship with God, then relapsing into bad habits. As a sailor, he denounced his faith after being influenced by a shipmate who discussed with him "Characteristicks of Men, Manners, Opinions, Times", a book by the Third Earl of Shaftesbury. In a series of letters Newton later wrote, "Like an unwary sailor who quits his port just before a rising storm, I renounced the hopes and comforts of the Gospel at the very time when every other comfort was about to fail me." His disobedience caused him to be pressed into the Royal Navy, and he took advantage of opportunities to overstay his leave. 
He deserted the navy to visit Mary "Polly" Catlett, a family friend with whom he had fallen in love. After enduring humiliation for deserting, he was traded as crew to a slave ship. 
He began a career in slave trading.
Newton often openly mocked the captain by creating obscene poems and songs about him, which became so popular that the crew began to join in. His disagreements with several colleagues resulted in his being starved almost to death, imprisoned while at sea, and chained like the slaves they carried. He was himself enslaved and forced to work on a plantation in the British colony Sierra Leone near the Sherbro River. After several months he came to think of Sierra Leone as his home, but his father intervened after Newton sent him a letter describing his circumstances, and crew from another ship happened to find him. Newton claimed the only reason he left the colony was because of Polly.
While aboard the ship "Greyhound", Newton gained notoriety as being one of the most profane men the captain had ever met. In a culture where sailors habitually swore, Newton was admonished several times for not only using the worst words the captain had ever heard, but creating new ones to exceed the limits of verbal debauchery. In March 1748, while the "Greyhound" was in the North Atlantic, a violent storm came upon the ship that was so rough it swept overboard a crew member who was standing where Newton had been moments before. After hours of the crew emptying water from the ship and expecting to be capsized, Newton and another mate tied themselves to the ship's pump to keep from being washed overboard, working for several hours. After proposing the measure to the captain, Newton had turned and said, "If this will not do, then Lord have mercy upon us!" Newton rested briefly before returning to the deck to steer for the next eleven hours. During his time at the wheel, he pondered his divine challenge.
About two weeks later, the battered ship and starving crew landed in Lough Swilly, Ireland. For several weeks before the storm, Newton had been reading "The Christian's Pattern", a summary of the 15th-century "The Imitation of Christ" by Thomas à Kempis. The memory of his own "Lord have mercy upon us!" uttered during a moment of desperation in the storm did not leave him; he began to ask if he was worthy of God's mercy or in any way redeemable. Not only had he neglected his faith but directly opposed it, mocking others who showed theirs, deriding and denouncing God as a myth. He came to believe that God had sent him a profound message and had begun to work through him.
Newton's conversion was not immediate, but he contacted Polly's family and announced his intention to marry her. Her parents were hesitant as he was known to be unreliable and impetuous. They knew he was profane too but allowed him to write to Polly, and he set to begin to submit to authority for her sake. He sought a place on a slave ship bound for Africa, and Newton and his crewmates participated in most of the same activities he had written about before; the only immorality from which he was able to free himself was profanity. After a severe illness his resolve was renewed, yet he retained the same attitude towards slavery as was held by his contemporaries. Newton continued in the slave trade through several voyages where he sailed the coasts of Africa, now as a captain, and procured slaves being offered for sale in larger ports, transporting them to North America. 
In between voyages, he married Polly in 1750, and he found it more difficult to leave her at the beginning of each trip. After three shipping voyages in the slave trade, Newton was promised a position as ship's captain with cargo unrelated to slavery. But at the age of thirty, he collapsed and never sailed again.
Working as a customs agent in Liverpool starting in 1756, Newton began to teach himself Latin, Greek, and theology. He and Polly immersed themselves in the church community, and Newton's passion was so impressive that his friends suggested he become a priest in the Church of England. He was turned down by John Gilbert, Archbishop of York, in 1758, ostensibly for having no university degree, although the more likely reasons were his leanings toward evangelism and tendency to socialise with Methodists. Newton continued his devotions, and after being encouraged by a friend, he wrote about his experiences in the slave trade and his conversion. William Legge, 2nd Earl of Dartmouth, impressed with his story, sponsored Newton for ordination by John Green, Bishop of Lincoln, and offered him the curacy of Olney, Buckinghamshire, in 1764.
Olney was a village of about 2,500 residents whose main industry was making lace by hand. The people were mostly illiterate and many of them were poor. Newton's preaching was unique in that he shared many of his own experiences from the pulpit; many clergy preached from a distance, not admitting any intimacy with temptation or sin. He was involved in his parishioners' lives and was much loved, although his writing and delivery were sometimes unpolished. But his devotion and conviction were apparent and forceful, and he often said his mission was to "break a hard heart and to heal a broken heart". He struck a friendship with William Cowper, a gifted writer who had failed at a career in law and suffered bouts of insanity, attempting suicide several times. Cowper enjoyed Olney and Newton's company; he was also new to Olney and had gone through a spiritual conversion similar to Newton's. Together, their effect on the local congregation was impressive. In 1768, they found it necessary to start a weekly prayer meeting to meet the needs of an increasing number of parishioners. They also began writing lessons for children.
Partly from Cowper's literary influence, and partly because learned vicars were expected to write verses, Newton began to try his hand at hymns, which had become popular through the language, made plain for common people to understand. Several prolific hymn writers were at their most productive in the 18th century, including Isaac Watts whose hymns Newton had grown up hearing and Charles Wesley, with whom Newton was familiar. Wesley's brother John, the eventual founder of the Methodist Church, had encouraged Newton to go into the clergy. Watts was a pioneer in English hymn writing, basing his work after the Psalms. The most prevalent hymns by Watts and others were written in the common meter in 8.6.8.6: the first line is eight syllables and the second is six.
Newton and Cowper attempted to present a poem or hymn for each prayer meeting. The lyrics to "Amazing Grace" were written in late 1772 and probably used in a prayer meeting for the first time on 1 January 1773. A collection of the poems Newton and Cowper had written for use in services at Olney was bound and published anonymously in 1779 under the title "Olney Hymns". Newton contributed 280 of the 348 texts in "Olney Hymns"; "1 Chronicles 17:16–17, Faith's Review and Expectation" was the title of the poem with the first line "Amazing grace! (how sweet the sound)".
The general impact of "Olney Hymns" was immediate and it became a widely popular tool for evangelicals in Britain for many years. Scholars appreciated Cowper's poetry somewhat more than Newton's plaintive and plain language, expressing his forceful personality. The most prevalent themes in the verses written by Newton in "Olney Hymns" are faith in salvation, wonder at God's grace, his love for Jesus, and his cheerful exclamations of the joy he found in his faith. As a reflection of Newton's connection to his parishioners, he wrote many of the hymns in first person, admitting his own experience with sin. Bruce Hindmarsh in "Sing Them Over Again To Me: Hymns and Hymnbooks in America" considers "Amazing Grace" an excellent example of Newton's testimonial style afforded by the use of this perspective. Several of Newton's hymns were recognised as great work ("Amazing Grace" was not among them), while others seem to have been included to fill in when Cowper was unable to write. Jonathan Aitken calls Newton, specifically referring to "Amazing Grace", an "unashamedly middlebrow lyricist writing for a lowbrow congregation", noting that only twenty-one of the nearly 150 words used in all six verses have more than one syllable.
William Phipps in the "Anglican Theological Review" and author James Basker have interpreted the first stanza of "Amazing Grace" as evidence of Newton's realisation that his participation in the slave trade was his wretchedness, perhaps representing a wider common understanding of Newton's motivations. Newton joined forces with a young man named William Wilberforce, the British Member of Parliament who led the Parliamentarian campaign to abolish the slave trade in the British Empire, culminating in the Slave Trade Act 1807. But Newton did not become an ardent and outspoken abolitionist until after he left Olney in the 1780s; he is not known to have connected writing the hymn known as "Amazing Grace" to anti-slavery sentiments. 
The lyrics in "Olney Hymns" were arranged by their association to the Biblical verses that would be used by Newton and Cowper in their prayer meetings, and did not address any political objective. For Newton, the beginning of the year was a time to reflect on one's spiritual progress. At the same time he completed a diary which has since been lost that he had begun 17 years before, two years after he quit sailing. The last entry of 1772 was a recounting of how much he had changed since then.
The title ascribed to the hymn, "1 Chronicles 17:16–17", refers to David's reaction to the prophet Nathan telling him that God intends to maintain his family line forever. Some Christians interpret this as a prediction that Jesus Christ, as a descendant of David, was promised by God as the salvation for all people. Newton's sermon on that January day in 1773 focused on the necessity to express one's gratitude for God's guidance, that God is involved in the daily lives of Christians though they may not be aware of it, and that patience for deliverance from the daily trials of life is warranted when the glories of eternity await. Newton saw himself a sinner like David who had been chosen, perhaps undeservedly, and was humbled by it. According to Newton, unconverted sinners were "blinded by the god of this world" until "mercy came to us not only undeserved but undesired ... our hearts endeavored to shut him out till he overcame us by the power of his grace."
The New Testament served as the basis for many of the lyrics of "Amazing Grace". The first verse, for example, can be traced to the story of the Prodigal Son. In the Gospel of Luke the father says, "For this son of mine was dead and is alive again; he was lost, and is found". The story of Jesus healing a blind man who tells the Pharisees that he can now see is told in the Gospel of John. Newton used the words "I was blind but now I see" and declared "Oh to grace how great a debtor!" in his letters and diary entries as early as 1752. The effect of the lyrical arrangement, according to Bruce Hindmarsh, allows an instant release of energy in the exclamation "Amazing grace!", to be followed by a qualifying reply in "how sweet the sound". In "An Annotated Anthology of Hymns", Newton's use of an exclamation at the beginning of his verse is called "crude but effective" in an overall composition that "suggest(s) a forceful, if simple, statement of faith". Grace is recalled three times in the following verse, culminating in Newton's most personal story of his conversion, underscoring the use of his personal testimony with his parishioners.
The sermon preached by Newton was his last of those that William Cowper heard in Olney, since Cowper's mental instability returned shortly thereafter. One author suggests Newton may have had his friend in mind, employing the themes of assurance and deliverance from despair for Cowper's benefit.
Although it had its roots in England, "Amazing Grace" became an integral part of the Christian tapestry in the United States. More than 60 of Newton and Cowper's hymns were republished in other British hymnals and magazines, but "Amazing Grace" was not, appearing only once in a 1780 hymnal sponsored by the Countess of Huntingdon. Scholar John Julian commented in his 1892 "A Dictionary of Hymnology" that outside of the United States, the song was unknown and it was "far from being a good example of Newton's finest work". Between 1789 and 1799, four variations of Newton's hymn were published in the US in Baptist, Dutch Reformed, and Congregationalist hymnodies; by 1830 Presbyterians and Methodists also included Newton's verses in their hymnals.
The greatest influences in the 19th century that propelled "Amazing Grace" to spread across the US and become a staple of religious services in many denominations and regions were the Second Great Awakening and the development of shape note singing communities. A tremendous religious movement swept the US in the early 19th century, marked by the growth and popularity of churches and religious revivals that got their start on the frontier in Kentucky and Tennessee. Unprecedented gatherings of thousands of people attended camp meetings where they came to experience salvation; preaching was fiery and focused on saving the sinner from temptation and backsliding. Religion was stripped of ornament and ceremony, and made as plain and simple as possible; sermons and songs often used repetition to get across to a rural population of poor and mostly uneducated people the necessity of turning away from sin. Witnessing and testifying became an integral component to these meetings, where a congregation member or stranger would rise and recount his turn from a sinful life to one of piety and peace. "Amazing Grace" was one of many hymns that punctuated fervent sermons, although the contemporary style used a refrain, borrowed from other hymns, that employed simplicity and repetition such as:
Simultaneously, an unrelated movement of communal singing was established throughout the South and Western states. A format of teaching music to illiterate people appeared in 1800. It used four sounds to symbolise the basic scale: fa-sol-la-fa-sol-la-mi-fa. Each sound was accompanied by a specifically shaped note and thus became known as shape note singing. The method was simple to learn and teach, so schools were established throughout the South and West. Communities would come together for an entire day of singing in a large building where they sat in four distinct areas surrounding an open space, one member directing the group as a whole. Other groups would sing outside, on benches set up in a square. Preachers used shape note hymns to teach people on the frontier and to raise the emotion of camp meetings. Most of the music was Christian, but the purpose of communal singing was not primarily spiritual. Communities either could not afford music accompaniment or rejected it out of a Calvinistic sense of simplicity, so the songs were sung a cappella.
When originally used in Olney, it is unknown what music, if any, accompanied the verses written by John Newton. Contemporary hymnbooks did not contain music and were simply small books of religious poetry. The first known instance of Newton's lines joined to music was in "A Companion to the Countess of Huntingdon's Hymns" (London, 1808), where it is set to the tune "Hephzibah" by English composer John Husband. Common meter hymns were interchangeable with a variety of tunes; more than twenty musical settings of "Amazing Grace" circulated with varying popularity until 1835, when American composer William Walker assigned Newton's words to a traditional song named "New Britain". This was an amalgamation of two melodies ("Gallaher" and "St. Mary"), first published in the "Columbian Harmony" by Charles H. Spilman and Benjamin Shaw (Cincinnati, 1829). Spilman and Shaw, both students at Kentucky's Centre College, compiled their tunebook both for public worship and revivals, to satisfy "the wants of the Church in her triumphal march". Most of the tunes had been previously published, but "Gallaher" and "St. Mary" had not. As neither tune is attributed and both show elements of oral transmission, scholars can only speculate that they are possibly of British origin. A manuscript from 1828 by Lucius Chapin, a famous hymn writer of that time, contains a tune very close to "St. Mary", but that does not mean that he wrote it.
"Amazing Grace", with the words written by Newton and joined with "New Britain", the melody most currently associated with it, appeared for the first time in Walker's shape note tunebook "Southern Harmony" in 1847. It was, according to author Steve Turner, a "marriage made in heaven ... The music behind 'amazing' had a sense of awe to it. The music behind 'grace' sounded graceful. There was a rise at the point of confession, as though the author was stepping out into the open and making a bold declaration, but a corresponding fall when admitting his blindness." Walker's collection was enormously popular, selling about 600,000 copies all over the US when the total population was just over 20 million. Another shape note tunebook named "The Sacred Harp" (1844) by Georgia residents Benjamin Franklin White and Elisha J. King became widely influential and continues to be used.
Another verse was first recorded in Harriet Beecher Stowe's immensely influential 1852 anti-slavery novel "Uncle Tom's Cabin". Three verses were emblematically sung by Tom in his hour of deepest crisis. He sings the sixth and fifth verses in that order, and Stowe included another verse, not written by Newton, that had been passed down orally in African-American communities for at least 50 years. It was one of between 50 and 70 verses of a song titled "Jerusalem, My Happy Home", which was first published in a 1790 book called "A Collection of Sacred Ballads":
"Amazing Grace" came to be an emblem of a Christian movement and a symbol of the US itself as the country was involved in a great political experiment, attempting to employ democracy as a means of government. Shape-note singing communities, with all the members sitting around an open center, each song employing a different song leader, illustrated this in practice. Simultaneously, the US began to expand westward into previously unexplored territory that was often wilderness. The "dangers, toils, and snares" of Newton's lyrics had both literal and figurative meanings for Americans. This became poignantly true during the most serious test of American cohesion in the U.S. Civil War (1861–1865). "Amazing Grace", set to "New Britain", was included in two hymnals distributed to soldiers. With death so real and imminent, religious services in the military became commonplace. The hymn was translated into other languages as well: while on the Trail of Tears, the Cherokee sang Christian hymns as a way of coping with the ongoing tragedy, and a version of the song by Samuel Worcester that had been translated into the Cherokee language became very popular.
Although "Amazing Grace" set to "New Britain" was popular, other versions existed regionally. Primitive Baptists in the Appalachian region often used "New Britain" with other hymns, and sometimes sing the words of "Amazing Grace" to other folk songs, including titles such as "In the Pines", "Pisgah", "Primrose", and "Evan", as all are able to be sung in common meter, of which the majority of their repertoire consists. In the late 19th century, Newton's verses were sung to a tune named "Arlington" as frequently as to "New Britain" for a time.
Two musical arrangers named Dwight Moody and Ira Sankey heralded another religious revival in the cities of the US and Europe, giving the song international exposure. Moody's preaching and Sankey's musical gifts were significant; their arrangements were the forerunners of gospel music, and churches all over the US were eager to acquire them. Moody and Sankey began publishing their compositions in 1875, and "Amazing Grace" appeared three times with three different melodies, but they were the first to give it its title; hymns were typically published using the incipits (first line of the lyrics), or the name of the tune such as "New Britain". Publisher Edwin Othello Excell gave the version of "Amazing Grace" set to "New Britain" immense popularity by publishing it in a series of hymnals that were used in urban churches. Excell altered some of Walker's music, making it more contemporary and European, giving "New Britain" some distance from its rural folk-music origins. Excell's version was more palatable for a growing urban middle class and arranged for larger church choirs. Several editions featuring Newton's first three stanzas and the verse previously included by Harriet Beecher Stowe in "Uncle Tom's Cabin" were published by Excell between 1900 and 1910. His version of "Amazing Grace" became the standard form of the song in American churches.
With the advent of recorded music and radio, "Amazing Grace" began to cross over from primarily a gospel standard to secular audiences. The ability to record combined with the marketing of records to specific audiences allowed "Amazing Grace" to take on thousands of different forms in the 20th century. Where Edwin Othello Excell sought to make the singing of "Amazing Grace" uniform throughout thousands of churches, records allowed artists to improvise with the words and music specific to each audience. AllMusic lists over 1,000 recordings – including re-releases and compilations – as of 2019. Its first recording is an a cappella version from 1922 by the Sacred Harp Choir. It was included from 1926 to 1930 in Okeh Records' catalogue, which typically concentrated strongly on blues and jazz. Demand was high for black gospel recordings of the song by H. R. Tomlin and J. M. Gates. A poignant sense of nostalgia accompanied the recordings of several gospel and blues singers in the 1940s and 1950s who used the song to remember their grandparents, traditions, and family roots. It was recorded with musical accompaniment for the first time in 1930 by Fiddlin' John Carson, although to another folk hymn named "At the Cross", not to "New Britain". "Amazing Grace" is emblematic of several kinds of folk music styles, often used as the standard example to illustrate such musical techniques as lining out and call and response, that have been practised in both black and white folk music.
Mahalia Jackson's 1947 version received significant radio airplay, and as her popularity grew throughout the 1950s and 1960s, she often sang it at public events such as concerts at Carnegie Hall. Author James Basker states that the song has been employed by African Americans as the "paradigmatic Negro spiritual" because it expresses the joy felt at being delivered from slavery and worldly miseries. Anthony Heilbut, author of "The Gospel Sound", states that the "dangers, toils, and snares" of Newton's words are a "universal testimony" of the African American experience. During the civil rights movement and opposition to the Vietnam War, the song took on a political tone. Mahalia Jackson employed "Amazing Grace" for Civil Rights marchers, writing that she used it "to give magical protection a charm to ward off danger, an incantation to the angels of heaven to descend ... I was not sure the magic worked outside the church walls ... in the open air of Mississippi. But I wasn't taking any chances." Folk singer Judy Collins, who knew the song before she could remember learning it, witnessed Fannie Lou Hamer leading marchers in Mississippi in 1964, singing "Amazing Grace". Collins also considered it a talisman of sorts, and saw its equal emotional impact on the marchers, witnesses, and law enforcement who opposed the civil rights demonstrators. According to fellow folk singer Joan Baez, it was one of the most requested songs from her audiences, but she never realised its origin as a hymn; by the time she was singing it in the 1960s she said it had "developed a life of its own". It even made an appearance at the Woodstock Music Festival in 1969 during Arlo Guthrie's performance.
Collins decided to record it in the late 1960s amid an atmosphere of counterculture introspection; she was part of an encounter group that ended a contentious meeting by singing "Amazing Grace" as it was the only song to which all the members knew the words. Her producer was present and suggested she include a version of it on her 1970 album "Whales & Nightingales". Collins, who had a history of alcohol abuse, claimed that the song was able to "pull her through" to recovery. It was recorded in St. Paul's, the chapel at Columbia University, chosen for the acoustics. She chose an "a cappella" arrangement that was close to Edwin Othello Excell's, accompanied by a chorus of amateur singers who were friends of hers. Collins connected it to the Vietnam War, to which she objected: "I didn't know what else to do about the war in Vietnam. I had marched, I had voted, I had gone to jail on political actions and worked for the candidates I believed in. The war was still raging. There was nothing left to do, I thought ... but sing 'Amazing Grace'." Gradually and unexpectedly, the song began to be played on the radio, and then be requested. It rose to number 15 on the "Billboard" Hot 100, remaining on the charts for 15 weeks, as if, she wrote, her fans had been "waiting to embrace it". In the UK, it charted 8 times between 1970 and 1972, peaking at number 5 and spending a total of 75 weeks on popular music charts. Her rendition also reached number 5 in New Zealand and number 12 in Ireland in 1971.
Although Collins used it as a catharsis for her opposition to the Vietnam War, two years after her rendition, the Royal Scots Dragoon Guards, senior Scottish regiment of the British Army, recorded an instrumental version featuring a bagpipe soloist accompanied by a pipe band. The tempo of their arrangement was slowed to allow for the bagpipes, but it was based on Collins': it began with a bagpipe solo introduction similar to her lone voice, then it was accompanied by the band of bagpipes and horns, whereas in her version she is backed up by a chorus. It topped the "RPM" national singles chart in Canada for three weeks, and rose as high as number 11 in the US. It is also a controversial instrumental, as it combined pipes with a military band. The Pipe Major of the Royal Scots Dragoon Guards was summoned to Edinburgh Castle and chastised for demeaning the bagpipes.
Aretha Franklin and Rod Stewart also recorded "Amazing Grace" around the same time, and both of their renditions were popular. All four versions were marketed to distinct types of audiences, thereby assuring its place as a pop song. Johnny Cash recorded it on his 1975 album "Sings Precious Memories", dedicating it to his older brother Jack, who had been killed in a mill accident when they were boys in Dyess, Arkansas. Cash and his family sang it to themselves while they worked in the cotton fields following Jack's death. Cash often included the song when he toured prisons, saying "For the three minutes that song is going on, everybody is free. It just frees the spirit and frees the person."
The U.S. Library of Congress has a collection of 3,000 versions of and songs inspired by "Amazing Grace", some of which were first-time recordings by folklorists Alan and John Lomax, a father and son team who in 1932 travelled thousands of miles across the southern states of the US to capture the different regional styles of the song. More contemporary renditions include samples from such popular artists as Sam Cooke and the Soul Stirrers (1963), the Byrds (1970), Elvis Presley (1971), Skeeter Davis (1972), Mighty Clouds of Joy (1972), Amazing Rhythm Aces (1975), Willie Nelson (1976), the Lemonheads (1992), LeperKhanz on the album "Tiocfaidh Ár Lá" (2005), MNL48 (2018), and Five for Fighting (2020).
Following the appropriation of the hymn in secular music, "Amazing Grace" became such an icon in American culture that it has been used for a variety of secular purposes and marketing campaigns, placing it in danger of becoming a cliché. It has been mass-produced on souvenirs, lent its name to a Superman villain, appeared on "The Simpsons" to demonstrate the redemption of a murderous character named Sideshow Bob, incorporated into Hare Krishna chants and adapted for Wicca ceremonies. It can also be sung to the theme from "The Mickey Mouse Club", as Garrison Keillor has observed. The hymn has been employed in several films, including "Alice's Restaurant", "Invasion of the Body Snatchers", "Coal Miner's Daughter", and "Silkwood". It is referenced in the 2006 film "Amazing Grace", which highlights Newton's influence on the leading British abolitionist William Wilberforce, and in the film biography of Newton, "Newton's Grace". The 1982 science fiction film "" used "Amazing Grace" amid a context of Christian symbolism, to memorialise Mr. Spock following his death, but more practically, because the song has become "instantly recognizable to many in the audience as music that sounds appropriate for a funeral" according to a "Star Trek" scholar. Since 1954, when an organ instrumental of "New Britain" became a best-seller, "Amazing Grace" has been associated with funerals and memorial services. The hymn has become a song that inspires hope in the wake of tragedy, becoming a sort of "spiritual national anthem" according to authors Mary Rourke and Emily Gwathmey. For example, President Barack Obama recited and later sang the hymn at the memorial service for Clementa Pinckney, who was one of the nine victims of the Charleston church shooting in 2015.
In recent years, the words of the hymn have been changed in some religious publications to downplay a sense of imposed self-loathing by its singers. The second line, "That saved a wretch like me!" has been rewritten as "That saved and strengthened me", "save a soul like me", or "that saved and set me free". Kathleen Norris in her book "Amazing Grace: A Vocabulary of Faith" characterises this transformation of the original words as "wretched English" making the line that replaces the original "laughably bland". Part of the reason for this change has been the altered interpretations of what wretchedness and grace means. Newton's Calvinistic view of redemption and divine grace formed his perspective that he considered himself a sinner so vile that he was unable to change his life or be redeemed without God's help. Yet his lyrical subtlety, in Steve Turner's opinion, leaves the hymn's meaning open to a variety of Christian and non-Christian interpretations. "Wretch" also represents a period in Newton's life when he saw himself outcast and miserable, as he was when he was enslaved in Sierra Leone; his own arrogance was matched by how far he had fallen in his life.
Due to its immense popularity and iconic nature, the meaning behind the words of "Amazing Grace" has become as individual as the singer or listener. Bruce Hindmarsh suggests that the secular popularity of "Amazing Grace" is due to the absence of any mention of God in the lyrics until the fourth verse (by Excell's version, the fourth verse begins "When we've been there ten thousand years"), and that the song represents the ability of humanity to transform itself instead of a transformation taking place at the hands of God. "Grace", however, had a clearer meaning to John Newton, as he used the word to represent God or the power of God.
The transformative power of the song was investigated by journalist Bill Moyers in a documentary released in 1990. Moyers was inspired to focus on the song's power after watching a performance at Lincoln Center, where the audience consisted of Christians and non-Christians, and he noticed that it had an equal impact on everybody in attendance, unifying them. James Basker also acknowledged this force when he explained why he chose "Amazing Grace" to represent a collection of anti-slavery poetry: "there is a transformative power that is applicable ... : the transformation of sin and sorrow into grace, of suffering into beauty, of alienation into empathy and connection, of the unspeakable into imaginative literature."
Moyers interviewed Collins, Cash, opera singer Jessye Norman, Appalachian folk musician Jean Ritchie and her family, white Sacred Harp singers in Georgia, black Sacred Harp singers in Alabama, and a prison choir at the Texas State Penitentiary at Huntsville. Collins, Cash, and Norman were unable to discern if the power of the song came from the music or the lyrics. Norman, who once notably sang it at the end of a large outdoor rock concert for Nelson Mandela's 70th birthday, stated, "I don't know whether it's the text I don't know whether we're talking about the lyrics when we say that it touches so many people or whether it's that tune that everybody knows." A prisoner interviewed by Moyers explained his literal interpretation of the second verse: "'Twas grace that taught my heart to fear, and grace my fears relieved" by saying that the fear became immediately real to him when he realised he may never get his life in order, compounded by the loneliness and restriction in prison. Gospel singer Marion Williams summed up its effect: "That's a song that gets to everybody".
The "Dictionary of American Hymnology" claims it is included in more than a thousand published hymnals, and recommends its use for "occasions of worship when we need to confess with joy that we are saved by God's grace alone; as a hymn of response to forgiveness of sin or as an assurance of pardon; as a confession of faith or after the sermon".

</doc>
<doc id="1397" url="https://en.wikipedia.org/wiki?curid=1397" title="AOL">
AOL

AOL (stylized as Aol., formerly a company known as AOL Inc. and originally known as America Online) is an American web portal and online service provider based in New York City. It is a brand marketed by Verizon Media.
The service traces its history to an online service known as PlayNET. PlayNET licensed their software to Quantum Link (Q-Link), who went online in November 1985. A new IBM PC client launched in 1988, eventually renamed as America Online in 1989. AOL grew to become the largest online service, displacing established players like CompuServe and The Source. By 1995, AOL had about three million active users.
AOL was one of the early pioneers of the Internet in the mid-1990s, and the most recognized brand on the web in the United States. It originally provided a dial-up service to millions of Americans, as well as providing a web portal, e-mail, instant messaging and later a web browser following its purchase of Netscape. In 2001, at the height of its popularity, it purchased the media conglomerate Time Warner in the largest merger in U.S. history. AOL rapidly declined thereafter, partly due to the decline of dial-up and rise of broadband. AOL was eventually spun off from Time Warner in 2009, with Tim Armstrong appointed the new CEO. Under his leadership, the company invested in media brands and advertising technologies.
On June 23, 2015, AOL was acquired by Verizon Communications for $4.4 billion.
AOL began in 1983, as a short-lived venture called Control Video Corporation (or CVC), founded by William von Meister. Its sole product was an online service called GameLine for the Atari 2600 video game console, after von Meister's idea of buying music on demand was rejected by Warner Bros. Subscribers bought a modem from the company for US$49.95 and paid a one-time US$15 setup fee. GameLine permitted subscribers to temporarily download games and keep track of high scores, at a cost of US$1 per game. The telephone disconnected and the downloaded game would remain in GameLine's Master Module and playable until the user turned off the console or downloaded another game.
In January 1983, Steve Case was hired as a marketing consultant for Control Video on the recommendation of his brother, investment banker Dan Case. In May 1983, Jim Kimsey became a manufacturing consultant for Control Video, which was near bankruptcy. Kimsey was brought in by his West Point friend Frank Caufield, an investor in the company. In early 1985, von Meister left the company.
On May 24, 1985, Quantum Computer Services, an online services company, was founded by Jim Kimsey from the remnants of Control Video, with Kimsey as chief executive officer, and Marc Seriff as chief technology officer. The technical team consisted of Marc Seriff, Tom Ralston, Ray Heinrich, Steve Trus, Ken Huntsman, Janet Hunter, Dave Brown, Craig Dykstra, Doug Coward, and Mike Ficco. In 1987, Case was promoted again to executive vice-president. Kimsey soon began to groom Case to take over the role of CEO, which he did when Kimsey retired in 1991.
Kimsey changed the company's strategy, and in 1985, launched a dedicated online service for Commodore 64 and 128 computers, originally called Quantum Link ("Q-Link" for short). The Quantum Link software was based on software licensed from PlayNet, Inc, (founded in 1983 by Howard Goldberg and Dave Panzl). The service was different from other online services as it used the computing power of the Commodore 64 and the Apple II rather than just a "dumb" terminal. It passed tokens back and forth and provided a fixed price service tailored for home users. In May 1988, Quantum and Apple launched AppleLink Personal Edition for Apple II and Macintosh computers. In August 1988, Quantum launched PC Link, a service for IBM-compatible PCs developed in a joint venture with the Tandy Corporation. After the company parted ways with Apple in October 1989, Quantum changed the service's name to America Online. Case promoted and sold AOL as the online service for people unfamiliar with computers, in contrast to CompuServe, which was well established in the technical community.
From the beginning, AOL included online games in its mix of products; many classic and casual games were included in the original PlayNet software system. In the early years of AOL the company introduced many innovative online interactive titles and games, including:
In February 1991, AOL for DOS was launched using a GeoWorks interface followed a year later by AOL for Windows. This coincided with growth in pay-based online services, like Prodigy, CompuServe, and GEnie. 1991 also saw the introduction of an original Dungeons & Dragons title called "Neverwinter Nights" from Stormfront Studios; which was one of the first Multiplayer Online Role Playing Games to depict the adventure with graphics instead of text.
During the early 1990s, the average subscription lasted for about 25 months and accounted for $350 in total revenue. Advertisements invited modem owners to "Try America Online FREE", promising free software and trial membership. AOL discontinued Q-Link and PC Link in late 1994. In September 1993, AOL added Usenet access to its features. This is commonly referred to as the "Eternal September", as Usenet's cycle of new users was previously dominated by smaller numbers of college and university freshmen gaining access in September and taking a few weeks to acclimate. This also coincided with a new "carpet bombing" marketing campaign by CMO Jan Brandt to distribute as many free trial AOL trial disks as possible through nonconventional distribution partners. At one point, 50% of the CDs produced worldwide had an AOL logo. AOL quickly surpassed GEnie, and by the mid-1990s, it passed Prodigy (which for several years allowed AOL advertising) and CompuServe.
Over the next several years, AOL launched services with the National Education Association, the American Federation of Teachers, "National Geographic", the Smithsonian Institution, the Library of Congress, Pearson, Scholastic, ASCD, NSBA, NCTE, Discovery Networks, Turner Education Services (CNN Newsroom), NPR, The Princeton Review, Stanley Kaplan, Barron's, Highlights for Kids, the U.S. Department of Education, and many other education providers. AOL offered the first real-time homework help service (the Teacher Pager—1990; prior to this, AOL provided homework help bulletin boards), the first service by children, for children (Kids Only Online, 1991), the first online service for parents (the Parents Information Network, 1991), the first online courses (1988), the first omnibus service for teachers (the Teachers' Information Network, 1990), the first online exhibit (Library of Congress, 1991), the first parental controls, and many other online education firsts.
AOL purchased search engine WebCrawler in 1995, but sold it to Excite the following year; the deal made Excite the sole search and directory service on AOL. After the deal closed in March 1997, AOL launched its own branded search engine, based on Excite, called NetFind. This was renamed to AOL Search in 1999.
AOL charged its users an hourly fee until December 1996, when the company changed to a flat monthly rate of $19.95. During this time, AOL connections were flooded with users trying to connect, and many canceled their accounts due to constant busy signals. A commercial was made featuring Steve Case telling people AOL was working day and night to fix the problem. Within three years, AOL's user base grew to 10 million people. In 1995 AOL was headquartered at 8619 Westwood Center Drive in the Tysons Corner CDP in unincorporated Fairfax County, Virginia, near the Town of Vienna.
AOL was quickly running out of room in October 1996 for its network at the Fairfax County campus. In mid-1996, AOL moved to 22000 AOL Way in Dulles, unincorporated Loudoun County, Virginia to provide room for future growth. In a five-year landmark agreement with the most popular operating system, AOL was bundled with Windows software.
On March 31, 1996, the short-lived eWorld was purchased by AOL. In 1997, about half of all U.S. homes with Internet access had it through AOL. During this time, AOL's content channels, under Jason Seiken, including News, Sports, and Entertainment, experienced their greatest growth as AOL become the dominant online service internationally with more than 34 million subscribers. In November 1998, AOL announced it would acquire Netscape, best known for their web browser, in a major $4.2 billion deal. The deal closed on March 17, 1999. Another large acquisition in December 1999 was that of MapQuest, for $1.1 billion.
In January 2000, AOL and Time Warner announced plans to merge, forming AOL Time Warner, Inc. The terms of the deal called for AOL shareholders to own 55% of the new, combined company. The deal closed on January 11, 2001. The new company was led by executives from AOL, SBI, and Time Warner. Gerald Levin, who had served as CEO of Time Warner, was CEO of the new company. Steve Case served as Chairman, J. Michael Kelly (from AOL) was the Chief Financial Officer, Robert W. Pittman (from AOL) and Dick Parsons (from Time Warner) served as Co-Chief Operating Officers. In 2002, Jonathan Miller became CEO of AOL. The following year, AOL Time Warner dropped the "AOL" from its name. It was the largest merger in history when completed with the combined value of the companies at $360 billion. This value fell sharply, as low as $120 billion as markets repriced AOL's valuation as a pure internet firm more modestly when combined with the traditional media and cable business. This state didn't last long, and the company's value rose again within 3 months. By the end of that year, the tide had turned against "pure" internet companies, with many collapsing under falling stock prices, and even the strongest companies in the field losing up to 75% of their market value. The decline continued though 2001, but even with the losses, AOL was among the internet giants that continued to outperform brick and mortar companies.
In 2004, along with the launch of AOL 9.0 Optimized, AOL also made available the option of personalized greetings which would enable the user to hear his or her name while accessing basic functions and mail alerts, or while logging in or out. In 2005, AOL broadcast the Live 8 concert live over the Internet, and thousands of users downloaded clips of the concert over the following months. In late 2005, AOL released AOL Safety & Security Center, a bundle of McAfee Antivirus, CA anti-spyware, and proprietary firewall and phishing protection software. News reports in late 2005 identified companies such as Yahoo!, Microsoft, and Google as candidates for turning AOL into a joint venture. Those plans were abandoned when it was revealed on December 20, 2005, that Google would purchase a 5% share of AOL for $1 billion.
On April 3, 2006, AOL announced it was retiring the full name America Online; the official name of the service became AOL, and the full name of the Time Warner subdivision became AOL LLC.
On June 8, 2006, AOL offered a new program called AOL Active Security Monitor, a diagnostic tool which checked the local PC's security status, and recommended additional security software from AOL or Download.com. The program rated the computer on a variety of different areas of security and general computer health. Two months later, AOL released AOL Active Virus Shield. This software was developed by Kaspersky Lab. Active Virus Shield software was free and did not require an AOL account, only an internet email address. The ISP side of AOL UK was bought by The Carphone Warehouse in October 2006 to take advantage of their 100,000 LLU customers, making The Carphone Warehouse the biggest LLU provider in the UK.
In August 2006, AOL announced they would give away email accounts and software previously available only to its paying customers provided the customer accessed AOL or AOL.com through a non-AOL-owned access method (otherwise known as "third party transit", "bring your own access", or "BYOA"). The move was designed to reduce costs associated with the "Walled Garden" business model by reducing usage of AOL-owned access points and shifting members with high-speed internet access from client-based usage to the more lucrative advertising provider, AOL.com. The change from paid to free was also designed to slow the rate of members canceling their accounts and defecting to Microsoft Hotmail, Yahoo!, or other free email providers. The other free services included:
Also that month, AOL informed its American customers it would be increasing the price of its dial-up access to US$25.90. The increase was part of an effort to migrate the service's remaining dial-up users to broadband, as the increased price was the same price they had been charging for monthly DSL access. However, AOL has since started offering their services for $9.95 a month for unlimited dial-up access.
On November 16, 2006, Randy Falco succeeded Jonathan Miller as CEO. In December 2006, AOL closed their last remaining call center in the United States, "taking the America out of America Online" according to industry pundits. Service centers based in India and the Philippines continue to this day to provide customer support and technical assistance to subscribers.
On September 17, 2007, AOL announced it was moving one of its corporate headquarters from Dulles, Virginia, to New York City and combining its various advertising units into a new subsidiary called Platform A. This action followed several advertising acquisitions, most notably Advertising.com, and highlighted the company's new focus on advertising-driven business models. AOL management stressed "significant operations" will remain in Dulles, which included the company's access services and modem banks.
In October 2007, AOL announced it would move one of its other headquarters from Loudoun County, Virginia, to New York City; it would continue to operate its Virginia offices. As part of the impending move to New York and the restructuring of responsibilities at the Dulles headquarters complex after the Reston move, AOL CEO Randy Falco announced on October 15, 2007, plans to lay off 2,000 employees worldwide by the end of 2007, beginning "immediately". The end result was a near 40% layoff across the board at AOL. Most compensation packages associated with the October 2007 layoffs included a minimum of 120 days of severance pay, 60 of which were given in lieu of the 60-day advance notice requirement by provisions of the 1988 Federal WARN Act.
By November 2007, AOL's customer base had been reduced to 10.1 million subscribers, just narrowly ahead of Comcast and AT&T Yahoo!. According to Falco, as of December 2007, the conversion rate of accounts from paid access to free access was over 80%.
On January 3, 2008, AOL announced the closing of one of its three Northern Virginia data centers, Reston Technology Center, and sold it to CRG West. On February 6, Time Warner CEO Jeff Bewkes announced Time Warner would split AOL's internet access and advertising businesses in two, with the possibility of later selling the internet access division.
On March 13, 2008, AOL purchased the social networking site Bebo for $850m (£417m). On July 25, AOL announced it was shedding Xdrive, AOL Pictures, and BlueString to save on costs and focus on its core advertising business. AOL Pictures was terminated on December 31. On October 31, AOL Hometown (a web hosting service for the websites of AOL customers) and the AOL Journal blog hosting service were eliminated.
On March 12, 2009, Tim Armstrong, formerly with Google, was named Chairman and CEO of AOL. Shortly thereafter, on May 28, Time Warner announced it would spin off AOL as an independent company once Google's shares ceased at the end of the fiscal year. On November 23, AOL unveiled a sneak preview of a new brand identity which has the wordmark "Aol." superimposed onto canvases created by commissioned artists. The new identity, designed by Wolff Olins, was enacted onto all of AOL's services on December 10, the date AOL traded independently for the first time since the Time Warner merger on the New York Stock Exchange under the symbol AOL.
On April 6, 2010, AOL announced plans to shut down or sell Bebo; on June 16, the property was sold to Criterion Capital Partners for an undisclosed amount, believed to be around $10 million. In December, AIM eliminated access to AOL chat rooms noting a marked decline of patronage in recent months.
Under Armstrong's leadership, AOL began taking steps in a new business direction, marked by a series of acquisitions. On June 11, 2009, AOL had already announced the acquisition of Patch Media, a network of community-specific news and information sites which focuses on individual towns and communities. On September 28, 2010, at the San Francisco TechCrunch Disrupt Conference, AOL signed an agreement to acquire TechCrunch to further its overall strategy of providing premier online content. On December 12, 2010, AOL acquired about.me, a personal profile and identity platform, four days after that latter's public launch.
On January 31, 2011, AOL announced the acquisition of European video distribution network, goviral. In March 2011, AOL acquired "HuffPost" for $315 million. Shortly after the acquisition was announced, Huffington Post co-founder Arianna Huffington replaced AOL Content Chief David Eun, assuming the role of President and Editor-in-Chief of the AOL Huffington Post Media Group. On March 10, AOL announced it would cut around 900 workers due to the HuffPost acquisition.
On September 14, 2011, AOL formed a strategic ad selling partnership with two of its largest competitors, Yahoo and Microsoft. According to the new partnership, the three companies would begin selling inventory on each other's sites. The strategy was designed to help them compete with Google and ad networks.
On February 28, 2012, AOL partnered with PBS to launch MAKERS, a digital documentary series focusing on high-achieving women in male-dominated industries such as war, comedy, space, business, Hollywood and politics. Subjects for MAKERS episodes have included Oprah Winfrey, Hillary Clinton, Sheryl Sandberg, Martha Stewart, Indra Nooyi, Lena Dunham, and Ellen DeGeneres.
On March 15, 2012, AOL announced the acquisition of Hipster, a mobile photo-sharing app for an undisclosed amount. On April 9, 2012, AOL announced a deal to sell 800 patents to Microsoft for $1.056 billion. The deal includes a "perpetual" license for AOL to use these patents.
In April, AOL took several steps to expand its ability to generate revenue through online video advertising. The company announced it would offer gross rating point (GRP) guarantee for online video, mirroring the TV ratings system and guaranteeing audience delivery for online video advertising campaigns bought across its properties. This announcement came just days before the Digital Content NewFront (DCNF) a two-week event held by AOL, Google, Hulu, Microsoft, Vevo and Yahoo to showcase the participating sites' digital video offerings. The Digital Content NewFront were conducted in advance of the traditional television upfronts in hopes of diverting more advertising money into the digital space. On April 24, the company launched the AOL On network, a single website for its video output.
In February 2013, AOL reported its fourth quarter revenue of $599.5 million, its first growth in quarterly revenue in 8 years.
In August 2013, Armstrong announced Patch Media would scale back or sell hundreds of its local news sites. Not long afterwards, layoffs began, with up to 500 out of 1,100 positions initially impacted. On January 15, 2014, Patch Media was spun off, with majority ownership being held by Hale Global. By the end of 2014, AOL controlled 0.74% of the global advertising market, well behind industry leader Google's 31.4%.
On January 23, 2014, AOL acquired Gravity, a software startup that tracked users’ online behavior and tailored ads and content based on their interests, for $83 million. The deal, which included roughly 40 Gravity employees and their personalization technology, was CEO Tim Armstrong's fourth largest deal since taking over the company in 2009. Later that year, AOL also acquired Vidible, which developed technology to help websites run video content from other publishers, and help video publishers sell their content to these websites. The deal, which was announced December 1, 2014, was reportedly worth roughly $50 million.
On July 16, 2014, AOL earned an Emmy nomination for the AOL original series, The Future Starts Here, in the News and Documentary category. This came days after AOL earned its first Primetime Emmy Award nomination for "Park Bench with Steve Buscemi" in the Outstanding Short Form Variety Series category, which later won the award. Created and hosted by Tiffany Shlain, the series focused on human's relationship with technology and featured episodes such as The Future of Our Species, Why We Love Robots, and A Case for Optimism.
On May 12, 2015, Verizon announced plans to buy AOL for $50 per share in a deal valued at $4.4 billion. The transaction was completed on June 23. Armstrong, who continued to lead the firm following regulatory approval, called the deal the logical next step for AOL. "If you look forward five years, you're going to be in a space where there are going to be massive, global-scale networks, and there's no better partner for us to go forward with than Verizon." he said. "It's really not about selling the company today. It's about setting up for the next five to 10 years."
Analyst David Bank said he thought the deal made sense for Verizon. The deal will broaden Verizon's advertising sales platforms and increase its video production ability through websites such as "HuffPost", TechCrunch, and Engadget. However, Craig Moffett said it was unlikely the deal would make a big difference to Verizon's bottom line. AOL had about two million dial-up subscribers at the time of the buyout. The announcement caused AOL's stock price to rise 17%, while Verizon's stock price dropped slightly.
Shortly before the Verizon purchase, on April 14, 2015, AOL launched ONE by AOL, a digital marketing programmatic platform that unifies buying channels and audience management platforms to track and optimize campaigns over multiple screens. Later that year, on September 15, AOL expanded the product with ONE by AOL: Creative, which is geared towards creative and media agencies to similarly connect marketing and ad distribution efforts.
On May 8, 2015, AOL reported its first-quarter revenue of $625.1 million, $483.5 million of which came from advertising and related operations, marking a 7% increase from Q1 2014. Over that year, the AOL Platforms division saw a 21% increase in revenue, but a drop in adjusted OIBDA due to increased investments in the company's video and programmatic platforms.
On June 29, 2015, AOL announced a deal with Microsoft to take over the majority of its digital advertising business. Under the pact, as many as 1,200 Microsoft employees involved with the business will be transferred to AOL, and the company will take over the sale of display, video, and mobile ads on various Microsoft platforms in nine countries, including Brazil, Canada, the United States, and the United Kingdom. Additionally, Google Search will be replaced on AOL properties with Bing—which will display advertising sold by Microsoft. Both advertising deals are subject to affiliate marketing revenue sharing.
On July 22, 2015, AOL received two News and Documentary Emmy nominations, one for MAKERS in the Outstanding Historical Programming category, and the other for "True Trans With Laura Jane Grace", which documented the story of Laura Jane Grace, a transgender musician best known as the founder, lead singer, songwriter and guitarist of the punk rock band Against Me!, and her decision to come out publicly and overall transition experience.
On September 3, 2015, AOL agreed to buy Millennial Media for US$238 million. On October 23, 2015, AOL completed the acquisition.
On October 1, 2015, Go90, a free ad-supported mobile video service aimed at young adult and teen viewers that Verizon owns and AOL oversees and operates launched its content publicly after months of beta testing. The initial launch line-up included content from Comedy Central, HuffPost, Nerdist News, Univision News, Vice, ESPN and MTV.
On January 25, 2016, AOL expanded its ONE platform by introducing ONE by AOL: Publishers, which combines six previously separate technologies to offer various publisher capabilities such as customizing video players, offering premium ad experience to boost visibility, and generating large video libraries. The announcement was made in tandem with AOL's acquisition of AlephD, a Paris-based startup focused on publisher analytics of ad price tracking based on historical data. AOL announced AlephD would be a part of the ONE by AOL: Publishers platform.
On April 20, 2016, AOL acquired virtual reality studio RYOT to bring immersive 360 degree video and VR content to HuffPost's global audience across desktop, mobile, and apps.
In July 2016, Verizon Communications announced its intent to purchase the core internet business of Yahoo!. Verizon tentatively plans to merge AOL with Yahoo into a new company called "Oath Inc.".
In April 2018, Oath Inc. sold Moviefone to MoviePass Parent Helios and Matheson Analytics.
As of 2019, following media brands became subsidiary of AOL's parent Verizon Media.
AOL's content contributors consists of over 20,000 bloggers, including politicians, celebrities, academics, and policy experts, who contribute on a wide range of topics making news.
In addition to mobile-optimized web experiences, AOL produces mobile applications for existing AOL properties like Autoblog, Engadget, The Huffington Post, TechCrunch, and products such as Alto, Pip, and Vivv.
AOL has a global portfolio of media brands and advertising services across mobile, desktop, and TV. Services include brand integration and sponsorships through its in-house branded content arm, Partner Studio by AOL, as well as data and programmatic offerings through ad technology stack, ONE by AOL.
AOL acquired a number of businesses and technologies help to form ONE by AOL. These acquisitions included AdapTV in 2013 and Convertro, Precision Demand, and Vidible in 2014. ONE by AOL is further broken down into ONE by AOL for Publishers (formerly Vidible, AOL On Network and Be On for Publishers) and ONE by AOL for Advertisers, each of which have several sub-platforms.
On 10 September 2018, AOL's parent company Oath consolidated Yahoo BrightRoll, One by AOL and Yahoo Gemini to ‘simplify’ adtech service by launching a single advertising proposition dubbed Oath Ad Platforms.
AOL offers a range of integrated products and properties including communication tools, mobile apps and services and subscription packages.
AOL Desktop is an internet suite produced by AOL from 2007 that integrates a web browser, a media player and an instant messenger client. Version 10.X was based on AOL OpenRide, it is an upgrade from such. The macOS version is based on WebKit.
AOL Desktop version 10.X was different from previous AOL browsers and AOL Desktop versions. Its features are focused on web browsing as well as email. For instance, one does not have to sign into AOL in order to use it as a regular browser. In addition, non-AOL email accounts can be accessed through it. Primary buttons include "MAIL", "IM", and several shortcuts to various web pages. The first two require users to sign in, but the shortcuts to web pages can be used without authentication. AOL Desktop version 10.X was late marked as unsupported in favor of supporting the AOL Desktop 9.X versions.
Version 9.8 was released, replacing the Internet Explorer components of the internet browser with CEF (Chromium Embedded Framework) to give users an improved web browsing experience closer to that of Chrome
Version 11 of AOL Desktop, currently in Beta, is a total rewrite but maintains a similar user interface to the previous 9.8.X series of releases.
In 2017, a new paid version called AOL Desktop Gold was released, available for $4.99 per month after trial. It replaced the previous free version.
In its earlier incarnation as a "walled garden" community and service provider, AOL received criticism for its community policies, terms of service, and customer service. Prior to 2006, AOL was known for its direct mailing of CD-ROMs and 3.5-inch floppy disks containing its software. The disks were distributed in large numbers; at one point, half of the CDs manufactured worldwide had AOL logos on them. The marketing tactic was criticized for its environmental cost, and AOL CDs were recognized as "PC World"s most annoying tech product.
AOL used a system of volunteers to moderate its chat rooms, forums and user communities. The program dated back to AOL's early days, when it charged by the hour for access and one of its highest billing services was chat. AOL provided free access to community leaders in exchange for moderating the chat rooms, and this effectively made chat very cheap to operate, and more lucrative than AOL's other services of the era. There were 33,000 community leaders in 1996. All community leaders received hours of training and underwent a probationary period. While most community leaders moderated chat rooms, some ran AOL communities and controlled their layout and design, with as much as 90% of AOL's content being created or overseen by community managers until 1996.
By 1996, ISPs were beginning to charge flat rates for unlimited access, which they could do at a profit because they only provided internet access. Even though AOL would lose money with such a pricing scheme, it was forced by market conditions to offer unlimited access in October 1996. In order to return to profitability, AOL rapidly shifted its focus from content creation to advertising, resulting in less of a need to carefully moderate every forum and chat room to keep users willing to pay by the minute to remain connected.
After unlimited access, AOL considered scrapping the program entirely, but continued it with a reduced number of community leaders, with scaled-back roles in creating content. Although community leaders continued to receive free access, after 1996 they were motivated more by the prestige of the position and the access to moderator tools and restricted areas within AOL. By 1999, there were over 15,000 volunteers in the program.
In May 1999, two former volunteers filed a class-action lawsuit alleging AOL violated the Fair Labor Standards Act by treating volunteers like employees. Volunteers had to apply for the position, commit to working for at least three to four hours a week, fill out timecards and sign a non-disclosure agreement. On July 22, AOL ended its youth corps, which consisted of 350 underage community leaders. At this time, the United States Department of Labor began an investigation into the program, but it came to no conclusions about AOL's practices.
AOL ended its community leader program on June 8, 2005. The class action lawsuit dragged on for years, even after AOL ended the program and AOL declined as a major internet company. In 2010, AOL finally agreed to settle the lawsuit for $15 million. The community leader program was found to be an example of co-production in a 2009 article in International Journal of Cultural Studies.
AOL has faced a number of lawsuits over claims that it has been slow to stop billing customers after their accounts have been canceled, either by the company or the user. In addition, AOL changed its method of calculating used minutes in response to a class action lawsuit. Previously, AOL would add 15 seconds to the time a user was connected to the service and round up to the next whole minute (thus, a person who used the service for 12 minutes and 46 seconds would be charged for 14 minutes). AOL claimed this was to account for sign on/sign off time, but because this practice was not made known to its customers, the plaintiffs won (some also pointed out that signing on and off did not always take 15 seconds, especially when connecting via another ISP). AOL disclosed its connection-time calculation methods to all of its customers and credited them with extra free hours. In addition, the AOL software would notify the user of exactly how long they were connected and how many minutes they were being charged.
AOL was sued by the Ohio Attorney General in October 2003 for improper billing practices. The case was settled on June 8, 2005. AOL agreed to resolve any consumer complaints filed with the Ohio AG's office. In December 2006, AOL agreed to provide restitution to Florida consumers to settle the case filed against them by the Florida Attorney General.
Many customers complained that AOL personnel ignored their demands to cancel service and stop billing. In response to approximately 300 consumer complaints, the New York Attorney General's office began an inquiry of AOL's customer service policies. The investigation revealed that the company had an elaborate scheme for rewarding employees who purported to retain or "save" subscribers who had called to cancel their Internet service. In many instances, such retention was done against subscribers' wishes, or without their consent. Under the scheme, customer service personnel received bonuses worth tens of thousands of dollars if they could successfully dissuade or "save" half of the people who called to cancel service. For several years, AOL had instituted minimum retention or "save" percentages, which consumer representatives were expected to meet. These bonuses, and the minimum "save" rates accompanying them, had the effect of employees not honoring cancellations, or otherwise making cancellation unduly difficult for consumers.
On August 24, 2005, America Online agreed to pay $1.25 million to the state of New York and reformed its customer service procedures. Under the agreement, AOL would no longer require its customer service representatives to meet a minimum quota for customer retention in order to receive a bonus. However the agreement only covered people in the state of New York.
On June 13, 2006, Vincent Ferrari documented his account cancellation phone call in a blog post, stating he had switched to broadband years earlier. In the recorded phone call, the AOL representative refused to cancel the account unless the 30-year-old Ferrari explained why AOL hours were still being recorded on it. Ferrari insisted that AOL software was not even installed on the computer. When Ferrari demanded that the account be canceled regardless, the AOL representative asked to speak with Ferrari's father, for whom the account had been set up. The conversation was aired on CNBC. When CNBC reporters tried to have an account on AOL cancelled, they were hung up on immediately and it ultimately took more than 45 minutes to cancel the account.
On July 19, 2006, AOL's entire retention manual was released on the Internet. On August 3, 2006, Time Warner announced that the company would be dissolving AOL's retention centers due to its profits hinging on $1 billion in cost cuts. The company estimated that it would lose more than six million subscribers over the following year.
Prior to 2006, AOL was infamous for the unsolicited mass direct mail of 3½" floppy disks and CD-ROMs containing their software. They were the most frequent user of this marketing tactic, and received criticism for the environmental cost of the campaign. According to "PC World", in the 1990s "you couldn't open a magazine ("PC World" included) or your mailbox without an AOL disk falling out of it".
The mass distribution of these disks was seen as wasteful by the public and led to protest groups. One such was No More AOL CDs, a web-based effort by two IT workers to collect one million disks with the intent to return the disks to AOL. The website was started in August 2001, and an estimated 410,176 CDs were collected by August 2007 when the project was shut down.
In 2000, AOL was served with an $8 billion lawsuit alleging that its AOL 5.0 software caused significant difficulties for users attempting to use third-party Internet service providers. The lawsuit sought damages of up to $1000 for each user that had downloaded the software cited at the time of the lawsuit. AOL later agreed to a settlement of $15 million, without admission of wrongdoing. The AOL software then was given a feature called AOL Dialer, or AOL Connect on . This feature allowed users to connect to the ISP without running the full interface. This allowed users to use only the applications they wish to use, especially if they do not favor the AOL Browser.
AOL 9.0 was once identified by Stopbadware as being "under investigation" for installing additional software without disclosure, and modifying browser preferences, toolbars, and icons. However, as of the release of AOL 9.0 VR (Vista Ready) on January 26, 2007, it was no longer considered badware due to changes AOL made in the software.
When AOL gave clients access to Usenet in 1993, they hid at least one newsgroup in standard list view: "alt.aol-sucks". AOL did list the newsgroup in the alternative description view, but changed the description to "Flames and complaints about America Online". With AOL clients swarming Usenet newsgroups, the old, existing user base started to develop a strong distaste for both AOL and its clients, referring to the new state of affairs as Eternal September.
AOL discontinued access to Usenet on June 25, 2005. No official details were provided as to the cause of decommissioning Usenet access, except providing users the suggestion to access Usenet services from a third-party, Google Groups. AOL then provided community-based message boards in lieu of Usenet.
AOL has a detailed set of guidelines and expectations for users on their service, known as the Terms of Service (TOS, also known as Conditions of Service, or COS in the UK). It is separated into three different sections: "Member Agreement", "Community Guidelines" and "Privacy Policy". All three agreements are presented to users at time of registration and digital acceptance is achieved when they access the AOL service. During the period when volunteer chat room hosts and board monitors were used, chat room hosts were given a brief online training session and test on Terms of Service violations.
There have been many complaints over rules that govern an AOL user's conduct. Some users disagree with the TOS, citing the guidelines are too strict to follow coupled with the fact the TOS may change without users being made aware. A considerable cause for this was likely due to alleged censorship of user-generated content during the earlier years of growth for AOL.
In early 2005, AOL stated its intention to implement a certified email system called Goodmail, which will allow companies to send email to users with whom they have pre-existing business relationships, with a visual indication that the email is from a trusted source and without the risk that the email messages might be blocked or stripped by spam filters.
This decision drew fire from MoveOn, which characterized the program as an "email tax", and the Electronic Frontier Foundation (EFF), which characterized it as a shakedown of non-profits. A website called Dearaol.com was launched, with an online petition and a blog that garnered hundreds of signatures from people and organizations expressing their opposition to AOL's use of Goodmail.
Esther Dyson defended the move in an editorial in "The New York Times", saying "I hope Goodmail succeeds, and that it has lots of competition. I also think it and its competitors will eventually transform into services that more directly serve the interests of mail recipients. Instead of the fees going to Goodmail and AOL, they will also be shared with the individual recipients."
Tim Lee of the Technology Liberation Front posted an article that questioned the Electronic Frontier Foundation's adopting a confrontational posture when dealing with private companies. Lee's article cited a series of discussions on Declan McCullagh's Politechbot mailing list on this subject between the EFF's Danny O'Brien and antispammer Suresh Ramasubramanian, who has also compared the EFF's tactics in opposing Goodmail to tactics used by Republican political strategist Karl Rove. SpamAssassin developer Justin Mason posted some criticism of the EFF's and Moveon's "going overboard" in their opposition to the scheme.
The dearaol.com campaign lost momentum and disappeared, with the last post to the now defunct dearaol.com blog—"AOL starts the shakedown" being made on May 9, 2006.
Comcast, who also used the service, announced on its website that Goodmail had ceased operations and as of February 4, 2011 they no longer used the service.
On August 4, 2006, AOL released a compressed text file on one of its websites containing 20 million search keywords for over 650,000 users over a 3-month period between March 1, 2006 and May 31, intended for research purposes. AOL pulled the file from public access by August 7, but not before its wide distribution on the Internet by others. Derivative research, titled "A Picture of Search" was published by authors Pass, Chowdhury and Torgeson for The First International Conference on Scalable Information Systems.
The data were used by websites such as AOLstalker for entertainment purposes, where users of AOLstalker are encouraged to judge AOL clients based on the humorousness of personal details revealed by search behavior.
In 2003, Jason Smathers, an AOL employee, was convicted of stealing America Online's 92 million screen names and selling them to a known spammer. Smathers pled guilty to conspiracy charges in 2005. Smathers pled guilty to violations of the US CAN-SPAM Act of 2003. He was sentenced in August 2005 to 15 months in prison; the sentencing judge also recommended Smathers be forced to pay $84,000 in restitution, triple the $28,000 that he sold the addresses for.
On February 27, 2012, a class action lawsuit was filed against Support.com, Inc. and partner AOL, Inc. The lawsuit alleged Support.com and AOL's Computer Checkup "scareware" (which uses software developed by Support.com) misrepresented that their software programs would identify and resolve a host of technical problems with computers, offered to perform a free “scan,” which often found problems with users' computers. The companies then offered to sell software—for which AOL allegedly charged $4.99 a month and Support.com $29—to remedy those problems. Both AOL, Inc. and Support.com, Inc. settled on May 30, 2013, for $8.5 million. This included $25.00 to each valid class member and $100,000 each to Consumer Watchdog and the Electronic Frontier Foundation. Judge Jacqueline Scott Corley wrote: “Distributing a portion of the [funds] to Consumer Watchdog will meet the interests of the silent class members because the organization will use the funds to help protect consumers across the nation from being subject to the types of fraudulent and misleading conduct that is alleged here,” and “EFF’s mission includes a strong consumer protection component, especially in regards to online protection.”
AOL continues to market Computer Checkup. It is not clear if this latest Computer Checkup continues to use scareware techniques.
Following media reports about PRISM, NSA's massive electronic surveillance program, in June 2013, several technology companies were identified as participants, including AOL. According to leaks of said program, AOL joined the PRISM program in 2011.
At one time, most AOL users had an online "profile" hosted by the AOL Hometown service. When AOL Hometown was discontinued, users had to create a new profile on Bebo. This was an unsuccessful attempt to create a social network that would compete with Facebook. When the value of Bebo decreased to a tiny fraction of the $850 million AOL paid for it, users were forced to recreate their profiles yet again, on a new service called AOL Lifestream.
AOL took the decision to shut down Lifestream on February 24, 2017, and gave users one month's notice to save off photos and videos that had been uploaded to Lifestream. Following the shutdown, AOL no longer provides any option for hosting user profiles.
During the Hometown/Bebo/Lifestream era, another user's profile could be displayed by clicking the "Buddy Info" button in the AOL Desktop software. After the shutdown of Lifestream, clicking "Buddy Info" does something that provides no information whatsoever about the selected buddy: it causes the AIM home page (www.aim.com) to be displayed.

</doc>
<doc id="1400" url="https://en.wikipedia.org/wiki?curid=1400" title="Anno Domini">
Anno Domini

The terms (AD) and before Christ (BC) are used to label or number years in the Julian and Gregorian calendars. The term "" is Medieval Latin and means "in the year of the Lord", but is often presented using "our Lord" instead of "the Lord", taken from the full original phrase "anno Domini nostri Jesu Christi", which translates to "in the year of our Lord Jesus Christ".
This calendar era is based on the traditionally reckoned year of the conception or birth of Jesus of Nazareth, with "AD" counting years from the start of this epoch, and "BC" denoting years before the start of the era. There is no year zero in this scheme, so the year AD 1 immediately follows the year 1 BC. This dating system was devised in 525 by Dionysius Exiguus of Scythia Minor, but was not widely used until after 800.
The Gregorian calendar is the most widely used calendar in the world today. For decades, it has been the unofficial global standard, adopted in the pragmatic interests of international communication, transportation, and commercial integration, and recognized by international institutions such as the United Nations.
Traditionally, English follows Latin usage by placing the "AD" abbreviation before the year number. However, BC is placed after the year number (for example: AD , but 68 BC), which also preserves syntactic order. The abbreviation is also widely used after the number of a century or millennium, as in "fourth century AD" or "second millennium AD" (although conservative usage formerly rejected such expressions). Because BC is the English abbreviation for "Before Christ", it is sometimes incorrectly concluded that AD means "After Death", i.e., after the death of Jesus. However, this would mean that the approximate 33 years commonly associated with the life of Jesus would be included in neither the BC nor the AD time scales.
Terminology that is viewed by some as being more neutral and inclusive of non-Christian people is to call this the Current or Common Era (abbreviated as CE), with the preceding years referred to as Before the Common or Current Era (BCE). Astronomical year numbering and ISO 8601 avoid words or abbreviations related to Christianity, but use the same numbers for AD years.
The "Anno Domini" dating system was devised in 525 by Dionysius Exiguus to enumerate the years in his Easter table. His system was to replace the Diocletian era that had been used in an old Easter table because he did not wish to continue the memory of a tyrant who persecuted Christians. The last year of the old table, Diocletian Anno Martyrium 247, was immediately followed by the first year of his table, Anno Domini 532. When he devised his table, Julian calendar years were identified by naming the consuls who held office that year—he himself stated that the "present year" was "the consulship of Probus Junior", which was 525 years "since the incarnation of our Lord Jesus Christ". Thus Dionysius implied that Jesus' incarnation occurred 525 years earlier, without stating the specific year during which his birth or conception occurred. "However, nowhere in his exposition of his table does Dionysius relate his epoch to any other dating system, whether consulate, Olympiad, year of the world, or regnal year of Augustus; much less does he explain or justify the underlying date."
Bonnie J. Blackburn and Leofranc Holford-Strevens briefly present arguments for 2 BC, 1 BC, or AD 1 as the year Dionysius intended for the Nativity or incarnation. Among the sources of confusion are:
It is not known how Dionysius established the year of Jesus's birth. Two major theories are that Dionysius based his calculation on the Gospel of Luke, which states that Jesus was "about thirty years old" shortly after "the fifteenth year of the reign of Tiberius Caesar", and hence subtracted thirty years from that date, or that Dionysius counted back 532 years from the first year of his new table.
It has also been speculated by Georges Declercq that Dionysius' desire to replace Diocletian years with a calendar based on the incarnation of Christ was intended to prevent people from believing the imminent end of the world. At the time, it was believed by some that the resurrection of the dead and end of the world would occur 500 years after the birth of Jesus. The old "Anno Mundi" calendar theoretically commenced with the creation of the world based on information in the Old Testament. It was believed that, based on the "Anno Mundi" calendar, Jesus was born in the year 5500 (5500 years after the world was created) with the year 6000 of the "Anno Mundi" calendar marking the end of the world. "Anno Mundi" 6000 (approximately AD 500) was thus equated with the end of the world but this date had already passed in the time of Dionysius.
The Anglo-Saxon historian Saint (Venerable) Bede, who was familiar with the work of Dionysius Exiguus, used "Anno Domini" dating in his "Ecclesiastical History of the English People", which he completed in AD 731. In the "History" he also used the Latin phrase "ante [...] incarnationis dominicae tempus anno sexagesimo" ("in the sixtieth year before the time of the Lord's incarnation"), which is equivalent to the English "before Christ", to identify years before the first year of this era. Both Dionysius and Bede regarded "Anno Domini" as beginning at the incarnation of Jesus Christ, but "the distinction between Incarnation and Nativity was not drawn until the late 9th century, when in some places the Incarnation epoch was identified with Christ's conception, i. e., the Annunciation on March 25" ("Annunciation style" dating).
On the continent of Europe, "Anno Domini" was introduced as the era of choice of the Carolingian Renaissance by the English cleric and scholar Alcuin in the late eighth century. Its endorsement by Emperor Charlemagne and his successors popularizing the use of the epoch and spreading it throughout the Carolingian Empire ultimately lies at the core of the system's prevalence. According to the Catholic Encyclopedia, popes continued to date documents according to regnal years for some time, but usage of AD gradually became more common in Catholic countries from the 11th to the 14th centuries. In 1422, Portugal became the last Western European country to switch to the system begun by Dionysius. Eastern Orthodox countries only began to adopt AD instead of the Byzantine calendar in 1700 when Russia did so, with others adopting it in the 19th and 20th centuries.
Although "Anno Domini" was in widespread use by the 9th century, the term "Before Christ" (or its equivalent) did not become common until much later. Bede used the expression "anno [...] ante incarnationem Dominicam" (in the year before the incarnation of the Lord) twice. "Anno ante Christi nativitatem" (in the year before the birth of Christ) is found in 1474 in a work by a German monk. In 1627, the French Jesuit theologian Denis Pétau (Dionysius Petavius in Latin), with his work "De doctrina temporum", popularized the usage "ante Christum" (Latin for "Before Christ") to mark years prior to AD.
When the reckoning from Jesus' incarnation began replacing the previous dating systems in western Europe, various people chose different Christian feast days to begin the year: Christmas, Annunciation, or Easter. Thus, depending on the time and place, the year number changed on different days in the year, which created slightly different styles in chronology:
With these various styles, the same day could, in some cases, be dated in 1099, 1100 or 1101.
The date of birth of Jesus of Nazareth is not stated in the gospels or in any secular text, but most scholars assume a date of birth between 6 BC and 4 BC. The historical evidence is too fragmentary to allow a definitive dating, but the date is estimated through two different approaches – one by analyzing references to known historical events mentioned in the Nativity accounts in the Gospels of Luke and Matthew, and the second by working backwards from the estimation of the start of the ministry of Jesus.
During the first six centuries of what would come to be known as the Christian era, European countries used various systems to count years. Systems in use included consular dating, imperial regnal year dating, and Creation dating.
Although the last non-imperial consul, Basilius, was appointed in 541 by Emperor Justinian I, later emperors through Constans II (641–668) were appointed consuls on the first of January after their accession. All of these emperors, except Justinian, used imperial post-consular years for the years of their reign, along with their regnal years. Long unused, this practice was not formally abolished until Novell XCIV of the law code of Leo VI did so in 888.
Another calculation had been developed by the Alexandrian monk Annianus around the year AD 400, placing the Annunciation on 25 March AD 9 (Julian)—eight to ten years after the date that Dionysius was to imply. Although this incarnation was popular during the early centuries of the Byzantine Empire, years numbered from it, an "Era of Incarnation", were exclusively used and are still used in Ethiopia. This accounts for the seven- or eight-year discrepancy between the Gregorian and Ethiopian calendars. Byzantine chroniclers like Maximus the Confessor, George Syncellus, and Theophanes dated their years from Annianus' creation of the world. This era, called "Anno Mundi", "year of the world" (abbreviated AM), by modern scholars, began its first year on 25 March 5492 BC. Later Byzantine chroniclers used "Anno Mundi" years from 1 September 5509 BC, the Byzantine Era. No single "Anno Mundi" epoch was dominant throughout the Christian world. Eusebius of Caesarea in his "Chronicle" used an era beginning with the birth of Abraham, dated in 2016 BC (AD 1 = 2017 Anno Abrahami).
Spain and Portugal continued to date by the Spanish Era (also called Era of the Caesars), which began counting from 38 BC, well into the Middle Ages. In 1422, Portugal became the last Catholic country to adopt the "Anno Domini" system.
The Era of Martyrs, which numbered years from the accession of Diocletian in 284, who launched the most severe persecution of Christians, was used by the Church of Alexandria and is still used, officially, by the Coptic Orthodox and Coptic Catholic churches. It was also used by the Ethiopian church. Another system was to date from the crucifixion of Jesus, which as early as Hippolytus and Tertullian was believed to have occurred in the consulate of the Gemini (AD 29), which appears in some medieval manuscripts.
Alternative names for the "Anno Domini" era include "vulgaris aerae" (found 1615 in Latin),
"Vulgar Era" (in English, as early as 1635),
"Christian Era" (in English, in 1652),
"Common Era" (in English, 1708),
and "Current Era".
Since 1856, the alternative abbreviations CE and BCE, (sometimes written C.E. and B.C.E.) are sometimes used in place of AD and BC.
The "Common/Current Era" ("CE") terminology is often preferred by those who desire a term that does not explicitly make religious references.
For example, Cunningham and Starr (1998) write that "B.C.E./C.E. […] do not presuppose faith in Christ and hence are more appropriate for interfaith dialog than the conventional B.C./A.D." Upon its foundation, the Republic of China adopted the Minguo Era, but used the Western calendar for international purposes. The translated term was (). Later, in 1949, the People's Republic of China adopted () for all purposes domestic and foreign.
In the AD year numbering system, whether applied to the Julian or Gregorian calendars, AD 1 is immediately preceded by 1 BC, with nothing in between them (there was no year zero). There are debates as to whether a new decade, century, or millennium begins on a year ending in zero or one.
For computational reasons, astronomical year numbering and the ISO 8601 standard designate years so that AD 1 = year 1, 1 BC = year 0, 2 BC = year −1, etc. In common usage, ancient dates are expressed in the Julian calendar, but ISO 8601 uses the Gregorian calendar and astronomers may use a variety of time scales depending on the application. Thus dates using the year 0 or negative years may require further investigation before being converted to BC or AD.

</doc>
<doc id="1404" url="https://en.wikipedia.org/wiki?curid=1404" title="AV">
AV

AV and variants may refer to:

</doc>
<doc id="1408" url="https://en.wikipedia.org/wiki?curid=1408" title="Alcuin">
Alcuin

Alcuin of York (; ; 735 – 19 May 804) – also called Ealhwine, Alhwin, or Alchoin – was an English scholar, clergyman, poet, and teacher from York, Northumbria. He was born around 735 and became the student of Archbishop Ecgbert at York. At the invitation of Charlemagne, he became a leading scholar and teacher at the Carolingian court, where he remained a figure in the 780s and 790s. During this period, he perfected Carolingian minuscule, an easily read manuscript hand using a mixture of upper- and lower-case letters. Latin paleography in the eighth century leaves little room for a single origin of the script, and sources contradict his importance as no proof has been found of his direct involvement in the creation of the script. Carolingian minuscule was already in use before Alcuin arrived in Francia. Most likely he was responsible for copying and preserving the script while at the same time restoring the purity of the form. 
Alcuin wrote many theological and dogmatic treatises, as well as a few grammatical works and a number of poems. In 796, he was made abbot of Marmoutier Abbey, in Tours, where he remained until his death. "The most learned man anywhere to be found", according to Einhard's "Life of Charlemagne" (c. 817–833), he is considered among the most important architects of the Carolingian Renaissance. Among his pupils were many of the dominant intellectuals of the Carolingian era.
Alcuin was born in Northumbria, presumably sometime in the 730s. Virtually nothing is known of his parents, family background, or origin. In common hagiographical fashion, the "Vita Alcuini" asserts that Alcuin was "of noble English stock", and this statement has usually been accepted by scholars. Alcuin's own work only mentions such collateral kinsmen as Wilgils, father of the missionary saint Willibrord; and Beornrad (also spelled Beornred), abbot of Echternach and bishop of Sens. Willibrord, Alcuin and Beornrad were all related by blood.
In his "Life" of St Willibrord, Alcuin writes that Wilgils, called a "paterfamilias", had founded an oratory and church at the mouth of the Humber, which had fallen into Alcuin's possession by inheritance. Because in early Anglo-Latin writing "paterfamilias" ("head of a family, householder") usually referred to a ("churl"), Donald A. Bullough suggests that Alcuin's family was of ("churlish") status: i.e., free but subordinate to a noble lord, and that Alcuin and other members of his family rose to prominence through beneficial connections with the aristocracy. If so, Alcuin's origins may lie in the southern part of what was formerly known as Deira.
The young Alcuin came to the cathedral church of York during the golden age of Archbishop Ecgbert and his brother, the Northumbrian King Eadberht. Ecgbert had been a disciple of the Venerable Bede, who urged him to raise York to an archbishopric. King Eadberht and Archbishop Ecgbert oversaw the re-energising and reorganisation of the English church, with an emphasis on reforming the clergy and on the tradition of learning that Bede had begun. Ecgbert was devoted to Alcuin, who thrived under his tutelage.
The York school was renowned as a centre of learning in the liberal arts, literature, and science, as well as in religious matters. From here, Alcuin drew inspiration for the school he would lead at the Frankish court. He revived the school with the trivium and quadrivium disciplines, writing a codex on the trivium, while his student Hraban wrote one on the quadrivium.
Alcuin graduated to become a teacher during the 750s. His ascendancy to the headship of the York school, the ancestor of St Peter's School, began after Aelbert became Archbishop of York in 767. Around the same time, Alcuin became a deacon in the church. He was never ordained a priest. Though no real evidence shows that he took monastic vows, he lived as if he had.
In 781, King Elfwald sent Alcuin to Rome to petition the pope for official confirmation of York's status as an archbishopric and to confirm the election of the new archbishop, Eanbald I. On his way home, he met Charlemagne (whom he had met once before), this time in the Italian city of Parma.
Alcuin's intellectual curiosity allowed him to be reluctantly persuaded to join Charlemagne's court. He joined an illustrious group of scholars whom Charlemagne had gathered around him, the mainsprings of the Carolingian Renaissance: Peter of Pisa, Paulinus of Aquileia, Rado, and Abbot Fulrad. Alcuin would later write, "the Lord was calling me to the service of King Charles".
Alcuin became master of the Palace School of Charlemagne in Aachen () in 782. It had been founded by the king's ancestors as a place for the education of the royal children (mostly in manners and the ways of the court). However, Charlemagne wanted to include the liberal arts, and most importantly, the study of religion. From 782 to 790, Alcuin taught Charlemagne himself, his sons Pepin and Louis, as well as young men sent to be educated at court, and the young clerics attached to the palace chapel. Bringing with him from York his assistants Pyttel, Sigewulf, and Joseph, Alcuin revolutionised the educational standards of the Palace School, introducing Charlemagne to the liberal arts and creating a personalised atmosphere of scholarship and learning, to the extent that the institution came to be known as the 'school of Master Albinus'.
In this role as adviser, he took issue with the emperor's policy of forcing pagans to be baptised on pain of death, arguing, "Faith is a free act of the will, not a forced act. We must appeal to the conscience, not compel it by violence. You can force people to be baptised, but you cannot force them to believe." His arguments seem to have prevailed – Charlemagne abolished the death penalty for paganism in 797.
Charlemagne gathered the best men of every land in his court, and became far more than just the king at the centre. It seems that he made many of these men his closest friends and counsellors. They referred to him as 'David', a reference to the Biblical king David. Alcuin soon found himself on intimate terms with Charlemagne and the other men at court, where pupils and masters were known by affectionate and jesting nicknames. Alcuin himself was known as 'Albinus' or 'Flaccus'. While at Aachen, Alcuin bestowed pet names upon his pupils – derived mainly from Virgil's "Eclogues". According to the "Encyclopædia Britannica", "He loved Charlemagne and enjoyed the king's esteem, but his letters reveal that his fear of him was as great as his love."
In 790, Alcuin returned from the court of Charlemagne to England, to which he had remained attached. He dwelt there for some time, but Charlemagne then invited him back to help in the fight against the Adoptionist heresy, which was at that time making great progress in Toledo, the old capital of the Visigoths and still a major city for the Christians under Islamic rule in Spain. He is believed to have had contacts with Beatus of Liébana, from the Kingdom of Asturias, who fought against Adoptionism. At the Council of Frankfurt in 794, Alcuin upheld the orthodox doctrine against the views expressed by Felix of Urgel, an heresiarch according to the Catholic Encyclopaedia. Having failed during his stay in Northumbria to influence King Æthelred in the conduct of his reign, Alcuin never returned home.
He was back at Charlemagne's court by at least mid-792, writing a series of letters to Æthelred, to Hygbald, Bishop of Lindisfarne, and to Æthelhard, Archbishop of Canterbury in the succeeding months, dealing with the Viking attack on Lindisfarne in July 793. These letters and Alcuin's poem on the subject, , provide the only significant contemporary account of these events. In his description of the Viking attack, he wrote: "Never before has such terror appeared in Britain. Behold the church of St Cuthbert, splattered with the blood of God's priests, robbed of its ornaments."
In 796, Alcuin was in his 60s. He hoped to be free from court duties and upon the death of Abbot Itherius of Saint Martin at Tours, Charlemagne put Marmoutier Abbey into Alcuin's care, with the understanding that he should be available if the king ever needed his counsel. There, he encouraged the work of the monks on the beautiful Carolingian minuscule script, ancestor of modern Roman typefaces.
Alcuin died on 19 May 804, some 10 years before the emperor, and was buried at St. Martin's Church under an epitaph that partly read:
The majority of details on Alcuin's life come from his letters and poems. Also, autobiographical sections are in Alcuin's poem on York and in the "Vita Alcuini", a hagiography written for him at Ferrières in the 820s, possibly based in part on the memories of Sigwulf, one of Alcuin's pupils.
The collection of mathematical and logical word problems entitled "Propositiones ad acuendos juvenes" ("Problems to Sharpen Youths") is sometimes attributed to Alcuin. In a 799 letter to Charlemagne, the scholar claimed to have sent "certain figures of arithmetic for the joy of cleverness", which some scholars have identified with the "Propositiones."
The text contains about 53 mathematical word problems (with solutions), in no particular pedagogical order. Among the most famous of these problems are: four that involve river crossings, including the problem of three anxious brothers, each of whom has an unmarried sister whom he cannot leave alone with either of the other men lest she be defiled (Problem 17); the problem of the wolf, goat, and cabbage (Problem 18); and the problem of "the two adults and two children where the children weigh half as much as the adults" (Problem 19). Alcuin's sequence is the solution to one of the problems of that book.
Alcuin made the abbey school into a model of excellence and many students flocked to it. He had many manuscripts copied using outstandingly beautiful calligraphy, the Carolingian minuscule based on round and legible uncial letters. He wrote many letters to his English friends, to Arno, bishop of Salzburg and above all to Charlemagne. These letters (of which 311 are extant) are filled mainly with pious meditations, but they form an important source of information as to the literary and social conditions of the time and are the most reliable authority for the history of humanism during the Carolingian age. Alcuin trained the numerous monks of the abbey in piety, and in the midst of these pursuits, he died.
Alcuin is the most prominent figure of the Carolingian Renaissance, in which three main periods have been distinguished: in the first of these, up to the arrival of Alcuin at the court, the Italians occupy a central place; in the second, Alcuin and the Anglo-Saxons are dominant; in the third (from 804), the influence of Theodulf the Visigoth is preponderant.
Alcuin also developed manuals used in his educational work – a grammar and works on rhetoric and dialectics. These are written in the form of dialogues, and in two of them the interlocutors are Charlemagne and Alcuin. He wrote several theological treatises: a "De fide Trinitatis", and commentaries on the Bible. Alcuin is credited with inventing the first known question mark, though it did not resemble the modern symbol.
Alcuin transmitted to the Franks the knowledge of Latin culture, which had existed in Anglo-Saxon England. A number of his works still exist. Besides some graceful epistles in the style of Venantius Fortunatus, he wrote some long poems, and notably he is the author of a history (in verse) of the church at York, "Versus de patribus, regibus et sanctis Eboracensis ecclesiae". At the same time, he is noted for making one of the only explicit comments on Old English poetry surviving from the early Middle Ages, in a letter to one Speratus, the bishop of an unnamed English see (possibly Unwona of Leicester): ("Let God's words be read at the episcopal dinner-table. It is right that a reader should be heard, not a harpist, patristic discourse, not pagan song. What has Hinield to do with Christ?").
Historian John Boswell cited Alcuin's writings as demonstrating a personal outpouring of his internalized homosexual feelings. Others agree that Alcuin at times "comes perilously close to communicating openly his same-sex desires", and this reflects the erotic subculture of the Carolingian monastic school, but also perhaps a 'queer space' where "erotic attachment and affections may be safely articulated". According to David Clark, passages in some of Alcuin's writings can be seen to display homosocial desire, even possibly homoerotic imagery. However, he argues that it is not possible to necessarily determine whether they were the result of an outward expression of erotic feelings on the part of Alcuin. 
The interpretation of homosexual desire has been disputed by Allen Frantzen, who identifies Alcuin's language with that of medieval Christian "amicitia" or friendship. Douglas Dales and Rowan Williams say "the use of language drawn [by Alcuin] from the "Song of Songs" transforms apparently erotic language into something within Christian friendship – 'an ordained affection.
Alcuin was also a close friend of Charlemagne's sister Gisela, Abbess of Chelles, and he hailed her as "a noble sister in the bond of sweet love". He wrote to Charlemagne's daughters Rotrudis and Bertha, "the devotion of my heart specially tends towards you both because of the familiarity and dedication you have shown me". He dedicated the last two books of his commentary on John's gospel to them both.
Despite inconclusive evidence of Alcuin's personal passions, he was clear in his own writings that the men of Sodom had been punished with fire for "sinning against nature with men" – a view commonly held by the Church at the time. Such sins, argued Alcuin, were therefore more serious than lustful acts with women, for which the earth was cleansed and revivified by the water of the Flood, and merit to be "withered by flames unto eternal barrenness".
In several churches of the Anglican Communion, Alcuin is celebrated on 20 May, the first available day after the day of his death (as Dunstan is celebrated on 19 May).
Alcuin College, one of the colleges of the University of York, England, is named after him.
In January 2020, Alcuin was the subject of the BBC Radio 4 programme "In Our Time".
For a complete census of Alcuin's works, see Marie-Hélène Jullien and Françoise Perelman, eds., "Clavis scriptorum latinorum medii aevi: Auctores Galliae 735–987. Tomus II: Alcuinus." Turnhout: Brepols, 1999.
Of Alcuin's letters, just over 310 have survived.

</doc>
<doc id="1409" url="https://en.wikipedia.org/wiki?curid=1409" title="Angilbert">
Angilbert

Angilbert ( – 18 February 814), sometimes known as Saint Angilbert or Angilberk or Engelbert, was a noble Frankish poet who was educated under Alcuin and served Charlemagne as a secretary, diplomat, and son-in-law. He was venerated as a pre-Congregation saint and is still honored on the day of his death, 18 February.
Angilbert seems to have been brought up at the court of Charlemagne at the palace school in Aquae Grani (Aachen). He was educated there as the pupil and then friend of the great English scholar Alcuin. When Charlemagne sent his young son Pepin to Italy as King of the Lombards Angilbert went along as "primicerius palatii," a high administrator of the satellite court. As the friend and adviser of Pepin, he assisted for a while in the government of Italy. Angilbert delivered the document on Iconoclasm from the Frankish Synod of Frankfurt to Pope Adrian I, and was later sent on three important embassies to the pope, in 792, 794, and 796. At one time, he served an officer of the maritime provinces. He accompanied Charlemagne to Rome in 800 and was one of the witnesses to his will in 811.
There are various traditions concerning Angilbert's relationship with Bertha, daughter of Charlemagne. One holds that they were married, another that they were not. They had, however, at least two sons and one daughter, one of whom, Nithard, became a notable figure in the mid-9th century, and the daughter Bertha, went on to marry Helgaud II, count of Ponthieu. Control of marriage and the meanings of legitimacy were hotly contested in the Middle Ages. Bertha and Angilbert are an example of how resistance to the idea of a sacramental marriage could coincide with holding church offices. On the other hand, some historians have speculated that Charlemagne opposed formal marriages for his daughters out of concern for political rivalries from their potential husbands; none of Charlemagne's daughters were married, despite political offers of arranged marriages.
In 790, Angilbert retired to the abbey of Centulum, the "Monastery of St Richarius" () at present-day Saint-Riquier in Picardy. Elected abbot in 794, he rebuilt the monastery and endowed it with a library of 200 volumes. It was not uncommon for the Merovingian, Carolingian, or later kings to make laymen abbots of monasteries; the layman would often use the income of the monastery as his own and leave the monks a bare minimum for the necessary expenses of the foundation. Angilbert, in contrast, spent a great deal rebuilding Saint-Riquier; when he completed it, Charlemagne spent Easter of the year 800 there. In keeping with Carolingian policies, Angilbert established a school at Saint-Riquier to educate the local boys.
Angilbert's Latin poems reveal the culture and tastes of a man of the world, enjoying the closest intimacy with the imperial family. Charlemagne and the other men at court were known by affectionate and jesting nicknames. Charlemagne was referred to as "David", a reference to the Biblical king David. Angilbert was nicknamed "Homer" because he wrote poetry, and was the probable author of an epic, of which the fragment which has been preserved describes the life at the palace and the meeting between Charlemagne and Leo III. It is a mosaic from Virgil, Ovid, Lucan and Venantius Fortunatus, composed in the manner of Einhard's use of Suetonius. Of the shorter poems, besides the greeting to Pippin on his return from the campaign against the Avars (796), an epistle to David (i.e., Charlemagne) incidentally reveals a delightful picture of the poet living with his children in a house surrounded by pleasant gardens near the emperor's palace. The reference to Bertha, however, is distant and respectful, her name occurring merely on the list of princesses to whom he sends his salutation.
Angilbert's poems were published by Ernst Dümmler in the "Monumenta Germaniae Historica". For criticisms of this edition, see Ludwig Traube in Max Roediger's "Schriften für germanische Philologie" (1888).

</doc>
<doc id="1412" url="https://en.wikipedia.org/wiki?curid=1412" title="Amine">
Amine

In organic chemistry, amines (, ) are compounds and functional groups that contain a basic nitrogen atom with a lone pair. Amines are formally derivatives of ammonia, wherein one or more hydrogen atoms have been replaced by a substituent such as an alkyl or aryl group (these may respectively be called alkylamines and arylamines; amines in which both types of substituent are attached to one nitrogen atom may be called alkylarylamines). Important amines include amino acids, biogenic amines, trimethylamine, and aniline; see for a list of amines. Inorganic derivatives of ammonia are also called amines, such as monochloramine (NClH).
The substituent -NH is called an amino group.
Compounds with a nitrogen atom attached to a carbonyl group, thus having the structure R–CO–NR′R″, are called amides and have different chemical properties from amines.
Amines can be classified according to the nature and number of substituents on nitrogen. Aliphatic amines contain only H and alkyl substituents. Aromatic amines have the nitrogen atom connected to an aromatic ring.
Amines, alkyl and aryl alike, are organized into three subcategories based on the number of carbon atoms adjacent to the nitrogen:
A fourth subcategory is determined by the connectivity of the substituents attached to the nitrogen:
It is also possible to have four organic substituents on the nitrogen. These species are not amines but are quaternary ammonium cations and have a charged nitrogen center. Quaternary ammonium salts exist with many kinds of anions.
Amines are named in several ways. Typically, the compound is given the prefix "amino-" or the suffix "-amine". The prefix ""N"-" shows substitution on the nitrogen atom. An organic compound with multiple amino groups is called a diamine, triamine, tetraamine and so forth.
Systematic names for some common amines:
Hydrogen bonding significantly influences the properties of primary and secondary amines. For example, methyl and ethyl amines are gases under standard conditions, whereas the corresponding methyl and ethyl alcohols are liquids. Amines possess a characteristic ammonia smell, liquid amines have a distinctive "fishy" smell.
The nitrogen atom features a lone electron pair that can bind H to form an ammonium ion RNH. The lone electron pair is represented in this article by a two dots above or next to the N. The water solubility of simple amines is enhanced by hydrogen bonding involving these lone electron pairs. Typically salts of ammonium compounds exhibit the following order of solubility in water: primary ammonium () > secondary ammonium () > tertiary ammonium (RNH). Small aliphatic amines display significant solubility in many solvents, whereas those with large substituents are lipophilic. Aromatic amines, such as aniline, have their lone pair electrons conjugated into the benzene ring, thus their tendency to engage in hydrogen bonding is diminished. Their boiling points are high and their solubility in water is low.
Typically the presence of an amine functional group is deduced by a combination of techniques, including mass spectrometry as well as NMR and IR spectroscopies. H NMR signals for amines disappear upon treatment of the sample with DO. In their infrared spectrum primary amines exhibit two N-H bands, whereas secondary amines exhibit only one.
Alkyl amines characteristically feature tetrahedral nitrogen centers. C-N-C and C-N-H angles approach the idealized angle of 109°. C-N distances are slightly shorter than C-C distances. The energy barrier for the nitrogen inversion of the stereocenter is about 7 kcal/mol for a trialkylamine. The interconversion has been compared to the inversion of an open umbrella into a strong wind.
Amines of the type NHRR′ and NRR′R″ are chiral: the nitrogen center bears four substituents counting the lone pair. Because of the low barrier to inversion, amines of the type NHRR′ cannot be obtained in optical purity. For chiral tertiary amines, NRR′R″ can only be resolved when the R, R′, and R″ groups are constrained in cyclic structures such as N-substituted aziridines (quaternary ammonium salts are resolvable).
In aromatic amines ("anilines"), nitrogen is often nearly planar owing to conjugation of the lone pair with the aryl substituent. The C-N distance is correspondingly shorter. In aniline, the C-N distance is the same as the C-C distances.
Like ammonia, amines are bases. Compared to alkali metal hydroxides, amines are weaker (see table for examples of conjugate acid "K" values). 
The basicity of amines depends on:
Owing to inductive effects, the basicity of an amine might be expected to increase with the number of alkyl groups on the amine. Correlations are complicated owing to the effects of solvation which are opposite the trends for inductive effects. Solvation effects also dominate the basicity of aromatic amines (anilines). For anilines, the lone pair of electrons on nitrogen delocalises into the ring, resulting in decreased basicity. Substituents on the aromatic ring, and their positions relative to the amino group, also affect basicity as seen in the table.
Solvation significantly affects the basicity of amines. N-H groups strongly interact with water, especially in ammonium ions. Consequently, the basicity of ammonia is enhanced by 10 by solvation. The intrinsic basicity of amines, i.e. the situation where solvation is unimportant, has been evaluated in the gas phase. In the gas phase, amines exhibit the basicities predicted from the electron-releasing effects of the organic substituents. Thus tertiary amines are more basic than secondary amines, which are more basic than primary amines, and finally ammonia is least basic. The order of pK's (basicities in water) does not follow this order. Similarly aniline is more basic than ammonia in the gas phase, but ten thousand times less so in aqueous solution.
In aprotic polar solvents such as DMSO, DMF, and acetonitrile the energy of solvation is not as high as in protic polar solvents like water and methanol. For this reason, the basicity of amines in these aprotic solvents is almost solely governed by the electronic effects.
Industrially significant amines are prepared from ammonia by alkylation with alcohols:
Unlike the reaction of amines with alkyl halides, the industrial method is green insofar that the coproduct is water. The reaction of amines and ammonia with alkyl halides is used for synthesis in the laboratory:
Such reactions, which are most useful for alkyl iodides and bromides, are rarely employed because the degree of alkylation is difficult to control. Selectivity can be improved via the Delépine reaction, although this is rarely employed on an industrial scale.
Disubstituted alkenes react with HCN in the presence of strong acids to give formamides, which can be decarbonylated. This method, the Ritter reaction, can be used industrially to produce tertiary amines such a tert-octylamine.
Hydroamination of alkenes is also widely practiced. The reaction is catalyzed by zeolite-based solid acids.
Via the process of hydrogenation, nitriles are reduced to amines using hydrogen in the presence of a nickel catalyst. Reactions are sensitive to acidic or alkaline conditions, which can cause hydrolysis of the –CN group. LiAlH is more commonly employed for the reduction of nitriles on the laboratory scale. Similarly, LiAlH reduces amides to amines. Many amines are produced from aldehydes and ketones via reductive amination, which can either proceed catalytically or stoichiometrically.
Aniline (CHNH) and its derivatives are prepared by reduction of the nitroaromatics. In industry, hydrogen is the preferred reductant, whereas, in the laboratory, tin and iron are often employed.
Many methods exist for the preparation of amines, many of these methods being rather specialized.
Aside from their basicity, the dominant reactivity of amines is their nucleophilicity. Most primary amines are good ligands for metal ions to give coordination complexes. Amines are alkylated by alkyl halides. Acyl chlorides and acid anhydrides react with primary and secondary amines to form amides (the "Schotten–Baumann reaction").
Similarly, with sulfonyl chlorides, one obtains sulfonamides. This transformation, known as the Hinsberg reaction, is a chemical test for the presence of amines.
Because amines are basic, they neutralize acids to form the corresponding ammonium salts RNH. When formed from carboxylic acids and primary and secondary amines, these salts thermally dehydrate to form the corresponding amides.
Amines react with nitrous acid to give diazonium salts. The alkyl diazonium salts are of little synthetic importance because they are too unstable. The most important members are derivatives of aromatic amines such as aniline ("phenylamine") (A = aryl or naphthyl):
Anilines and naphthylamines form more stable diazonium salts, which can be isolated in the crystalline form. Diazonium salts undergo a variety of useful transformations involving replacement of the N group with anions. For example, cuprous cyanide gives the corresponding nitriles:
Aryldiazonium couple with electron-rich aromatic compounds such as a phenol to form azo compounds. Such reactions are widely applied to the production of dyes.
Imine formation is an important reaction. Primary amines react with ketones and aldehydes to form imines. In the case of formaldehyde (R′  H), these products typically exist as cyclic trimers.
Reduction of these imines gives secondary amines:
Similarly, secondary amines react with ketones and aldehydes to form enamines:
An overview of the reactions of amines is given below:
Amines are ubiquitous in biology. The breakdown of amino acids releases amines, famously in the case of decaying fish which smell of trimethylamine. Many neurotransmitters are amines, including epinephrine, norepinephrine, dopamine, serotonin, and histamine. Protonated amino groups () are the most common positively charged moieties in proteins, specifically in the amino acid lysine. The anionic polymer DNA is typically bound to various amine-rich proteins. Additionally, the terminal charged primary ammonium on lysine forms salt bridges with carboxylate groups of other amino acids in polypeptides, which is one of the primary influences on the three-dimensional structures of proteins.
Primary aromatic amines are used as a starting material for the manufacture of azo dyes. It reacts with nitrous acid to form diazonium salt, which can undergo coupling reaction to form an azo compound. As azo-compounds are highly coloured, they are widely used in dyeing industries, such as:
Many drugs are designed to mimic or to interfere with the action of natural amine neurotransmitters, exemplified by the amine drugs:
Aqueous monoethanolamine (MEA), diglycolamine (DGA), diethanolamine (DEA), diisopropanolamine (DIPA) and methyldiethanolamine (MDEA) are widely used industrially for removing carbon dioxide (CO) and hydrogen sulfide (HS) from natural gas and refinery process streams. They may also be used to remove CO from combustion gases and flue gases and may have potential for abatement of greenhouse gases. Related processes are known as sweetening.
Low molecular weight simple amines, such as ethylamine, are only weakly toxic with between 100 and 1000 mg/kg. They are skin irritants, especially as some are easily absorbed through the skin. Amines are a broad class of compounds, and more complex members of the class can be extremely bioactive, for example strychnine and heroin.

</doc>
<doc id="1416" url="https://en.wikipedia.org/wiki?curid=1416" title="April 29">
April 29


</doc>
<doc id="1417" url="https://en.wikipedia.org/wiki?curid=1417" title="August 14">
August 14


</doc>
<doc id="1418" url="https://en.wikipedia.org/wiki?curid=1418" title="Absolute zero">
Absolute zero

Absolute zero is the lowest limit of the thermodynamic temperature scale, a state at which the enthalpy and entropy of a cooled ideal gas reach their minimum value, taken as zero kelvins. The fundamental particles of nature have minimum vibrational motion, retaining only quantum mechanical, zero-point energy-induced particle motion. The theoretical temperature is determined by extrapolating the ideal gas law; by international agreement, absolute zero is taken as −273.15° on the Celsius scale (International System of Units), which equals −459.67° on the Fahrenheit scale (United States customary units or Imperial units). The corresponding Kelvin and Rankine temperature scales set their zero points at absolute zero by definition.
It is commonly thought of as the lowest temperature possible, but it is not the lowest "enthalpy" state possible, because all real substances begin to depart from the ideal gas when cooled as they approach the change of state to liquid, and then to solid; and the sum of the enthalpy of vaporization (gas to liquid) and enthalpy of fusion (liquid to solid) exceeds the ideal gas's change in enthalpy to absolute zero. In the quantum-mechanical description, matter (solid) at absolute zero is in its ground state, the point of lowest internal energy.
The laws of thermodynamics indicate that absolute zero cannot be reached using only thermodynamic means, because the temperature of the substance being cooled approaches the temperature of the cooling agent asymptotically, and a system at absolute zero still possesses quantum mechanical zero-point energy, the energy of its ground state at absolute zero. The kinetic energy of the ground state cannot be removed. 
Scientists and technologists routinely achieve temperatures close to absolute zero, where matter exhibits quantum effects such as superconductivity and superfluidity.
At temperatures near , nearly all molecular motion ceases and Δ"S" = 0 for any adiabatic process, where "S" is the entropy. In such a circumstance, pure substances can (ideally) form perfect crystals as "T" → 0. Max Planck's strong form of the third law of thermodynamics states the entropy of a perfect crystal vanishes at absolute zero in which a perfect crystal is gone. The original Nernst "heat theorem" makes the weaker and less controversial claim that the entropy change for any isothermal process approaches zero as "T" → 0:
The implication is that the entropy of a perfect crystal approaches a constant value.
The Nerst postulate identifies the isotherm T = 0 as coincident with the adiabat S = 0, although other isotherms and adiabats are distinct. As no two adiabats intersect, no other adiabat can intersect the T = 0 isotherm. Consequently no adiabatic process initiated at nonzero temperature can lead to zero temperature. (≈ Callen, pp. 189–190)
A perfect crystal is one in which the internal lattice structure extends uninterrupted in all directions. The perfect order can be represented by translational symmetry along three (not usually orthogonal) axes. Every lattice element of the structure is in its proper place, whether it is a single atom or a molecular grouping. For substances that exist in two (or more) stable crystalline forms, such as diamond and graphite for carbon, there is a kind of "chemical degeneracy". The question remains whether both can have zero entropy at "T" = 0 even though each is perfectly ordered.
Perfect crystals never occur in practice; imperfections, and even entire amorphous material inclusions, can and do get "frozen in" at low temperatures, so transitions to more stable states do not occur.
Using the Debye model, the specific heat and entropy of a pure crystal are proportional to "T", while the enthalpy and chemical potential are proportional to "T". (Guggenheim, p. 111) These quantities drop toward their "T" = 0 limiting values and approach with "zero" slopes. For the specific heats at least, the limiting value itself is definitely zero, as borne out by experiments to below 10 K. Even the less detailed Einstein model shows this curious drop in specific heats. In fact, all specific heats vanish at absolute zero, not just those of crystals. Likewise for the coefficient of thermal expansion. Maxwell's relations show that various other quantities also vanish. These phenomena were unanticipated.
Since the relation between changes in Gibbs free energy ("G"), the enthalpy ("H") and the entropy is
thus, as "T" decreases, Δ"G" and Δ"H" approach each other (so long as Δ"S" is bounded). Experimentally, it is found that all spontaneous processes (including chemical reactions) result in a decrease in "G" as they proceed toward equilibrium. If Δ"S" and/or "T" are small, the condition Δ"G" < 0 may imply that Δ"H" < 0, which would indicate an exothermic reaction. However, this is not required; endothermic reactions can proceed spontaneously if the "T"Δ"S" term is large enough.
Moreover, the slopes of the derivatives of Δ"G" and Δ"H" converge and are equal to zero at "T" = 0. This ensures that Δ"G" and Δ"H" are nearly the same over a considerable range of temperatures and justifies the approximate empirical Principle of Thomsen and Berthelot, which states that "the equilibrium state to which a system proceeds is the one that evolves the greatest amount of heat", i.e., an actual process is the "most exothermic one". (Callen, pp. 186–187)
One model that estimates the properties of an electron gas at absolute zero in metals is the Fermi gas. The electrons, being Fermions, must be in different quantum states, which leads the electrons to get very high typical velocities, even at absolute zero. The maximum energy that electrons can have at absolute zero is called the Fermi energy. The Fermi temperature is defined as this maximum energy divided by Boltzmann's constant, and is of the order of 80,000 K for typical electron densities found in metals. For temperatures significantly below the Fermi temperature, the electrons behave in almost the same way as at absolute zero. This explains the failure of the classical equipartition theorem for metals that eluded classical physicists in the late 19th century.
A Bose–Einstein condensate (BEC) is a state of matter of a dilute gas of weakly interacting bosons confined in an external potential and cooled to temperatures very near absolute zero. Under such conditions, a large fraction of the bosons occupy the lowest quantum state of the external potential, at which point quantum effects become apparent on a macroscopic scale.
This state of matter was first predicted by Satyendra Nath Bose and Albert Einstein in 1924–25. Bose first sent a paper to Einstein on the quantum statistics of light quanta (now called photons). Einstein was impressed, translated the paper from English to German and submitted it for Bose to the "Zeitschrift für Physik", which published it. Einstein then extended Bose's ideas to material particles (or matter) in two other papers.
Seventy years later, in 1995, the first gaseous condensate was produced by Eric Cornell and Carl Wieman at the University of Colorado at Boulder NIST-JILA lab, using a gas of rubidium atoms cooled to 170 nanokelvins (nK) ().
A record cold temperature of 450 ± 80 picokelvins (pK) () in a BEC of sodium atoms was achieved in 2003 by researchers at Massachusetts Institute of Technology (MIT). The associated black-body (peak emittance) wavelength of 6,400 kilometers is roughly the radius of Earth.
Absolute, or thermodynamic, temperature is conventionally measured in kelvins (Celsius-scaled increments) and in the Rankine scale (Fahrenheit-scaled increments) with increasing rarity. Absolute temperature measurement is uniquely determined by a multiplicative constant which specifies the size of the "degree", so the "ratios" of two absolute temperatures, "T"/"T", are the same in all scales. The most transparent definition of this standard comes from the Maxwell–Boltzmann distribution. It can also be found in Fermi–Dirac statistics (for particles of half-integer spin) and Bose–Einstein statistics (for particles of integer spin). All of these define the relative numbers of particles in a system as decreasing exponential functions of energy (at the particle level) over "kT", with "k" representing the Boltzmann constant and "T" representing the temperature observed at the macroscopic level.
Temperatures that are expressed as negative numbers on the familiar Celsius or Fahrenheit scales are simply colder than the zero points of those scales. Certain systems can achieve truly negative temperatures; that is, their thermodynamic temperature (expressed in kelvins) can be of a negative quantity. A system with a truly negative temperature is not colder than absolute zero. Rather, a system with a negative temperature is hotter than "any" system with a positive temperature, in the sense that if a negative-temperature system and a positive-temperature system come in contact, heat flows from the negative to the positive-temperature system.
Most familiar systems cannot achieve negative temperatures because adding energy always increases their entropy. However, some systems have a maximum amount of energy that they can hold, and as they approach that maximum energy their entropy actually begins to decrease. Because temperature is defined by the relationship between energy and entropy, such a system's temperature becomes negative, even though energy is being added. As a result, the Boltzmann factor for states of systems at negative temperature increases rather than decreases with increasing state energy. Therefore, no complete system, i.e. including the electromagnetic modes, can have negative temperatures, since there is no highest energy state, so that the sum of the probabilities of the states would diverge for negative temperatures. However, for quasi-equilibrium systems (e.g. spins out of equilibrium with the electromagnetic field) this argument does not apply, and negative effective temperatures are attainable.
On 3 January 2013, physicists announced that for the first time they had created a quantum gas made up of potassium atoms with a negative temperature in motional degrees of freedom.
One of the first to discuss the possibility of an absolute minimal temperature was Robert Boyle. His 1665 "New Experiments and Observations touching Cold", articulated the dispute known as the "primum frigidum". The concept was well known among naturalists of the time. Some contended an absolute minimum temperature occurred within earth (as one of the four classical elements), others within water, others air, and some more recently within nitre. But all of them seemed to agree that, "There is some body or other that is of its own nature supremely cold and by participation of which all other bodies obtain that quality."
The question whether there is a limit to the degree of coldness possible, and, if so, where the zero must be placed, was first addressed by the French physicist Guillaume Amontons in 1702, in connection with his improvements in the air thermometer. His instrument indicated temperatures by the height at which a certain mass of air sustained a column of mercury—the volume, or "spring" of the air varying with temperature. Amontons therefore argued that the zero of his thermometer would be that temperature at which the spring of the air was reduced to nothing. He used a scale that marked the boiling point of water at +73 and the melting point of ice at +, so that the zero was equivalent to about −240 on the Celsius scale. Amontons held that the absolute zero cannot be reached, so never attempted to compute it explicitly.
The value of −240 °C, or "431 divisions [in Fahrenheit's thermometer] below the cold of freezing water" was published by George Martine in 1740.
This close approximation to the modern value of −273.15 °C for the zero of the air thermometer was further improved upon in 1779 by Johann Heinrich Lambert, who observed that might be regarded as absolute cold.
Values of this order for the absolute zero were not, however, universally accepted about this period. Pierre-Simon Laplace and Antoine Lavoisier, in their 1780 treatise on heat, arrived at values ranging from 1,500 to 3,000 below the freezing point of water, and thought that in any case it must be at least 600 below. John Dalton in his "Chemical Philosophy" gave ten calculations of this value, and finally adopted −3,000 °C as the natural zero of temperature.
After James Prescott Joule had determined the mechanical equivalent of heat, Lord Kelvin approached the question from an entirely different point of view, and in 1848 devised a scale of absolute temperature that was independent of the properties of any particular substance and was based on Carnot's theory of the Motive Power of Heat and data published by Henri Victor Regnault. It followed from the principles on which this scale was constructed that its zero was placed at −273 °C, at almost precisely the same point as the zero of the air thermometer. This value was not immediately accepted; values ranging from to , derived from laboratory measurements and observations of astronomical refraction, remained in use in the early 20th century.
With a better theoretical understanding of absolute zero, scientists were eager to reach this temperature in the lab. By 1845, Michael Faraday had managed to liquefy most gases then known to exist, and reached a new record for lowest temperatures by reaching . Faraday believed that certain gases, such as oxygen, nitrogen, and hydrogen, were permanent gases and could not be liquefied. Decades later, in 1873 Dutch theoretical scientist Johannes Diderik van der Waals demonstrated that these gases could be liquefied, but only under conditions of very high pressure and very low temperatures. In 1877, Louis Paul Cailletet in France and Raoul Pictet in Switzerland succeeded in producing the first droplets of liquid air . This was followed in 1883 by the production of liquid oxygen by the Polish professors Zygmunt Wróblewski and Karol Olszewski.
Scottish chemist and physicist James Dewar and Dutch physicist Heike Kamerlingh Onnes took on the challenge to liquefy the remaining gases, hydrogen and helium. In 1898, after 20 years of effort, Dewar was first to liquefy hydrogen, reaching a new low-temperature record of . However, Kamerlingh Onnes, his rival, was the first to liquefy helium, in 1908, using several precooling stages and the Hampson–Linde cycle. He lowered the temperature to the boiling point of helium . By reducing the pressure of the liquid helium he achieved an even lower temperature, near 1.5 K. These were the coldest temperatures achieved on Earth at the time and his achievement earned him the Nobel Prize in 1913. Kamerlingh Onnes would continue to study the properties of materials at temperatures near absolute zero, describing superconductivity and superfluids for the first time.
The average temperature of the universe today is approximately , based on measurements of cosmic microwave background radiation.
Absolute zero cannot be achieved, although it is possible to reach temperatures close to it through the use of cryocoolers, dilution refrigerators, and nuclear adiabatic demagnetization. The use of laser cooling has produced temperatures less than a billionth of a kelvin. At very low temperatures in the vicinity of absolute zero, matter exhibits many unusual properties, including superconductivity, superfluidity, and Bose–Einstein condensation. To study such phenomena, scientists have worked to obtain even lower temperatures.

</doc>
<doc id="1419" url="https://en.wikipedia.org/wiki?curid=1419" title="Adiabatic process">
Adiabatic process

An adiabatic process occurs without transferring heat or mass between a thermodynamic system and its surroundings. Unlike an isothermal process, an adiabatic process transfers energy to the surroundings only as work. It also conceptually undergirds the theory used to expound the first law of thermodynamics and is therefore a key thermodynamic concept.
Some chemical and physical processes occur too rapidly for energy to enter or leave the system as heat, allowing a convenient "adiabatic approximation". For example, the adiabatic flame temperature uses this approximation to calculate the upper limit of flame temperature by assuming combustion loses no heat to its surroundings.
In meteorology and oceanography, adiabatic cooling produces condensation of moisture or salinity, oversaturating the parcel. Therefore, the excess must be removed. There, the process becomes a "pseudo-adiabatic process" whereby the liquid water or salt that condenses is assumed to be removed upon formation by idealized instantaneous precipitation. The pseudoadiabatic process is only defined for expansion because a compressed parcel becomes warmer and remains undersaturated.
A process without transfer of heat or matter to or from a system, so that , is called adiabatic, and such a system is said to be adiabatically isolated. The assumption that a process is adiabatic is a frequently made simplifying assumption. For example, the compression of a gas within a cylinder of an engine is assumed to occur so rapidly that on the time scale of the compression process, little of the system's energy can be transferred out as heat to the surroundings. Even though the cylinders are not insulated and are quite conductive, that process is idealized to be adiabatic. The same can be said to be true for the expansion process of such a system.
The assumption of adiabatic isolation is useful and often combined with other such idealizations to calculate a good first approximation of a system's behaviour. For example, according to Laplace, when sound travels in a gas, there is no time for heat conduction in the medium, and so the propagation of sound is adiabatic. For such an adiabatic process, the modulus of elasticity (Young's modulus) can be expressed as , where is the ratio of specific heats at constant pressure and at constant volume ( ) and is the pressure of the gas .
For a closed system, one may write the first law of thermodynamics as : , where denotes the change of the system's internal energy, the quantity of energy added to it as heat, and the work done by the system on its surroundings.
Naturally occurring adiabatic processes are irreversible (entropy is produced).
The transfer of energy as work into an adiabatically isolated system can be imagined as being of two idealized extreme kinds. In one such kind, no entropy is produced within the system (no friction, viscous dissipation, etc.), and the work is only pressure-volume work (denoted by ). In nature, this ideal kind occurs only approximately because it demands an infinitely slow process and no sources of dissipation.
The other extreme kind of work is isochoric work (), for which energy is added as work solely through friction or viscous dissipation within the system. A stirrer that transfers energy to a viscous fluid of an adiabatically isolated system with rigid walls, without phase change, will cause a rise in temperature of the fluid, but that work is not recoverable. Isochoric work is irreversible. The second law of thermodynamics observes that a natural process, of transfer of energy as work, always consists at least of isochoric work and often both of these extreme kinds of work. Every natural process, adiabatic or not, is irreversible, with , as friction or viscosity are always present to some extent.
The adiabatic compression of a gas causes a rise in temperature of the gas. Adiabatic expansion against pressure, or a spring, causes a drop in temperature. In contrast, free expansion is an isothermal process for an ideal gas.
Adiabatic heating occurs when the pressure of a gas is increased by work done on it by its surroundings, e.g., a piston compressing a gas contained within a cylinder and raising the temperature where in many practical situations heat conduction through walls can be slow compared with the compression time. This finds practical application in diesel engines which rely on the lack of heat dissipation during the compression stroke to elevate the fuel vapor temperature sufficiently to ignite it.
Adiabatic heating occurs in the Earth's atmosphere when an air mass descends, for example, in a katabatic wind, Foehn wind, or chinook wind flowing downhill over a mountain range. When a parcel of air descends, the pressure on the parcel increases. Because of this increase in pressure, the parcel's volume decreases and its temperature increases as work is done on the parcel of air, thus increasing its internal energy, which manifests itself by a rise in the temperature of that mass of air. The parcel of air can only slowly dissipate the energy by conduction or radiation (heat), and to a first approximation it can be considered adiabatically isolated and the process an adiabatic process.
Adiabatic cooling occurs when the pressure on an adiabatically isolated system is decreased, allowing it to expand, thus causing it to do work on its surroundings. When the pressure applied on a parcel of air is reduced, the air in the parcel is allowed to expand; as the volume increases, the temperature falls as its internal energy decreases. Adiabatic cooling occurs in the Earth's atmosphere with orographic lifting and lee waves, and this can form pileus or lenticular clouds.
Adiabatic cooling does not have to involve a fluid. One technique used to reach very low temperatures (thousandths and even millionths of a degree above absolute zero) is via adiabatic demagnetisation, where the change in magnetic field on a magnetic material is used to provide adiabatic cooling. Also, the contents of an expanding universe can be described (to first order) as an adiabatically cooling fluid. (See heat death of the universe.)
Rising magma also undergoes adiabatic cooling before eruption, particularly significant in the case of magmas that rise quickly from great depths such as kimberlites.
In the Earth's convecting mantle (the asthenosphere) beneath the lithosphere, the mantle temperature is approximately an adiabat. The slight decrease in temperature with shallowing depth is due to the decrease in pressure the shallower the material is in the Earth.
Such temperature changes can be quantified using the ideal gas law, or the hydrostatic equation for atmospheric processes.
In practice, no process is truly adiabatic. Many processes rely on a large difference in time scales of the process of interest and the rate of heat dissipation across a system boundary, and thus are approximated by using an adiabatic assumption. There is always some heat loss, as no perfect insulators exist.
The mathematical equation for an ideal gas undergoing a reversible (i.e., no entropy generation) adiabatic process can be represented by the polytropic process equation
where is pressure, is volume, and for this case , where
For a monatomic ideal gas, , and for a diatomic gas (such as nitrogen and oxygen, the main components of air) . Note that the above formula is only applicable to classical ideal gases and not Bose–Einstein or Fermi gases.
For reversible adiabatic processes, it is also true that
where "T" is an absolute temperature. This can also be written as
The compression stroke in a gasoline engine can be used as an example of adiabatic compression. The model assumptions are: the uncompressed volume of the cylinder is one litre (1 L = 1000 cm = 0.001 m); the gas within is the air consisting of molecular nitrogen and oxygen only (thus a diatomic gas with 5 degrees of freedom, and so ); the compression ratio of the engine is 10:1 (that is, the 1 L volume of uncompressed gas is reduced to 0.1 L by the piston); and the uncompressed gas is at approximately room temperature and pressure (a warm room temperature of ~27 °C, or 300 K, and a pressure of 1 bar = 100 kPa, i.e. typical sea-level atmospheric pressure).
so our adiabatic constant for this example is about 6.31 Pa m.
The gas is now compressed to a 0.1 L (0.0001 m) volume (we will assume this happens quickly enough that no heat can enter or leave the gas through the walls). The adiabatic constant remains the same, but with the resulting pressure unknown
so solving for "P":
or 25.1 bar. Note that this pressure increase is more than a simple 10:1 compression ratio would indicate; this is because the gas is not only compressed, but the work done to compress the gas also increases its internal energy, which manifests itself by a rise in the gas temperature and an additional rise in pressure above what would result from a simplistic calculation of 10 times the original pressure.
We can solve for the temperature of the compressed gas in the engine cylinder as well, using the ideal gas law, "PV" = "nRT" ("n" is amount of gas in moles and "R" the gas constant for that gas). Our initial conditions being 100 kPa of pressure, 1 L volume, and 300 K of temperature, our experimental constant ("nR") is:
We know the compressed gas has  = 0.1 L and  = , so we can solve for temperature:
That is a final temperature of 753 K, or 479 °C, or 896 °F, well above the ignition point of many fuels. This is why a high-compression engine requires fuels specially formulated to not self-ignite (which would cause engine knocking when operated under these conditions of temperature and pressure), or that a supercharger with an intercooler to provide a pressure boost but with a lower temperature rise would be advantageous. A diesel engine operates under even more extreme conditions, with compression ratios of 16:1 or more being typical, in order to provide a very high gas temperature, which ensures immediate ignition of the injected fuel.
For an adiabatic free expansion of an ideal gas, the gas is contained in an insulated container and then allowed to expand in a vacuum. Because there is no external pressure for the gas to expand against, the work done by or on the system is zero. Since this process does not involve any heat transfer or work, the first law of thermodynamics then implies that the net internal energy change of the system is zero. For an ideal gas, the temperature remains constant because the internal energy only depends on temperature in that case. Since at constant temperature, the entropy is proportional to the volume, the entropy increases in this case, therefore this process is irreversible.
The definition of an adiabatic process is that heat transfer to the system is zero, . Then, according to the first law of thermodynamics,
where is the change in the internal energy of the system and is work done "by" the system. Any work () done must be done at the expense of internal energy , since no heat is being supplied from the surroundings. Pressure–volume work done "by" the system is defined as
However, does not remain constant during an adiabatic process but instead changes along with .
It is desired to know how the values of and relate to each other as the adiabatic process proceeds. For an ideal gas ( recall ideal gas law ) the internal energy is given by
where is the number of degrees of freedom divided by two, is the universal gas constant and is the number of moles in the system (a constant).
Differentiating equation (3) yields
Equation (4) is often expressed as because .
Now substitute equations (2) and (4) into equation (1) to obtain
factorize :
and divide both sides by :
After integrating the left and right sides from to and from to and changing the sides respectively,
Exponentiate both sides, substitute with , the heat capacity ratio
and eliminate the negative sign to obtain
Therefore,
and
Substituting the ideal gas law into the above, we obtain
which simplifies to
The change in internal energy of a system, measured from state 1 to state 2, is equal to
At the same time, the work done by the pressure–volume changes as a result from this process, is equal to
Since we require the process to be adiabatic, the following equation needs to be true
By the previous derivation,
Rearranging (4) gives
Substituting this into (2) gives
Integrating we obtain the expression for work,
Substituting in second term,
Rearranging,
Using the ideal gas law and assuming a constant molar quantity (as often happens in practical cases),
By the continuous formula,
or
Substituting into the previous expression for ,
Substituting this expression and (1) in (3) gives
Simplifying,
An adiabat is a curve of constant entropy in a diagram. Some properties of adiabats on a "P"–"V" diagram are indicated. These properties may be read from the classical behaviour of ideal gases, except in the region where "PV" becomes small (low temperature), where quantum effects become important.
The right diagram is a "P"–"V" diagram with a superposition of adiabats and isotherms:
The isotherms are the red curves and the adiabats are the black curves.
The adiabats are isentropic.
Volume is the horizontal axis and pressure is the vertical axis.
The term "adiabatic" () is an anglicization of the Greek term ἀδιάβατος "impassable" (used by Xenophon of rivers).
It is used in the thermodynamic sense by Rankine (1866), and adopted by Maxwell in 1871 (explicitly attributing the term to Rankine).
The etymological origin corresponds here to an impossibility of transfer of energy as heat and of transfer of matter across the wall.
The Greek word ἀδιάβατος is formed from privative ἀ- ("not") and διαβατός, "passable", in turn deriving from διά ("through"), and βαῖνειν ("to walk, go, come").
The adiabatic process has been important for thermodynamics since its early days. It was important in the work of Joule because it provided a way of nearly directly relating quantities of heat and work.
Energy can enter or leave a thermodynamic system enclosed by walls that prevent mass transfer only as heat or work. Therefore, a quantity of work in such a system can be related almost directly to an equivalent quantity of heat in a cycle of two limbs. The first limb is an isochoric adiabatic work process increasing the system's internal energy; the second, an isochoric and workless heat transfer returning the system to its original state. Accordingly, Rankine measured quantity of heat in units of work, rather than as a calorimetric quantity . In 1854, Rankine used a quantity that he called "the thermodynamic function" that later was called entropy, and at that time he wrote also of the "curve of no transmission of heat", which he later called an adiabatic curve. Besides its two isothermal limbs, Carnot's cycle has two adiabatic limbs.
For the foundations of thermodynamics, the conceptual importance of this was emphasized by Bryan, by Carathéodory, and by Born. The reason is that calorimetry presupposes a type of temperature as already defined before the statement of the first law of thermodynamics, such as one based on empirical scales. Such a presupposition involves making the distinction between empirical temperature and absolute temperature. Rather, the definition of absolute thermodynamic temperature is best left till the second law is available as a conceptual basis.
In the eighteenth century, the law of conservation of energy was not yet fully formulated or established, and the nature of heat was debated. One approach to these problems was to regard heat, measured by calorimetry, as a primary substance that is conserved in quantity. By the middle of the nineteenth century, it was recognized as a form of energy, and the law of conservation of energy was thereby also recognized. The view that eventually established itself, and is currently regarded as right, is that the law of conservation of energy is a primary axiom, and that heat is to be analyzed as consequential. In this light, heat cannot be a component of the total energy of a single body because it is not a state variable but, rather, a variable that describes a transfer between two bodies. The adiabatic process is important because it is a logical ingredient of this current view.
This present article is written from the viewpoint of macroscopic thermodynamics, and the word "adiabatic" is used in this article in the traditional way of thermodynamics, introduced by Rankine. It is pointed out in the present article that, for example, if a compression of a gas is rapid, then there is little time for heat transfer to occur, even when the gas is not adiabatically isolated by a definite wall. In this sense, a rapid compression of a gas is sometimes approximately or loosely said to be "adiabatic", though often far from isentropic, even when the gas is not adiabatically isolated by a definite wall.
Quantum mechanics and quantum statistical mechanics, however, use the word "adiabatic" in a very different sense, one that can at times seem almost opposite to the classical thermodynamic sense. In quantum theory, the word "adiabatic" can mean something perhaps near isentropic, or perhaps near quasi-static, but the usage of the word is very different between the two disciplines.
On the one hand, in quantum theory, if a perturbative element of compressive work is done almost infinitely slowly (that is to say quasi-statically), it is said to have been done "adiabatically". The idea is that the shapes of the eigenfunctions change slowly and continuously, so that no quantum jump is triggered, and the change is virtually reversible. While the occupation numbers are unchanged, nevertheless there is change in the energy levels of one-to-one corresponding, pre- and post-compression, eigenstates. Thus a perturbative element of work has been done without heat transfer and without introduction of random change within the system. For example, Max Born writes "Actually, it is usually the 'adiabatic' case with which we have to do: i.e. the limiting case where the external force (or the reaction of the parts of the system on each other) acts very slowly. In this case, to a very high approximation
that is, there is no probability for a transition, and the system is in the initial state after cessation of the perturbation. Such a slow perturbation is therefore reversible, as it is classically."
On the other hand, in quantum theory, if a perturbative element of compressive work is done rapidly, it randomly changes the occupation numbers of the eigenstates, as well as changing their shapes. In that theory, such a rapid change is said not to be "adiabatic", and the contrary word "diabatic" is applied to it. One might guess that perhaps Clausius, if he were confronted with this, in the now-obsolete language he used in his day, would have said that "internal work" was done and that 'heat was generated though not transferred'.
In classical thermodynamics, such a rapid change would still be called adiabatic because the system is adiabatically isolated, and there is no transfer of energy as heat. The strong irreversibility of the change, due to viscosity or other entropy production, does not impinge on this classical usage.
Thus for a mass of gas, in macroscopic thermodynamics, words are so used that a compression is sometimes loosely or approximately said to be adiabatic if it is rapid enough to avoid heat transfer, even if the system is not adiabatically isolated. But in quantum statistical theory, a compression is not called adiabatic if it is rapid, even if the system is adiabatically isolated in the classical thermodynamic sense of the term. The words are used differently in the two disciplines, as stated just above.

</doc>
<doc id="1422" url="https://en.wikipedia.org/wiki?curid=1422" title="Amide">
Amide

In organic chemistry, an amide, also known as an organic amide or a carboxamide, is a compound with the general formula RC(=O)NR′R″, where R, R', and R″ represent organic groups or hydrogen atoms. The amide group is called a peptide bond when it is part of the main chain of a protein, and isopeptide bond when it occurs in a side chain, such as in the amino acids asparagine and glutamine. It can be viewed as a derivative of a carboxylic acid RC(=O)OH with the hydroxyl group –OH replaced by an amine group –NR′R″; or, equivalently, an acyl (alkanoyl) group RC(=O)– joined to an amine group.
Common examples of amides are acetamide HC–CONH2, benzamide CH–CONH2, and dimethylformamide HCON(–CH).
Amides are qualified as primary, secondary, and tertiary according to whether the amine subgroup has the form –NH, –NHR, or –NRR', where R and R' are groups other than hydrogen.
The core –C(=O)N= of amides is called the amide group (specifically, carboxamide group).
Amides are pervasive in nature and technology. Proteins and important plastics like Nylons, Aramid, Twaron, and Kevlar are polymers whose units are connected by amide groups (polyamides); these linkages are easily formed, confer structural rigidity, and resist hydrolysis. Amides include many other important biological compounds, as well as many drugs like paracetamol, penicillin and LSD. Low molecular weight amides, such as dimethylformamide, are common solvents.
In the usual nomenclature, one adds the term "amide" to the stem of the parent acid's name. For instance, the amide derived from acetic acid is named acetamide (CHCONH). IUPAC recommends ethanamide, but this and related formal names are rarely encountered. When the amide is derived from a primary or secondary amine, the substituents on nitrogen are indicated first in the name. Thus, the amide formed from dimethylamine and acetic acid is "N","N"-dimethylacetamide (CHCONMe, where Me = CH). Usually even this name is simplified to dimethylacetamide. Cyclic amides are called lactams; they are necessarily secondary or tertiary amides.
The term "amide" is variously pronounced or or .
Different pronunciations may be used for the two main senses, saying for the carbonyl–nitrogen compound and for the anion. Others replace one of these with .
The lone pair of electrons on the nitrogen atom is delocalized into the carbonyl group, thus forming a partial double bond between nitrogen and carbon. In fact the O, C and N atoms have molecular orbitals occupied by delocalized electrons, forming a conjugated system. Consequently, the three bonds of the nitrogen in amides is not pyramidal (as in the amines) but planar.
The structure of an amide can be described also as a resonance between two alternative structures:
It is estimated that for acetamide, structure A makes a 62% contribution to the structure, while structure B makes a 28% contribution. (These figures do not sum to 100% because there are additional less-important resonance forms that are not depicted above). There is also a hydrogen bond present between the active groups hydrogen and nitrogen atoms. Resonance is largely prevented in the very strained quinuclidone.
Compared to amines, amides are very weak bases. While the conjugate acid of an amine has a p"K" of about 9.5, the conjugate acid of an amide has a p"K" around −0.5. Therefore, amides don't have as clearly noticeable acid–base properties in water. This relative lack of basicity is explained by the withdrawing of electrons from the amine by the carbonyl. On the other hand, amides are much stronger bases than carboxylic acids, esters, aldehydes, and ketones (their conjugate acids' p"K"s are between −6 and −10).
The proton of a primary or secondary amide does not dissociate readily under normal conditions; its p"K" is usually well above 15. Conversely, under extremely acidic conditions, the carbonyl oxygen can become protonated with a p"K" of roughly −1. It is not only because of the positive charge on the nitrogen, but also because of the negative charge on the oxygen gained through resonance.
Because of the greater electronegativity of oxygen, the carbonyl (C=O) is a stronger dipole than the N–C dipole. The presence of a C=O dipole and, to a lesser extent a N–C dipole, allows amides to act as H-bond acceptors. In primary and secondary amides, the presence of N–H dipoles allows amides to function as H-bond donors as well. Thus amides can participate in hydrogen bonding with water and other protic solvents; the oxygen atom can accept hydrogen bonds from water and the N–H hydrogen atoms can donate H-bonds. As a result of interactions such as these, the water solubility of amides is greater than that of corresponding hydrocarbons. These hydrogen bonds are also have an important role in the secondary structure of proteins.
The solubilities of amides and esters are roughly comparable. Typically amides are less soluble than comparable amines and carboxylic acids since these compounds can both donate and accept hydrogen bonds. Tertiary amides, with the important exception of "N","N"-dimethylformamide, exhibit low solubility in water.
The presence of the amide group –C(=O)N– is generally easily established, at least in small molecules. It can be distinguished from nitro and cyano groups in IR spectra. Amides exhibit a moderately intense "ν" band near 1650 cm. By H NMR spectroscopy, CONHR signals occur at low fields. In X-ray crystallography, the C(=O)N center together with the three immediately adjacent atoms characteristically define a plane.
Amides undergo many chemical reactions, although they are less reactive than esters. Amides hydrolyse in hot alkali as well as in strong acidic conditions. Acidic conditions yield the carboxylic acid and the ammonium ion while basic hydrolysis yield the carboxylate ion and ammonia. The protonation of the initially generated amine under acidic conditions and the deprotonation of the initially generated carboxylic acid under basic conditions render these processes non-catalytic and irreversible. Amides are also versatile precursors to many other functional groups. Electrophiles react with the carbonyl oxygen. This step often precedes hydrolysis, which is catalyzed by both Brønsted acids and Lewis acids. Enzymes, e.g. peptidases and artificial catalysts, are known to accelerate the hydrolysis reactions.
Many methods exist in amide synthesis. 
Amides can be prepared by coupling carboxylic acid with an amine. The direct reaction generally requires high temperatures to drive off the water:
Many methods involve "activating" the carboxylic acid by converting it to a better electrophile; such as esters, acid chlorides (Schotten-Baumann reaction), or anhydrides (Lumière–Barbier method). 
Conventional methods in peptide synthesis use coupling agents such as HATU, HOBt, or PyBOP. 
A variety of reagents, e.g. Tris(2,2,2-trifluoroethyl) borate have been developed for specialized applications.
Dehydrogenative acylation of amines is catalyzed by organoruthenium compounds:
The reaction proceed by one dehydrogenation of the alcohol to the aldehyde followed by formation of a hemiaminal, which undergoes a second dehydrogenation to the amide. Elimination of water in the hemiaminal to the imine is not observed.
Transamidation is typically very slow, but it is accelerated with Lewis acid and organometallic catalysts:
Primary amides (RC(O)NH) are more amenable to this reaction.

</doc>
<doc id="1423" url="https://en.wikipedia.org/wiki?curid=1423" title="Animism">
Animism

Animism (from Latin: "", 'breath, spirit, life') is the belief that objects, places, and creatures all possess a distinct spiritual essence. Potentially, animism perceives all things—animals, plants, rocks, rivers, weather systems, human handiwork, and perhaps even words—as animated and alive. Animism is used in the anthropology of religion as a term for the belief system of many indigenous peoples, especially in contrast to the relatively more recent development of organised religions.
Although each culture has its own different mythologies and rituals, "animism" is said to describe the most common, foundational thread of indigenous peoples' "spiritual" or "supernatural" perspectives. The animistic perspective is so widely held and inherent to most indigenous peoples that they often do not even have a word in their languages that corresponds to "animism" (or even "religion"); the term is an anthropological construct.
Largely due to such ethnolinguistic and cultural discrepancies, opinion has differed on whether "animism" refers to an ancestral mode of experience common to indigenous peoples around the world, or to a full-fledged religion in its own right. The currently accepted definition of "animism" was only developed in the late 19th century (1871) by Sir Edward Tylor, who formulated it as "one of anthropology's earliest concepts, if not the first."
Animism encompasses the beliefs that all material phenomena have agency, that there exists no hard and fast distinction between the spiritual and physical (or material) world and that soul or spirit or sentience exists not only in humans, but also in other animals, plants, rocks, geographic features such as mountains or rivers or other entities of the natural environment:water sprites, vegetation deities, tree sprites, etc. Animism may further attribute a life force to abstract concepts such as words, true names or metaphors in mythology. Some members of the non-tribal world also consider themselves animists (such as author Daniel Quinn, sculptor Lawson Oyekan, and many contemporary Pagans).
Sir Edward Tylor had initially wanted to describe the phenomenon as "spiritualism", but realised that such would cause confusion with the modern religion of Spiritualism, which was then prevalent across Western nations. He adopted the term "animism" from the writings of German scientist Georg Ernst Stahl, who had developed the term "" in 1708 as a biological theory that souls formed the vital principle and that the normal phenomena of life and the abnormal phenomena of disease could be traced to spiritual causes.
The first known usage in English appeared in 1819.
Earlier anthropological perspectives, which have since been termed the old animism, were concerned with knowledge on what is alive and what factors make something alive. The old animism assumed that animists were individuals who were unable to understand the difference between persons and things. Critics of the old animism have accused it of preserving "colonialist and dualist worldviews and rhetoric."
The idea of animism was developed by anthropologist Sir Edward Tylor through his 1871 book "Primitive Culture", in which he defined it as "the general doctrine of souls and other spiritual beings in general." According to Tylor, animism often includes "an idea of pervading life and will in nature;" a belief that natural objects other than humans have souls. This formulation was little different from that proposed by Auguste Comte as "fetishism," but the terms now have distinct meanings.
For Tylor, animism represented the earliest form of religion, being situated within an evolutionary framework of religion which has developed in stages and which will ultimately lead to humanity rejecting religion altogether in favor of scientific rationality.
Thus, for Tylor, animism was fundamentally seen as a mistake, a basic error from which all religion grew. He did not believe that animism was inherently illogical, but he suggested that it arose from early humans' dreams and visions and thus was a rational system. However, it was based on erroneous, unscientific observations about the nature of reality. Stringer notes that his reading of "Primitive Culture" led him to believe that Tylor was far more sympathetic in regard to "primitive" populations than many of his contemporaries and that Tylor expressed no belief that there was any difference between the intellectual capabilities of "savage" people and Westerners.
The idea that there had once been "one universal form of primitive religion" (whether labelled "animism", "totemism", or "shamanism") has been dismissed as "unsophisticated" and "erroneous" by archaeologist Timothy Insoll, who stated that "it removes complexity, a precondition of religion now, in "all" its variants."
Tylor's definition of animism was part of a growing international debate on the nature of "primitive society" by lawyers, theologians, and philologists. The debate defined the field of research of a new science: "anthropology". By the end of the 19th century, an orthodoxy on "primitive society" had emerged, but few anthropologists still would accept that definition. The "19th-century armchair anthropologists" argued "primitive society" (an evolutionary category) was ordered by kinship and divided into exogamous descent groups related by a series of marriage exchanges. Their religion was animism, the belief that natural species and objects had souls.
With the development of private property, the descent groups were displaced by the emergence of the territorial state. These rituals and beliefs eventually evolved over time into the vast array of "developed" religions. According to Tylor, the more scientifically advanced a society became, the fewer members of that society believed in animism. However, any remnant ideologies of souls or spirits, to Tylor, represented "survivals" of the original animism of early humanity.
In 1869 (three years after Tylor proposed his definition of animism), Edinburgh lawyer John Ferguson McLennan, argued that the animistic thinking evident in fetishism gave rise to a religion he named "Totemism". Primitive people believed, he argued, that they were descended of the same species as their totemic animal.
Subsequent debate by the 'armchair anthropologists' (including J. J. Bachofen, Émile Durkheim, and Sigmund Freud) remained focused on totemism rather than animism, with few directly challenging Tylor's definition. Anthropologists "have commonly avoided the issue of animism and even the term itself rather than revisit this prevalent notion in light of their new and rich ethnographies."
According to anthropologist Tim Ingold, animism shares similarities to totemism but differs in its focus on individual spirit beings which help to perpetuate life, whereas totemism more typically holds that there is a primary source, such as the land itself or the ancestors, who provide the basis to life. Certain indigenous religious groups such as the Australian Aboriginals are more typically totemic in their worldview, whereas others like the Inuit are more typically animistic.
From his studies into child development, Jean Piaget suggested that children were born with an innate animist worldview in which they anthropomorphized inanimate objects, and that it was only later that they grew out of this belief. Conversely, from her ethnographic research, Margaret Mead argued the opposite, believing that children were not born with an animist worldview but that they became acculturated to such beliefs as they were educated by their society.
Stewart Guthrie saw animism—or "attribution" as he preferred it—as an evolutionary strategy to aid survival. He argued that both humans and other animal species view inanimate objects as potentially alive as a means of being constantly on guard against potential threats. His suggested explanation, however, did not deal with the question of why such a belief became central to religion. In 2000, Guthrie suggested that the "most widespread" concept of animism was that it was the "attribution of spirits to natural phenomena
such as stones and trees."
Many anthropologists ceased using the term "animism", deeming it to be too close to early anthropological theory and religious polemic. However, the term had also been claimed by religious groups—namely indigenous communities and nature worshipers—who felt that it aptly described their own beliefs, and who in some cases actively identified as "animists." It was thus readopted by various scholars, who began using the term in a different way, placing the focus on knowing how to behave toward other persons, some of whom aren't human. As religious studies scholar Graham Harvey stated, while the "old animist" definition had been problematic, the term "animism" was nevertheless "of considerable value as a critical, academic term for a style of religious and cultural relating to the world."
The new animism emerged largely from the publications of anthropologist Irving Hallowell, produced on the basis of his ethnographic research among the Ojibwe communities of Canada in the mid-20th century. For the Ojibwe encountered by Hallowell, "personhood" did not require human-likeness, but rather humans were perceived as being like other persons, who for instance included rock persons and bear persons. For the Ojibwe, these persons were each wilful beings who gained meaning and power through their interactions with others; through respectfully interacting with other persons, they themselves learned to "act as a person."
Hallowell's approach to the understanding of Ojibwe personhood differed strongly from prior anthropological concepts of animism. He emphasized the need to challenge the modernist, Western perspectives of what a person is by entering into a dialogue with different worldwide-views. Hallowell's approach influenced the work of anthropologist Nurit Bird-David, who produced a scholarly article reassessing the idea of animism in 1999. Seven comments from other academics were provided in the journal, debating Bird-David's ideas.
More recently postmodern anthropologists are increasingly engaging with the concept of animism. Modernism is characterized by a Cartesian subject-object dualism that divides the subjective from the objective, and culture from nature. In this view, animism is the inverse of scientism, and hence inherently invalid. Drawing on the work of Bruno Latour, these anthropologists question such modernist assumptions, and theorize that all societies continue to "animate" the world around them, but not just as a Tylorian survival of primitive thought. Rather, the instrumental reason characteristic of modernity is limited to our "professional subcultures," which allows us to treat the world as a detached mechanical object in a delimited sphere of activity.
We, like animists, also continue to create personal relationships with elements of the so-called objective world, whether pets, cars, or teddy-bears, who we recognize as subjects. As such, these entities are "approached as communicative subjects rather than the inert objects perceived by modernists." These approaches are careful to avoid the modernist assumptions that the environment consists dichotomously of a physical world distinct from humans, and from modernist conceptions of the person as composed dualistically as body and soul.
Nurit Bird-David argues that:Positivistic ideas about the meaning of 'nature', 'life' and 'personhood' misdirected these previous attempts to understand the local concepts. Classical theoreticians (it is argued) attributed their own modernist ideas of self to 'primitive peoples' while asserting that the 'primitive peoples' read their idea of self into others!She explains that animism is a "relational epistemology" rather than a Tylorian failure of primitive reasoning. That is, self-identity among animists is based on their relationships with others, rather than some distinctive feature of the self. Instead of focusing on the essentialized, modernist self (the "individual"), persons are viewed as bundles of social relationships ("dividuals"), some of which include "superpersons" (i.e. non-humans).
Stewart Guthrie expressed criticism of Bird-David's attitude towards animism, believing that it promulgated the view that "the world is in large measure whatever our local imagination makes it." This, he felt, would result in anthropology abandoning "the scientific project."
Like Bird-David, Tim Ingold argues that animists do not see themselves as separate from their environment:Hunter-gatherers do not, as a rule, approach their environment as an external world of nature that has to be 'grasped' intellectually…indeed the separation of mind and nature has no place in their thought and practice.Rane Willerslev extends the argument by noting that animists reject this Cartesian dualism, and that the animist self identifies with the world, "feeling at once "within" and "apart" from it so that the two glide ceaselessly in and out of each other in a sealed circuit." The animist hunter is thus aware of himself as a human hunter, but, through mimicry is able to assume the viewpoint, senses, and sensibilities of his prey, to be one with it. Shamanism, in this view, is an everyday attempt to influence spirits of ancestors and animals by mirroring their behaviours as the hunter does his prey.
Cultural ecologist and philosopher David Abram articulates an intensely ethical and ecological understanding of animism grounded in the phenomenology of sensory experience. In his books "The Spell of the Sensuous" and "Becoming Animal," Abram suggests that material things are never entirely passive in our direct perceptual experience, holding rather that perceived things actively "solicit our attention" or "call our focus," coaxing the perceiving body into an ongoing participation with those things.
In the absence of intervening technologies, he suggests, sensory experience is inherently animistic in that it discloses a material field that is animate and self-organizing from the get-go. Drawing upon contemporary cognitive and natural science, as well as upon the perspectival worldviews of diverse indigenous oral cultures, Abram proposes a richly pluralist and story-based cosmology in which matter is alive through and through. He suggests that such a relational ontology is in close accord with our spontaneous perceptual experience; it would draw us back to our senses and to the primacy of the sensuous terrain, enjoining a more respectful and ethical relation to the more-than-human community of animals, plants, soils, mountains, waters, and weather-patterns that materially sustains us.
In contrast to a long-standing tendency in the Western social sciences, which commonly provide rational explanations of animistic experience, Abram develops an animistic account of reason itself. He holds that civilized reason is sustained only by an intensely animistic participation between human beings and their own written signs. For instance, as soon as we turn our gaze toward the alphabetic letters written on a page or a screen, we "see what they say"—the letters, that is, seem to speak to us—much as spiders, trees, gushing rivers and lichen-encrusted boulders once spoke to our oral ancestors. For Abram, reading can usefully be understood as an intensely concentrated form of animism, one that effectively eclipses all of the other, older, more spontaneous forms of animistic participation in which we once engaged.To tell the story in this manner—to provide an animistic account of reason, rather than the other way around—is to imply that animism is the wider and more inclusive term, and that oral, mimetic modes of experience still underlie, and support, all our literate and technological modes of reflection. When reflection's rootedness in such bodily, participatory modes of experience is entirely unacknowledged or unconscious, reflective reason becomes dysfunctional, unintentionally destroying the corporeal, sensuous world that sustains it.
Religious studies scholar Graham Harvey defined "animism" as the belief "that the world is full of persons, only some of whom are human, and that life is always lived in relationship with others." He added that it is therefore "concerned with learning how to be a good person in respectful relationships with other persons."
In his "Handbook of Contemporary Animism" (2013), Harvey identifies the animist perspective in line with Martin Buber's "I-thou" as opposed to "I-it." In such, Harvey says, the animist takes an I-thou approach to relating to his world, whereby objects and animals are treated as a "thou" rather than as an "it."
There is ongoing disagreement (and no general consensus) as to whether animism is merely a singular, broadly encompassing religious belief or a worldview in and of itself, comprising many diverse mythologies found worldwide in many diverse cultures. This also raises a controversy regarding the ethical claims animism may or may not make: whether animism ignores questions of ethics altogether; or, by endowing various non-human elements of nature with spirituality or personhood, in fact promotes a complex ecological ethics.
In many animistic world views, the human being is often regarded as on a roughly equal footing with other animals, plants, and natural forces.
A shaman is a person regarded as having access to, and influence in, the world of benevolent and malevolent spirits, who typically enters into a trance state during a ritual, and practices divination and healing.
According to Mircea Eliade, shamanism encompasses the premise that shamans are intermediaries or messengers between the human world and the spirit worlds. Shamans are said to treat ailments/illness by mending the soul. Alleviating traumas affecting the soul/spirit restores the physical body of the individual to balance and wholeness. The shaman also enters supernatural realms or dimensions to obtain solutions to problems afflicting the community. Shamans may visit other worlds/dimensions to bring guidance to misguided souls and to ameliorate illnesses of the human soul caused by foreign elements. The shaman operates primarily within the spiritual world, which in turn affects the human world. The restoration of balance results in the elimination of the ailment.
Abram, however, articulates a less supernatural and much more ecological understanding of the shaman's role than that propounded by Eliade. Drawing upon his own field research in Indonesia, Nepal, and the Americas, Abram suggests that in animistic cultures, the shaman functions primarily as an intermediary between the human community and the more-than-human community of active agencies—the local animals, plants, and landforms (mountains, rivers, forests, winds, and weather patterns, all of which are felt to have their own specific sentience). Hence, the shaman's ability to heal individual instances of dis-ease (or imbalance) within the human community is a by-product of her/his more continual practice of balancing the reciprocity between the human community and the wider collective of animate beings in which that community is embedded.
Animism is not the same as pantheism, although the two are sometimes confused. Moreover, some religions are both pantheistic and animistic. One of the main differences is that while animists believe everything to be spiritual in nature, they do not necessarily see the spiritual nature of everything in existence as being united (monism), the way pantheists do. As a result, animism puts more emphasis on the uniqueness of each individual soul. In pantheism, everything shares the same spiritual essence, rather than having distinct spirits and/or souls.
Animism entails the belief that "all living things have a soul," and thus a central concern of animist thought surrounds how animals can be eaten or otherwise used for humans' subsistence needs. The actions of non-human animals are viewed as "intentional, planned and purposive," and they are understood to be persons because they are both alive and communicate with others.
In animist world-views, non-human animals are understood to participate in kinship systems and ceremonies with humans, as well as having their own kinship systems and ceremonies. Harvey cited an example of an animist understanding of animal behaviour that occurred at a powwow held by the Conne River Mi'kmaq in 1996; an eagle flew over the proceedings, circling over the central drum group. The assembled participants called out "kitpu" ('eagle'), conveying welcome to the bird and expressing pleasure at its beauty, and they later articulated the view that the eagle's actions reflected its approval of the event and the Mi'kmaq's return to traditional spiritual practices.
Some animists also view plant and fungi life as persons and interact with them accordingly. The most common encounter between humans and these plant and fungi persons is with the former's collection of the latter for food, and for animists this interaction typically has to be carried out respectfully. Harvey cited the example of Maori communities in New Zealand, who often offer "karakia" invocations to sweet potatoes as they dig the latter up; while doing so there is an awareness of a kinship relationship between the Maori and the sweet potatoes, with both understood as having arrived in Aotearoa together in the same canoes.
In other instances, animists believe that interaction with plant and fungi persons can result in the communication of things unknown or even otherwise unknowable. Among some modern Pagans, for instance, relationships are cultivated with specific trees, who are understood to bestow knowledge or physical gifts, such as flowers, sap, or wood that can be used as firewood or to fashion into a wand; in return, these Pagans give offerings to the tree itself, which can come in the form of libations of mead or ale, a drop of blood from a finger, or a strand of wool.
Various animistic cultures also comprehend stones as persons. Discussing ethnographic work conducted among the Ojibwe, Harvey noted that their society generally conceived of stones as being inanimate, but with two notable exceptions: the stones of the Bell Rocks and those stones which are situated beneath trees struck by lightning, which were understood to have become Thunderers themselves. The Ojibwe conceived of weather as being capable of having personhood, with storms being conceived of as persons known as 'Thunderers' whose sounds conveyed communications and who engaged in seasonal conflict over the lakes and forests, throwing lightning at lake monsters. Wind, similarly, can be conceived as a person in animistic thought.
The importance of place is also a recurring element of animism, with some places being understood to be persons in their own right.
Animism can also entail relationships being established with non-corporeal spirit entities.
In the early 20th century, William McDougall defended a form of Animism in his book "Body and Mind: A History and Defence of Animism" (1911).
Physicist Nick Herbert has argued for "quantum animism" in which mind permeates the world at every level:
Werner Krieglstein wrote regarding his "quantum Animism":
In "Error and Loss: A Licence to Enchantment", Ashley Curtis (2018) has argued that the Cartesian idea of an experiencing subject facing off with an inert physical world is incoherent at its very foundation, and that this incoherence is predicted rather than belied by Darwinism. Human reason (and its rigorous extension in the natural sciences) fits an evolutionary niche just as echolocation does for bats and infrared vision does for pit vipers, and is—according to western science's own dictates—epistemologically on par with, rather than superior to, such capabilities. The meaning or aliveness of the "objects" we encounter—rocks, trees, rivers, other animals—thus depends its validity not on a detached cognitive judgment, but purely on the quality of our experience. The animist experience, and the wolf's or raven's experience, thus become licensed as equally valid worldviews to the modern western scientific one; they are more valid, since they are not plagued with the incoherence that inevitably crops up when "objective existence" is separated from "subjective experience."
Harvey opined that animism's views on personhood represented a radical challenge to the dominant perspectives of modernity, because it accords "intelligence, rationality, consciousness, volition, agency, intentionality, language and desire" to non-humans. Similarly, it challenges the view of human uniqueness that is prevalent in both Abrahamic religions and Western rationalism.
Animist beliefs can also be expressed through artwork. For instance, among the Maori communities of New Zealand, there is an acknowledgment that creating art through carving wood or stone entails violence against the wood or stone person, and that the persons who are damaged therefore have to be placated and respected during the process; any excess or waste from the creation of the artwork is returned to the land, while the artwork itself is treated with particular respect. Harvey therefore argued that the creation of art among the Maori was not about creating an inanimate object for display, but rather a transformation of different persons within a relationship.
Harvey expressed the view that animist worldviews were present in various works of literature, citing such examples as the writings of Alan Garner, Leslie Silko, Barbara Kingsolver, Alice Walker, Daniel Quinn, Linda Hogan, David Abram, Patricia Grace, Chinua Achebe, Ursula Le Guin, Louise Erdrich, and Marge Piercy.
Animist worldviews have also been identified in the animated films of Hayao Miyazaki.

</doc>
<doc id="1425" url="https://en.wikipedia.org/wiki?curid=1425" title="Antonio Vivaldi">
Antonio Vivaldi

Antonio Lucio Vivaldi (, ; ; 4 March 1678 – 28 July 1741) was an Italian Baroque composer, virtuoso violinist, teacher, impresario, and Roman Catholic priest. Born in Venice, the capital of the Venetian Republic, he is regarded as one of the greatest Baroque composers, and his influence during his lifetime was widespread across Europe. He composed many instrumental concertos, for the violin and a variety of other musical instruments, as well as sacred choral works and more than forty operas. His best-known work is a series of violin concertos known as the "Four Seasons".
Many of his compositions were written for the all-female music ensemble of the "Ospedale della Pietà", a home for abandoned children. Vivaldi had worked there as a Catholic priest for years and was employed there from 1703 to 1715 and from 1723 to 1740. Vivaldi also had some success with expensive stagings of his operas in Venice, Mantua and Vienna. After meeting the Emperor Charles VI, Vivaldi moved to Vienna, hoping for royal support. However, the Emperor died soon after Vivaldi's arrival, and Vivaldi himself died in poverty less than a year later.
Antonio Lucio Vivaldi was born on 4 March 1678 in Venice, then the capital of the Venetian Republic. He was baptized immediately after his birth at his home by the midwife, which led to a belief that his life was somehow in danger. Though the reasons for the child's immediate baptism are not known for certain, it was done most likely due either to his poor health or to an earthquake that shook the city that day. In the trauma of the earthquake, Vivaldi's mother may have dedicated him to the priesthood. The ceremonies which had been omitted were supplied two months later.
Vivaldi's parents were Giovanni Battista Vivaldi and Camilla Calicchio, as recorded in the register of San Giovanni in Bragora. Vivaldi had five known siblings: Bonaventura Tomaso Vivaldi, Margarita Gabriela Vivaldi, Cecilia Maria Vivaldi, Francesco Gaetano Vivaldi, and Zanetta Anna Vivaldi. Giovanni Battista, who was a barber before becoming a professional violinist, taught Antonio to play the violin and then toured Venice playing the violin with his young son. Antonio was probably taught at an early age, judging by the extensive musical knowledge he had acquired by the age of 24, when he started working at the Ospedale della Pietà. Giovanni Battista was one of the founders of the "Sovvegno dei musicisti di Santa Cecilia", an association of musicians.
The president of the "Sovvegno" was Giovanni Legrenzi, an early Baroque composer and the "maestro di cappella" at St Mark's Basilica. It is possible that Legrenzi gave the young Antonio his first lessons in composition. The German scholar Walter Kolneder has discerned the influence of Legrenzi's style in Vivaldi's early liturgical work "Laetatus sum" (RV Anh 31), written in 1691 at the age of thirteen. Vivaldi's father may have been a composer himself: in 1689, an opera titled "La Fedeltà sfortunata" was composed by a Giovanni Battista Rossi—the name under which Vivaldi's father had joined the Sovvegno di Santa Cecilia.
Vivaldi's health was problematic. One of his symptoms, "strettezza di petto" ("tightness of the chest"), has been interpreted as a form of asthma. This did not prevent him from learning to play the violin, composing, or taking part in musical activities, although it did stop him from playing wind instruments. In 1693, at the age of fifteen, he began studying to become a priest. He was ordained in 1703, aged 25, and was soon nicknamed "il Prete Rosso", "The Red Priest". ("" is Italian for "red", and would have referred to the color of his hair, a family trait.)
Not long after his ordination, in 1704, he was given a dispensation from celebrating Mass most likely because of his ill health. Vivaldi said Mass as a priest only a few times, and appeared to have withdrawn from liturgical duties, though he remained a member of the priesthood. It is thought that this is also due to his habit of composing while performing mass. He seems to have remained committed to Catholicism, since the entry in the Vienna death records for him reads, "Antonio Vivaldi, Secular Priest". It is thought that he remained a devout Catholic, indeed, in 1792, the Protestant composer Ernst Ludwig Gerber, wrote of the aged Vivaldi that "the rosary never left his hand except when he picked up the pen to write an opera".
In September 1703, Vivaldi became "maestro di violino" (master of violin) at an orphanage called the Pio Ospedale della Pietà (Devout Hospital of Mercy) in Venice. While Vivaldi is most famous as a composer, he was regarded as an exceptional technical violinist as well. The German architect Johann Friedrich Armand von Uffenbach referred to Vivaldi as "the famous composer and violinist" and said that "Vivaldi played a solo accompaniment excellently, and at the conclusion he added a free fantasy [an improvised cadenza] which absolutely astounded me, for it is hardly possible that anyone has ever played, or ever will play, in such a fashion."
Vivaldi was only 25 when he started working at the orphanage. Over the next thirty years he composed most of his major works while working there. There were four similar institutions in Venice; their purpose was to give shelter and education to children who were abandoned or orphaned, or whose families could not support them. They were financed by funds provided by the Republic. The boys learned a trade and had to leave when they reached the age of fifteen. The girls received a musical education, and the most talented among them stayed and became members of the Ospedale's renowned orchestra and choir.
Shortly after Vivaldi's appointment, the orphans began to gain appreciation and esteem abroad, too. Vivaldi wrote concertos, cantatas and sacred vocal music for them. These sacred works, which number over 60, are varied: they included solo motets and large-scale choral works for soloists, double chorus, and orchestra. In 1704, the position of teacher of "viola all'inglese" was added to his duties as violin instructor. The position of "maestro di coro", which was at one time filled by Vivaldi, required a lot of time and work. He had to compose an oratorio or concerto at every feast and teach the orphans both music theory and how to play certain instruments.
His relationship with the board of directors of the Ospedale was often strained. The board had to take a vote every year on whether to keep a teacher. The vote on Vivaldi was seldom unanimous, and went 7 to 6 against him in 1709. After a year as a freelance musician, he was recalled by the Ospedale with a unanimous vote in 1711; clearly during his year's absence the board had realized the importance of his role. He became responsible for all of the musical activity of the institution when he was promoted to "maestro de' concerti" (music director) in 1716.
In 1705, the first collection ("Connor Cassara") of his works was published by Giuseppe Sala: his Opus 1 is a collection of 12 sonatas for two violins and basso continuo, in a conventional style. In 1709, a second collection of 12 sonatas for violin and basso continuo appeared—Opus 2. A real breakthrough as a composer came with his first collection of 12 concerti for one, two, and four violins with strings, "L'estro armonico" (Opus 3), which was published in Amsterdam in 1711 by Estienne Roger, dedicated to Grand Prince Ferdinand of Tuscany. The prince sponsored many musicians including Alessandro Scarlatti and George Frideric Handel. He was a musician himself, and Vivaldi probably met him in Venice. "L'estro armonico" was a resounding success all over Europe. It was followed in 1714 by "La stravaganza" (Opus 4), a collection of concerti for solo violin and strings, dedicated to an old violin student of Vivaldi's, the Venetian noble Vettor Dolfin.
In February 1711, Vivaldi and his father traveled to Brescia, where his setting of the Stabat Mater (RV 621) was played as part of a religious festival. The work seems to have been written in haste: the string parts are simple, the music of the first three movements is repeated in the next three, and not all the text is set. Nevertheless, perhaps in part because of the forced essentiality of the music, the work is considered to be one of his early masterpieces.
Despite his frequent travels from 1718, the Ospedale paid him 2 sequins to write two concerti a month for the orchestra and to rehearse with them at least five times when in Venice. The orphanage's records show that he was paid for 140 concerti between 1723 and 1733.
In early 18th-century Venice, opera was the most popular musical entertainment. It proved most profitable for Vivaldi. There were several theaters competing for the public's attention. Vivaldi started his career as an opera composer as a sideline: his first opera, "Ottone in villa" (RV 729) was performed not in Venice, but at the Garzerie Theater in Vicenza in 1713. The following year, Vivaldi became the impresario of the Teatro San Angelo in Venice, where his opera "Orlando finto pazzo" (RV 727) was performed. The work was not to the public's taste, and it closed after a couple of weeks, being replaced with a repeat of a different work already given the previous year.
In 1715, he presented "Nerone fatto Cesare" (RV 724, now lost), with music by seven different composers, of which he was the leader. The opera contained eleven arias, and was a success. In the late season, Vivaldi planned to put on an opera entirely of his own creation, "Arsilda, regina di Ponto" (RV 700), but the state censor blocked the performance. The main character, Arsilda, falls in love with another woman, Lisea, who is pretending to be a man. Vivaldi got the censor to accept the opera the following year, and it was a resounding success.
During this period, the "Pietà" commissioned several liturgical works. The most important were two oratorios. "Moyses Deus Pharaonis", (RV 643) is now lost. The second, "Juditha triumphans" (RV 644), celebrates the victory of the Republic of Venice against the Turks and the recapture of the island of Corfu. Composed in 1716, it is one of his sacred masterpieces. All eleven singing parts were performed by girls of the orphanage, both the female and male roles. Many of the arias include parts for solo instruments—recorders, oboes, violas d'amore, and mandolins—that showcased the range of talents of the girls.
Also in 1716, Vivaldi wrote and produced two more operas, "L'incoronazione di Dario" (RV 719) and "La costanza trionfante degli amori e degli odi" (RV 706). The latter was so popular that it performed two years later, re-edited and retitled "Artabano re dei Parti" (RV 701, now lost). It was also performed in Prague in 1732. In the years that followed, Vivaldi wrote several operas that were performed all over Italy.
His progressive operatic style caused him some trouble with more conservative musicians such as Benedetto Marcello, a magistrate and amateur musician who wrote a pamphlet denouncing Vivaldi and his operas. The pamphlet, "Il teatro alla moda", attacks the composer even as it does not mention him directly. The cover drawing shows a boat (the Sant'Angelo), on the left end of which stands a little angel wearing a priest's hat and playing the violin. The Marcello family claimed ownership of the Teatro Sant'Angelo, and a long legal battle had been fought with the management for its restitution, without success. The obscure text under the engraving mentions non-existent places and names: for example, "ALDIVIVA" is an anagram of "A. Vivaldi".
In a letter written by Vivaldi to his patron Marchese Bentivoglio in 1737, he makes reference to his "94 operas". Only around 50 operas by Vivaldi have been discovered, and no other documentation of the remaining operas exists. Although Vivaldi may have been exaggerating, it is plausible that, in his dual role of composer and "impresario", he may have either written or been responsible for the production of as many as 94 operas—given that his career had by then spanned almost 25 years. While Vivaldi certainly composed many operas in his time, he never attained the prominence of other great composers such as Alessandro Scarlatti, Johann Adolph Hasse, Leonardo Leo, and Baldassare Galuppi, as evidenced by his inability to keep a production running for an extended period of time in any major opera house.
In 1717 or 1718, Vivaldi was offered a prestigious new position as "Maestro di Cappella" of the court of prince Philip of Hesse-Darmstadt, governor of Mantua, in the northwest of Italy. He moved there for three years and produced several operas, among them "Tito Manlio" (RV 738). In 1721, he was in Milan, where he presented the pastoral drama "La Silvia" (RV 734); nine arias from it survive. He visited Milan again the following year with the oratorio "L'adorazione delli tre re magi al bambino Gesù" (RV 645, now lost). In 1722 he moved to Rome, where he introduced his operas' new style. The new pope Benedict XIII invited Vivaldi to play for him. In 1725, Vivaldi returned to Venice, where he produced four operas in the same year.
During this period Vivaldi wrote the "Four Seasons", four violin concertos that give musical expression to the seasons of the year. Though three of the concerti are wholly original, the first, "Spring", borrows motifs from a Sinfonia in the first act of Vivaldi's contemporaneous opera "Il Giustino". The inspiration for the concertos was probably the countryside around Mantua. They were a revolution in musical conception: in them Vivaldi represented flowing creeks, singing birds (of different species, each specifically characterized), barking dogs, buzzing mosquitoes, crying shepherds, storms, drunken dancers, silent nights, hunting parties from both the hunters' and the prey's point of view, frozen landscapes, ice-skating children, and warming winter fires. Each concerto is associated with a sonnet, possibly by Vivaldi, describing the scenes depicted in the music. They were published as the first four concertos in a collection of twelve, "Il cimento dell'armonia e dell'inventione", Opus 8, published in Amsterdam by Michel-Charles Le Cène in 1725.
During his time in Mantua, Vivaldi became acquainted with an aspiring young singer Anna Tessieri Girò, who would become his student, protégée, and favorite "prima donna". Anna, along with her older half-sister Paolina, moved in with Vivaldi and regularly accompanied him on his many travels. There was speculation as to the nature of Vivaldi's and Girò's relationship, but no evidence exists to indicate anything beyond friendship and professional collaboration. Vivaldi, in fact, adamantly denied any romantic relationship with Girò in a letter to his patron Bentivoglio dated 16 November 1737.
At the height of his career, Vivaldi received commissions from European nobility and royalty. The "serenata" (cantata) "Gloria e Imeneo" (RV 687) was commissioned in 1725 by the French ambassador to Venice in celebration of the marriage of Louis XV. The following year, another "serenata", "La Sena festeggiante" (RV 694), was written for and premiered at the French embassy as well, celebrating the birth of the French royal princesses, Henriette and Louise Élisabeth. Vivaldi's Opus 9, "La cetra", was dedicated to Emperor Charles VI. In 1728, Vivaldi met the emperor while the emperor was visiting Trieste to oversee the construction of a new port. Charles admired the music of the Red Priest so much that he is said to have spoken more with the composer during their one meeting than he spoke to his ministers in over two years. He gave Vivaldi the title of knight, a gold medal and an invitation to Vienna. Vivaldi gave Charles a manuscript copy of "La cetra", a set of concerti almost completely different from the set of the same title published as Opus 9. The printing was probably delayed, forcing Vivaldi to gather an improvised collection for the emperor.
Accompanied by his father, Vivaldi traveled to Vienna and Prague in 1730, where his opera "Farnace" (RV 711) was presented; it garnered six revivals. Some of his later operas were created in collaboration with two of Italy's major writers of the time. "L'Olimpiade" and "Catone in Utica" were written by Pietro Metastasio, the major representative of the Arcadian movement and court poet in Vienna. "La Griselda" was rewritten by the young Carlo Goldoni from an earlier libretto by Apostolo Zeno.
Like many composers of the time, Vivaldi faced financial difficulties in his later years. His compositions were no longer held in such high esteem as they once had been in Venice; changing musical tastes quickly made them outmoded. In response, Vivaldi chose to sell off sizeable numbers of his manuscripts at paltry prices to finance his migration to Vienna. The reasons for Vivaldi's departure from Venice are unclear, but it seems likely that, after the success of his meeting with Emperor Charles VI, he wished to take up the position of a composer in the imperial court. On his way to Vienna, Vivaldi may have stopped in Graz to see Anna Girò.
It is also likely that Vivaldi went to Vienna to stage operas, especially as he took up residence near the Kärntnertortheater. Shortly after his arrival in Vienna, Charles VI died, which left the composer without any royal protection or a steady source of income. Soon afterwards, Vivaldi became impoverished and died during the night of 27/28 July 1741, aged 63, of "internal infection", in a house owned by the widow of a Viennese saddlemaker. On 28 July, Vivaldi was buried in a simple grave in a burial ground that was owned by the public hospital fund. His funeral took place at St. Stephen's Cathedral. Contrary to popular legend, the young Joseph Haydn had nothing to do with his burial, since no music was performed on that occasion. The cost of his funeral with a 'Kleingeläut' was 19 Gulden 45 Kreuzer which was rather expensive for the lowest class of peal of bells.
Vivaldi was buried next to Karlskirche, a baroque church in an area which is now part of the site of the TU Wien. The house where he lived in Vienna has since been destroyed; the Hotel Sacher is built on part of the site. Memorial plaques have been placed at both locations, as well as a Vivaldi "star" in the Viennese Musikmeile and a monument at the Rooseveltplatz.
Only two, possibly three original portraits of Vivaldi are known to survive: an engraving, an ink sketch and an oil painting. The engraving, which was the basis of several copies produced later by other artists, was made in 1725 by François Morellon de La Cave for the first edition of "Il cimento dell'armonia e dell'inventione", and shows Vivaldi holding a sheet of music. The ink sketch, a caricature, was done by Ghezzi in 1723 and shows Vivaldi's head and shoulders in profile. It exists in two versions: a first jotting kept at the Vatican Library, and a much lesser-known, slightly more detailed copy recently discovered in Moscow. The oil painting, which can be seen in the International Museum and Library of Music of Bologna, is anonymous and is thought to depict Vivaldi due to its strong resemblance to the La Cave engraving.
Vivaldi's music was innovative. He brightened the formal and rhythmic structure of the concerto, in which he looked for harmonic contrasts and innovative melodies and themes. Many of his compositions are flamboyantly exuberant.
Johann Sebastian Bach was deeply influenced by Vivaldi's concertos and arias (recalled in his "St John Passion", "St Matthew Passion", and cantatas). Bach transcribed six of Vivaldi's concerti for solo keyboard, three for organ, and one for four harpsichords, strings, and basso continuo (BWV 1065) based upon the concerto for four violins, two violas, cello, and basso continuo (RV 580).
During his lifetime, Vivaldi was popular in many countries throughout Europe, including France, but after his death his popularity dwindled. After the end of the Baroque period, Vivaldi's published concerti became relatively unknown, and were largely ignored. Even his most famous work, "The Four Seasons", was unknown in its original edition during the Classical and Romantic periods.
In the early 20th century, Fritz Kreisler's Concerto in C, in the Style of Vivaldi (which he passed off as an original Vivaldi work) helped revive Vivaldi's reputation. This spurred the French scholar Marc Pincherle to begin an academic study of Vivaldi's oeuvre. Many Vivaldi manuscripts were rediscovered, which were acquired by the Turin National University Library as a result of the generous sponsorship of Turinese businessmen Roberto Foa and Filippo Giordano, in memory of their sons. This led to a renewed interest in Vivaldi by, among others, Mario Rinaldi, Alfredo Casella, Ezra Pound, Olga Rudge, Desmond Chute, Arturo Toscanini, Arnold Schering and Louis Kaufman, all of whom were instrumental in the revival of Vivaldi throughout the 20th century.
In 1926, in a monastery in Piedmont, researchers discovered fourteen folios of Vivaldi's work that were previously thought to have been lost during the Napoleonic Wars. Some missing volumes in the numbered set were discovered in the collections of the descendants of the Grand Duke Durazzo, who had acquired the monastery complex in the 18th century. The volumes contained 300 concertos, 19 operas and over 100 vocal-instrumental works.
The resurrection of Vivaldi's unpublished works in the 20th century is mostly due to the efforts of Alfredo Casella, who in 1939 organized the historic Vivaldi Week, in which the rediscovered Gloria (RV 589) and l'Olimpiade were revived. Since World War II, Vivaldi's compositions have enjoyed wide success. Historically informed performances, often on "original instruments", have increased Vivaldi's fame still further.
Recent rediscoveries of works by Vivaldi include two psalm settings of "Nisi Dominus" (RV 803, in eight movements) and Dixit Dominus (RV 807, in eleven movements). These were identified in 2003 and 2005 respectively, by the Australian scholar Janice Stockigt. The Vivaldi scholar Michael Talbot described RV 807 as "arguably the best nonoperatic work from Vivaldi's pen to come to light since […] the 1920s". Vivaldi's 1730 opera "Argippo" (RV 697), which had been considered lost, was rediscovered in 2006 by the harpsichordist and conductor Ondřej Macek, whose Hofmusici orchestra performed the work at Prague Castle on 3 May 2008—its first performance since 1730.
A composition by Vivaldi is identified by RV number, which refers to its place in the "Ryom-Verzeichnis" or "Répertoire des oeuvres d'Antonio Vivaldi", a catalog created in the 20th century by the musicologist Peter Ryom.
"Le quattro stagioni" (The Four Seasons) of 1723 is his most famous work. Part of "Il cimento dell'armonia e dell'inventione" ("The Contest between Harmony and Invention"), it depicts moods and scenes from each of the four seasons. This work has been described as an outstanding instance of pre-19th century program music.
Vivaldi wrote more than 500 other concertos. About 350 of these are for solo instrument and strings, of which 230 are for violin, the others being for bassoon, cello, oboe, flute, viola d'amore, recorder, lute, or mandolin. About forty concertos are for two instruments and strings, and about thirty are for three or more instruments and strings.
As well as about 46 operas, Vivaldi composed a large body of sacred choral music, such as Magnificat. Other works include sinfonias, about 90 sonatas and chamber music.
Some sonatas for flute, published as "Il Pastor Fido", have been erroneously attributed to Vivaldi, but were composed by Nicolas Chédeville.
Vivaldi's works attracted cataloging efforts befitting a major composer. Scholarly work intended to increase the accuracy and variety of Vivaldi performances also supported new discoveries which made old catalogs incomplete. Works still in circulation today may be numbered under several different systems (some earlier catalogs are mentioned here).
Because the simply consecutive Complete Edition (CE) numbers did not reflect the individual works (Opus numbers) into which compositions were grouped, numbers assigned by Antonio Fanna were often used in conjunction with CE numbers. Combined Complete Edition (CE)/Fanna numbering was especially common in the work of Italian groups driving the mid-20th century revival of Vivaldi, such as Gli Accademici di Milano under Piero Santi. For example, the Bassoon Concerto in B major, "La Notte" RV 501, became CE 12, F. VIII,1
Despite the awkwardness of having to overlay Fanna numbers onto the Complete Edition number for meaningful grouping of Vivaldi's oeuvre, these numbers displaced the older Pincherle numbers as the (re-)discovery of more manuscripts had rendered older catalogs obsolete.
This cataloging work was led by the Istituto Italiano Antonio Vivaldi, where Gian Francesco Malipiero was both the director and the editor of the published scores (Edizioni G. Ricordi). His work built on that of Antonio Fanna, a Venetian businessman and the Institute's founder, and thus formed a bridge to the scholarly catalog dominant today.
Compositions by Vivaldi are identified today by RV number, the number assigned by Danish musicologist Peter Ryom in works published mostly in the 1970s, such as the "Ryom-Verzeichnis" or "Répertoire des oeuvres d'Antonio Vivaldi". Like the Complete Edition before it, the RV does not typically assign its single, consecutive numbers to "adjacent" works that occupy one of the composer's single opus numbers. Its goal as a modern catalog is to index the manuscripts and sources that establish the existence and nature of all known works.
The movie "" was completed in 2005 as an Italian-French co-production under the direction of . In 2005, ABC Radio National commissioned a radio play about Vivaldi, which was written by Sean Riley. Entitled "The Angel and the Red Priest", the play was later adapted for the stage and was performed at the Adelaide Festival of the Arts.

</doc>
<doc id="1428" url="https://en.wikipedia.org/wiki?curid=1428" title="Adrian">
Adrian

Adrian is a form of the Latin given name "Adrianus" or "Hadrianus". Its ultimate origin is most likely via the former river Adria from the Venetic and Illyrian word "adur", meaning 'sea' or 'water'. Adur also means 'holy fire' in Middle Persian language. 
The Adria was until the 8th century BC the main channel of the Po River into the Adriatic Sea but ceased to exist before the 1st century BC. Hecataeus of Miletus (c.550 - c.476 BC) asserted that both the Etruscan harbor city of Adria and the Adriatic Sea had been named after it. Emperor Hadrian's family was named after the city or region of Adria/Hadria, now Atri, in Picenum, which most likely started as an Etruscan or Greek colony of the older harbor city of the same name. 
Several saints and six popes have borne this name, including the only English pope, Adrian IV, and the only Dutch pope, Adrian VI. As an English name, it has been in use since the Middle Ages, although it did not become common until modern times.

</doc>
<doc id="1433" url="https://en.wikipedia.org/wiki?curid=1433" title="Aare">
Aare

The Aare () or Aar () is a tributary of the High Rhine and the longest river that both rises and ends entirely within Switzerland.
Its total length from its source to its junction with the Rhine comprises about , during which distance it descends , draining an area of , almost entirely within Switzerland, and accounting for close to half the area of the country, including all of Central Switzerland.
There are more than 40 hydroelectric plants along the course of the Aare.
The river's name dates to at least the La Tène period, and it is attested as "Nantaror" "Aare valley" in the Berne zinc tablet.
The name was Latinized as "Arula"/"Arola"/"Araris".
The Aare rises in the great Aargletschers (Aare Glaciers) of the Bernese Alps, in the canton of Bern and west of the Grimsel Pass. The Finsteraargletscher and Lauteraargletscher come together to form the Unteraargletscher (Lower Aar Glacier), which is the main source of water for the Grimselsee (Lake of Grimsel). The Oberaargletscher (Upper Aar Glacier) feeds the Oberaarsee, which also flows into the Grimselsee. The Aare leaves the Grimselsee just to the east to the Grimsel Hospiz, below the Grimsel Pass, and then flows northwest through the Haslital, forming on the way the magnificent Handegg Waterfall, , past Guttannen.
Right after Innertkirchen it is joined by its first major tributary, the Gamderwasser. Less than later the river carves through a limestone ridge in the Aare Gorge (). It is here that the Aare proves itself to be more than just a river, as it attracts thousands of tourists annually to the causeways through the gorge. A little past Meiringen, near Brienz, the river expands into Lake Brienz. Near the west end of the lake it indirectly receives its first important tributary, the Lütschine, by the Lake of Brienz. It then runs across the swampy plain of the Bödeli (Swiss German diminutive for ground) between Interlaken and Unterseen before flowing into Lake Thun.
Near the west end of Lake Thun, the river indirectly receives the waters of the Kander, which has just been joined by the Simme, by the Lake of Thun. Lake Thun marks the head of navigation. On flowing out of the lake it passes through Thun, and then flows through the city of Bern, passing beneath eighteen bridges and around the steeply-flanked peninsula on which the Old City of Berne is located. The river soon changes its northwesterly flow for a due westerly direction, but after receiving the Saane or La Sarine it turns north until it nears Aarberg. There, in one of the major Swiss engineering feats of the 19th century, the Jura water correction, the river, which had previously rendered the countryside north of Bern a swampland through frequent flooding, was diverted by the Aare-Hagneck Canal into the Lac de Bienne. From the upper end of the lake, at Nidau, the river issues through the Nidau-Büren Canal, also called the Aare Canal, and then runs east to Büren. The lake absorbs huge amounts of eroded gravel and snowmelt that the river brings from the Alps, and the former swamps have become fruitful plains: they are known as the "vegetable garden of Switzerland".
From here the Aare flows northeast for a long distance, past the ambassador town Solothurn (below which the Grosse Emme flows in on the right), Aarburg (where it is joined by the Wigger), Olten, Aarau, near which is the junction with the Suhre, and Wildegg, where the Seetal Aabach falls in on the right. A short distance further, below Brugg it receives first the Reuss, its major tributary, and shortly afterwards the Limmat, its second strongest tributary. It now turns to north, and soon becomes itself a tributary of the Rhine, which it even surpasses in volume when the two rivers unite downstream from Koblenz (Switzerland), opposite Waldshut in Germany. The Rhine, in turn, empties into the North Sea after crossing into the Netherlands.

</doc>
<doc id="1435" url="https://en.wikipedia.org/wiki?curid=1435" title="Abbotsford, Scottish Borders">
Abbotsford, Scottish Borders

Abbotsford is a historic country house in the Scottish Borders, near Galashiels, on the south bank of the River Tweed. It was formerly the residence of historical novelist and poet, Sir Walter Scott. It is a Category A Listed Building and the estate is listed in the Inventory of Gardens and Designed Landscapes in Scotland.
The nucleus of the estate was a small farm of , called Cartleyhole, nicknamed Clarty (i.e., muddy) Hole, and was bought by Scott on the lapse of his lease (1811) of the neighbouring house of Ashestiel. Scott renamed it "Abbotsford" after a neighbouring ford used by the monks of Melrose Abbey. Following a modest enlargement of the original farmhouse in 1811–12, massive expansions took place in 1816–19 and 1822–24. In this mansion Scott he gathered a large library, a collection of ancient furniture, arms and armour, and other relics and curiosities especially connected with Scottish history, notably the Celtic Torrs Pony-cap and Horns and the Woodwrae Stone, all now in the Museum of Scotland. Scott described the resulting building as "a sort of romance in Architecture" and "a kind of Conundrum Castle to be sure".
The last and principal acquisition was that of Toftfield (afterwards named Huntlyburn), purchased in 1817. The new house was then begun and completed in 1824.
The general ground-plan is a parallelogram, with irregular outlines, one side overlooking the Tweed; and the style is mainly the Scottish Baronial. With his architects William Atkinson and Edward Blore Scott was a pioneer of the Scottish Baronial style of architecture: the house is recognized as a highly influential creation with themes from Abbotsford being reflected across many buildings in the Scottish Borders and beyond. The manor as a whole appears as a "castle-in-miniature", with small towers and imitation battlements decorating the house and garden walls. Into various parts of the fabric were built relics and curiosities from historical structures, such as the doorway of the old Tolbooth in Edinburgh. Scott collected many of these curiosities to be built into the walls of the South Garden, which previously hosted a colonnade of gothic arches along the garden walls. Along the path of the former colonnade sits the remains of Edinburgh's 15th century Mercat Cross and several examples of classical sculpture.
The estate and its neo-Medieval features nod towards Scott's desire for a historical feel, but the writer ensured that the house would provide all the comforts of modern living. As a result, Scott used the space as a proving-ground for new technologies. The house was outfitted with early gas lighting and pneumatic bells connecting residents with servants elsewhere in the house.
Scott had only enjoyed his residence one year when (1825) he met with that reverse of fortune which involved the estate in debt. In 1830, the library and museum were presented to him as a free gift by the creditors. The property was wholly disencumbered in 1847 by Robert Cadell, the publisher, who cancelled the bond upon it in exchange for the family's share in the copyright of Sir Walter's works. 
Scott's only son Walter did not live to enjoy the property, having died on his way from India in 1847. Among subsequent possessors were Scott's grandson Walter Scott Lockhart (later Walter Lockhart Scott, 1826–1853), his younger sister Charlotte Harriet Jane Hope-Scott (née Lockhart) 1828–1858, J. R. Hope Scott, QC, and his daughter (Scott's great-granddaughter), the Hon. Mrs Maxwell Scott.
The house was opened to the public in 1833, but continued to be occupied by Scott's descendants until 2004. The last of his direct descendants to hold the Lairdship of Abbotsford was his great-great-great-granddaughter Dame Jean Maxwell-Scott (8 June 1923 – 5 May 2004). She inherited it from her elder sister Patricia Maxwell-Scott in 1998. The sisters turned the house into one of Scotland's premier tourist attractions, after they had to rely on paying visitors to afford the upkeep of the house. It had electricity installed only in 1962.
Dame Jean was at one time a lady-in-waiting to Princess Alice, Duchess of Gloucester, patron of the Dandie Dinmont Club, a breed of dog named after one of Sir Walter Scott's characters; and a horse trainer, one of whose horses, Sir Wattie, ridden by Ian Stark, won two silver medals at the 1988 Summer Olympics.
On Dame Jean's death the Abbotsford Trust was established to safeguard the estate.
In 2005, Scottish Borders Council considered an application by a property developer to build a housing estate on the opposite bank of the River Tweed from Abbotsford, to which Historic Scotland and the National Trust for Scotland objected. There have been modifications to the proposed development, but it is still being opposed in 2020.
Sir Walter Scott rescued the "jougs" from Threave Castle in Dumfries and Galloway and attached them to the castellated gateway he built at Abbotsford.
Tweedbank railway station is located near to Abbotsford.
Abbotsford gave its name to the Abbotsford Club, founded by William Barclay Turnbull in 1833 or 1834 in Scott's honour, and a successor to the Bannatyne and Maitland Clubs. It was a text publication society, which existed to print and publish historical works connected with Scott's writings. Its publications extended from 1835 to 1864.
In 2012, a new Visitor Centre opened at Abbotsford which houses a small exhibition, gift shop and Ochiltree's Dining, a café/restaurant with views over the house and grounds. The house re-opened to the public after extensive renovations in 2013.
In 2014 it won the European Union Prize for Cultural Heritage / Europa Nostra Award for its recent conservation project.
Attribution

</doc>
<doc id="1436" url="https://en.wikipedia.org/wiki?curid=1436" title="Abraham">
Abraham

Abraham (originally Abram) is the common patriarch of the Abrahamic religions, including Judaism, Christianity and Islam. In Judaism, he is the founding father of the covenant of the pieces, the special relationship between the Hebrews and God; in Christianity, he is the prototype of all believers, Jewish or Gentile; and in Islam he is seen as a link in the chain of prophets that begins with Adam and culminates in Muhammad.
The narrative in the Book of Genesis revolves around the themes of posterity and land. Abraham is called by God to leave the house of his father Terah and settle in the land originally given to Canaan but which God now promises to Abraham and his progeny. Various candidates are put forward who might inherit the land after Abraham; and, while promises are made to Ishmael about founding a great nation, Isaac, Abraham's son by his half-sister Sarah, inherits God's promises to Abraham. Abraham purchases a tomb (the Cave of the Patriarchs) at Hebron to be Sarah's grave, thus establishing his right to the land; and, in the second generation, his heir Isaac is married to a woman from his own kin, thus ruling the Canaanites out of any inheritance. Abraham later marries Keturah and has six more sons; but, on his death, when he is buried beside Sarah, it is Isaac who receives "all Abraham's goods", while the other sons receive only "gifts" (Genesis 25:5–8).
The Abraham story cannot be definitively related to any specific time, and it is widely agreed that the patriarchal age, along with The Exodus and the period of the judges, is a late literary construct that does not relate to any period in actual history. A common hypothesis among scholars is that it was composed in the early Persian period (late 6th century BCE) as a result of tensions between Jewish landowners who had stayed in Judah during the Babylonian captivity and traced their right to the land through their "father Abraham", and the returning exiles who based their counterclaim on Moses and The Exodus tradition.
Terah, the ninth in descent from Noah, was the father of three sons: Abram, Nahor, and Haran. The entire family, including grandchildren, lived in Ur of the Chaldees. According to a midrash, Abram worked in Terah's idol shop in his youth. Haran was the father of Lot, and thus Lot was Abram's nephew. Haran died in his native city, Ur of the Chaldees.
Abram married Sarah (Sarai), who was barren. Terah, with Abram, Sarai, and Lot, then departed for Canaan, but settled in a place named Haran, where Terah died at the age of 205. God had told Abram to leave his country and kindred and go to a land that he would show him, and promised to make of him a great nation, bless him, make his name great, bless them that bless him, and curse them who may curse him. Abram was 75 years old when he left Haran with his wife Sarai, his nephew Lot, and the substance and souls that they had acquired, and traveled to Shechem in Canaan.
Then he pitched his tent in the east of Bethel.
There was a severe famine in the land of Canaan, so that Abram and Lot and their households traveled to Egypt. On the way Abram told Sarai to say that she was his sister, so that the Egyptians would not kill him. When they entered Egypt, the Pharaoh's officials praised Sarai's beauty to Pharaoh, and they took her into the palace and gave Abram goods in exchange. God afflicted Pharaoh and his household with plagues, which led Pharaoh to try to find out what was wrong. Upon discovering that Sarai was a married woman, Pharaoh demanded that Abram and Sarai leave.
When they lived for a while in the Negev after being banished from Egypt and came back to the Bethel and Ai area, Abram's and Lot's sizable herds occupied the same pastures. This became a problem for the herdsmen, who were assigned to each family's cattle. The conflicts between herdsmen had become so troublesome that Abram suggested that Lot choose a separate area, either on the left hand or on the right hand, that there be no conflict amongst brethren. Lot decided to go eastward to the plain of Jordan, where the land was well watered everywhere as far as Zoar, and he dwelled in the cities of the plain toward Sodom. Abram went south to Hebron and settled in the plain of Mamre, where he built another altar to worship God.
During the rebellion of the Jordan River cities, Sodom and Gomorrah, against Elam, Abram's nephew, Lot, was taken prisoner along with his entire household by the invading Elamite forces. The Elamite army came to collect the spoils of war, after having just defeated the king of Sodom's armies. Lot and his family, at the time, were settled on the outskirts of the Kingdom of Sodom which made them a visible target.
One person who escaped capture came and told Abram what happened. Once Abram received this news, he immediately assembled 318 trained servants. Abram's force headed north in pursuit of the Elamite army, who were already worn down from the Battle of Siddim. When they caught up with them at Dan, Abram devised a battle plan by splitting his group into more than one unit, and launched a night raid. Not only were they able to free the captives, Abram's unit chased and slaughtered the Elamite King Chedorlaomer at Hobah, just north of Damascus. They freed Lot, as well as his household and possessions, and recovered all of the goods from Sodom that had been taken.
Upon Abram's return, Sodom's king came out to meet with him in the Valley of Shaveh, the "king's dale". Also, Melchizedek king of Salem (Jerusalem), a priest of God Most High, brought out bread and wine and blessed Abram and God. Abram then gave Melchizedek a tenth of everything. The king of Sodom then offered to let Abram keep all the possessions if he would merely return his people. Abram refused any deal from the king of Sodom, other than the share to which his allies were entitled.
The voice of the Lord came to Abram in a vision and repeated the promise of the land and descendants as numerous as the stars. Abram and God made a covenant ceremony, and God told of the future bondage of Israel in Egypt. God described to Abram the land that his offspring would claim: the land of the Kenites, Kenizzites, Kadmonites, Hittites, Perizzites, Rephaims, Amorites, Canaanites, Girgashites, and Jebusites.
Abram and Sarai tried to make sense of how he would become a progenitor of nations, because after 10 years of living in Canaan, no child had been born. Sarai then offered her Egyptian handmaiden, Hagar, to Abram with the intention that she would bear him a son.
After Hagar found she was pregnant, she began to despise her mistress, Sarai. Sarai responded by mistreating Hagar, and Hagar fled into the wilderness. An angel spoke with Hagar at the fountain on the way to Shur. He instructed her to return to Abram's camp and that her son would be "a wild ass of a man; his hand shall be against every man, and every man's hand against him; and he shall dwell in the face of all his brethren." She was told to call her son Ishmael. Hagar then called God who spoke to her "El-roi", ("Thou God seest me:" KJV). From that day onward, the well was called Beer-lahai-roi, ("The well of him that liveth and seeth me." KJV margin). She then did as she was instructed by returning to her mistress in order to have her child. Abram was 86 years of age when Ishmael was born.
Thirteen years later, when Abram was 99 years of age, God declared Abram's new name: "Abraham" – "a father of many nations". Abraham then received the instructions for the covenant, of which circumcision was to be the sign.
God declared Sarai's new name: "Sarah", blessed her, and told Abraham, "I will give thee a son also of her". Abraham laughed, and "said in his heart, 'Shall a "child" be born unto him that is a hundred years old? and shall Sarah, that is ninety years old, bear [a child]?'" Immediately after Abraham's encounter with God, he had his entire household of men, including himself (age 99) and Ishmael (age 13), circumcised.
Not long afterward, during the heat of the day, Abraham had been sitting at the entrance of his tent by the terebinths of Mamre. He looked up and saw three men in the presence of God. Then he ran and bowed to the ground to welcome them. Abraham then offered to wash their feet and fetch them a morsel of bread, to which they assented. Abraham rushed to Sarah's tent to order ash cakes made from choice flour, then he ordered a servant-boy to prepare a choice calf. When all was prepared, he set curds, milk and the calf before them, waiting on them, under a tree, as they ate.
One of the visitors told Abraham that upon his return next year, Sarah would have a son. While at the tent entrance, Sarah overheard what was said and she laughed to herself about the prospect of having a child at their ages. The visitor inquired of Abraham why Sarah laughed at bearing a child at her age, as nothing is too hard for God. Frightened, Sarah denied laughing.
After eating, Abraham and the three visitors got up. They walked over to the peak that overlooked the 'cities of the plain' to discuss the fate of Sodom and Gomorrah for their detestable sins that were so great, it moved God to action. Because Abraham's nephew was living in Sodom, God revealed plans to confirm and judge these cities. At this point, the two other visitors left for Sodom. Then Abraham turned to God and pleaded decrementally with Him (from fifty persons to less) that "if there were at least ten righteous men found in the city, would not God spare the city?" For the sake of ten righteous people, God declared that he would not destroy the city.
When the two visitors arrived in Sodom to conduct their report, they planned on staying in the city square. However, Abraham's nephew, Lot, met with them and strongly insisted that these two "men" stay at his house for the night. A rally of men stood outside of Lot's home and demanded that Lot bring out his guests so that they may "know" ( 5) them. However, Lot objected and offered his virgin daughters who had not "known" (v. 8) man to the rally of men instead. They rejected that notion and sought to break down Lot's door to get to his male guests, thus confirming the wickedness of the city and portending their imminent destruction.
Early the next morning, Abraham went to the place where he stood before God. He "looked out toward Sodom and Gomorrah" and saw what became of the cities of the plain, where not even "ten righteous" (v. 18:32) had been found, as "the smoke of the land went up as the smoke of a furnace."
Abraham settled between Kadesh and Shur in what the Bible anachronistically calls "the land of the Philistines". While he was living in Gerar, Abraham openly claimed that Sarah was his sister. Upon discovering this news, King Abimelech had her brought to him. God then came to Abimelech in a dream and declared that taking her would result in death because she was a man's wife. Abimelech had not laid hands on her, so he inquired if he would also slay a righteous nation, especially since Abraham had claimed that he and Sarah were siblings. In response, God told Abimelech that he did indeed have a blameless heart and that is why he continued to exist. However, should he not return the wife of Abraham back to him, God would surely destroy Abimelech and his entire household. Abimelech was informed that Abraham was a prophet who would pray for him.
Early next morning, Abimelech informed his servants of his dream and approached Abraham inquiring as to why he had brought such great guilt upon his kingdom. Abraham stated that he thought there was no fear of God in that place, and that they might kill him for his wife. Then Abraham defended what he had said as not being a lie at all: "And yet indeed "she is" my sister; she "is" the daughter of my father, but not the daughter of my mother; and she became my wife." Abimelech returned Sarah to Abraham, and gave him gifts of sheep, oxen, and servants; and invited him to settle wherever he pleased in Abimelech's lands. Further, Abimelech gave Abraham a thousand pieces of silver to serve as Sarah's vindication before all. Abraham then prayed for Abimelech and his household, since God had stricken the women with infertility because of the taking of Sarah.
After living for some time in the land of the Philistines, Abimelech and Phicol, the chief of his troops, approached Abraham because of a dispute that resulted in a violent confrontation at a well. Abraham then reproached Abimelech due to his Philistine servant's aggressive attacks and the seizing of Abraham's well. Abimelech claimed ignorance of the incident. Then Abraham offered a pact by providing sheep and oxen to Abimelech. Further, to attest that Abraham was the one who dug the well, he also gave Abimelech seven ewes for proof. Because of this sworn oath, they called the place of this well: Beersheba. After Abimelech and Phicol headed back to Philistia, Abraham planted a tamarisk grove in Beersheba and called upon "the name of the , the everlasting God."
As had been prophesied in Mamre the previous year, Sarah became pregnant and bore a son to Abraham, on the first anniversary of the covenant of circumcision. Abraham was "an hundred years old", when his son whom he named Isaac was born; and he circumcised him when he was eight days old. For Sarah, the thought of giving birth and nursing a child, at such an old age, also brought her much laughter, as she declared, "God hath made me to laugh, so that all who hear will laugh with me." Isaac continued to grow and on the day he was weaned, Abraham held a great feast to honor the occasion. During the celebration, however, Sarah found Ishmael mocking; an observation that would begin to clarify the birthright of Isaac.
Ishmael was fourteen years old when Abraham's son Isaac was born to Sarah. When she found Ishmael teasing Isaac, Sarah told Abraham to send both Ishmael and Hagar away. She declared that Ishmael would not share in Isaac's inheritance. Abraham was greatly distressed by his wife's words and sought the advice of his God. God told Abraham not to be distressed but to do as his wife commanded. God reassured Abraham that "in Isaac shall seed be called to thee." He also said that Ishmael would make a nation, "because he is thy seed".
Early the next morning, Abraham brought Hagar and Ishmael out together. He gave her bread and water and sent them away. The two wandered in the wilderness of Beersheba until her bottle of water was completely consumed. In a moment of despair, she burst into tears. After God heard the boy's voice, an angel of the Lord confirmed to Hagar that he would become a great nation, and will be "living on his sword". A well of water then appeared so that it saved their lives. As the boy grew, he became a skilled archer living in the wilderness of Paran. Eventually his mother found a wife for Ishmael from her home country, the land of Egypt.
At some point in Isaac's youth, Abraham was commanded by God to offer his son up as a sacrifice in the land of Moriah. The patriarch traveled three days until he came to the mount that God told him of. He then commanded the servants to remain while he and Isaac proceeded alone into the mount. Isaac carried the wood upon which he would be sacrificed. Along the way, Isaac asked his father where the animal for the burnt offering was, to which Abraham replied "God will provide himself a lamb for a burnt offering". Just as Abraham was about to sacrifice his son, he was interrupted by the angel of the Lord, and he saw behind him a "ram caught in a thicket by his horns", which he sacrificed instead of his son. The place was later named as Jehovah-jireh. For his obedience he received another promise of numerous descendants and abundant prosperity. After this event, Abraham went to Beersheba.
Sarah died, and Abraham buried her in the Cave of the Patriarchs (the "cave of Machpelah"), near Hebron which he had purchased along with the adjoining field from Ephron the Hittite. After the death of Sarah, Abraham took another wife, a concubine named Keturah, by whom he had six sons: Zimran, Jokshan, Medan, Midian, Ishbak, and Shuah. According to the Bible, reflecting the change of his name to "Abraham" meaning "a father of many nations", Abraham is considered to be the progenitor of many nations mentioned in the Bible, among others the Israelites, Ishmaelites, Edomites, Amalekites, Kenizzites, Midianites and Assyrians, and through his nephew Lot he was also related to the Moabites and Ammonites. Abraham lived to see his son marry Rebekah, and to see the birth of his twin grandsons Jacob and Esau. He died at age 175, and was buried in the cave of Machpelah by his sons Isaac and Ishmael.
In the early and middle 20th century, leading archaeologists such as William F. Albright and biblical scholars such as Albrecht Alt believed that the patriarchs and matriarchs were either real individuals or believable composites of people who lived in the "patriarchal age", the 2nd millennium BCE. But, in the 1970s, new arguments concerning Israel's past and the biblical texts challenged these views; these arguments can be found in Thomas L. Thompson's "The Historicity of the Patriarchal Narratives" (1974), and John Van Seters' "Abraham in History and Tradition" (1975). Thompson, a literary scholar, based his argument on archaeology and ancient texts. His thesis centered on the lack of compelling evidence that the patriarchs lived in the 2nd millennium BCE, and noted how certain biblical texts reflected first millennium conditions and concerns. Van Seters examined the patriarchal stories and argued that their names, social milieu, and messages strongly suggested that they were Iron Age creations. By the beginning of the 21st century, archaeologists had given up hope of recovering any context that would make Abraham, Isaac or Jacob credible historical figures.
Abraham's story, like those of the other patriarchs, most likely had a substantial oral prehistory, and his name is apparently very ancient, as the tradition found in Genesis no longer understands its original meaning (probably "Father is exalted" – the meaning offered in Genesis 17:5, "Father of a multitude", is a popular etymology). At some stage the oral traditions became part of the written tradition of the Pentateuch; a majority of scholars believe this stage belongs to the Persian period, roughly 520–320 BCE. The mechanisms by which this came about remain unknown, but there are currently two important hypotheses. The first, called Persian Imperial authorisation, is that the post-Exilic community devised the Torah as a legal basis on which to function within the Persian Imperial system; the second is that the Pentateuch was written to provide the criteria for determining who would belong to the post-Exilic Jewish community and to establish the power structures and relative positions of its various groups, notably the priesthood and the lay "elders".
Nevertheless, the completion of the Torah and its elevation to the centre of post-Exilic Judaism was as much or more about combining older texts as writing new ones – the final Pentateuch was based on existing traditions. In Ezekiel , written during the Exile (i.e., in the first half of the 6th century BCE), Ezekiel, an exile in Babylon, tells how those who remained in Judah are claiming ownership of the land based on inheritance from Abraham; but the prophet tells them they have no claim because they do not observe Torah. Isaiah similarly testifies of tension between the people of Judah and the returning post-Exilic Jews (the "gôlâ"), stating that God is the father of Israel and that Israel's history begins with the Exodus and not with Abraham. The conclusion to be inferred from this and similar evidence (e.g., Ezra–Nehemiah), is that the figure of Abraham must have been preeminent among the great landowners of Judah at the time of the Exile and after, serving to support their claims to the land in opposition to those of the returning exiles.
Abraham is given a high position of respect in three major world faiths, Judaism, Christianity and Islam. In Judaism, he is the founding father of the Covenant, the special relationship between the Jewish people and God – leading to the belief that the Jews are the Chosen People of God. In Christianity, the Apostle Paul taught that Abraham's faith in God – preceding the Mosaic law – made him the prototype of all believers, circumcised and uncircumcised. In Islam, the prophet Muhammad claimed Abraham, whose submission to God constituted "Islam", was a "believer before the fact" and undercut Jewish claims to an exclusive relationship with God and the Covenant.
In Jewish tradition, Abraham is called "Avraham Avinu" (אברהם אבינו), "our father Abraham," signifying that he is both the biological progenitor of the Jews and the father of Judaism, the first Jew. His story is read in the weekly Torah reading portions, predominantly in the parashot: Lech-Lecha (לֶךְ-לְךָ), Vayeira (וַיֵּרָא), Chayei Sarah (חַיֵּי שָׂרָה), and Toledot (תּוֹלְדֹת).
In Jewish legend, God created heaven and earth for the sake of the merits of Abraham. After the Biblical flood, Abraham was the only one among the pious who solemnly swore never to forsake God, studied in the house of Noah and Shem to learn about the "Ways of God," continued the line of High Priest from Noah and Shem, and descended the office to Levi and his seed forever. Before leaving his father's land, Abraham was miraculously saved from the fiery furnace of Nimrod following his brave action of breaking the idols of the Chaldeans into pieces. During his sojourning in Canaan, Abraham was accustomed to extend hospitality to travelers and strangers and taught how to praise God also knowledge of God to those who had received his kindness.
Besides Isaac and Jacob, he is the one whose name would appear united with God, as God in Judaism was called "Elohei Abraham, Elohei Yitzchaq ve Elohei Ya`aqob" ("God of Abraham, God of Isaac, and God of Jacob") and never the God of any one else. He was also mentioned as the father of thirty nations.
Abraham is generally credited as the author of the "Sefer Yetzirah", one of the earliest extant books on Jewish mysticism.
According to Pirkei Avot, Abraham underwent ten tests at God's command. The Binding of Isaac is specified in the Bible as a test; the other nine are not specified, but later rabbinical sources give various enumerations.
Abraham does not loom so large in Christianity as he does in Judaism and Islam. It is Jesus as the Jewish Messiah who is central to Christianity, and the idea of a divine Messiah is what separates Christianity from the other two religions. In Romans 4, Abraham's merit is less his obedience to the divine will than his faith in God's ultimate grace; this faith provides him the merit for God having chosen him for the covenant, and the covenant becomes one of faith, not obedience.
The Roman Catholic Church calls Abraham "our father in Faith" in the Eucharistic prayer of the Roman Canon, recited during the Mass. He is also commemorated in the calendars of saints of several denominations: on 20 August by the Maronite Church, 28 August in the Coptic Church and the Assyrian Church of the East (with the full office for the latter), and on 9 October by the Roman Catholic Church and the Lutheran Church–Missouri Synod. In the introduction to his 15th-century translation of the Golden Legend's account of Abraham, William Caxton noted that this patriarch's life was read in church on Quinquagesima Sunday.
He is the patron saint of those in the hospitality industry. The Eastern Orthodox Church commemorates him as the "Righteous Forefather Abraham", with two feast days in its liturgical calendar. The first time is on 9 October (for those churches which follow the traditional Julian Calendar, 9 October falls on 22 October of the modern Gregorian Calendar), where he is commemorated together with his nephew "Righteous Lot". The other is on the "Sunday of the Forefathers" (two Sundays before Christmas), when he is commemorated together with other ancestors of Jesus. Abraham is also mentioned in the Divine Liturgy of Saint Basil the Great, just before the Anaphora, and Abraham and Sarah are invoked in the prayers said by the priest over a newly married couple.
Islam regards Abraham as a link in the chain of prophets that begins with Adam and culminates in Muhammad.
"Ibrāhīm" is mentioned in 35 chapters of the Quran, more often than any other biblical personage apart from Moses. He is called both a "hanif" (monotheist) and "muslim" (one who submits), and Muslims regard him as a prophet and patriarch, the archetype of the perfect Muslim, and the revered reformer of the Kaaba in Mecca. Islamic traditions consider Ibrāhīm the first Pioneer of Islam (which is also called "millat Ibrahim", the "religion of Abraham"), and that his purpose and mission throughout his life was to proclaim the Oneness of God. In Islam, Abraham holds an exalted position among the major prophets and he is referred to as "Ibrahim Khalilullah", meaning "Abraham the Beloved of Allah".
Besides Ishaq and Yaqub, Ibrahim is among the most honorable and the most excellent men in sight of God. Ibrahim was also mentioned in Quran as "Father of Muslims" and the role model for the community.
The Druze regard Abraham as the third spokesman ("natiq") after Adam and Noah, who helped transmit the foundational teachings of monotheism ("tawhid") intended for the larger audience.
Paintings on the life of Abraham tend to focus on only a few incidents: the sacrifice of Isaac; meeting Melchizedek; entertaining the three angels; Hagar in the desert; and a few others. Additionally, Martin O'Kane, a professor of Biblical Studies, writes that the parable of Lazarus resting in the "Bosom of Abraham", as described in the Gospel of Luke, became an iconic image in Christian works. According to O'Kane, artists often chose to divert from the common literary portrayal of Lazarus sitting next to Abraham at a banquet in Heaven and instead focus on the "somewhat incongruous notion of Abraham, the most venerated of patriarchs, holding a naked and vulnerable child in his bosom". Several artists have been inspired by the life of Abraham, including Albrecht Dürer (1471–1528), Caravaggio (1573–1610), Donatello, Raphael, Philip van Dyck (Dutch painter, 1680–1753), and Claude Lorrain (French painter, 1600–1682). Rembrandt (Dutch, 1606–1669) created at least seven works on Abraham, Peter Paul Rubens (1577–1640) did several, Marc Chagall did at least five on Abraham, Gustave Doré (French illustrator, 1832–1883) did six, and James Tissot (French painter and illustrator, 1836–1902) did over twenty works on the subject.
The Sarcophagus of Junius Bassus depicts a set of biblical stories, including Abraham about to sacrifice Isaac. These sculpted scenes are on the outside of a marble Early Christian sarcophagus used for the burial of Junius Bassus. He died in 359. This sarcophagus has been described as "probably the single most famous piece of early Christian relief sculpture." The sarcophagus was originally placed in or under Old St. Peter's Basilica, was rediscovered in 1597, and is now below the modern basilica in the Museo Storico del Tesoro della Basilica di San Pietro (Museum of St. Peter's Basilica) in the Vatican. The base is approximately 4 × 8 × 4 feet. The Old Testament scenes depicted were chosen as precursors of Christ's sacrifice in the New Testament, in an early form of typology. Just to the right of the middle is Daniel in the lion's den and on the left is Abraham about to sacrifice Isaac.
George Segal created figural sculptures by molding plastered gauze strips over live models in his 1987 work "Abraham's Farewell to Ishmael". The human condition was central to his concerns, and Segal used the Old Testament as a source for his imagery. This sculpture depicts the dilemma faced by Abraham when Sarah demanded that he expel Hagar and Ishmael. In the sculpture, the father's tenderness, Sarah's rage, and Hagar's resigned acceptance portray a range of human emotions. The sculpture was donated to the Miami Art Museum after the artist's death in 2000.
Usually Abraham can be identified by the context of the image the meeting with Melchizedek, , or . In solo portraits a sword or knife may be used as his attribute, as in by Gian Maria Morlaiter or by Lorenzo Monaco. He always wears a gray or white beard.
As early as the beginning of the 3rd century, Christian art followed Christian typology in making the sacrifice of Isaac a foreshadowing of Christ's sacrifice on the cross and its memorial in the sacrifice of the Mass. See for example engraved with Abraham's and other sacrifices taken to prefigure that of Christ in the Eucharist.
Some early Christian writers interpreted the three visitors as the triune God. Thus in Santa Maria Maggiore, Rome, portrays only the visitors against a gold ground and puts semitransparent copies of them in the "heavenly" space above the scene. In Eastern Orthodox art the visit is the chief means by which the Trinity is pictured (). Some images do not include Abraham and Sarah, like Andrei Rublev's "Trinity", which shows only the three visitors as beardless youths at a table.
"Fear and Trembling" (original Danish title: "Frygt og Bæven") is an influential philosophical work by Søren Kierkegaard, published in 1843 under the pseudonym "Johannes de silentio" ("John the Silent"). Kierkegaard wanted to understand the anxiety that must have been present in Abraham when God asked him to sacrifice his son. W. G. Hardy's novel "Father Abraham" (1935), tells the fictionalized life of Abraham.
In 1681, Marc-Antoine Charpentier released a Dramatic motet "Sacrificim Abrahae" H 402 - 402 a - 402 b, for soloists, chorus, doubling instruments and bc. Sébastien de Brossard released a cantate Abraham (date unknown).
In 1994, Steve Reich released an opera named "The Cave". The title refers to the Cave of the Patriarchs. The narrative of the opera is based on the story of Abraham and his immediate family as it is recounted in the various religious texts, and as it is understood by individual people from different cultures and religious traditions.
Bob Dylan's "Highway 61 Revisited" is the title track for his 1965 album "Highway 61 Revisited". In 2004, "Rolling Stone" magazine ranked the song as number 364 in their 500 Greatest Songs of All Time. The song has five stanzas. In each stanza, someone describes an unusual problem that is ultimately resolved on Highway 61. In Stanza 1, God tells Abraham to "kill me a son". God wants the killing done on Highway 61. Abram, the original name of the biblical Abraham, is also the name of Dylan's own father.

</doc>
<doc id="1437" url="https://en.wikipedia.org/wiki?curid=1437" title="Abraxas">
Abraxas

Abraxas (, variant form Abrasax, ΑΒΡΑΣΑΞ) is a word of mystic meaning in the system of the Gnostic Basilides, being there applied to the "Great Archon" (Gk., "megas archōn"), the princeps of the 365 spheres (Gk., "ouranoi"). The word is found in Gnostic texts such as the "Holy Book of the Great Invisible Spirit", and also appears in the Greek Magical Papyri. It was engraved on certain antique gemstones, called on that account Abraxas stones, which were used as amulets or charms. As the initial spelling on stones was "Abrasax" (Αβρασαξ), the spelling of "Abraxas" seen today probably originates in the confusion made between the Greek letters Sigma (Σ) and Xi (Ξ) in the Latin transliteration.
The seven letters spelling its name may represent each of the seven classic planets. The word may be related to "Abracadabra", although other explanations exist.
There are similarities and differences between such figures in reports about Basilides's teaching, ancient Gnostic texts, the larger Greco-Roman magical traditions, and modern magical and esoteric writings. Speculations have proliferated on Abraxas in recent centuries, who has been claimed to be both an Egyptian god and a demon.
Gaius Julius Hyginus ("Fab". 183) gives "Abrax Aslo Therbeeo" as names of horses of the sun mentioned by 'Homerus.' The passage is miserably corrupt: but it may not be accidental that the first three syllables make Abraxas.
The proper form of the name is evidently "Abrasax", as with the Greek writers, Hippolytus, Epiphanias, Didymus ("De Trin". iii. 42), and Theodoret; also Augustine and 'Praedestinatus'; and in nearly all the legends on gems. By a probably euphonic inversion the translator of Irenaeus and the other Latin authors have "Abraxas", which is found in the magical papyri, and even, though most sparingly, on engraved stones.
The attempts to discover a derivation for the name, Greek, Hebrew, Coptic, or other, have not been entirely successful:
Perhaps the word may be included among those mysterious expressions discussed by Adolf von Harnack, “which belong to no known speech, and by their singular collocation of vowels and consonants give evidence that they belong to some mystic dialect, or take their origin from some supposed divine inspiration.”
The Egyptian author of the book "De Mysteriis" in reply to Porphyry (vii. 4) admits a preference of 'barbarous' to vernacular names in sacred things, urging a peculiar sanctity in the languages of certain nations, as the Egyptians and Assyrians; and Origen ("Contra Cels". i. 24) refers to the 'potent names' used by Egyptian sages, Persian Magi, and Indian Brahmins, signifying deities in the several languages.
It is uncertain what the actual role and function of Abraxas was in the Basilidian system, as our authorities (see below) often show no direct acquaintance with the doctrines of Basilides himself.
In the system described by Irenaeus, "the Unbegotten Father" is the progenitor of "Nous", and from "Nous Logos", from "Logos Phronesis", from "Phronesis Sophia" and "Dynamis", from "Sophia" and "Dynamis" principalities, powers, and angels, the last of whom create "the first heaven." They in turn originate a second series, who create a second heaven. The process continues in like manner until 365 heavens are in existence, the angels of the last or visible heaven being the authors of our world. "The ruler" ["principem, i.e.", probably "ton archonta"] of the 365 heavens "is Abraxas, and for this reason he contains within himself 365 numbers."
The name occurs in the "Refutation of all Heresies" (vii. 26) by Hippolytus, who appears in these chapters to have followed the "Exegetica" of Basilides. After describing the manifestation of the Gospel in the Ogdoad and Hebdomad, he adds that the Basilidians have a long account of the innumerable creations and powers in the several 'stages' of the upper world ("diastemata"), in which they speak of 365 heavens and say that "their great archon" is Abrasax, because his name contains the number 365, the number of the days in the year; i.e. the sum of the numbers denoted by the Greek letters in ΑΒΡΑΣΑΞ according to the rules of isopsephy is 365:
Epiphanius ("Haer". 69, 73 f.) appears to follow partly Irenaeus, partly the lost Compendium of Hippolytus. He designates Abraxas more distinctly as "the power above all, and First Principle," "the cause and first archetype" of all things; and mentions that the Basilidians referred to 365 as the number of parts ("mele") in the human body, as well as of days in the year.
The author of the appendix to Tertullian "De Praescr. Haer". (c. 4), who likewise follows Hippolytus's Compendium, adds some further particulars; that 'Abraxas' gave birth to Mind ("nous"), the first in the series of primary powers enumerated likewise by Irenaeus and Epiphanius; that the world, as well as the 365 heavens, was created in honour of 'Abraxas;' and that Christ was sent not by the Maker of the world but by 'Abraxas.'
Nothing can be built on the vague allusions of Jerome, according to whom 'Abraxas' meant for Basilides "the greatest God" ("De vir. ill". 21), "the highest God" ("Dial. adv. Lucif". 23), "the Almighty God" ("Comm. in Amos" iii. 9), and "the Lord the Creator" ("Comm. in Nah". i. 11). The notices in Theodoret ("Haer. fab". i. 4), Augustine ("Haer". 4), and 'Praedestinatus' (i. 3), have no independent value.
It is evident from these particulars that Abrasax was the name of the first of the 365 Archons, and accordingly stood below Sophia and Dynamis and their progenitors; but his position is not expressly stated, so that the writer of the supplement to Tertullian had some excuse for confusing him with "the Supreme God."
With the availability of primary sources, such as those in the Nag Hammadi library, the identity of Abrasax remains unclear. The "Holy Book of the Great Invisible Spirit", for instance, refers to Abrasax as an Aeon dwelling with Sophia and other Aeons of the Pleroma in the light of the luminary Eleleth. In several texts, the luminary Eleleth is the last of the luminaries (Spiritual Lights) that come forward, and it is the Aeon Sophia, associated with Eleleth, who encounters darkness and becomes involved in the chain of events that leads to the Demiurge's rule of this world, and the salvage effort that ensues. As such, the role of Aeons of Eleleth, including Abraxas, Sophia, and others, pertains to this outer border of the Pleroma that encounters the ignorance of the world of Lack and interacts to rectify the error of ignorance in the world of materiality.
The Catholic church later deemed Abraxas a pagan god, and ultimately branded him a demon as documented in J. Collin de Plancy's "Infernal Dictionary", Abraxas (or Abracax) is labeled the "supreme God" of the Basilidians, whom he describes as "heretics of the second century." He further indicated the Basilidians attributed to Abraxas the rule over "365 skies" and "365 virtues". In a final statement on Basilidians, de Plancy states that their view was that Jesus Christ was merely a "benevolent ghost sent on Earth by Abrasax."
A vast number of engraved stones are in existence, to which the name "Abrasax-stones" has long been given. One particularly fine example was included as part of the Thetford treasure from fourth century Norfolk, UK. The subjects are mythological, and chiefly grotesque, with various inscriptions, in which ΑΒΡΑΣΑΞ often occurs, alone or with other words. Sometimes the whole space is taken up with the inscription. In certain obscure magical writings of Egyptian origin ἀβραξάς or ἀβρασάξ is found associated with other names which frequently accompany it on gems; it is also found on the Greek metal "tesseræ" among other mystic words. The meaning of the legends is seldom intelligible: but some of the gems are amulets; and the same may be the case with nearly all.
In a great majority of instances the name Abrasax is associated with a singular composite figure, having a Chimera-like appearance somewhat resembling a basilisk or the Greek primordial god Chronos (not to be confused with the Greek titan Cronus). According to E. A. Wallis Budge, "as a Pantheus, i.e. All-God, he appears on the amulets with the head of a cock (Phœbus) or of a lion (Ra or Mithras), the body of a man, and his legs are serpents which terminate in scorpions, types of the Agathodaimon. In his right hand he grasps a club, or a flail, and in his left is a round or oval shield." This form was also referred to as the Anguipede. Budge surmised that Abrasax was "a form of the Adam Kadmon of the Kabbalists and the Primal Man whom God made in His own image."
Some parts at least of the figure mentioned above are solar symbols, and the Basilidian Abrasax is manifestly connected with the sun. J. J. Bellermann has speculated that "the whole represents the Supreme Being, with his Five great Emanations, each one pointed out by means of an expressive emblem. Thus, from the human body, the usual form assigned to the Deity, forasmuch as it is written that God created man in his own image, issue the two supporters, "Nous" and "Logos", symbols of the inner sense and the quickening understanding, as typified by the serpents, for the same reason that had induced the old Greeks to assign this reptile for an attribute to Pallas. His head—a cock's—represents "Phronesis", the fowl being emblematical of foresight and vigilance. His two hands bear the badges of "Sophia" and "Dynamis", the shield of Wisdom, and the scourge of Power."
In the absence of other evidence to show the origin of these curious relics of antiquity the occurrence of a name known as Basilidian on patristic authority has not unnaturally been taken as a sufficient mark of origin, and the early collectors and critics assumed this whole group to be the work of Gnostics. During the last three centuries attempts have been made to sift away successively those gems that had no claim to be considered in any sense Gnostic, or specially Basilidian, or connected with Abrasax. The subject is one which has exercised the ingenuity of many savants, but it may be said that all the engraved stones fall into three classes:
While it would be rash to assert positively that no existing gems were the work of Gnostics, there is no valid reason for attributing all of them to such an origin. The fact that the name occurs on these gems in connection with representations of figures with the head of a cock, a lion, or an ass, and the tail of a serpent was formerly taken in the light of what Irenaeus says about the followers of Basilides:
Incantations by mystic names were characteristic of the hybrid Gnosticism planted in Spain and southern Gaul at the end of the fourth century and at the beginning of the fifth, which Jerome connects with Basilides and which (according to his "Epist"., lxxv.) used the name Abrasax.
It is therefore not unlikely that some Gnostics used amulets, though the confident assertions of modern writers to this effect rest on no authority. Isaac de Beausobre properly calls attention to the significant silence of Clement in the two passages in which he instructs the Christians of Alexandria on the right use of rings and gems, and the figures which may legitimately be engraved on them ("Paed". 241 ff.; 287 ff.). But no attempt to identify the figures on existing gems with the personages of Gnostic mythology has had any success, and "Abrasax" is the only Gnostic term found in the accompanying legends that is not known to belong to other religions or mythologies. The present state of the evidence therefore suggests that their engravers and the Basilidians received the mystic name from a common source now unknown.
Having due regard to the magic papyri, in which many of the unintelligible names of the Abrasax-stones reappear, besides directions for making and using gems with similar figures and formulas for magical purposes, it can scarcely be doubted that many of these stones are pagan amulets and instruments of magic.
The magic papyri reflect the same ideas as the Abrasax-gems and often bear Hebraic names of God. The following example is illustrative: "I conjure you by Iaō Sabaōth Adōnai Abrasax, and by the great god, Iaeō". The patriarchs are sometimes addressed as deities; for which fact many instances may be adduced. In the group "Iakoubia, Iaōsabaōth Adōnai Abrasax," the first name seems to be composed of Jacob and Ya. Similarly, entities considered angels in Judaism are invoked as gods alongside Abrasax: thus "I conjure you... by the god Michaēl, by the god Souriēl, by the god Gabriēl, by the god Raphaēl, by the god Abrasax Ablathanalba Akrammachari...".
In text PGM V. 96-172, Abrasax is identified as part of the "true name which has been transmitted to the prophets of Israel" of the "Headless One, who created heaven and earth, who created night and day... Osoronnophris whom none has ever seen... awesome and invisible god with an empty spirit"; the name also includes Iaō and Adōnai. "Osoronnophris" represents Egyptian "Wsir Wn-nfr", "Osiris the Perfect Being". Another identification with Osiris is made in PGM VII. 643-51: "you are not wine, but the guts of Osiris, the guts of... Ablanathanalba Akrammachamarei Eee, who has been stationed over necessity, Iakoub Ia Iaō Sabaōth Adōnai Abrasax." PGM VIII. 1-63, on the other hand, identifies Abrasax as a name of "Hermes" (i.e. Thoth). Here the numerological properties of the name are invoked, with its seven letters corresponding to the seven planets and its isopsephic value of 365 corresponding to the days of the year. Thoth is also identified with Abrasax in PGM LXXIX. 1-7: "I am the soul of darkness, Abrasax, the eternal one, Michaēl, but my true name is Thōouth, Thōouth."
One papyrus titled the "Monad" or the "Eighth Book of Moses" (PGM XIII. 1-343) contains an invocation to a supreme creator God; Abrasax is given as being the name of this God in the language of the baboons. The papyrus goes on to describe a cosmogonic myth about Abrasax, describing how he created the Ogdoad by laughing. His first laughter created light; his second divided the primordial waters; his third created the mind; his fourth created fertility and procreation; his fifth created fate; his sixth created time (as the sun and moon); and his seventh and final laughter created the soul. Then, from various sounds made by Abrasax, there arose the serpent Python who "foreknew all things", the first man (or Fear), and the god Iaō, "who is lord of all". The man fought with Iaō, and Abrasax declared that Iaō's power would derive from both of the others, and that Iaō would take precedence over all the other gods. This text also describes Helios as an archangel of God/Abrasax.
The Leyden Papyrus recommends that this invocation be pronounced to the moon:
The magic word "Ablanathanalba," which reads in Greek the same backward as forward, also occurs in the Abrasax-stones as well as in the magic papyri. This word is usually conceded to be derived from the Hebrew (Aramaic), meaning "Thou art our father" (אב לן את), and also occurs in connection with Abrasax; the following inscription is found upon a metal plate in the Carlsruhe Museum:
АВРАΣАΞ<br>
ΑΒΛΑΝΑΘ<br>
ΑΝΑΛΒΑ

</doc>
<doc id="1438" url="https://en.wikipedia.org/wiki?curid=1438" title="Absalom">
Absalom

Absalom ( "Aḇšālōm", "father of peace"), according to the Hebrew Bible, was the third son of David, King of Israel with Maacah, daughter of Talmai, King of Geshur.
Absalom, David's third son, by Maacah, was born in Hebron. He moved at an early age along with the transfer of the capital to Jerusalem, where he spent most of his life. He was a great favorite of his father, and of the people. His charming manners, personal beauty, insinuating ways, love of pomp, and royal pretensions, captivated the hearts of the people from the beginning. He lived in great style, drove in a magnificent chariot, and had fifty men run before him.
Little is known of Absalom's family life, but the biblical narrative states that he had three sons and one daughter, whose name was Tamar and is described as a beautiful woman. From the language of , "I have no son to keep my name in remembrance", it is implied that his sons died at an early age.
Although he had no sons says that Absalom had another daughter or granddaughter named Maacah, who later became the favorite wife of Rehoboam. Maacah was the mother of Abijah of Judah, and grandmother of Asa of Judah. She served as queen mother for Asa, until he deposed her for idolatry.
Absalom's sister, who was also called Tamar, was raped by Amnon, who was their half-brother. Amnon was also David's eldest son. After the rape, Absalom waited two years, and then avenged Tamar by sending his servants to murder a drunken Amnon at a feast, to which Absalom had invited all the king's sons.
After this murder Absalom fled to Talmai, who was the king of Geshur and Absalom's maternal grandfather. It was not until three years later that Absalom was fully reinstated in his father's favour and finally returned to Jerusalem. (see Joab).
While at Jerusalem, Absalom built support for himself by speaking to those who came to King David for justice, saying, "See, your claims are good and right; but there is no one deputed by the king to hear you", perhaps reflecting flaws in the judicial system of the united monarchy. "If only I were the judge of the land! Then all who had a suit or cause might come to me, and I would give them justice." He made gestures of flattery by kissing those who bowed before him instead of accepting supplication. He "stole the hearts of the people of Israel".
After four years he declared himself king, raised a revolt at Hebron, the former capital, and slept with his father's concubines. All Israel and Judah flocked to him, and David, attended only by the Cherethites and Pelethites and his former bodyguard, which had followed him from Gath, found it expedient to flee. The priests Zadok and Abiathar remained in Jerusalem, and their sons Jonathan and Ahimaaz served as David's spies. Absalom reached the capital and consulted with the renowned Ahithophel (sometimes spelled Achitophel).
David took refuge from Absalom's forces beyond the Jordan River. However, he took the precaution of instructing a servant, Hushai, to infiltrate Absalom's court and subvert it. Hushai convinced Absalom to ignore Ahithophel's advice to attack his father while he was on the run, and instead to prepare his forces for a major attack. This gave David critical time to prepare his own troops for the battle.
A fateful battle was fought in the Wood of Ephraim (the name suggests a locality west of the Jordan) and Absalom's army was completely routed. Absalom's head was caught in the boughs of an oak tree as the mule he was riding ran beneath it. He was discovered there still alive by one of David's men, who reported this to Joab, the king's commander. Joab, accustomed to avenging himself, took this opportunity to even the score with Absalom. Absalom had once set Joab's field on fire and then made Amasa Captain of the Host instead of Joab. Killing Absalom was against David's explicit command, "Beware that none touch the young man Absalom". Joab killed Absalom with three darts through the heart.
When David heard that Absalom was killed, although not how he was killed, he greatly sorrowed.
David withdrew to the city (Mahanaim) in mourning, until Joab roused him from "the extravagance of his grief" and called on him to fulfill his duty to his people.
Absalom had erected a monument near Jerusalem to perpetuate his name:
An ancient monument in the Kidron Valley near the Old City of Jerusalem, known as the Tomb of Absalom or Absalom's Pillar and traditionally identified as the monument of the biblical narrative, is now dated by modern archeologists to the first century AD. The Jewish Encyclopedia reports: "A tomb twenty feet high and twenty-four feet square, which late tradition points out as the resting-place of Absalom. It is situated in the eastern part of the valley of Kidron, to the east of Jerusalem. In all probability it is the tomb of Alexander Jannæus (Conder, in Hastings' "Dict. Bible", article "Jerusalem", p. 597). It existed in the days of Josephus ("Antiquities" vii. 10, § 3). However, archaeologists have now dated the tomb to the 1st century AD. In a 2013 conference, Professor Gabriel Barkay suggested that it could be the tomb of Herod Agrippa, the grandson of Herod the Great, based in part on the similarity to Herod's newly discovered tomb at Herodium. For centuries, it was the custom among passers-by—Jews, Christians and Muslims—to throw stones at the monument. Residents of Jerusalem would bring their unruly children to the site to teach them what became of a rebellious son.
The life and death of Absalom offered to the rabbis a welcome theme wherewith to warn the people against false ambition, vainglory, and unfilial conduct. The vanity with which he displayed his beautiful hair, the rabbis say, became his snare and his stumbling-block. "By his long hair the Nazirite entangled the people to rebel against his father, and by it he himself became entangled, to fall a victim to his pursuers" (Mishnah Soṭah, i. 8). And again, elsewhere: "By his vile stratagem he deceived and stole three hearts, that of his father, of the elders, and finally of the whole nation of Israel, and for this reason three darts were thrust into his heart to end his treacherous life" (Tosef., Soṭah, iii. 17). More striking is the following: "Did one ever hear of an oak-tree having a heart? And yet in the oak-tree in whose branches Absalom was caught, we read that upon its heart he was held up still alive while the darts were thrust through him [Mek., Shirah, § 6]. This is to show that when a man becomes so heartless as to make war against his own father, nature itself takes on a heart to avenge the deed."
Popular legend states that the eye of Absalom was of immense size, signifying his insatiable greed (Niddah, 24b). Indeed, "hell itself opened beneath him, and David, his father, cried seven times: 'My son! my son!' while bewailing his death, praying at the same time for his redemption from the seventh section of Gehenna, to which he was consigned" (Soṭah, 10b). According to R. Meir (Sanh. 103b), "he has no share in the life to come". And according to the description of Gehenna by Joshua ben Levi, who, like Dante, wandered through hell under the guidance of the angel Duma, Absalom still dwells there, having the rebellious heathen in charge; and when the angels with their fiery rods run also against Absalom to smite him like the rest, a heavenly voice says: "Spare Absalom, the son of David, My servant."

</doc>
<doc id="1439" url="https://en.wikipedia.org/wiki?curid=1439" title="Abydos">
Abydos

Abydos may mean:
Abidos may mean:
Abidu may mean:

</doc>
<doc id="1440" url="https://en.wikipedia.org/wiki?curid=1440" title="Abydos, Egypt">
Abydos, Egypt

Abydos (; Sahidic ') is one of the oldest cities of ancient Egypt, and also of the eighth nome in Upper Egypt. It is located about west of the Nile at latitude 26° 10' N, near the modern Egyptian towns of El Araba El Madfuna and El Balyana. In the ancient Egyptian language, the city was called Abdju"' ("ꜣbḏw" or "AbDw"). The English name "Abydos" comes from the Greek , a name borrowed by Greek geographers from the unrelated city of Abydos on the Hellespont.
Considered one of the most important archaeological sites in Egypt, the sacred city of Abydos was the site of many ancient temples, including Umm el-Qa'ab, a royal necropolis where early pharaohs were entombed. These tombs began to be seen as extremely significant burials and in later times it became desirable to be buried in the area, leading to the growth of the town's importance as a cult site.
Today, Abydos is notable for the memorial temple of Seti I, which contains an inscription from the nineteenth dynasty known to the modern world as the Abydos King List. It is a chronological list showing cartouches of most dynastic pharaohs of Egypt from Menes until Seti I's father, Ramesses I.
The Great Temple and most of the ancient town are buried under the modern buildings to the north of the Seti temple. Many of the original structures and the artifacts within them are considered irretrievable and lost; many may have been destroyed by the new construction.
Most of Upper Egypt became unified under rulers from Abydos during the Naqada III period (3200-3000 BCE), at the expense of rival cities such as Hierakonpolis. The conflicts leading to the supremacy of Abydos may appear on numerous reliefs of the Naqada II period, such as the Gebel el-Arak Knife, or the frieze of Tomb 100 at Hierakonpolis.
Tombs and at least one temple of rulers of the Predynastic period have been found at Umm El Qa'ab including that of Narmer, dating to circa 3100 BCE. The temple and town continued to be rebuilt at intervals down to the times of the Thirtieth Dynasty, and the cemetery was in continuous use.
The pharaohs of the First Dynasty were buried in Abydos, including Narmer, who is regarded as the founder of the First Dynasty, and his successor, Aha. It was in this time period that the Abydos boats were constructed. Some pharaohs of the Second Dynasty were also buried in Abydos. The temple was renewed and enlarged by these pharaohs as well. Funerary enclosures, misinterpreted in modern times as great 'forts', were built on the desert behind the town by three kings of the Second Dynasty; the most complete is that of Khasekhemwy, the Shunet El Zebib.
From the Fifth Dynasty, the deity Khentiamentiu, "foremost of the Westerners", came to be seen as a manifestation of the dead pharaoh in the underworld. Pepi I (Sixth Dynasty) constructed a funerary chapel which evolved over the years into the Great Temple of Osiris, the ruins of which still exist within the town enclosure. Abydos became the centre of the worship of the Isis and Osiris cult.
During the First Intermediate Period, the principal deity of the area, Khentiamentiu, began to be seen as an aspect of Osiris, and the deities gradually merged and came to be regarded as one. Khentiamentiu's name became an epithet of Osiris. King Mentuhotep II was the first to build a royal chapel. In the Twelfth Dynasty a gigantic tomb was cut into the rock by Senusret III. Associated with this tomb was a "cenotaph", a cult temple and a small town known as "Wah-Sut", that was used by the workers for these structures. Next to the cenotaph at least two kings of the Thirteenth Dynasty were buried (in tombs S9 and S10) as well as some rulers of the Second Intermediate Period, such as Senebkay. An indigenous line of kings, the Abydos Dynasty, may have ruled the region from Abydos at the time.
New construction during the Eighteenth Dynasty began with a large chapel of Ahmose I. The Pyramid of Ahmose I was also constructed at Abydos—the only pyramid in the area; very little of it remains today.
Thutmose III built a far larger temple, about . He also made a processional way leading past the side of the temple to the cemetery beyond, featuring a great gateway of granite.
Seti I, during the Nineteenth Dynasty, founded a temple to the south of the town in honor of the ancestral pharaohs of the early dynasties; this was finished by Ramesses II, who also built a lesser temple of his own. Merneptah added the Osireion, just to the north of the temple of Seti.
Ahmose II in the Twenty-sixth Dynasty rebuilt the temple again, and placed in it a large monolith shrine of red granite, finely wrought. The foundations of the successive temples were comprised within approximately . depth of the ruins discovered in modern times; these needed the closest examination to discriminate the various buildings, and were recorded by more than 4,000 measurements and 1,000 levellings.
The last building added was a new temple of Nectanebo I, built in the Thirtieth Dynasty. From the Ptolemaic times of the Greek occupancy of Egypt, that began three hundred years before the Roman occupancy that followed, the structures began to decay and no later works are known.
From earliest times, Abydos was a cult centre, first of the local deity, Khentiamentiu, and from the end of the Old Kingdom, the rising cult of Osiris. A tradition developed that the Early Dynastic cemetery was the burial place of Osiris and the tomb of Djer was reinterpreted as that of Osiris.
Decorations in tombs throughout Egypt, such as the one displayed to the right, record pilgrimages to Abydos by wealthy families.
From the First Dynasty to the Twenty-sixth Dynasty, nine or ten temples were successively built on one site at Abydos. The first was an enclosure, about , enclosed by a thin wall of unbaked bricks. Incorporating one wall of this first structure, the second temple of about square was built with walls about thick. An outer "temenos" (enclosure) wall surrounded the grounds. This outer wall was made wider some time around the Second or Third Dynasty. The old temple entirely vanished in the Fourth Dynasty, and a smaller building was erected behind it, enclosing a wide hearth of black ashes. Pottery models of offerings are found in these ashes and were probably the substitutes for live sacrifices decreed by Khufu (or Cheops) in his temple reforms.
At an undetermined date, a great clearance of temple offerings had been made and the modern discovery of a chamber into which they were gathered yielded the fine ivory carvings and the glazed figures and tiles that demonstrate the splendid work of the First Dynasty. A vase of Menes with purple hieroglyphs inlaid into a green glaze and tiles with relief figures are the most important pieces found. The noble statuette of Cheops in ivory, found in the stone chamber of the temple, gives the only portrait of this great pharaoh.
The temple was entirely rebuilt on a larger scale by Pepi I in the Sixth Dynasty. He placed a great stone gateway to the temenos, an outer temenos wall and gateway, with a colonnade between the gates. His temple was about inside, with stone gateways front and back, showing that it was of the processional type. In the Eleventh Dynasty Mentuhotep I added a colonnade and altars. Soon after, Mentuhotep II entirely rebuilt the temple, laying a stone pavement over the area, about square. He also added subsidiary chambers. Soon thereafter, in the Twelfth Dynasty, Senusret I laid massive foundations of stone over the pavement of his predecessor. A great temenos was laid out enclosing a much larger area and the new temple itself was about three times the earlier size.
The temple of Seti I was built on entirely new ground half a mile to the south of the long series of temples just described. This surviving building is best known as the Great Temple of Abydos, being nearly complete and an impressive sight. A principal purpose of the temple was to serve as a memorial to king Seti I, as well as to show reverence for the early pharaohs, which is incorporated within as part of the "Rite of the Ancestors".
The long list of the pharaohs of the principal dynasties—recognized by Seti—are carved on a wall and known as the "Abydos King List" (showing the cartouche name of many dynastic pharaohs of Egypt from the first, Narmer or Menes, until Seti's time)- with the exception of those noted above. There were significant names deliberately left off of the list. So rare, as an almost complete list of pharaoh names, the Table of Abydos, rediscovered by William John Bankes, has been called the "Rosetta Stone" of Egyptian archaeology, analogous to the Rosetta Stone for Egyptian writing, beyond the Narmer Palette.
There were also seven chapels built for the worship of the pharaoh and principal deities. These included three chapels for the "state" deities Ptah, Re-Horakhty, and (centrally positioned) Amun-Re and the challenge for the Abydos triad of Osiris, Isis and Horus. The rites recorded in the deity chapels represent the first complete form known of the Daily Ritual, which was performed daily in temples across Egypt throughout the pharaonic period. At the back of the temple is an enigmatic structure known as the Osireion, which served as a cenotaph for Seti-Osiris, and is thought to be connected with the worship of Osiris as an "Osiris tomb". It is possible that from those chambers was led out the great Hypogeum for the celebration of the Osiris mysteries, built by Merenptah. The temple was originally long, but the forecourts are scarcely recognizable, and the part still in good condition is about
Except for the list of pharaohs and a panegyric on Ramesses II, the subjects are not historical, but religious in nature, dedicated to the transformation of the king after his death. The temple reliefs are celebrated for their delicacy and artistic refinement, utilizing both the archaism of earlier dynasties with the vibrancy of late 18th Dynasty reliefs. The sculptures had been published mostly in hand copy, not facsimile, by Auguste Mariette in his "Abydos", I. The temple has been partially recorded epigraphically by Amice Calverley and Myrtle Broome in their 4 volume publication of "The Temple of King Sethos I at Abydos" (1933–1958).
The Osirion or Osireon is an ancient Egyptian temple. It is located to the rear of the temple of Seti I. It is an integral part of Seti I's funeral complex and is built to resemble an 18th Dynasty Valley of the Kings tomb.
The adjacent temple of Ramesses II was much smaller and simpler in plan; but it had a fine historical series of scenes around the outside that lauded his achievements, of which the lower parts remain. The outside of the temple was decorated with scenes of the Battle of Kadesh. His list of pharaohs, similar to that of Seti I, formerly stood here; but the fragments were removed by the French consul and sold to the British Museum.
The royal necropolises of the earliest dynasties were placed about a mile into the great desert plain, in a place now known as Umm El Qa'ab "The Mother of Pots" because of the shards remaining from all of the devotional objects left by religious pilgrims.
The earliest burial is about inside, a pit lined with brick walls, and originally roofed with timber and matting. Others tombs also built before Menes are . The probable tomb of Menes is of the latter size.
Afterward, the tombs increased in size and complexity. The tomb-pit was surrounded by chambers to hold offerings, the sepulchre being a great wooden chamber in the midst of the brick-lined pit. Rows of small pits, tombs for the servants of the pharaoh, surrounded the royal chamber, many dozens of such burials being usual. Some of the offerings included sacrificed animals, such as the asses found in the tomb of Merneith. Evidence of human sacrifice exists in the early tombs, such as the 118 servants in the tomb of Merneith, but this practice was changed into symbolic offerings later.
By the end of the Second Dynasty the type of tomb constructed changed to a long passage with chambers on either side, the royal burial being in the middle of the length. The greatest of these tombs with its dependencies, covered a space of over , however it is possible for this to have been several tombs which abutted one another during construction; the Egyptians had no means of mapping the positioning of the tombs. The contents of the tombs have been nearly destroyed by successive plunderers; but enough remained to show that rich jewellery was placed on the mummies, a profusion of vases of hard and valuable stones from the royal table service stood about the body, the store-rooms were filled with great jars of wine, perfumed ointments, and other supplies, and tablets of ivory and of ebony were engraved with a record of the yearly annals of the reigns. The seals of various officials, of which over 200 varieties have been found, give an insight into the public arrangements.
A cemetery for private persons was put into use during the First Dynasty, with some pit-tombs in the town. It was extensive in the Twelfth and Thirteenth Dynasties and contained many rich tombs. A large number of fine tombs were made in the Eighteenth to Twentieth Dynasties, and members of later dynasties continued to bury their dead here until the Roman period. Many hundreds of funeral steles were removed by Auguste Mariette's workmen, without any details of the burials being noted. Later excavations have been recorded by Edward R. Ayrton, Abydos, iii.; Maclver, "El Amrah and Abydos"; and Garstang, "El Arabah".
Some of the tomb structures, referred to as "forts" by modern researchers, lay behind the town. Known as Shunet ez Zebib, it is about over all, and one still stands high. It was built by Khasekhemwy, the last pharaoh of the Second Dynasty. Another structure nearly as large adjoined it, and probably is older than that of Khasekhemwy. A third "fort" of a squarer form is now occupied by a convent of the Coptic Orthodox Church of Alexandria; its age cannot be ascertained.
The area now known as Kom El Sultan is a big mudbrick structure, the purpose of which is not clear and thought to have been at the original settlement area, dated to the Early Dynastic Period. The structure includes the early temple of Osiris.
Some of the hieroglyphs carved over an arch on the site have been interpreted in esoteric and "ufological" circles as depicting modern technology.
The "helicopter" image is the result of carved stone being re-used over time. The initial carving was made during the reign of Seti I and translates to "He who repulses the nine [enemies of Egypt]". This carving was later filled in with plaster and re-carved during the reign of Ramesses II with the title "He who protects Egypt and overthrows the foreign countries". Over time, the plaster has eroded away, leaving both inscriptions partially visible and creating a palimpsest-like effect of overlapping hieroglyphs.

</doc>
<doc id="1441" url="https://en.wikipedia.org/wiki?curid=1441" title="Abydos (Hellespont)">
Abydos (Hellespont)

Abydos (, ) was an ancient city and bishopric in Mysia. It was located at the Nara Burnu promontory on the Asian coast of the Hellespont, opposite the ancient city of Sestos, and near the city of Çanakkale in Turkey. Abydos was founded in c. 670 BC at the most narrow point in the straits, and thus was one of the main crossing points between Europe and Asia, until its replacement by the crossing between Lampsacus and Kallipolis in the 13th century, and the abandonment of Abydos in the early 14th century.
In Greek mythology, Abydos is presented in the myth of Hero and Leander as the home of Leander. The city is also mentioned in "Rodanthe and Dosikles", a novel written by Theodore Prodromos, a 12th-century writer, in which Dosikles kidnaps Rodanthe at Abydos.
In 1675, the site of Abydos was first identified, and was subsequently visited by numerous classicists and travellers, such as Robert Wood, Richard Chandler, and Lord Byron. The city's acropolis is known in Turkish as Mal Tepe.
Following the city's abandonment, the ruins of Abydos were scavenged for building materials from the 14th to the 19th century, and remains of walls and buildings continued to be reported until at least the 19th century, however, little remains and the area was declared a restricted military zone in the early 20th century, thus little to no excavation has taken place.
Abydos is mentioned in the "Iliad" as a Trojan ally, and, according to Strabo, was occupied by Bebryces and later Thracians after the Trojan War. It has been suggested that the city was originally a Phoenician colony as there was a temple of Aphrodite Porne (Aphrodite the Harlot) within Abydos. Abydos was settled by Milesian colonists contemporaneously with the foundation of the cities of Priapos and Prokonnesos in . Strabo related that Gyges, King of Lydia, granted his consent to the Milesians to settle Abydos; it is argued that this was carried out by Milesian mercenaries to act as a garrison to prevent Thracian raids into Asia Minor. The city became a thriving centre for tuna exportation as a result of the high yield of tuna in the Hellespont.
Abydos was ruled by Daphnis, a pro-Persian tyrant, in the 520s BC, but was occupied by the Persian Empire in 514. Darius I destroyed the city following his Scythian campaign in 512. Abydos participated in the Ionian Revolt in the early 5th century BC, however, the city returned briefly to Persian control as, in 480, at the onset of the Second Persian invasion of Greece, Xerxes I and the Persian army passed through Abydos on their march to Greece. After the failed Persian invasion, Abydos became a member of the Athenian-led Delian League, and was part of the Hellespontine district. Ostensibly an ally, Abydos was hostile to Athens throughout this time, and contributed a "phoros" of 4-6 talents. Xenophon documented that Abydos possessed gold mines at Astyra or Kremaste at the time of his writing.
During the Second Peloponnesian War, a Spartan expedition led by Dercylidas arrived at Abydos in early May 411 BC and successfully convinced the city to defect from the Delian League and fight against Athens, at which time he was made harmost (commander/governor) of Abydos. A Spartan fleet was defeated by Athens at Abydos in the autumn of 411 BC. Abydos was attacked by the Athenians in the winter of 409/408 BC, but was repelled by a Persian force led by Pharnabazus, satrap (governor) of Hellespontine Phrygia. Dercylidas held the office of harmost of Abydos until at least . According to Aristotle, Abydos had an oligarchic constitution at this time. At the beginning of the Corinthian War in 394 BC, Agesilaus II, King of Sparta, passed through Abydos into Thrace. Abydos remained an ally of Sparta throughout the war and Dercylidas served as harmost of the city from 394 until he was replaced by Anaxibius in ; the latter was killed in an ambush near Abydos by the Athenian general Iphicrates in . At the conclusion of the Corinthian War, under the terms of the Peace of Antalcidas in 387 BC, Abydos was annexed to the Persian Empire. Within the Persian Empire, Abydos was administered as part of the satrapy of Hellespontine Phrygia, and was ruled by the tyrant Philiscus in 368. In , the city came under the control of the tyrant Iphiades.
Abydos remained under Persian control until it was seized by a Macedonian army led by Parmenion, a general of Philip II, in the spring of 336 BC. In 335, whilst Parmenion besieged the city of Pitane, Abydos was besieged by a Persian army led by Memnon of Rhodes, forcing Parmenion to abandon his siege of Pitane and march north to relieve Abydos. Alexander ferried across from Sestos to Abydos in 334 and travelled south to the city of Troy, after which he returned to Abydos. The following day, Alexander left Abydos and led his army north to Percote. Alexander later established a royal mint at Abydos, as well as at other cities in Asia Minor.
After the death of Alexander the Great in 323 BC, Abydos, as part of the satrapy of Hellespontine Phrygia, came under the control of Leonnatus as a result of the Partition of Babylon. At the Partition of Triparadisus in 321 BC, Arrhidaeus succeeded Leonnatus as satrap of Hellespontine Phrygia.
In 302, during the Fourth War of the Diadochi, Lysimachus, King of Thrace, crossed over into Asia Minor and invaded the kingdom of Antigonus I. Unlike the neighbouring cities of Parium and Lampsacus which surrendered, Abydos resisted Lysimachus and was besieged. Lysimachus was forced to abandon the siege, however, after the arrival of a relief force sent by Demetrius, son of King Antigonus I. According to Polybius, by the third century BC, the neighbouring city of Arisbe had become subordinate to Abydos. The city of Dardanus also came under the control of Abydos at some point in the Hellenistic period. Abydos became part of the Seleucid Empire after 281 BC. The city was conquered by Ptolemy III Euergetes, King of Egypt, in 245 BC, and remained under Ptolemaic control until at least 241, as Abydos had become part of the Kingdom of Pergamon by c. 200 BC.
During the Second Macedonian War, Abydos was besieged by Philip V, King of Macedonia, in 200 BC, during which many of its citizens chose to commit suicide rather than surrender. Marcus Aemilius Lepidus met with Philip V during the siege to deliver an ultimatum on behalf of the Roman senate. Ultimately, the city was forced to surrender to Philip V due to a lack of reinforcements. The Macedonian occupation ended after the Peace of Flamininus at the end of the war in 196 BC. At this time, Abydos was substantially depopulated and partially ruined as a result of the Macedonian occupation.
In the spring of 196 BC, Abydos was seized by Antiochus III, "Megas Basileus" of the Seleucid Empire, who refortified the city in 192/191 BC. Antiochus III later withdrew from Abydos during the Roman-Seleucid War, thus allowing for the transportation of the Roman army into Asia Minor by October 190 BC. Dardanus was subsequently liberated from Abydene control, and the Treaty of Apamea of 188 BC returned Abydos to the Kingdom of Pergamon. A gymnasium was active at Abydos in the 2nd century BC.
Attalus III, King of Pergamon, bequeathed his kingdom to Rome upon his death in 133 BC, and thus Abydos became part of the province of Asia. The gold mines of Abydos at Astyra or Kremaste were near exhaustion at the time was Strabo was writing. The city was counted amongst the "telonia" (custom houses) of the province of Asia in the "lex portorii Asiae" of 62 AD, and formed part of the "conventus iuridicus Adramytteum". Abydos is mentioned in the "Tabula Peutingeriana" and Antonine Itinerary. The mint of Abydos ceased to function in the mid-3rd century AD.
It is believed that Abydos, with Sestos and Lampsacus, is referred to as one of the "three large capital cities" of the Roman Empire in "Weilüe", a 3rd-century AD Chinese text. The city was the centre for customs collection at the southern entrance of the Sea of Marmara, and was administered by a "komes ton Stenon" (count of the Straits) or an "archon" from the 3rd century to the 5th century AD. In the 6th century AD, Emperor Justinian I introduced the office of "komes Abydou" with responsibility for collecting customs duty in Abydos.
Pope Martin I rested at Abydos in the summer of 653 whilst en route to Constantinople. As a result of the administrative reforms of the 7th century, Abydos came to be administered as part of the theme of Opsikion. The office of "kommerkiarios" of Abydos is first attested in the mid-7th century, and was later sometimes combined with the office of "paraphylax", the military governor of the fort, introduced in the 8th century, at which time the office of "komes ton stenon" is last mentioned.
After the 7th century AD, Abydos became a major seaport. Maslama ibn Abd al-Malik, during his campaign against Constantinople, crossed over into Thrace at Abydos in July 717. The office of "archon" at Abydos was restored in the late 8th century and endured until the early 9th century. In 801, Empress Irene reduced commercial tariffs collected at Abydos. Emperor Nikephoros I, Irene's successor, introduced a tax on slaves purchased beyond the city. The city later also became part of the theme of the Aegean Sea and was the seat of a "tourmarches".
Abydos was sacked by an Arab fleet led by Leo of Tripoli in 904 AD whilst en route to Constantinople. The revolt of Bardas Phokas was defeated by Emperor Basil II at Abydos in 989 AD. In 992, the Venetians were granted reduced commercial tariffs at Abydos as a special privilege. In the early 11th century, Abydos became the seat of a separate command and the office of "strategos" (governor) of Abydos is first mentioned in 1004 with authority over the northern shore of the Hellespont and the islands of the Sea of Marmara.
In 1024, a Rus' raid led by a certain Chrysocheir defeated the local commander at Abydos and proceeded to travel south through the Hellespont. Following the Battle of Manzikert, Abydos was seized by the Seljuk Turks, but was recovered in 1086 AD, in which year Leo Kephalas was appointed "katepano" of Abydos. Abydos' population likely increased at this time as a result of the arrival of refugees from northwestern Anatolia who had fled the advance of the Turks. In 1092/1093, the city was attacked by Tzachas, a Turkish pirate. Emperor Manuel I Komnenos repaired Abydos' fortifications in the late 12th century.
By the 13th century AD, the crossing from Lampsacus to Kallipolis had become more common and largely replaced the crossing from Abydos to Sestos. During the Fourth Crusade, in 1204, the Venetians seized Abydos, and, following the Sack of Constantinople and the formation of the Latin Empire later that year, Emperor Baldwin granted the land between Abydos and Adramyttium to his brother Henry of Flanders. Henry of Flanders passed through Abydos on 11 November 1204 and continued his march to Adramyttium. Abydos was seized by the Empire of Nicaea, a successor state of the Eastern Roman Empire, during its offensive in 1206–1207, but was reconquered by the Latin Empire in 1212–1213. The city was later recovered by Emperor John III Vatatzes. Abydos declined in the 13th century, and was eventually abandoned between 1304 and 1310/1318 due to the threat of Turkish tribes and disintegration of Roman control over the region.
The bishopric of Abydus appears in all the "Notitiae Episcopatuum" of the Patriarchate of Constantinople from the mid-7th century until the time of Andronikos III Palaiologos (1341), first as a suffragan of Cyzicus and then from 1084 as a metropolitan see without suffragans. The earliest bishop mentioned in extant documents is Marcian, who signed the joint letter of the bishops of Hellespontus to Emperor Leo I the Thracian in 458, protesting about the murder of Proterius of Alexandria. A letter of Peter the Fuller (471–488) mentions a bishop of Abydus called Pamphilus. Ammonius signed the decretal letter of the Council of Constantinople in 518 against Severus of Antioch and others. Isidore was at the Third Council of Constantinople (680–681), John at the Trullan Council (692), Theodore at the Second Council of Nicaea (787). An unnamed bishop of Abydus was a counsellor of Emperor Nikephoros II in 969.
Seals attest Theodosius as bishop of Abydos in the 11th century, and John as metropolitan bishop of Abydos in the 11/12th century. Abydos remained a metropolitan see until the city fell to the Turks in the 14th century. The diocese is currently a titular see of the Patriarchate of Constantinople, and Gerasimos Papadopoulos was titular Bishop of Abydos from 1962 until his death in 1995. Simeon Kruzhkov was bishop of Abydos from May to September 1998. Kyrillos Katerelos was consecrated bishop of Abydos in 2008.
In 1222, during the Latin occupation, the papal legate Giovanni Colonna united the dioceses of Abydos and Madytos and placed the see under direct Papal authority. No longer a residential bishopric, Abydus is today listed by the Catholic Church as a titular see.
Notes
Citations

</doc>
<doc id="1442" url="https://en.wikipedia.org/wiki?curid=1442" title="August 15">
August 15


</doc>
<doc id="1445" url="https://en.wikipedia.org/wiki?curid=1445" title="Acacia sensu lato">
Acacia sensu lato

Acacia s.l. (pronounced or ), known commonly as mimosa, acacia, thorntree or wattle, is a polyphyletic genus of shrubs and trees belonging to the subfamily Mimosoideae of the family Fabaceae. It was described by the Swedish botanist Carl Linnaeus in 1773 based on the African species "Acacia nilotica". Many non-Australian species tend to be thorny, whereas the majority of Australian acacias are not. All species are pod-bearing, with sap and leaves often bearing large amounts of tannins and condensed tannins that historically found use as pharmaceuticals and preservatives.
The genus "Acacia" constitutes, in its traditional circumspection, the second largest genus in Fabaceae ("Astragalus" being the largest), with roughly 1,300 species, about 960 of them native to Australia, with the remainder spread around the tropical to warm-temperate regions of both hemispheres, including Europe, Africa, southern Asia, and the Americas (see List of "Acacia" species). The genus was divided into five separate genera under the tribe "Acacieae". The genus now called "Acacia" represents the majority of the Australian species and a few native to southeast Asia, Réunion, and Pacific Islands. Most of the species outside Australia, and a small number of Australian species, are classified into "Vachellia" and "Senegalia". The two final genera, "Acaciella" and "Mariosousa", each contain about a dozen species from the Americas (but see "Classification" below for the ongoing debate concerning their taxonomy).
English botanist and gardener Philip Miller adopted the name "Acacia" in 1754. The generic name is derived from (), the name given by early Greek botanist-physician Pedanius Dioscorides (middle to late first century) to the medicinal tree "A. nilotica" in his book "Materia Medica". This name derives from the Ancient Greek word for its characteristic thorns, (; "thorn"). The species name "nilotica" was given by Linnaeus from this tree's best-known range along the Nile river. This became the type species of the genus.
The traditional circumscription of "Acacia" eventually contained approximately 1,300 species. However, evidence began to accumulate that the genus as described was not monophyletic. Queensland botanist Les Pedley proposed the subgenus "Phyllodineae" be renamed "Racosperma" and published the binomial names. This was taken up in New Zealand but generally not followed in Australia, where botanists declared more study was needed.
Eventually, consensus emerged that "Acacia" needed to be split as it was not monophyletic. This led to Australian botanists Bruce Maslin and Tony Orchard pushing for the retypification of the genus with an Australian species instead of the original African type species, an exception to traditional rules of priority that required ratification by the International Botanical Congress. That decision has been controversial, and debate continued, with some taxonomists (and many other biologists) deciding to continue to use the traditional "Acacia sensu lato" circumscription of the genus, in defiance of decisions by an International Botanical Congress. However, a second International Botanical Congress has now confirmed the decision to apply the name "Acacia" to the mostly Australian plants, which some had been calling "Racosperma", and which had formed the overwhelming majority of "Acacia sensu lato". Debate continues regarding the traditional acacias of Africa, possibly placed in "Senegalia" and "Vachellia", and some of the American species, possibly placed in "Acaciella" and "Mariosousa".
Acacias belong to the subfamily Mimosoideae, the major clades of which may have formed in response to drying trends and fire regimes that accompanied increased seasonality during the late Oligocene to early Miocene (∼25 mya). Pedley (1978), following Vassal (1972), viewed Acacia as comprising three large subgenera, but subsequently (1986) raised the rank of these groups to genera Acacia, "Senegalia" ("s.l.") and "Racosperma", which was underpinned by later genetic studies.
In common parlance, the term "acacia" is occasionally applied to species of the genus "Robinia", which also belongs in the pea family. "Robinia pseudoacacia", an American species locally known as black locust, is sometimes called "false acacia" in cultivation in the United Kingdom and throughout Europe.
The leaves of acacias are compound pinnate in general. In some species, however, more especially in the Australian and Pacific Islands species, the leaflets are suppressed, and the leaf-stalks (petioles) become vertically flattened in order to serve the purpose of leaves. These are known as "phyllodes". The vertical orientation of the phyllodes protects them from intense sunlight since with their edges towards the sky and earth they do not intercept light as fully as horizontally placed leaves. A few species (such as "Acacia glaucoptera") lack leaves or phyllodes altogether but instead possess cladodes, modified leaf-like photosynthetic stems functioning as leaves.
The small flowers have five very small petals, almost hidden by the long stamens, and are arranged in dense, globular or cylindrical clusters; they are yellow or cream-colored in most species, whitish in some, or even purple ("Acacia purpureopetala") or red ("Acacia leprosa" 'Scarlet Blaze'). "Acacia" flowers can be distinguished from those of a large related genus, "Albizia", by their stamens, which are not joined at the base. Also, unlike individual "Mimosa" flowers, those of "Acacia" have more than ten stamens.
The plants often bear spines, especially those species growing in arid regions. These sometimes represent branches that have become short, hard, and pungent, though they sometimes represent leaf-stipules. "Acacia armata" is the kangaroo-thorn of Australia, and "Acacia erioloba" (syn. "Acacia eriolobata") is the camelthorn of Africa.
Acacia seeds can be difficult to germinate. Research has found that immersing the seeds in various temperatures (usually around 80 °C (176 °F)) and manual seed coat chipping can improve growth to around 80%.
In the Central American bullthorn acacias—"Acacia sphaerocephala", "Acacia cornigera" and "Acacia collinsii" — some of the spiny stipules are large, swollen and hollow. These afford shelter for several species of "Pseudomyrmex" ants, which feed on extrafloral nectaries on the leaf-stalk and small lipid-rich food-bodies at the tips of the leaflets called Beltian bodies. In return, the ants add protection to the plant against herbivores. Some species of ants will also remove competing plants around the acacia, cutting off the offending plants' leaves with their jaws and ultimately killing them. Other associated ant species appear to do nothing to benefit their hosts.
Similar mutualisms with ants occur on "Acacia" trees in Africa, such as the whistling thorn acacia. The acacias provide shelter for ants in similar swollen stipules and nectar in extrafloral nectaries for their symbiotic ants, such as "Crematogaster mimosae". In turn, the ants protect the plant by attacking large mammalian herbivores and stem-boring beetles that damage the plant.
The predominantly herbivorous spider "Bagheera kiplingi", which is found in Central America and Mexico, feeds on nubs at the tips of the acacia leaves, known as Beltian bodies, which contain high concentrations of protein. These nubs are produced by the acacia as part of a symbiotic relationship with certain species of ant, which also eat them.
In Australia, "Acacia" species are sometimes used as food plants by the larvae of hepialid moths of the genus "Aenetus" including "A. ligniveren". These burrow horizontally into the trunk then vertically down. Other Lepidoptera larvae which have been recorded feeding on "Acacia" include brown-tail, "Endoclita malabaricus" and turnip moth. The leaf-mining larvae of some bucculatricid moths also feed on "Acacia"; "Bucculatrix agilis" feeds exclusively on "Acacia horrida" and "Bucculatrix flexuosa" feeds exclusively on "Acacia nilotica".
Acacias contain a number of organic compounds that defend them from pests and grazing animals.
Acacia seeds are often used for food and a variety of other products.
In Myanmar, Laos, and Thailand, the feathery shoots of "Acacia pennata" (common name "cha-om", ชะอม and "su pout ywet" in Burmese) are used in soups, curries, omelettes, and stir-fries.
Various species of acacia yield gum. True gum arabic is the product of "Acacia senegal", abundant in dry tropical West Africa from Senegal to northern Nigeria.
"Acacia nilotica" (syn. "Acacia arabica") is the gum arabic tree of India, but yields a gum inferior to the true gum arabic. Gum arabic is used in a wide variety of food products, including some soft drinks and confections.
The ancient Egyptians used acacia gum in paints.
The gum of "Acacia xanthophloea" and "Acacia karroo" has a high sugar content and is sought out by the lesser bushbaby. "Acacia karroo" gum was once used for making confectionery and traded under the name "Cape Gum". It was also used medicinally to treat cattle suffering poisoning by "Moraea" species.
"Acacia" species have possible uses in folk medicine. A 19th-century Ethiopian medical text describes a potion made from an Ethiopian species (known as "grar") mixed with the root of the "tacha", then boiled, as a cure for rabies.
An astringent medicine high in tannins, called catechu or cutch, is procured from several species, but more especially from "Senegalia catechu" (syn. "Acacia catechu"), by boiling down the wood and evaporating the solution so as to get an extract. The catechu extract from "A. catechu" figures in the history of chemistry in giving its name to the catechin, catechol, and catecholamine chemical families ultimately derived from it.
A few species are widely grown as ornamentals in gardens; the most popular perhaps is "A. dealbata" (silver wattle), with its attractive glaucous to silvery leaves and bright yellow flowers; it is erroneously known as "mimosa" in some areas where it is cultivated, through confusion with the related genus "Mimosa".
Another ornamental acacia is the fever tree. Southern European florists use "A. baileyana", "A. dealbata", "A. pycnantha" and "A. retinodes" as cut flowers and the common name there for them is mimosa.
Ornamental species of acacias are also used by homeowners and landscape architects for home security. The sharp thorns of some species are a deterrent to trespassing, and may prevent break-ins if planted under windows and near drainpipes. The aesthetic characteristics of acacia plants, in conjunction with their home security qualities, makes them a reasonable alternative to constructed fences and walls.
"Acacia farnesiana" is used in the perfume industry due to its strong fragrance. The use of acacia as a fragrance dates back centuries.
Egyptian mythology has associated the acacia tree with characteristics of the tree of life, such as in the Myth of Osiris and Isis.
Several parts (mainly bark, root, and resin) of "Acacia" species are used to make incense for rituals. Acacia is used in incense mainly in India, Nepal, and China including in its Tibet region. Smoke from acacia bark is thought to keep demons and ghosts away and to put the gods in a good mood. Roots and resin from acacia are combined with rhododendron, acorus, cytisus, salvia, and some other components of incense. Both people and elephants like an alcoholic beverage made from acacia fruit.
According to Easton's Bible Dictionary, the acacia tree may be the “burning bush” (Exodus 3:2) which Moses encountered in the desert. Also, when God gave Moses the instructions for building the Tabernacle, he said to "make an ark" and "a table of acacia wood" (Exodus 25:10 & 23, Revised Standard Version). Also, in the Christian tradition, Christ's crown of thorns is thought to have been woven from acacia.
Acacia was used for Zulu warriors' iziQu (or isiKu) beads, which passed on through Robert Baden-Powell to the Scout movement's Wood Badge training award.
In Russia, Italy, and other countries, it is customary to present women with yellow mimosas (among other flowers) on International Women's Day (March 8). These "mimosas" may be from "A. dealbata" (silver wattle).
In 1918, May Gibbs, the popular Australian children's author, wrote the book 'Wattle Babies', in which a third-person narrator describes the lives of imaginary inhabitants of the Australian forests (the 'bush'). The main characters are the Wattle Babies, who are tiny people that look like acacia flowers and who interact with various forest creatures. Gibbs wrote "Wattle Babies are the sunshine of the Bush. In Winter, when the sky is grey and all the world seems cold, they put on their yellowest clothes and come out, for they have such cheerful hearts." Gibbs was referring to the fact that an abundance of acacias flower in August in Australia, in the midst of the southern hemisphere winter.
The bark of various Australian species, known as wattles, is very rich in tannin and forms an important article of export; important species include "A. pycnantha" (golden wattle), "A. decurrens" (tan wattle), "A. dealbata" (silver wattle) and "A. mearnsii" (black wattle).
Black wattle is grown in plantations in South Africa and South America. Most Australian "Acacia" species introduced to South Africa have become an enormous problem, due to their naturally aggressive propagation. The pods of "A. nilotica" (under the name of "neb-neb"), and of other African species, are also rich in tannin and used by tanners. In Yemen, the principal tannin substance was derived from the leaves of the salam-tree ("Acacia etbaica"), a tree known locally by the name "qaraẓ" ("garadh"). A bath solution of the crushed leaves of this tree, into which raw leather had been inserted for prolonged soaking, would take only 15 days for curing. The water and leaves, however, required changing after seven or eight days, and the leather needed to be turned over daily.
Some "Acacia" species are valuable as timber, such as "A. melanoxylon" (blackwood) from Australia, which attains a great size; its wood is used for furniture, and takes a high polish; and "A. omalophylla" (myall wood, also Australian), which yields a fragrant timber used for ornaments. "A. seyal" is thought to be the shittah-tree of the Bible, which supplied shittim-wood. According to the Book of Exodus, this was used in the construction of the Ark of the Covenant. "A. koa" from the Hawaiian Islands and "A. heterophylla" from Réunion are both excellent timber trees. Depending on abundance and regional culture, some "Acacia" species (e.g. "A. fumosa") are traditionally used locally as firewoods. It is also used to make homes for different animals.
In Indonesia (mainly in Sumatra) and in Malaysia (mainly in Sabah), plantations of "A. mangium" are being established to supply pulpwood to the paper industry.
Acacia wood pulp gives high opacity and below average bulk paper. This is suitable in lightweight offset papers used for Bibles and dictionaries. It is also used in paper tissue where it improves softness.
Acacias can be planted for erosion control, especially after mining or construction damage.
For the same reasons it is favored as an erosion-control plant, with its easy spreading and resilience, some varieties of acacia are potentially invasive species. One of the most globally significant invasive acacias is black wattle "A. mearnsii", which is taking over grasslands and abandoned agricultural areas worldwide, especially in moderate coastal and island regions where mild climate promotes its spread. Australian/New Zealand Weed Risk Assessment gives it a "high risk, score of 15" rating and it is considered one of the world's 100 most invasive species.
Extensive ecological studies should be performed before further introduction of acacia varieties, as this fast-growing genus, once introduced, spreads quickly and is extremely difficult to eradicate.
Nineteen different species of "Acacia" in the Americas contain cyanogenic glycosides, which, if exposed to an enzyme which specifically splits glycosides, can release hydrogen cyanide (HCN) in the "leaves". This sometimes results in the poisoning death of livestock.
If fresh plant material spontaneously produces 200 ppm or more HCN, then it is potentially toxic. This corresponds to about 7.5 μmol HCN per gram of fresh plant material. It turns out that, if acacia "leaves" lack the specific glycoside-splitting enzyme, then they may be less toxic than otherwise, even those containing significant quantities of cyanic glycosides.
Some "Acacia" species containing cyanogens include "Acacia erioloba", "A. cunninghamii", "A. obtusifolia", "A. sieberiana", and "A. sieberiana" var. "woodii"
The Arbre du Ténéré in Niger was the most isolated tree in the world, about from any other tree. The tree was knocked down by a truck driver in 1973.
In Nairobi, Kenya, the Thorn Tree Café is named after a Naivasha thorn tree ("Acacia xanthophloea") in its centre. Travelers used to pin notes to others to the thorns of the tree. The current tree is the third of the same variety.

</doc>
<doc id="1446" url="https://en.wikipedia.org/wiki?curid=1446" title="Acapulco">
Acapulco

Acapulco de Juárez (), commonly called Acapulco ( , ), is a city and major seaport in the state of Guerrero on the Pacific coast of Mexico, south of Mexico City. Acapulco is located on a deep, semicircular bay and has been a port since the early colonial period of Mexico's history. It is a port of call for shipping and cruise lines running between Panama and San Francisco, California, United States. The city of Acapulco is the largest in the state, far larger than the state capital Chilpancingo. Acapulco is also Mexico's largest beach and balneario resort city.
The city is one of Mexico's oldest beach resorts, which came into prominence in the 1940s through the 1960s as a getaway for Hollywood stars and millionaires. Acapulco was once a popular tourist resort, but due to a massive upsurge in gang violence and murder since 2014 it no longer attracts many foreign tourists, and most now only come from Mexico itself. It is both the second deadliest city in Mexico and the second-deadliest city in the world; the US government has warned its citizens not to travel there. In 2016 there were 918 murders, and the homicide rate was one of the highest in the world: 103 in every 100,000. In September 2018 the city's entire police force was disarmed by the military, due to suspicions that it has been infiltrated by drug gangs.
The resort area is divided into three parts: The north end of the bay and beyond is the "traditional" area, which encompasses the area from "Parque Papagayo" through the Zócalo and onto the beaches of "Caleta" and "Caletilla", the main part of the bay known as "Zona Dorada" ('golden zone' in Spanish), where the famous in the mid-20th century vacationed, and the south end, "Diamante" ('diamond' in Spanish), which is dominated by newer luxury high-rise hotels and condominiums.
The name "Acapulco" comes from Nahuatl language "Aca-pōl-co", and means "where the reeds were destroyed or washed away". The "de Juárez" was added to the official name in 1885 to honor Benito Juárez, former President of Mexico (1806–1872). The seal for the city shows broken reeds or cane. The island and municipality of Capul, in the Philippines, derives its name from Acapulco. Acapulco was the eastern end of the trans-Pacific sailing route from Acapulco to Manila, in what was then a Spanish colony.
By the 8th century around the Acapulco Bay area, there was a small culture which would first be dominated by the Olmecs, then by a number of others during the pre-Hispanic period before it ended in the 1520s. At Acapulco Bay itself, there were two Olmec sites, one by Playa Larga and the other on a hill known as "El Guitarrón". Olmec influence caused the small spread-out villages here to coalesce into larger entities and build ceremonial centers.
Later, Teotihuacan influence made its way here via Cuernavaca and Chilpancingo. Then Mayan influence arrived from the Isthmus of Tehuantepec and through what is now Oaxaca. This history is known through the archaeological artifacts that have been found here, especially at "Playa Hornos, Pie de la Cuesta", and "Tambuco".
In the 11th century, new waves of migration of Nahuas and "Coixas" came through here. These people were the antecedents of the Aztecs. In the later 15th century, after four years of military struggle, Acapulco became part of the Aztec Empire during the reign of Ahuizotl (1486–1502). It was annexed to a tributary province named "Tepecuacuilco". However, this was only transitory, as the Aztecs could only establish an unorganized military post at the city's outskirts. The city was in territory under control of the "Yopes", who continued defending it and living there until the arrival of the Spanish in the 1520s.
There are two stories about how Acapulco bay was discovered by Europeans. The first states that two years after the Spanish conquest of the Aztec Empire, Hernán Cortés sent explorers west to find gold. The explorers had subdued this area after 1523, and Captain Saavedra Cerón was authorized by Cortés to found a settlement here. The other states that the bay was discovered on December 13, 1526 by a small ship named the El Tepache Santiago captained by Santiago Guevara.
The first encomendero was established in 1525 at "Cacahuatepec", which is part of the modern Acapulco municipality. In 1531, a number of Spaniards, most notably Juan Rodriguez de Villafuerte, left the Oaxaca coast and founded the village of Villafuerte where the city of Acapulco now stands. Villafuerte was unable to subdue the local native peoples, and this eventually resulted in the Yopa Rebellion in the region of "Cuautepec". Hernán Cortés was obligated to send Vasco Porcayo to negotiate with the indigenous people giving concessions. The province of Acapulco became the encomendero of Rodriguez de Villafuerte who received taxes in the form of cocoa, cotton and corn.
Cortés established Acapulco as a major port by the early 1530s, with the first major road between Mexico City and the port constructed by 1531. The wharf, named Marqués, was constructed by 1533 between Bruja Point and Diamond Point. Soon after, the area was made an "alcadia" (major province or town).
Spanish trade in the Far East would give Acapulco a prominent position in the economy of New Spain. In 1550 thirty Spanish families were sent to live here from Mexico City to have a permanent base of European residents. Galleons started arriving in Acapulco from Asia by 1565. Acapulco would become the second most important port, after Veracruz, due to its direct trade with the Philippines. This trade would focus on the yearly Manila-Acapulco Galleon trade, which was the nexus of all kinds of communications between New Spain, Europe and Asia. In 1573, the port was granted the monopoly of the Manila trade.
The galleon trade made its yearly run from the mid-16th century until the early 19th. The luxury items it brought to New Spain attracted the attention of English and Dutch pirates, such as Francis Drake, Henry Morgan and Thomas Cavendish, who called it "The Black Ship". A Dutch fleet invaded Acapulco in 1615, destroying much of the town before being driven off. The Fort of San Diego was built the following year to protect the port and the cargo of arriving ships. The fort was destroyed by an earthquake in 1776 and was rebuilt between 1778 and 1783.
At the beginning of the 19th century, King Charles IV declared Acapulco a Ciudad Official and it became an essential part of the Spanish Crown. However, not long after, the Mexican War of Independence began. In 1810, José María Morelos y Pavón attacked and burnt down the city, after he defeated royalist commander Francisco Parés at the Battle of Tres Palos. The independence of Mexico in 1821 ended the run of the Manila Galleon.
Acapulco's importance as a port recovered during the California Gold Rush in the mid-19th-century, with ships going to and coming from Panama stopping here. This city was the besieged on 19 April 1854 by Antonio López de Santa Anna after Guerrero's leadership had rebelled by issuing the Plan de Ayutla. After an unsuccessful week of fighting, Santa Anna retreated.
In 1911, revolutionary forces took over the main plaza of Acapulco.
In 1920, the Prince of Wales (the future King Edward VIII) visited the area. Impressed by what he saw, he recommended the place to his compatriots in Europe, making it popular with the elite there. Much of the original hotel and trading infrastructure was built by a businessman named Albert B. Pullen from Corrigan, Texas, in the area now known as Old Acapulco. In 1933 Carlos Barnard started the first section of "Hotel El Mirador", with 12 rooms on the cliffs of La Quebrada. Wolf Schoenborn purchased large amounts of undeveloped land and Albert Pullen built the "Las Americas Hotel".
In the mid-1940s, the first commercial wharf and warehouses were built. In the early 1950s, President Miguel Alemán Valdés upgraded the port's infrastructure, installing electrical lines, drainage systems, roads and the first highway to connect the port with Mexico City.
The economy grew and foreign investment increased with it. During the 1950s, Acapulco became the fashionable place for millionaire Hollywood stars such as Elizabeth Taylor, Frank Sinatra, Eddie Fisher and Brigitte Bardot. The 1963 Hollywood movie "Fun in Acapulco", starring Elvis Presley, is set in Acapulco although the filming took place in the United States. Former swing musician Teddy Stauffer, the so-called "Mister Acapulco", was a hotel manager ("Villa Vera", "Casablanca"), who attracted many celebrities to Acapulco.
From a population of only 4,000 or 5,000 in the 1940s, by the early 1960s, Acapulco had a population of about 50,000. In 1958, the Diocese of Acapulco was created by Pope Pius XII. It became an archdiocese in 1983.
During the 1960s and 1970s, new hotel resorts were built, and accommodation and transport were made cheaper. It was no longer necessary to be a millionaire to spend a holiday in Acapulco; the foreign and Mexican middle class could now afford to travel here. However, as more hotels were built in the south part of the bay, the old hotels of the 1950s lost their grandeur. For the 1968 Summer Olympics in neighboring Mexico City, Acapulco hosted the sailing (then yachting) events.
In the 1970s, there was a significant expansion of the port.
The Miss Universe 1978 pageant took place in the city. In 1983, singer-songwriter Juan Gabriel wrote the song "Amor eterno", which pays homage to Acapulco. The song was first and most famously recorded by Rocio Durcal. Additionally, Acapulco is the hometown of actress, singer, and comedian Aída Pierce, who found fame during the 1980s, 1990s and the first decade of the 21st century.
The tollway known as the "Ruta del Sol" was built during the 1990s, crossing the mountains between Mexico City and Acapulco. The journey takes only about three-and-a-half hours, making Acapulco a favorite weekend destination for Mexico City inhabitants. It was in that time period that the economic impact of Acapulco as a tourist destination increased positively, and as a result new types of services emerged, such as the Colegio Nautilus. This educational project, backed by the state government, was created for the families of local and foreign investors and businessmen living in Acapulco who were in need of a bilingual and international education for their children.
The port continued to grow and in 1996, a new private company, API Acapulco, was created to manage operations. This consolidated operations and now Acapulco is the major port for car exports to the Pacific.
The city was devastated by Hurricane Pauline in 1997. The storm stranded tourists and left more than 100 dead in the city. Most of the victims were from the shantytowns built on steep hillsides that surround the city. Other victims were swept away by thirty-foot waves and winds. The main road, Avenida Costera, became a fast-moving river of sludge three feet in depth.
In the 21st century, the Mexican Drug War has had a negative effect on tourism in Acapulco as rival drug traffickers fight each other for the Guerrero coast route that brings drugs from South America as well as soldiers that have been fighting the cartels since 2006.
A major gun battle between 18 gunmen and soldiers took place in the summer of 2009 in the Old Acapulco seaside area, lasting hours and killing 16 of the gunmen and two soldiers. This came after the swine flu outbreak earlier in the year nearly paralyzed the Mexican economy, forcing hotels to give discounts to bring tourists back. However, hotel occupancy for 2009 was down five percent from the year before. The death of Arturo Beltran Leyva in December 2009 resulted in infighting among different groups within the Beltran Leyva cartel.
Gang violence continued to plague Acapulco through 2010 and into 2011, most notably with at least 15 dying in drug-related violence on March 13, 2010, and another 15 deaths on January 8, 2011. Among the first incident's dead were six members of the city police and the brother of an ex-mayor. In the second incident, the headless bodies of 15 young men were found dumped near the Plaza Sendero shopping center. On August 20, 2011, Mexican authorities reported that five headless bodies were found in Acapulco, three of which were placed in the city's main tourist area and two of which were cut into multiple pieces.
On February 4, 2013, six Spanish men were tied up and robbed and the six Spanish women with them were gang-raped by five masked gunmen who stormed a beach house on the outskirts of Acapulco, though after these accusations, none of the victims decided to press charges. On September 28, 2014, Mexican politician Braulio Zaragoza was gunned down at the "El Mirador" hotel in the city. He was the leader of the conservative opposition National Action Party (PAN) in southern Guerrero state. Several politicians have been targeted by drug cartels operating in the area. Investigations are under way, but no arrests have yet been made. The insecurity due to individuals involved with drug cartels has cost the city of Acapulco its popularity among national and international tourists. It was stated by the "Dirección General de Aeronáutica Civil" that the number of international flyers coming to Acapulco decreased from 355,760 flyers registered in 2006 to 52,684 flyers in the year 2015, the number of international tourists flying to Acapulco dropped 85% in the interval of nine years.
The city, located on the Pacific coast of Mexico in the state of Guerrero, is classified as one of the state's seven regions, dividing the rest of the Guerrero coast into the Costa Grande and the Costa Chica. Forty percent of the municipality is mountainous terrain; another forty percent is semi-flat; and the other twenty percent is flat. Altitude varies from sea level to . The highest peaks are "Potrero, San Nicolas", and "Alto Camarón". One major river runs through the municipality, the "Papagayo", along with a number of "arroyos" (streams). There are also two small lagoons, Tres Palos and Coyuca, along with a number of thermal springs.
Acapulco features a tropical wet and dry climate (Köppen: Aw): hot with distinct wet and dry seasons, with more even temperatures between seasons than resorts farther north in Mexico, but this varies depending on altitude. The warmest areas are next to the sea where the city is. Tropical storms and hurricanes are threats from May through November. The forested area tends to lose leaves during the winter dry season, with evergreen pines in the highest elevations. Fauna consists mostly of deer, small mammals, a wide variety of both land and seabirds, and marine animals such as turtles. Oddly enough, January, its coolest month, also features its all-time record high.
The temperature of the sea is quite stable, with lows of between January – March, and a high of in August.
As the seat of a municipality, the city of Acapulco is the government authority for over 700 other communities, which together have a territory of 1,880.60 km. This municipality borders the municipalities of Chilpancingo, Juan R Escudero (Tierra Colorada), San Marcos, Coyuca de Benítez with the Pacific Ocean to the south.
The metropolitan area is made up of the municipalities of Acapulco de Juárez and Coyuca de Benitez. The area has a population () of 786,830.
Acapulco is the most populated city in the state of Guerrero, according to the results of the II Population and Housing Census 2010 carried out by the National Institute of Statistics and Geography (INEGI) with a census date of June 12, 2010, The city had until then a total population of 673 479 inhabitants, of that amount, 324 746 were men and 348 733 women. It is considered the twenty-second most populous city in Mexico and the tenth most populous metropolitan area in Mexico. It is also the city with the highest concentration of population of the homonymous municipality, representing 85.25 percent of the 789.971 inhabitants.
The metropolitan area of Acapulco is made up of six towns in the municipality of Acapulco de Juárez and four in the municipality of Coyuca de Benítez. In agreement with the last count and official delimitation realized in 2010 altogether by the National Institute of Statistics and Geography, the National Council of Population and the Secretariat of Social Development, the metropolitan area of Acapulco grouped a total of 863 431 inhabitants in a surface of 3 538.5 km², which placed it as the tenth most populated district in Mexico. It is estimated according to a study by the National Autonomous University of Mexico on climate and geography, carried out in 2002, that between 2015 and 2020 the city of Acapulco will exceed one million inhabitants.
<noinclude>
Tourism is the main economic activity of the municipality and most of this is centered on Acapulco Bay. About seventy-three percent of the municipality's population is involved in commerce, most of it related to tourism and the port. Mining and manufacturing employ less than twenty percent and only about five percent is dedicated to agriculture. Industrial production is limited mostly to bottling, milk products, cement products, and ice and energy production. Agricultural products include tomatoes, corn, watermelon, beans, green chili peppers, and melons.
Acapulco is one of Mexico's oldest coastal tourist destinations, reaching prominence in the 1950s as the place where Hollywood stars and millionaires vacationed on the beach in an exotic locale. In modern times, tourists in Acapulco have been facing problems with corrupt local police who steal money by extortion and intimidate visitors with threats of jail.
The city is divided into three tourist areas.
Traditional Acapulco is the old part of the port, where hotels like Hotel Los Flamingos, owned by personalities Johnny Weissmuller and John Wayne are located, is on the northern end of the bay. Anchored by attractions such as the beaches of Caleta and Caletilla, the cliff divers of La Quebrada, and the city square, known as "El Zocalo". The heyday of this part of Acapulco ran from the late 1930s until the 1960s, with development continuing through the 1980s. This older section of town now caters to a mostly middle-class, almost exclusively Mexican clientele, while the glitzier newer section caters to the Mexican upper classes, many of whom never venture into the older, traditional part of town.
Acapulco Dorado had its development between the 1950s and the 1970s, and is about 25 minutes from the Acapulco International Airport. It is the area that presents the most tourist influx in the port, runs through much of the Acapulco bay, from Icacos, passing through Costera Miguel Aleman Avenue, which is the main one, to Papagayo Park. It has several hotels,
Acapulco Diamante, also known as Punta Diamante, is the newest and most developed part of the port, with investment having created one of the greatest concentrations of luxury facilities in Mexico, including exclusive hotels and resorts of international chains, residential complexes, luxury condominiums and private villas, spas, restaurants, shopping areas and a golf course. Starting at the Scenic Highway in Las Brisas, it includes Puerto Marqués and Punta Diamante and extends to Barra Vieja Beach. It is 10 minutes from the Acapulco International Airport. In this area, all along "Boulevard de las Naciones", almost all transportation is by car, limousine or golf cart.
Acapulco's reputation of a high-energy party town and the nightlife have long been draws of the city for tourists. From November to April, luxury liners stop here daily and include ships such as the MS "Queen Victoria", the MS "Rotterdam", "Crystal Harmony", and all the Princess line ships. Despite Acapulco's international fame, most of its visitors are from central Mexico, especially the affluent from Mexico City. Acapulco is one of the embarkation ports for the Mexican cruise line Ocean Star Cruises.
For the Christmas season of 2009, Acapulco received 470,000 visitors, most of whom are Mexican nationals, adding 785 million pesos to the economy. Eighty percent arrive by land and eighteen percent by air. The area has over 25,000 condominiums, most of which function as second homes for their Mexican owners. Acapulco is still popular with Mexican celebrities and the wealthy, such as Luis Miguel and Plácido Domingo, who maintain homes there.
While much of the glitz and glamour that made Acapulco famous still remains, from the latter 20th century on, the city has also taken on other less-positive reputations. Some consider it a "passé" resort, eclipsed by the newer Cancún and Cabo San Lucas. Over the years, a number of problems have developed here, especially in the bay and the older sections of the city. The large number of wandering vendors on the beaches, who offer everything from newspapers to massages, are a recognized problem. It is a bother to tourists who simply want to relax on the beach, but the government says it is difficult to eradicate, as there is a lot of unemployment and poverty here. Around the city are many small shantytowns that cling to the mountainsides, populated by migrants who have come here looking for work. In the last decade, drug-related violence has caused massive problems for the local tourism trade.
Another problem is the garbage that has accumulated in the bay. Although 60.65 tons have recently been extracted from the bays of Acapulco and nearby Zihuatanejo, more needs to be done. Most of trash removal during the off seasons is done on the beaches and in the waters closest to them. However, the center of the bay is not touched. The reason trash winds up in the bay is that it is common here to throw it in streets, rivers and the bay itself. The most common items cleaned out of the bay are beer bottles and car tires. Acapulco has seen some success in this area, having several beaches receiving the high "blue flag" certifications for cleanliness and water quality.
Acapulco's gastronomy is very rich. The following are typical dishes from the region:
Relleno is baked pork with a variety of vegetables and fruits such as potatoes, raisins, carrots and chiles. It is eaten with bread called "bolillo".
Pozole is a soup with a salsa base (it can be white, red or green), corn, meat that can be either pork or chicken and it is accompanied with "antojitos" (snacks) like tostadas, tacos and tamales. This dish is served as part of a weekly Thursday event in the city and the state, with many restaurants offering the meal with special entertainment, from bands to dancers to celebrity impersonators.
Acapulco's main attraction is its nightlife, as it has been for many decades. Nightclubs change names and owners frequently.
For example, Baby 'O has been open to the national and international public since 1976 and different celebrities have visited their installations such as Mexican singer Luis Miguel, Bono from U2 and Sylvester Stallone. Another nightclub is Palladium, located in the Escénica Avenue, the location gives the nightclub a beautiful view of the Santa Lucia Bay at night. Various DJs have had performances in Palladium among them DVBBS, Tom Swoon, Nervo and Junkie KID.
Informal lobby or poolside cocktail bars often offer free live entertainment. In addition, there is the beach bar zone, where younger crowds go. These are located along the Costera road, face the ocean and feature techno or alternative rock. Most are concentrated between the Fiesta Americana and Continental Plaza hotels. These places tend to open earlier and have more informal dress. There is a bungee jump in this area as well.
Another attraction at Acapulco is the La Quebrada Cliff Divers. The tradition started in the 1930s when young men casually competed against each other to see who could dive from the highest point into the sea below. Eventually, locals began to ask for tips for those coming to see the men dive. Today the divers are professionals, diving from heights of into an inlet that is only wide and deep, after praying first at a shrine to the Virgin of Guadalupe. On December 12, the feast day of this Virgin, freestyle cliff divers jump into the sea to honor her. Dives range from the simple to the complicated and end with the "Ocean of Fire" when the sea is lit with gasoline, making a circle of flames which the diver aims for. The spectacle can be seen from a public area which charges a small fee or from the Hotel Plaza Las Glorias/El Mirador from its bar or restaurant terrace.
There are a number of beaches in the Acapulco Bay and the immediate coastline. In the bay proper there are the La Angosta (in the Quebrada), Caleta, Caletilla, Dominguillo, Tlacopanocha, Hornos, Hornitos, Honda, Tamarindo, Condesa, Guitarrón, Icacos, Playuela, Playuelilla and Playa del Secreto. In the adjoining, smaller Bay of Puerto Marqués there is Pichilingue, Las Brisas, and Playa Roqueta. Facing open ocean just northwest of the bays is Pie de la Cuesta and southeast are Playa Revolcadero, Playa Aeromar, Playa Encantada and Barra Vieja. Two lagoons are in the area, Coyuca to the northwest of Acapulco Bay and Tres Palos to the southeast. Both lagoons have mangroves and offer boat tours. Tres Palos also has sea turtle nesting areas which are protected.
In addition to sunbathing, the beaches around the bay offer a number of services, such as boat rentals, boat tours, horseback riding, scuba diving and other aquatic sports. One popular cruise is from Caletilla Beach to Roqueta Island, which has places to snorkel, have lunch, and a lighthouse. There is also an underwater statue of the Virgin of Guadalupe here, created in 1958 by Armando Quesado in memory of a group of divers who died here. Many of the scuba-diving tours come to this area as well, where there are sunken ships, sea mountains, and cave rock formations. Another popular activity is deep-sea fishing. The major attraction is sail fishing. Fish caught here have weighed between 89 and 200 pounds. Sailfish are so plentiful that boat captains have been known to bet with a potential customer that if he does not catch anything, the trip is free.
In the old part of the city, there is a traditional main square called the Zócalo, lined with shade trees, cafés and shops. At the north end of the square is "Nuestra Señora de la Soledad" cathedral, with blue onion-shaped domes and Byzantine towers. The building was originally constructed as a movie set, but was later adapted into a church. Acapulco's most historic building is the Fort of San Diego, located east of the main square and originally built in 1616 to protect the city from pirate attacks. The fort was partially destroyed by the Dutch in the mid-17th century, rebuilt, then destroyed again in 1776 by an earthquake. It was rebuilt again by 1783 and this is the building that can be seen today, unchanged except for renovations done to it in 2000. Parts of the moats remain as well as the five bulwarks and the battlements. Today the fort serves as the Museo Histórico de Acapulco (Acapulco Historical Museum), which shows the port's history from the pre-Hispanic period until independence. There are temporary exhibits as well. For many years tourists could ride around the city in colorful horse-drawn carriages known as "calandrias", but the practice ended in February 2020 due to concerns about mistreatment of the animals.
The El Rollo Acapulco is a sea-life and aquatic park located on Costera Miguel Aleman. It offers wave pools, water slides and water toboggans. There are also dolphin shows daily and a swim with dolphins program. The center mostly caters to children. Another place that is popular with children is the "Parque Papagayo": a large family park which has a life-sized replica of a Spanish galleon, three artificial lakes, an aviary, a skating rink, rides, go-karts and more.
The Dolores Olmedo House is located in the traditional downtown of Acapulco and is noted for the murals by Diego Rivera that adorn it. Olmedo and Rivera had been friend since Olmedo was a child and Rivera spent the last two years of his life here. During that time, he painted nearly nonstop and created the outside walls with tile mosaics, featuring Aztec deities such as Quetzalcoatl. The interior of the home is covered in murals. The home is not a museum, so only the outside murals can be seen by the public.
There is a small museum called "Casa de la Máscara" (House of Masks) which is dedicated to masks, most of them from Mexico, but there are examples from many parts of the world. The collection contains about one thousand examples and is divided into seven rooms called Masks of the World, Mexico across History, The Huichols and the Jaguar, Alebrijes, Dances of Guerrero, Devils and Death, Identity and Fantasy, and Afro-Indian masks.
The Botanical Garden of Acapulco is a tropical garden located on lands owned by the Universidad Loyola del Pacífico. Most of the plants here are native to the region, and many, such as the Peltogyne mexicana or purple stick tree, are in danger of extinction.
One cultural event that is held yearly in Acapulco is the "Festival Internacional de la Nao", which takes place in the Fort of San Diego, located near the Zócalo in downtown of the city. The Festival honors the remembrance of the city's interaction and trades with Oriental territories which started back in the Sixteenth Century. The Nao Festival consists of cultural activities with the support of organizations and embassies from India, China, Japan, Philippines, Thailand, Indonesia and South Korea. The variety of events go from film projections, musical interpretations and theatre to gastronomical classes, some of the events are specifically for kids.
The annual French Festival takes place throughout Acapulco city and offers a multitude of events that cement cultural links between Mexico and France. The main features are a fashion show and a gourmet food fair. The Cinépolis Galerías Diana and the Teatro Juan Ruíz de Alarcón present French and French literary figures who give talks on their specialised subjects. Even some of the local nightclubs feature French DJs. Other festivals celebrated here include Carnival, the feast of San Isidro Labrador on 15 May, and in November, a crafts and livestock fair called the Nao de China.
There are a number of golf courses in Acapulco including the Acapulco Princess and the Pierre Marqués course, the latter designed by Robert Trent Jones in 1972 for the World Cup Golf Tournament. The Mayan Palace course was designed by Pedro Guericia and an economical course called the Club de Golf Acapulco is near the convention center. The most exclusive course is that of the Tres Vidas Golf Club, designed by Robert von Hagge. It is located next to the ocean and is home to flocks of ducks and other birds.
Another famous sport tournament that has been held in Acapulco since 1993 is the Abierto Mexicano Telcel tennis tournament, an ATP 500 event that takes place in the tennis courts of the Princess Mundo Imperial, a resort located in the Diamante zone of Acapulco. Initially it was played in clay courts but it changed to hard court. The event has gained popularity within the passing of the years, attracting some of the top tennis players in the world including Novak Djokovic, Rafael Nadal and Marin Cilic. The total prize money is US$250,000.00 for WTA (women) and US$1,200,000.00 for ATP (men).
Acapulco also has a bullring, called the Plaza de Toros, near Caletilla Beach. The season runs during the winter and is called the Fiesta Brava.
Before 2010, over 100,000 American teenagers and young adults traveled to resort areas and balnearios throughout Mexico during spring break each year. The main reason students head to Mexico is the drinking age of 18 years (versus 21 for the United States), something that has been marketed by tour operators along with the sun and ocean. This has become attractive since the 1990s, especially since more traditional spring break places such as Daytona Beach, Florida, have enacted restrictions on drinking and other behaviors. This legislation has pushed spring break tourism to various parts of Mexico, with Acapulco as one of the top destinations.
In the late 1990s and early 2000s, Cancún had been favored as the spring break destination of choice. However, Cancún has taken some steps to control the reckless behavior associated with the event, and students have been looking for someplace new. This led many more to choose Acapulco, in spite of the fact that for many travelers, the flight is longer and more expensive than to Cancún. Many were attracted by the glitzy hotels on the south side and Acapulco's famous nightlife. In 2008, 22,500 students came to Acapulco for spring break. Hotels did not get that many in 2009, due mostly to the economic situation in the United States, and partially because of scares of drug-related violence.
In February 2009, the US State Department issued a travel alert directed at college students planning spring break trips to Acapulco. The warning—a result of violent activity springing from Mexico's drug cartel débâcle—took college campuses by storm, with some schools going so far as to warn their students about the risks of travel to Mexico over spring break. Bill O'Reilly devoted a segment of his show, "The O'Reilly Factor", to urge students to stay away from Acapulco. In June 2009, a number of incidents occurred between the drug cartel and the government. These included coordinated attacks on police headquarters and open battles in the streets, involving large-caliber weapons and grenades. However, no incidents of violence against travelers on spring break were reported.
Many airlines fly to Acapulco International Airport. In the city, there are many buses and taxi services one can take to get from place to place, but most of the locals choose to walk to their destinations. However, an important mode of transportation is the government-subsidized 'Colectivo' cab system. These cabs cost 13 pesos per person to ride, but they are not private. The driver will pick up more passengers as long as seats are available, and will transport them to their destination based on first-come, first-served rules. The colectivos each travel a designated area of the city, the three main ones being Costera, Colosio, Coloso, or a mixture of the three. Coloso cabs travel mainly to old Acapulco. Colosio cabs travel through most of the tourist area of Acapulco. Costera cabs drive up and down the coast of Acapulco, where most of the hotels for visitors are located, but which includes some of old Acapulco. Where a driver will take you is partly his choice. Some are willing to travel to the other designated areas, especially during slow periods of the day.
The bus system is highly complex and can be rather confusing to an outsider. As far as transportation goes, it is the cheapest form, other than walking, in Acapulco. The most expensive buses have air conditioning, while the cheaper buses do not. For tourists, the Acapulco city government has established a system of yellow buses with Acapulco painted on the side of them. These buses are not for tourists only, but are certainly the nicest and most uniform of the bus systems. These buses travel the tourist section of Acapulco, driving up and down the coast. There are buses with specific routes and destinations, generally written on their windshields or shouted out by a barker riding in the front seat. Perhaps the most unusual thing about the privately operated buses is the fact that they are all highly decorated and personalized, with decals and home-made interior designs that range from comic book scenes, to pornography, and even to "Hello Kitty" themes.
The conflictive public transportation would be upgraded the 25th of June 2016 with the implementation of the Acabus. The Acabus infrastructure has a length of , counts with 16 stations that spread through the city of Acapulco and 5 routes. This project will help organize traffic because the buses now have a specific line on the roads and there would be more control over transportation and passengers.
In 2014, the idea to nominate the Manila-Acapulco Galleon Trade Route was initiated by the Mexican ambassador to UNESCO with the Filipino ambassador to UNESCO.
An Experts' Roundtable Meeting was held at the University of Santo Tomas (UST) on April 23, 2015 as part of the preparation of the Philippines for the possible transnational nomination of the Manila-Acapulco Galleon Trade Route to the World Heritage List. The nomination will be made jointly with Mexico.
The following are the experts and the topics they discussed during the roundtable meeting: Dr. Celestina Boncan on the Tornaviaje; Dr. Mary Jane A. Bolunia on Shipyards in the Bicol Region; Mr. Sheldon Clyde Jago-on, Bobby Orillaneda, and Ligaya Lacsina on Underwater Archaeology; Dr. Leovino Garcia on Maps and Cartography; Fr. Rene Javellana, S.J. on Fortifications in the Philippines; Felice Sta. Maria on Food; Dr. Fernando Zialcita on Textile; and Regalado Trota Jose on Historical Dimension. The papers presented and discussed during the roundtable meeting will be synthesized into a working document to establish the route's Outstanding Universal Value.
The Mexican side reiterated that they will also follow suit with the preparations for the route's nomination.
Spain has also backed the nomination of the Manila-Acapulco Trade Route Route in the UNESCO World Heritage Site list and has also suggested the Archives of the Manila-Acapulco Galleons to be nominated as part of a separate UNESCO list, the UNESCO Memory of the World Register.

</doc>
<doc id="1448" url="https://en.wikipedia.org/wiki?curid=1448" title="August 16">
August 16


</doc>
<doc id="1449" url="https://en.wikipedia.org/wiki?curid=1449" title="Alan Kay">
Alan Kay

Alan Curtis Kay (born May 17, 1940) is an American computer scientist. He has been elected a Fellow of the American Academy of Arts and Sciences, the National Academy of Engineering, and the Royal Society of Arts. He is best known for his pioneering work on object-oriented programming and windowing graphical user interface (GUI) design.
He was the president of the Viewpoints Research Institute before its closure in 2018, and an adjunct professor of computer science at the University of California, Los Angeles. He is also on the advisory board of TTI/Vanguard. Until mid-2005, he was a senior fellow at HP Labs, a visiting professor at Kyoto University, and an adjunct professor at the Massachusetts Institute of Technology (MIT).
Kay is also a former professional jazz guitarist, composer, and theatrical designer, and an amateur classical pipe organist.
In an interview on education in America with the Davis Group Ltd., Kay said:
Originally from Springfield, Massachusetts, Kay's family relocated several times due to his father's career in physiology before ultimately settling in the New York metropolitan area when he was nine.
He attended the prestigious Brooklyn Technical High School, where he was suspended due to insubordination in his senior year. Having already accumulated enough credits to graduate, Kay then attended Bethany College in Bethany, West Virginia. He majored in biology and minored in mathematics before he was asked to leave by the administration for protesting the institution's Jewish quota.
Thereafter, Kay taught guitar in Denver, Colorado for a year and hastily enlisted in the United States Air Force when the local draft board inquired about his nonstudent status. Assigned as a computer programmer (a rare billet dominated by women due to the secretarial connotations of the field in the era) after passing an aptitude test, he devised an early cross-platform file transfer system.
Following his discharge, Kay enrolled at the University of Colorado Boulder, earning a bachelor's degree in mathematics and molecular biology in 1966. Before and during this time, he worked as a professional jazz guitarist. During his studies at CU, he wrote the music for an adaptation of "The Hobbit" and other campus theatricals.
In the autumn of 1966, he began graduate school at the University of Utah College of Engineering. He earned a Master of Science (M.S.) in electrical engineering in 1968 before taking his Doctor of Philosophy (Ph.D.) in computer science in 1969. His doctoral dissertation, "FLEX: A Flexible Extendable Language", described the invention of a computer language known as FLEX. While there, he worked with "fathers of computer graphics" David C. Evans (who had been recently recruited from the University of California, Berkeley to start Utah's computer science department) and Ivan Sutherland (best known for writing such pioneering programs as Sketchpad). Their mentorship greatly inspired Kay's evolving views on objects and programming. As he grew busier with research for the Defense Advanced Research Projects Agency (DARPA), he ended his musical career.
In 1968, he met Seymour Papert and learned of the programming language Logo, a dialect of Lisp optimized for educational purposes. This led him to learn of the work of Jean Piaget, Jerome Bruner, Lev Vygotsky, and of constructionist learning, further influencing his professional orientation.
Leaving Utah as an associate professor of computer science in 1969, Kay became a visiting researcher at the Stanford Artificial Intelligence Laboratory in anticipation of accepting a professorship at Carnegie Mellon University. Instead, in 1970, he joined the Xerox PARC research staff in Palo Alto, California. Throughout the decade, he developed prototypes of networked workstations using the programming language Smalltalk. These inventions were later commercialized by Apple in their Lisa and Macintosh computers.
Kay is one of the fathers of the idea of object-oriented programming, which he named, along with some colleagues at PARC. Some of the original object-oriented concepts, including the use of the words 'object' and 'class', had been developed for Simula 67 at the Norwegian Computing Center. Later he said:
I'm sorry that I long ago coined the term "objects" for this topic because it gets many people to focus on the lesser idea. The big idea is "messaging".
While at PARC, Kay conceived the Dynabook concept, a key progenitor of laptop and tablet computers and the e-book. He is also the architect of the modern overlapping windowing graphical user interface (GUI). Because the Dynabook was conceived as an educational platform, Kay is considered to be one of the first researchers into mobile learning; many features of the Dynabook concept have been adopted in the design of the One Laptop Per Child educational platform, with which Kay is actively involved.
The field of computing is awaiting new revolution to happen, according to Kay, in which educational communities, parents, and children will not see in it a set of tools invented by Douglas Engelbart, but a medium in the Marshall McLuhan sense. He wrote:
As with Simulas leading to OOP, this encounter finally hit me with what the destiny of personal computing really was going to be. Not a personal dynamic vehicle, as in Engelbart's metaphor opposed to the IBM "railroads", but something much more profound: a personal dynamic medium. With a vehicle one could wait until high school and give "drivers ed", but if it was a medium, it had to extend into the world of childhood.
From 1981 to 1984, Kay was Atari's Chief Scientist. In 1984, he became an Apple Fellow. Following the closure of the Apple Advanced Technology Group in 1997, he was recruited by his friend Bran Ferren, head of research and development at Disney, to join Walt Disney Imagineering as a Disney Fellow. He remained there until Ferren left to start Applied Minds Inc with Imagineer Danny Hillis, leading to the cessation of the Fellows program. In 2001, he founded Viewpoints Research Institute, a non-profit organization dedicated to children, learning, and advanced software development. For its first ten years, Kay and his Viewpoints group were based at Applied Minds in Glendale, California, where he and Ferren continued to work together on various projects. Kay was also a Senior Fellow at Hewlett-Packard until HP disbanded the Advanced Software Research Team on July 20, 2005.
Kay taught a Fall 2011 class, "Powerful Ideas: Useful Tools to Understand the World", at New York University's Interactive Telecommunications Program (ITP) along with full-time ITP faculty member Nancy Hechinger. The goal of the class was to devise new forms of teaching/learning based on fundamental, powerful concepts rather than traditional rote learning.
In December 1995, while still at Apple, Kay collaborated with many others to start the open source Squeak version of Smalltalk, and he continues to work on it. As part of this effort, in November 1996, his team began research on what became the Etoys system. More recently he started, along with David A. Smith, David P. Reed, Andreas Raab, Rick McGeer, Julian Lombardi and Mark McCahill, the Croquet Project, an open source networked 2D and 3D environment for collaborative work.
In 2001, it became clear that the Etoy architecture in Squeak had reached its limits in what the Morphic interface infrastructure could do. Andreas Raab was a researcher working in Kay's group, then at Hewlett-Packard. He proposed defining a "script process" and providing a default scheduling mechanism that avoids several more general problems. The result was a new user interface, proposed to replace the Squeak Morphic user interface in the future. Tweak added mechanisms of islands, asynchronous messaging, players and costumes, language extensions, projects, and tile scripting. Its underlying object system is class-based, but to users (during programming) it acts like it is prototype-based. Tweak objects are created and run in Tweak project windows.
In November 2005, at the World Summit on the Information Society, the MIT research laboratories unveiled a new laptop computer, for educational use around the world. It has many names: the $100 Laptop, the One Laptop per Child program, the Children's Machine, and the XO-1. The program was begun and is sustained by Kay's friend Nicholas Negroponte, and is based on Kay's Dynabook ideal. Kay is a prominent co-developer of the computer, focusing on its educational software using Squeak and Etoys.
Kay has lectured extensively on the idea that the computer revolution is very new, and all of the good ideas have not been universally implemented. Lectures at OOPSLA 1997 conference and his ACM Turing award talk, entitled "The Computer Revolution Hasn't Happened Yet" were informed by his experiences with Sketchpad, Simula, Smalltalk, and the bloated code of commercial software.
On August 31, 2006, Kay's proposal to the United States National Science Foundation (NSF) was granted, thus funding Viewpoints Research Institute for several years. The proposal title was: "STEPS Toward the Reinvention of Programming": A compact and Practical Model of Personal Computing as a Self-exploratorium. A sense of what Kay is trying to do comes from this quote, from the abstract of a seminar on this given at Intel Research Labs, Berkeley: "The conglomeration of commercial and most open source software consumes in the neighborhood of several hundreds of millions of lines of code these days. We wonder: how small could be an understandable practical "Model T" design that covers this functionality? 1M lines of code? 200K LOC? 100K LOC? 20K LOC?"
Alan Kay has received many awards and honors. Among them:
His other honors include the J-D Warnier Prix d'Informatique, the ACM Systems Software Award, the NEC Computers & Communication Foundation Prize, the Funai Foundation Prize, the Lewis Branscomb Technology Award, and the ACM SIGCSE Award for Outstanding Contributions to Computer Science Education.

</doc>
<doc id="1451" url="https://en.wikipedia.org/wiki?curid=1451" title="APL (programming language)">
APL (programming language)

APL (named after the book "A Programming Language") is a programming language developed in the 1960s by Kenneth E. Iverson. Its central datatype is the multidimensional array. It uses a large range of special graphic symbols to represent most functions and operators, leading to very concise code. It has been an important influence on the development of concept modeling, spreadsheets, functional programming, and computer math packages. It has also inspired several other programming languages.
A mathematical notation for manipulating arrays was developed by Kenneth E. Iverson, starting in 1957 at Harvard University. In 1960, he began work for IBM where he developed this notation with Adin Falkoff and published it in his book "A Programming Language" in 1962. The preface states its premise:
This notation was used inside IBM for short research reports on computer systems, such as the Burroughs B5000 and its stack mechanism when stack machines versus register machines were being evaluated by IBM for upcoming computers.
Iverson also used his notation in a draft of the chapter "A Programming Language", written for a book he was writing with Fred Brooks, "Automatic Data Processing", which would be published in 1963.
In 1979, Iverson received the Turing Award for his work on APL.
As early as 1962, the first attempt to use the notation to describe a complete computer system happened after Falkoff discussed with William C. Carter his work to standardize the instruction set for the machines that later became the IBM System/360 family.
In 1963, Herbert Hellerman, working at the IBM Systems Research Institute, implemented a part of the notation on an IBM 1620 computer, and it was used by students in a special high school course on calculating transcendental functions by series summation. Students tested their code in Hellerman's lab. This implementation of a part of the notation was called Personalized Array Translator (PAT).
In 1963, Falkoff, Iverson, and Edward H. Sussenguth Jr., all working at IBM, used the notation for a formal description of the IBM System/360 series machine architecture and functionality, which resulted in a paper published in "IBM Systems Journal" in 1964. After this was published, the team turned their attention to an implementation of the notation on a computer system. One of the motivations for this focus of implementation was the interest of John L. Lawrence who had new duties with Science Research Associates, an educational company bought by IBM in 1964. Lawrence asked Iverson and his group to help use the language as a tool to develop and use computers in education.
After Lawrence M. Breed and Philip S. Abrams of Stanford University joined the team at IBM Research, they continued their prior work on an implementation programmed in FORTRAN IV for a part of the notation which had been done for the IBM 7090 computer running on the IBSYS operating system. This work was finished in late 1965 and later named IVSYS (for Iverson system). The basis of this implementation was described in detail by Abrams in a Stanford University Technical Report, "An Interpreter for Iverson Notation" in 1966, the academic aspect of this was formally supervised by Niklaus Wirth. Like Hellerman's PAT system earlier, this implementation did not include the APL character set but used special English reserved words for functions and operators. The system was later adapted for a time-sharing system and, by November 1966, it had been reprogrammed for the IBM System/360 Model 50 computer running in a time sharing mode and was used internally at IBM.
A key development in the ability to use APL effectively, before the wide use of cathode ray tube (CRT) terminals, was the development of a special IBM Selectric typewriter interchangeable typing element with all the special APL characters on it. This was used on paper printing terminal workstations using the Selectric typewriter and typing element mechanism, such as the IBM 1050 and IBM 2741 terminal. Keycaps could be placed over the normal keys to show which APL characters would be entered and typed when that key was struck. For the first time, a programmer could type in and see proper APL characters as used in Iverson's notation and not be forced to use awkward English keyword representations of them. Falkoff and Iverson had the special APL Selectric typing elements, 987 and 988, designed in late 1964, although no APL computer system was available to use them. Iverson cited Falkoff as the inspiration for the idea of using an IBM Selectric typing element for the APL character set.
Many APL symbols, even with the APL characters on the Selectric typing element, still had to be typed in by over-striking two extant element characters. An example is the "grade up" character, which had to be made from a "delta" (shift-H) and a "Sheffer stroke" (shift-M). This was necessary because the APL character set was much larger than the 88 characters allowed on the typing element, even when letters were restricted to upper-case (capitals).
The first APL interactive login and creation of an APL workspace was in 1966 by Larry Breed using an IBM 1050 terminal at the IBM Mohansic Labs near Thomas J. Watson Research Center, the home of APL, in Yorktown Heights, New York.
IBM was chiefly responsible for introducing APL to the marketplace. APL was first available in 1967 for the IBM 1130 as "APL\1130". It would run in as little as 8k 16-bit words of memory, and used a dedicated 1 megabyte hard disk.
APL gained its foothold on mainframe timesharing systems from the late 1960s through the early 1980s, in part because it would support multiple users on lower-specification systems that had no dynamic address translation hardware. Additional improvements in performance for selected IBM System/370 mainframe systems included the "APL Assist Microcode" in which some support for APL execution was included in the processor's firmware, as distinct from being implemented entirely by higher-level software. Somewhat later, as suitably performing hardware was finally growing available in the mid- to late-1980s, many users migrated their applications to the personal computer environment.
Early IBM APL interpreters for IBM 360 and IBM 370 hardware implemented their own multi-user management instead of relying on the host services, thus they were their own timesharing systems. First introduced in 1966, the "APL\360" system was a multi-user interpreter. The ability to programmatically communicate with the operating system for information and setting interpreter system variables was done through special privileged "I-beam" functions, using both monadic and dyadic operations.
In 1973, IBM released "APL.SV", which was a continuation of the same product, but which offered shared variables as a means to access facilities outside of the APL system, such as operating system files. In the mid-1970s, the IBM mainframe interpreter was even adapted for use on the IBM 5100 desktop computer, which had a small CRT and an APL keyboard, when most other small computers of the time only offered BASIC. In the 1980s, the "VSAPL" program product enjoyed wide use with Conversational Monitor System (CMS), Time Sharing Option (TSO), VSPC, MUSIC/SP, and CICS users.
In 1973–1974, Patrick E. Hagerty directed the implementation of the University of Maryland APL interpreter for the 1100 line of the Sperry UNIVAC 1100/2200 series mainframe computers. At the time, Sperry had nothing. In 1974, student Alan Stebbens was assigned the task of implementing an internal function. Xerox APL was available from June 1975 for Xerox 560 and Sigma 6, 7, and 9 mainframes running CP-V and for Honeywell CP-6.
In the 1960s and 1970s, several timesharing firms arose that sold APL services using modified versions of the IBM APL\360 interpreter. In North America, the better-known ones were I. P. Sharp Associates, Scientific Time Sharing Corporation (STSC), Time Sharing Resources (TSR), and The Computer Company (TCC). CompuServe also entered the market in 1978 with an APL Interpreter based on a modified version of Digital Equipment Corp and Carnegie Mellon's, which ran on DEC's KI and KL 36-bit machines. CompuServe's APL was available both to its commercial market and the consumer information service. With the advent first of less expensive mainframes such as the IBM 4300, and later the personal computer, by the mid-1980s, the timesharing industry was all but gone.
"Sharp APL" was available from I. P. Sharp Associates, first as a timesharing service in the 1960s, and later as a program product starting around 1979. "Sharp APL" was an advanced APL implementation with many language extensions, such as "packages" (the ability to put one or more objects into a single variable), file system, nested arrays, and shared variables.
APL interpreters were available from other mainframe and mini-computer manufacturers also, notably Burroughs, Control Data Corporation (CDC), Data General, Digital Equipment Corporation (DEC), Harris, Hewlett-Packard (HP), Siemens AG, Xerox, and others.
Garth Foster of Syracuse University sponsored regular meetings of the APL implementers' community at Syracuse's Minnowbrook Conference Center in Blue Mountain Lake, New York. In later years, Eugene McDonnell organized similar meetings at the Asilomar Conference Grounds near Monterey, California, and at Pajaro Dunes near Watsonville, California. The SIGAPL special interest group of the Association for Computing Machinery continues to support the APL community.
On microcomputers, which became available from the mid 1970s onwards, BASIC became the dominant programming language. Nevertheless, some microcomputers provided APL instead - the first being the Intel 8008-based MCM/70 which was released in 1974 and which was primarily used in education. Another machine of this time was the VideoBrain Family Computer, released in 1977, which was supplied with its dialect of APL called APL/S.
The Commodore SuperPET, introduced in 1981, included an APL interpreter developed by the University of Waterloo.
In 1976, Bill Gates claimed in his Open Letter to Hobbyists that Microsoft Corporation was implementing APL for the Intel 8080 and Motorola 6800 but had "very little incentive to make [it] available to hobbyists" because of software piracy. It was never released.
Starting in the early 1980s, IBM APL development, under the leadership of Jim Brown, implemented a new version of the APL language that contained as its primary enhancement the concept of "nested arrays", where an array can contain other arrays, and new language features which facilitated integrating nested arrays into program workflow. Ken Iverson, no longer in control of the development of the APL language, left IBM and joined I. P. Sharp Associates, where one of his major contributions was directing the evolution of Sharp APL to be more in accord with his vision.
As other vendors were busy developing APL interpreters for new hardware, notably Unix-based microcomputers, APL2 was almost always the standard chosen for new APL interpreter developments. Even today, most APL vendors or their users cite APL2 compatibility, as a selling point for those products.
"APL2" for IBM mainframe computers is still available. IBM cites its use for problem solving, system design, prototyping, engineering and scientific computations, expert systems, for teaching mathematics and other subjects, visualization and database access and was first available for CMS and TSO in 1984. The APL2 Workstation edition (Windows, OS/2, AIX, Linux, and Solaris) followed much later in the early 1990s.
Various implementations of APL by APLX, Dyalog, et al., include extensions for object-oriented programming, support for .NET Framework, XML-array conversion primitives, graphing, operating system interfaces, and lambda calculus expressions.
APL has formed the basis of, or influenced, the following languages:
APL has been both criticized and praised for its choice of a unique, non-standard character set. Some who learn it become ardent adherents, suggesting that there is some weight behind Iverson's idea that the notation used does make a difference. In the 1960s and 1970s, few terminal devices and even display monitors could reproduce the APL character set. The most popular ones employed the IBM Selectric print mechanism used with a special APL type element. One of the early APL line terminals (line-mode operation only, "not" full screen) was the Texas Instruments TI Model 745 (circa 1977) with the full APL character set which featured half and full duplex telecommunications modes, for interacting with an APL time-sharing service or remote mainframe to run a remote computer job, called an RJE.
Over time, with the universal use of high-quality graphic displays, printing devices and Unicode support, the APL character font problem has largely been eliminated. However, entering APL characters requires the use of input method editors, keyboard mappings, virtual/on-screen APL symbol sets, or easy-reference printed keyboard cards which can frustrate beginners accustomed to other programming languages. With beginners who have no prior experience with other programming languages, a study involving high school students found that typing and using APL characters did not hinder the students in any measurable way.
In defense of APL use, APL requires less coding to type in, and keyboard mappings become memorized over time. Also, special APL keyboards are manufactured and in use today, as are freely available downloadable fonts for operating systems such as Microsoft Windows. The reported productivity gains assume that one will spend enough time working in APL to make it worthwhile to memorize the symbols, their semantics, and keyboard mappings, not to mention a substantial number of idioms for common tasks.
Unlike traditionally structured programming languages, APL code is typically structured as chains of monadic or dyadic functions, and operators acting on arrays. APL has many nonstandard "primitives" (functions and operators) that are indicated by a single symbol or a combination of a few symbols. All primitives are defined to have the same precedence, and always associate to the right. Thus, APL is "read" or best understood from right-to-left.
Early APL implementations (circa 1970 or so) had no programming loop-flow control structures, such as codice_1 or codice_2 loops, and codice_3 constructs. Instead, they used array operations, and use of structured programming constructs was often not necessary, since an operation could be performed on a full array in one statement. For example, the codice_4 function (codice_5) can replace for-loop iteration: ιN when applied to a scalar positive integer yields a one-dimensional array (vector), 1 2 3 ... N. More recent implementations of APL generally include comprehensive control structures, so that data structure and program control flow can be clearly and cleanly separated.
The APL environment is called a "workspace". In a workspace the user can define programs and data, i.e., the data values exist also outside the programs, and the user can also manipulate the data without having to define a program. In the examples below, the APL interpreter first types six spaces before awaiting the user's input. Its own output starts in column one.
The user can save the workspace with all values, programs, and execution status.
APL uses a set of non-ASCII symbols, which are an extension of traditional arithmetic and algebraic notation. Having single character names for single instruction, multiple data (SIMD) vector functions is one way that APL enables compact formulation of algorithms for data transformation such as computing Conway's Game of Life in one line of code. In nearly all versions of APL, it is theoretically possible to express any computable function in one expression, that is, in one line of code.
Because of the unusual character set, many programmers use special keyboards with APL keytops to write APL code. Although there are various ways to write APL code using only ASCII characters, in practice it is almost never done. (This may be thought to support Iverson's thesis about notation as a tool of thought.) Most if not all modern implementations use standard keyboard layouts, with special mappings or input method editors to access non-ASCII characters. Historically, the APL font has been distinctive, with uppercase italic alphabetic characters and upright numerals and symbols. Most vendors continue to display the APL character set in a custom font.
Advocates of APL claim that the examples of so-called "write-only code" (badly written and almost incomprehensible code) are almost invariably examples of poor programming practice or novice mistakes, which can occur in any language. Advocates also claim that they are far more productive with APL than with more conventional computer languages, and that working software can be implemented in far less time and with far fewer programmers than using other technology.
They also may claim that because it is compact and terse, APL lends itself well to larger-scale software development and complexity, because the number of lines of code can be reduced greatly. Many APL advocates and practitioners also view standard programming languages such as COBOL and Java as being comparatively tedious. APL is often found where time-to-market is important, such as with trading systems.
APL makes a clear distinction between "functions" and "operators". Functions take arrays (variables or constants or expressions) as arguments, and return arrays as results. Operators (similar to higher-order functions) take functions or arrays as arguments, and derive related functions. For example, the "sum" function is derived by applying the "reduction" operator to the "addition" function. Applying the same reduction operator to the "maximum" function (which returns the larger of two numbers) derives a function which returns the largest of a group (vector) of numbers. In the J language, Iverson substituted the terms "verb" for "function" and "adverb" or "conjunction" for "operator".
APL also identifies those features built into the language, and represented by a symbol, or a fixed combination of symbols, as "primitives". Most primitives are either functions or operators. Coding APL is largely a process of writing non-primitive functions and (in some versions of APL) operators. However a few primitives are considered to be neither functions nor operators, most noticeably assignment.
Some words used in APL literature have meanings that differ from those in both mathematics and the generality of computer science.
APL has explicit representations of functions, operators, and syntax, thus providing a basis for the clear and explicit statement of extended facilities in the language, and tools to experiment on them.
This displays "Hello, world":
'Hello, world'
'Hello World,' sample user session on YouTube
A design theme in APL is to define default actions in some cases that would produce syntax errors in most other programming languages.
The 'Hello, world' string constant above displays, because display is the default action on any expression for which no action is specified explicitly (e.g. assignment, function parameter).
Another example of this theme is that exponentiation in APL is written as ", which indicates raising 2 to the power 3 (this would be written as " in some other languages and " in FORTRAN and Python): many languages use * to signify multiplication as in 2*3 but APL uses for that. However, if no base is specified (as with the statement " in APL, or " in other languages), in most other programming languages one would have a syntax error. APL however assumes the missing base to be the natural logarithm constant e (2.71828...), and so interpreting " as "".
Suppose that is an array of numbers. Then gives its average. Reading "right-to-left", gives the number of elements in X, and since is a dyadic operator, the term to its left is required as well. It is in parenthesis since otherwise X would be taken (so that the summation would be of , of each element of X divided by the number of elements in X), and adds all the elements of X. Building on this, calculates the standard deviation. Further, since assignment is an operator, it can appear within an expression, so 
would place suitable values into T, AV and SD. Naturally, one would make this expression into a function for repeated use rather than retyping it each time.
This following immediate-mode expression generates a typical set of "Pick 6" lottery numbers: six pseudo-random integers ranging from 1 to 40, "guaranteed non-repeating", and displays them sorted in ascending order:
x[⍋x←6?40]
The above does a lot, concisely; although it seems complex to a new APLer. It combines the following APL "functions" (also called "primitives" and "glyphs"):
Since there is no function to the left of the left-most x to tell APL what to do with the result, it simply outputs it to the display (on a single line, separated by spaces) without needing any explicit instruction to do that.
codice_6 also has a monadic equivalent called codice_15, which simply returns one random integer between 1 and its sole operand [to the right of it], inclusive. Thus, a role-playing game program might use the expression codice_16 to roll a twenty-sided die.
The following expression finds all prime numbers from 1 to R. In both time and space, the calculation complexity is formula_1 (in Big O notation).
(~R∊R∘.×R)/R←1↓ιR
Executed from right to left, this means:
(Note, this assumes the APL origin is 1, i.e., indices start with 1. APL can be set to use 0 as the origin, so that codice_45 is codice_46, which is convenient for some calculations.)
The following expression sorts a word list stored in matrix X according to word length:
X[⍋X+.≠' ';]
The following function "life", written in Dyalog APL, takes a boolean matrix and calculates the new generation according to Conway's Game of Life. It demonstrates the power of APL to implement a complex algorithm in very little code, but it is also very hard to follow unless one has advanced knowledge of APL.
In the following example, also Dyalog, the first line assigns some HTML code to a variable codice_47 and then uses an APL expression to remove all the HTML tags (explanation):
This is emphasized text.
APL is used for many purposes including financial and insurance applications, artificial intelligence,
neural networks
and robotics. It has been argued that APL is a calculation tool and not a programming language; its symbolic nature and array capabilities have made it popular with domain experts and data scientists who do not have or require the skills of a computer programmer.
APL is well suited to image manipulation and computer animation, where graphic transformations can be encoded as matrix multiplications. One of the first commercial computer graphics houses, Digital Effects, produced an APL graphics product named "Visions", which was used to create television commercials and animation for the 1982 film "Tron". Latterly, the Stormwind boating simulator uses APL to implement its core logic, its interfacing to the rendering pipeline middleware and a major part of its physics engine.
Today, APL remains in use in a wide range of commercial and scientific applications, for example
investment management,
asset management,
health care,
and DNA profiling, 
and by hobbyists.
The first implementation of APL using recognizable APL symbols was APL\360 which ran on the IBM System/360, and was completed in November 1966 though at that time remained in use only within IBM. In 1973 its implementors, Larry Breed, Dick Lathwell and Roger Moore, were awarded the Grace Murray Hopper Award from the Association for Computing Machinery (ACM). It was given "for their work in the design and implementation of APL\360, setting new standards in simplicity, efficiency, reliability and response time for interactive systems."
In 1975, the IBM 5100 microcomputer offered APL\360 as one of two built-in ROM-based interpreted languages for the computer, complete with a keyboard and display that supported all the special symbols used in the language.
Significant developments to APL\360 included CMS/APL, which made use of the virtual storage capabilities of CMS and APLSV, which introduced shared variables, system variables and system functions. It was subsequently ported to the IBM System/370 and VSPC platforms until its final release in 1983, after which it was replaced by APL2.
In 1968, APL\1130 became the first publicly available APL system, created by IBM for the IBM 1130. It became the most popular IBM Type-III Library software that IBM released.
APL*Plus and Sharp APL are versions of APL\360 with added business-oriented extensions such as data formatting and facilities to store APL arrays in external files. They were jointly developed by two companies, employing various members of the original IBM APL\360 development team.
The two companies were I. P. Sharp Associates (IPSA), an APL\360 services company formed in 1964 by Ian Sharp, Roger Moore and others, and STSC, a time-sharing and consulting service company formed in 1969 by Lawrence Breed and others. Together the two developed APL*Plus and thereafter continued to work together but develop APL separately as APL*Plus and Sharp APL. STSC ported APL*Plus to many platforms with versions being made for the VAX 11, PC and UNIX, whereas IPSA took a different approach to the arrival of the Personal Computer and made Sharp APL available on this platform using additional PC-XT/360 hardware. In 1993, Soliton Incorporated was formed to support Sharp APL and it developed Sharp APL into SAX (Sharp APL for Unix). , APL*Plus continues as APL2000 APL+Win.
In 1985, Ian Sharp, and Dan Dyer of STSC, jointly received the Kenneth E. Iverson Award for Outstanding Contribution to APL.
APL2 was a significant re-implementation of APL by IBM which was developed from 1971 and first released in 1984. It provides many additions to the language, of which the most notable is nested (non-rectangular) array support. it is available for mainframe computers running z/OS or z/VM and workstations running AIX, Linux, Sun Solaris, and Microsoft Windows.
The entire APL2 Products and Services Team was awarded the Iverson Award in 2007.
Dyalog APL was first released by British company Dyalog Ltd. in 1983 and, , is available for AIX, Linux (including on the Raspberry Pi), macOS and Microsoft Windows platforms. It is based on APL2, with extensions to support object-oriented programming and functional programming. Licences are free for personal/non-commercial use.
In 1995, two of the development team - John Scholes and Peter Donnelly - were awarded the Iverson Award for their work on the interpreter. Gitte Christensen and Morten Kromberg were joint recipients of the Iverson Award in 2016.
NARS2000 is an open-source APL interpreter written by Bob Smith, a prominent APL developer and implementor from STSC in the 1970s and 1980s. NARS2000 contains advanced features and new datatypes and runs natively on Microsoft Windows, and other platforms under Wine.
APLX is a cross-platform dialect of APL, based on APL2 and with several extensions, which was first released by British company MicroAPL in 2002. Although no longer in development or on commercial sale it is now available free of charge from Dyalog.
GNU APL is a free implementation of Extended APL as specified in ISO/IEC 13751:2001 and is thus an implementation of APL2. It runs on GNU/Linux and on Windows using Cygwin, and uses Unicode internally. It was written by Jürgen Sauermann.
Richard Stallman, founder of the GNU Project, was an early adopter of APL, using it to write a text editor as a high school student in the summer of 1969.
APL is traditionally an interpreted language, having language characteristics such as weak variable typing not well suited to compilation. However, with arrays as its core data structure it provides opportunities for performance gains through parallelism, parallel computing, massively parallel applications, and very-large-scale integration (VLSI), and from the outset APL has been regarded as a high-performance language - for example, it was noted for the speed with which it could perform complicated matrix operations "because it operates on arrays and performs operations like matrix inversion internally".
Nevertheless, APL is rarely purely interpreted and compilation or partial compilation techniques that are, or have been, used include the following:
Most APL interpreters support idiom recognition and evaluate common idioms as single operations. For example, by evaluating the idiom codice_48 as a single operation (where codice_49 is a Boolean vector and codice_50 is an array), the creation of two intermediate arrays is avoided.
Weak typing in APL means that a name may reference an array (of any datatype), a function or an operator. In general, the interpreter cannot know in advance which form it will be and must therefore perform analysis, syntax checking etc. at run-time. However, in certain circumstances, it is possible to deduce in advance what type a name is expected to reference and then generate bytecode which can be executed with reduced run-time overhead. This bytecode can also be optimised using compilation techniques such as constant folding or common subexpression elimination. The interpreter will execute the bytecode when present and when any assumptions which have been made are met. Dyalog APL includes support for optimised bytecode.
Compilation of APL has been the subject of research and experiment since the language first became available; the first compiler is considered to be the Burroughs APL-700 which was released around 1971. In order to be able to compile APL, language limitations have to be imposed. APEX is a research APL compiler which was written by Robert Bernecky and is available under the GNU Public License.
The STSC APL Compiler is a hybrid of a bytecode optimiser and a compiler - it enables compilation of functions to machine code provided that its sub-functions and globals are declared, but the interpreter is still used as a runtime library and to execute functions which do not meet the compilation requirements.
APL has been standardized by the American National Standards Institute (ANSI) working group X3J10 and International Organization for Standardization (ISO) and International Electrotechnical Commission (IEC), ISO/IEC Joint Technical Committee 1 Subcommittee 22 Working Group 3. The Core APL language is specified in ISO 8485:1989, and the Extended APL language is specified in ISO/IEC 13751:2001.

</doc>
<doc id="1453" url="https://en.wikipedia.org/wiki?curid=1453" title="ALGOL">
ALGOL

ALGOL (; short for "Algorithmic Language") is a family of imperative computer programming languages originally developed in 1958. ALGOL heavily influenced many other languages and was the standard method for algorithm description used by the Association for Computing Machinery (ACM) in textbooks and academic sources until object-oriented languages came around, for more than thirty years.
In the sense that the syntax of most modern languages is "Algol-like", it was arguably the most influential of the four high-level programming languages among which it was roughly contemporary: FORTRAN, Lisp, and COBOL. It was designed to avoid some of the perceived problems with FORTRAN and eventually gave rise to many other programming languages, including PL/I, Simula, BCPL, B, Pascal, and C.
ALGOL introduced code blocks and the codice_1...codice_2 pairs for delimiting them. It was also the first language implementing nested function definitions with lexical scope. Moreover, it was the first programming language which gave detailed attention to formal language definition and through the "Algol 60 Report" introduced Backus–Naur form, a principal formal grammar notation for language design.
There were three major specifications, named after the years they were first published:
ALGOL 68 is substantially different from ALGOL 60 and was not well received, so that in general "Algol" means ALGOL 60 and dialects thereof.
The International Algebraic Language (IAL), renamed ALGOL 58, was highly influential and generally considered the ancestor of most of the modern programming languages (the so-called Algol-like languages). Further, "ALGOL object code" was a simple, compact, and stack-based instruction set architecture commonly used in teaching compiler construction and other high order languages; of which Algol is generally considered the first.
ALGOL was developed jointly by a committee of European and American computer scientists in a meeting in 1958 at the Swiss Federal Institute of Technology in Zurich (ETH Zurich; cf. ALGOL 58). It specified three different syntaxes: a reference syntax, a publication syntax, and an implementation syntax. The different syntaxes permitted it to use different keyword names and conventions for decimal points (commas vs periods) for different languages.
ALGOL was used mostly by research computer scientists in the United States and in Europe. Its use in commercial applications was hindered by the absence of standard input/output facilities in its description and the lack of interest in the language by large computer vendors other than Burroughs Corporation. ALGOL 60 did however become the standard for the publication of algorithms and had a profound effect on future language development.
John Backus developed the "Backus normal form" method of describing programming languages specifically for ALGOL 58. It was revised and expanded by Peter Naur for ALGOL 60, and at Donald Knuth's suggestion renamed Backus–Naur form.
Peter Naur: "As editor of the ALGOL Bulletin I was drawn into the international discussions of the language and was selected to be member of the European language design group in November 1959. In this capacity I was the editor of the ALGOL 60 report, produced as the result of the ALGOL 60 meeting in Paris in January 1960."
The following people attended the meeting in Paris (from 1 to 16 January):
Alan Perlis gave a vivid description of the meeting: "The meetings were exhausting, interminable, and exhilarating. One became aggravated when one's good ideas were discarded along with the bad ones of others. Nevertheless, diligence persisted during the entire period. The chemistry of the 13 was excellent."
ALGOL 60 inspired many languages that followed it. Tony Hoare remarked: "Here is a language so far ahead of its time that it was not only an improvement on its predecessors but also on nearly all its successors." The Scheme programming language, a variant of Lisp that adopted the block structure and lexical scope of ALGOL, also adopted the wording "Revised Report on the Algorithmic Language Scheme" for its standards documents in homage to ALGOL.
As Peter Landin noted, the language Algol was the first language to combine seamlessly imperative effects with the (call-by-name) lambda calculus. Perhaps the most elegant formulation of the language is due to John C. Reynolds, and it best exhibits its syntactic and semantic purity. Reynolds's idealized Algol also made a convincing methodological argument regarding the suitability of local effects in the context of call-by-name languages, to be contrasted with the global effects used by call-by-value languages such as ML. The conceptual integrity of the language made it one of the main objects of semantic research, along with Programming Computable Functions (PCF) and ML.
To date there have been at least 70 augmentations, extensions, derivations and sublanguages of Algol 60.
The Burroughs dialects included special Bootstrapping dialects such as ESPOL and NEWP. The latter is still used for Unisys MCP system software.
ALGOL 60 as officially defined had no I/O facilities; implementations defined their own in ways that were rarely compatible with each other. In contrast, ALGOL 68 offered an extensive library of "transput" (input/output) facilities.
ALGOL 60 allowed for two evaluation strategies for parameter passing: the common call-by-value, and call-by-name. Call-by-name has certain effects in contrast to call-by-reference. For example, without specifying the parameters as "value" or "reference", it is impossible to develop a procedure that will swap the values of two parameters if the actual parameters that are passed in are an integer variable and an array that is indexed by that same integer variable. Think of passing a pointer to swap(i, A[i]) in to a function. Now that every time swap is referenced, it is reevaluated. Say i := 1 and A[i] := 2, so every time swap is referenced it will return the other combination of the values ([1,2], [2,1], [1,2] and so on). A similar situation occurs with a random function passed as actual argument.
Call-by-name is known by many compiler designers for the interesting "thunks" that are used to implement it. Donald Knuth devised the "man or boy test" to separate compilers that correctly implemented "recursion and non-local references." This test contains an example of call-by-name.
ALGOL 68 was defined using a two-level grammar formalism invented by Adriaan van Wijngaarden and which bears his name. Van Wijngaarden grammars use a context-free grammar to generate an infinite set of productions that will recognize a particular ALGOL 68 program; notably, they are able to express the kind of requirements that in many other programming language standards are labelled "semantics" and have to be expressed in ambiguity-prone natural language prose, and then implemented in compilers as "ad hoc" code attached to the formal language parser.
 procedure Absmax(a) Size:(n, m) Result:(y) Subscripts:(i, k);
Here is an example of how to produce a table using Elliott 803 ALGOL.
PUNCH(3) sends output to the teleprinter rather than the tape punch.<br>
SAMELINE suppresses the carriage return + line feed normally printed between arguments.<br>
ALIGNED(1,6) controls the format of the output with 1 digit before and 6 after the decimal point.
The following code samples are ALGOL 68 versions of the above ALGOL 60 code samples.
ALGOL 68 implementations used ALGOL 60's approaches to stropping. In ALGOL 68's case tokens with the bold typeface are reserved words, types (modes) or operators.
Note: lower (⌊) and upper (⌈) bounds of an array, and array slicing, are directly available to the programmer.
The variations and lack of portability of the programs from one implementation to another is easily demonstrated by the classic hello world program.
ALGOL 58 had no I/O facilities.
Since ALGOL 60 had no I/O facilities, there is no portable hello world program in ALGOL.
The next three examples are in Burroughs Extended Algol. The first two direct output at the interactive terminal they are run on. The first uses a character array, similar to C. The language allows the array identifier to be used as a pointer to the array, and hence in a REPLACE statement.
A simpler program using an inline format:
An even simpler program using the Display statement. Note that its output would end up at the system console ('SPO'):
An alternative example, using Elliott Algol I/O is as follows. Elliott Algol used different characters for "open-string-quote" and "close-string-quote":
Here is a version for the Elliott 803 Algol (A104) The standard Elliott 803 used 5 hole paper tape and thus only had upper case. The code lacked any quote characters so £ (UK Pound Sign) was used for open quote and ? (Question Mark) for close quote. Special sequences were placed in double quotes (e.g. ££L?? produced a new line on the teleprinter).
The ICT 1900 series Algol I/O version allowed input from paper tape or punched card. Paper tape 'full' mode allowed lower case. Output was to a line printer. The open and close quote characters were represented using '(' and ')' and spaces by %.
ALGOL 68 code was published with reserved words typically in lowercase, but bolded or underlined.
In the language of the "Algol 68 Report" the input/output facilities were collectively called the "Transput".
The ALGOLs were conceived at a time when character sets were diverse and evolving rapidly; also, the ALGOLs were defined so that only "uppercase" letters were required.
1960: IFIP – The Algol 60 language and report included several mathematical symbols which are available on modern computers and operating systems, but, unfortunately, were unsupported on most computing systems at the time. For instance: ×, ÷, ≤, ≥, ≠, ¬, ∨, ∧, ⊂, ≡, ␣ and ⏨.
1961 September: ASCII – The ASCII character set, then in an early stage of development, had the \ (Back slash) character added to it in order to support ALGOL's boolean operators /\ and \/.
1962: ALCOR – This character set included the unusual "᛭" runic cross character for multiplication and the "⏨" Decimal Exponent Symbol for floating point notation.
1964: GOST – The 1964 Soviet standard GOST 10859 allowed the encoding of 4-bit, 5-bit, 6-bit and 7-bit characters in ALGOL.
1968: The "Algol 68 Report" – used extant ALGOL characters, and further adopted →, ↓, ↑, □, ⌊, ⌈, ⎩, ⎧, ○, ⊥, and ¢ characters which can be found on the IBM 2741 keyboard with "typeball" (or "golf ball") print heads inserted (such as the APL golf ball). These became available in the mid-1960s while ALGOL 68 was being drafted. The report was translated into Russian, German, French, and Bulgarian, and allowed programming in languages with larger character sets, e.g., Cyrillic alphabet of the Soviet BESM-4. All ALGOL's characters are also part of the Unicode standard and most of them are available in several popular fonts.
2009 October: Unicode – The codice_3 (Decimal Exponent Symbol) for floating point notation was added to Unicode 5.2 for backward compatibility with historic Buran programme ALGOL software.

</doc>
<doc id="1456" url="https://en.wikipedia.org/wiki?curid=1456" title="AWK">
AWK

AWK ("awk") is a domain-specific language designed for text processing and typically used as a data extraction and reporting tool. Like sed and grep, it's a filter, and is a standard feature of most Unix-like operating systems.
The AWK language is a data-driven scripting language consisting of a set of actions to be taken against streams of textual data – either run directly on files or used as part of a pipeline – for purposes of extracting or transforming text, such as producing formatted reports. The language extensively uses the string datatype, associative arrays (that is, arrays indexed by key strings), and regular expressions. While AWK has a limited intended application domain and was especially designed to support one-liner programs, the language is Turing-complete, and even the early Bell Labs users of AWK often wrote well-structured large AWK programs.
AWK was created at Bell Labs in the 1970s, and its name is derived from the surnames of its authors: Alfred Aho, Peter Weinberger, and Brian Kernighan. The acronym is pronounced the same as the bird auk, which is on the cover of "The AWK Programming Language". When written in all lowercase letters, as codice_1, it refers to the Unix or Plan 9 program that runs scripts written in the AWK programming language.
AWK was initially developed in 1977 by Alfred Aho (author of egrep), Peter J. Weinberger (who worked on tiny relational databases), and Brian Kernighan; it takes its name from their respective initials. According to Kernighan, one of the goals of AWK was to have a tool that would easily manipulate both numbers and strings.
AWK was also inspired by Marc Rochkind's programming language that was used to search for patterns in input data, and was implemented using yacc.
As one of the early tools to appear in Version 7 Unix, AWK added computational features to a Unix pipeline besides the Bourne shell, the only scripting language available in a standard Unix environment. It is one of the mandatory utilities of the Single UNIX Specification, and is required by the Linux Standard Base specification.
AWK was significantly revised and expanded in 1985–88, resulting in the GNU AWK implementation written by Paul Rubin, Jay Fenlason, and Richard Stallman, released in 1988. GNU AWK may be the most widely deployed version because it is included with GNU-based Linux packages. GNU AWK has been maintained solely by Arnold Robbins since 1994. Brian Kernighan's nawk (New AWK) source was first released in 1993 unpublicized, and publicly since the late 1990s; many BSD systems use it to avoid the GPL license.
AWK was preceded by sed (1974). Both were designed for text processing. They share the line-oriented, data-driven paradigm, and are particularly suited to writing one-liner programs, due to the implicit main loop and current line variables. The power and terseness of early AWK programs – notably the powerful regular expression handling and conciseness due to implicit variables, which facilitate one-liners – together with the limitations of AWK at the time, were important inspirations for the Perl language (1987). In the 1990s, Perl became very popular, competing with AWK in the niche of Unix text-processing languages.
An AWK program is a series of pattern action pairs, written as:
where "condition" is typically an expression and "action" is a series of commands. The input is split into records, where by default records are separated by newline characters so that the input is split into lines. The program tests each record against each of the conditions in turn, and executes the "action" for each expression that is true. Either the condition or the action may be omitted. The condition defaults to matching every record. The default action is to print the record. This is the same pattern-action structure as sed.
In addition to a simple AWK expression, such as codice_2 or codice_3, the condition can be codice_4 or codice_5 causing the action to be executed before or after all records have been read, or "pattern1, pattern2" which matches the range of records starting with a record that matches "pattern1" up to and including the record that matches "pattern2" before again trying to match against "pattern1" on future lines.
In addition to normal arithmetic and logical operators, AWK expressions include the tilde operator, codice_6, which matches a regular expression against a string. As handy syntactic sugar, "/regexp/" without using the tilde operator matches against the current record; this syntax derives from sed, which in turn inherited it from the ed editor, where codice_7 is used for searching. This syntax of using slashes as delimiters for regular expressions was subsequently adopted by Perl and ECMAScript, and is now common. The tilde operator was also adopted by Perl.
AWK commands are the statements that are substituted for "action" in the examples above. AWK commands can include function calls, variable assignments, calculations, or any combination thereof. AWK contains built-in support for many functions; many more are provided by the various flavors of AWK. Also, some flavors support the inclusion of dynamically linked libraries, which can also provide more functions.
The "print" command is used to output text. The output text is always terminated with a predefined string called the output record separator (ORS) whose default value is a newline. The simplest form of this command is:
Although these fields ("$X") may bear resemblance to variables (the $ symbol indicates variables in Perl), they actually refer to the fields of the current record. A special case, "$0", refers to the entire record. In fact, the commands "codice_8" and "codice_12" are identical in functionality.
The "print" command can also display the results of calculations and/or function calls:
/regex_pattern/ {
Output may be sent to a file:
/regex_pattern/ {
or through a pipe:
/regex_pattern/ {
Awk's built-in variables include the field variables: $1, $2, $3, and so on ($0 represents the entire record). They hold the text or values in the individual text-fields in a record.
Other variables include:
Variable names can use any of the characters [A-Za-z0-9_], with the exception of language keywords. The operators "+ - * /" represent addition, subtraction, multiplication, and division, respectively. For string concatenation, simply place two variables (or string constants) next to each other. It is optional to use a space in between if string constants are involved, but two variable names placed adjacent to each other require a space in between. Double quotes delimit string constants. Statements need not end with semicolons. Finally, comments can be added to programs by using "#" as the first character on a line.
In a format similar to C, function definitions consist of the keyword codice_22, the function name, argument names and the function body. Here is an example of a function.
function add_three (number) {
This statement can be invoked as follows:
Functions can have variables that are in the local scope. The names of these are added to the end of the argument list, though values for these should be omitted when calling the function. It is convention to add some whitespace in the argument list before the local variables, to indicate where the parameters end and the local variables begin.
Here is the customary "Hello, world" program written in AWK:
Note that an explicit codice_23 statement is not needed here; since the only pattern is codice_4, no command-line arguments are processed.
Print all lines longer than 80 characters. Note that the default action is to print the current line.
length($0) > 80
Count words in the input and print the number of lines, words, and characters (like wc):
As there is no pattern for the first line of the program, every line of input matches by default, so the increment actions are executed for every line. Note that codice_25 is shorthand for codice_26.
"s" is incremented by the numeric value of "$NF", which is the last word on the line as defined by AWK's field separator (by default, white-space). "NF" is the number of fields in the current line, e.g. 4. Since "$4" is the value of the fourth field, "$NF" is the value of the last field in the line regardless of how many fields this line has, or whether it has more or fewer fields than surrounding lines. $ is actually a unary operator with the highest operator precedence. (If the line has no fields, then "NF" is 0, "$0" is the whole line, which in this case is empty apart from possible white-space, and so has the numeric value 0.)
At the end of the input the "END" pattern matches, so "s" is printed. However, since there may have been no lines of input at all, in which case no value has ever been assigned to "s", it will by default be an empty string. Adding zero to a variable is an AWK idiom for coercing it from a string to a numeric value. (Concatenating an empty string is to coerce from a number to a string, e.g. "s """. Note, there's no operator to concatenate strings, they're just placed adjacently.) With the coercion the program prints "0" on an empty input, without it an empty line is printed.
The action statement prints each line numbered. The printf function emulates the standard C printf and works similarly to the print command described above. The pattern to match, however, works as follows: "NR" is the number of records, typically lines of input, AWK has so far read, i.e. the current line number, starting at 1 for the first line of input. "%" is the modulo operator. "NR % 4 == 1" is true for the 1st, 5th, 9th, etc., lines of input. Likewise, "NR % 4 == 3" is true for the 3rd, 7th, 11th, etc., lines of input. The range pattern is false until the first part matches, on line 1, and then remains true up to and including when the second part matches, on line 3. It then stays false until the first part matches again on line 5.
Thus, the program prints lines 1,2,3, skips line 4, and then 5,6,7, and so on. For each line, it prints the line number (on a 6 character-wide field) and then the line contents. For example, when executed on this input:
The previous program prints:
As a special case, when the first part of a range pattern is constantly true, e.g. "1", the range will start at the beginning of the input. Similarly, if the second part is constantly false, e.g. "0", the range will continue until the end of input. For example,
prints lines of input from the first line matching the regular expression "^--cut here--$", that is, a line containing only the phrase "--cut here--", to the end.
Word frequency using associative arrays:
BEGIN {
END {
The BEGIN block sets the field separator to any sequence of non-alphabetic characters. Note that separators can be regular expressions. After that, we get to a bare action, which performs the action on every input line. In this case, for every field on the line, we add one to the number of times that word, first converted to lowercase, appears. Finally, in the END block, we print the words with their frequencies. The line
creates a loop that goes through the array "words", setting "i" to each "subscript" of the array. This is different from most languages, where such a loop goes through each "value" in the array. The loop thus prints out each word followed by its frequency count. codice_27 was an addition to the One True awk (see below) made after the book was published.
This program can be represented in several ways. The first one uses the Bourne shell to make a shell script that does everything. It is the shortest of these methods:
pattern="$1"
shift
awk '/'"$pattern"'/ { print FILENAME ":" $0 }' "$@"
The codice_28 in the awk command is not protected by single quotes so that the shell does expand the variable but it needs to be put in double quotes to properly handle patterns containing spaces. A pattern by itself in the usual way checks to see if the whole line (codice_29) matches. codice_16 contains the current filename. awk has no explicit concatenation operator; two adjacent strings concatenate them. codice_29 expands to the original unchanged input line.
There are alternate ways of writing this. This shell script accesses the environment directly from within awk:
export pattern="$1"
shift
awk '$0 ~ ENVIRON["pattern"] { print FILENAME ":" $0 }' "$@"
This is a shell script that uses codice_32, an array introduced in a newer version of the One True awk after the book was published. The subscript of codice_32 is the name of an environment variable; its result is the variable's value. This is like the getenv function in various standard libraries and POSIX. The shell script makes an environment variable codice_34 containing the first argument, then drops that argument and has awk look for the pattern in each file.
codice_6 checks to see if its left operand matches its right operand; codice_36 is its inverse. Note that a regular expression is just a string and can be stored in variables.
The next way uses command-line variable assignment, in which an argument to awk can be seen as an assignment to a variable:
pattern="$1"
shift
awk '$0 ~ pattern { print FILENAME ":" $0 }' "pattern=$pattern" "$@"
Or You can use the "-v var=value" command line option (e.g. "awk -v pattern="$pattern" ...").
Finally, this is written in pure awk, without help from a shell or without the need to know too much about the implementation of the awk script (as the variable assignment on command line one does), but is a bit lengthy:
BEGIN {
The codice_4 is necessary not only to extract the first argument, but also to prevent it from being interpreted as a filename after the codice_4 block ends. codice_39, the number of arguments, is always guaranteed to be ≥1, as codice_40 is the name of the command that executed the script, most often the string codice_41. Also note that codice_42 is the empty string, codice_43. codice_44 initiates a comment that expands to the end of the line.
Note the codice_45 block. awk only checks to see if it should read from standard input before it runs the command. This means that
only works because the fact that there are no filenames is only checked before codice_46 is run! If you explicitly set codice_39 to 1 so that there are no arguments, awk will simply quit because it feels there are no more input files. Therefore, you need to explicitly say to read from standard input with the special filename codice_48.
On Unix-like operating systems self-contained AWK scripts can be constructed using the shebang syntax.
For example, a script that prints the content of a given file may be built by creating a file named codice_49 with the following content:
{ print $0 }
It can be invoked with: codice_50
The codice_51 tells AWK that the argument that follows is the file to read the AWK program from, which is the same flag that is used in sed. Since they are often used for one-liners, both these programs default to executing a program given as a command-line argument, rather than a separate file.
AWK was originally written in 1977 and distributed with Version 7 Unix.
In 1985 its authors started expanding the language, most significantly by adding user-defined functions. The language is described in the book "The AWK Programming Language", published 1988, and its implementation was made available in releases of UNIX System V. To avoid confusion with the incompatible older version, this version was sometimes called "new awk" or "nawk". This implementation was released under a free software license in 1996 and is still maintained by Brian Kernighan (see external links below).
Old versions of Unix, such as UNIX/32V, included codice_52, which converted AWK to C. Kernighan wrote a program to turn awk into C++; its state is not known.

</doc>
<doc id="1460" url="https://en.wikipedia.org/wiki?curid=1460" title="Asgard">
Asgard

Asgard (Old Norse: Ásgarðr; “Enclosure of the Aesir”) is a location associated with gods. It is depicted in a multitude of Old Norse sagas and mythological texts. Some researchers have suggested Asgard to be one of the Nine Worlds surrounding the tree Yggdrasil. In Norse Mythology, Asgard is a fortified home to the Aesir tribe of gods located in the sky. Asgard consists of smaller realms that do not have as many depictions in mythological poems and prose. Asgard is set to be fully destroyed during Ragnarök, and later restored after the world's renewal.
The word Asgard consists of the Old Norse words ("god") and ("enclosure"). The latter is crucial to understanding the cultural and religious underpinnings of Norse mythology. It originates from the Germanic terms ("inside the fence") and ("beyond the fence"). represents the ordered state of existence, while embodies chaos and disorder. The walls surrounding Asgard signify its orderly nature and Aesir gods' organised way of living.
Historians refer to three principal sources that depict Asgard. They include the Poetic Edda, the Prose Edda, and Heimskringla, which consists of several sagas.
The Poetic Edda consists of several Old Norse poems of unknown authorship that date back to the 13th century. The majority of these poems come from the medieval text Codex Regius, also known as Konungsbók.
Völuspá, the first poem in the Poetic Edda, provides some of the most complete and accurate depictions of the 12 lesser realms of Asgard, which include Breidablik, Valhalla, and Thrudheim. It also describes the Yggdrasil, a mythical tree that connects all Nine Worlds with Asgard located beneath one of its three roots. Finally, Völuspá provides a vague description of the location of Iðavöllr, one of the most common meeting places of Aesir gods.
Grímnismál is one of the shorter poems in the Poetic Edda. It contains a brief depiction of Bifröst, one of the 12 realms of Asgard that connects it to Midgard.
The Prose Edda, also referred to as the Younger Edda, is often attributed to the 13 th century historian Snorri Sturluson. As one of the most detailed descriptions of Norse mythology, the Prose Edda provides a thorough history of Asgard and its inhabitants. It consists of four parts: Prologue, Gylfaginning, Skáldskaparmál, and Háttatal.
In Prologue, Snorri Sturluson shares his interpretation of the Skaldic poems and legends. His analysis corresponds to modern historians’ belief that Aesir gods were, in fact, real clans that travelled from the East to northern territories. According to Snorri, Asgard represented the town of Troy before Greek warriors overtook it. After the defeat, Trojans moved to northern Europe, where they became a dominant group due to their “"advanced technologies and culture"”. Eventually, other tribes began to perceive the Trojans and their leader Trór (Thor in Old Norse) as gods.
Gylfaginning, the second part of the Prose Edda, contains mythological depictions of world creation, in chronological order. In this section, Snorri establishes the fundamentals of Norse mythology, such as the creation and fortification of Asgard, and introduces the main Aesir gods such as Thor, Odin, and Baldur. Gylfaginning also describes Ragnarök, an event that would bring destruction to the Nine Worlds and cause their subsequent rebirth.
In Skáldskaparmál, Snorri shifts focus to language and the nature of poetry. In the dialogue between the Norse god, Aegir, and the Skaldic god, Bragi, it illustrates how various aspects of poetry and nature are intertwined. This part of the Prose Edda highlights the war between Aesir and Vanir gods, including the fortification of Asgard.
Heimskringla is a collection of sagas written by Snorri Sturluson that contains accounts on the Swedish and Norwegian king dynasties. The name of the saga comes from kringla heimsins (“the circle of the world”).
The first saga in the manuscript further develops Snorri’s historical interpretation of Old Norse mythos. In the Ynglinga Saga, he rejects his earlier notion of Troy as the historical location of Asgard. Snorri then provides an overview of Norse kings and their dynasties based on earlier sagas and poems. In his texts, he provides short depictions of Aesir gods, often searching for parallels between them and Norse kings.
While many sources mention Asgard as consisting of numerous distinct realms, only a handful of sagas provide their descriptions.
Ruled by Odin, Valhalla is fortified with a golden hall where the souls of mighty warriors arrive after their deaths in battle. It also serves as a home to Valkyries who oversee the souls of the dead and guide them to Valhalla. As attested in the Poetic Edda, Odin amasses an army, einherjar, for Ragnarök, where his warriors are expected to join him in battle. They train daily against each other to hone their combat skills. However, only half of those who have fallen in combat reach Valhalla. The others arrive at another realm, Fólkvangr, where the goddess Freyja resides.
Bifröst differs from other realms, as it connects Asgard, the world of gods, with Midgard, the world of people. In the Prose Edda, Snorri describes it as a rainbow bridge that starts in Himinbjörg. The Poetic Edda ultimately predicts its destruction in Ragnarök during the attack of the Muspelheim forces.
Fólkvangr is a rarely depicted realm of Asgard. Besides accepting half of those slain in battles, Fólkvangr’s principal inhabitants include Freyja and her two daughters, Gersemi and Hnoss. They reside in the main hall, Sessrúmnir, which is decorated with natural ornaments. Sagas in the Poetic Edda mention Fólkvangr’s rich flora and fauna, which correlates with Freyja’s love for nature and wild creatures.
Located on the border of Asgard, Himinbjörg is home to the god Heimdallr, who watches over Midgard and humanity. The Poetic Edda depicts Heimdallr as “drinking fine mead” in Himinbjörg while protecting the rainbow bridge, Bifröst. When enemies from Muspelheim destroy Bifröst, Heimdallr will blow in his horn Gjallarhorn to announce the beginning of Ragnarök.
According to Grímnismál, Bilskírnir is the largest building and one of the most significant realms of Asgard. It contains 540 rooms and serves as a residence of Thor, his wife Sif, and their many children. In the Prose Edda, Snorri predicts the partial destruction of Bilskirnir during the battle between Thor and the World Serpent Jörmungandr when Ragnarok comes.
Upon arrival in Asgard, Aesir gods make it their home, as attested by Snorri in the Prose Edda. After counselling with the head of Mimir, Odin assigns other gods to rule separate parts of the land and build palaces. However, their territories remain open to attacks from enemies, forcing Aesir to protect their lands.
One day, an unnamed giant, claiming to be a skillful smith, arrives at Asgard on his stallion, Svadilfari. He offers help in erecting a protective wall around Asgard in a mere three winters. In return for this favour, he asks for the sun, moon, and marriage with Freyja. Despite Freyja’s opposition, the gods agree to fulfill his request if he builds a wall in just one winter. As part of the deal, they guarantee the giant’s safety.
As time goes on, the gods grow desperate, as it becomes apparent that the giant will construct the wall on time. To their surprise, his stallion contributes much of the progress, swiftly moving boulders and rocks. To preserve Freyja and keep the sun and moon, one of the gods, Loki, comes up with a plan. He changes his appearance to that of a mare, and distracts Svadilfari to slow down construction. Without the help of his stallion, the giant cannot complete his task in time, and Thor breaks his skull with a hammer. Several months later, Loki gives birth to an eight-legged stallion, Sleipnir, who later becomes Odin’s steed. Aesir gods later finish the wall and fully fortify Asgard for future battles.
Ragnarök consists of a series of foretold events that ultimately lead to the destruction and subsequent renewal of the world.
Ragnarök begins after the invasion of fire giants from Muspelheim, who destroy the Bifröst. This causes Heimdallr to blow the Gjallarhorn, announcing the upcoming doom of gods. Odin swiftly consults with the head of Mimir, who foretells the destruction of Asgard and Odin’s death.
Aesir gods decide to march into battle, gathering their forces on the battlefield Vigrid (“Plain Where Battle Surges”). Their enemies, led by the fire giant Surt, march through Asgard, destroying many of the palaces and fortifications. Odin, Thor, Loki, Heimdallr, and other gods, die in the battle. As the Vigrid grounds become soaking wet with blood, the world is submerged underwater, ending everything that ever existed.
As attested in the Völuspá, after the destruction of the old world, a new one emerges. Several gods survive and restore Asgard, bringing it to the highest-ever levels of prosperity.
Thor first appeared in the Marvel Universe within comic series Journey into Mystery in the issues #83 during August 1962. Following this release, he becomes one of the central figures in the comics along with Loki and Odin. In the Marvel movie franchise, Thor and Loki make their first appearance together in the 2011 film Thor. After that, Thor becomes a regular character in the Marvel Cinematic Universe and reappears in several films, including the Avengers series. Asgard becomes the central element of the film , where it is destroyed following the Old Norse mythos. These and other Norse mythology elements also appear in video games, tv series, and books based on the Marvel Universe. 
These depictions do not follow the Old Norse sagas and poems carefully. However, many philologists began to notice an increased interest in Norse mythology from the general public due to their popularity.

</doc>
<doc id="1461" url="https://en.wikipedia.org/wiki?curid=1461" title="Apollo program">
Apollo program

The Apollo program, also known as Project Apollo, was the third United States human spaceflight program carried out by the National Aeronautics and Space Administration (NASA), which succeeded in landing the first humans on the Moon from 1969 to 1972. It was first conceived during Dwight D. Eisenhower's administration as a three-person spacecraft to follow the one-person Project Mercury, which put the first Americans in space. Apollo was later dedicated to President John F. Kennedy's national goal for the 1960s of "landing a man on the Moon and returning him safely to the Earth" in an address to Congress on May 25, 1961. It was the third US human spaceflight program to fly, preceded by the two-person Project Gemini conceived in 1961 to extend spaceflight capability in support of Apollo.
Kennedy's goal was accomplished on the Apollo 11 mission when astronauts Neil Armstrong and Buzz Aldrin landed their Apollo Lunar Module (LM) on July 20, 1969, and walked on the lunar surface, while Michael Collins remained in lunar orbit in the command and service module (CSM), and all three landed safely on Earth on July 24. Five subsequent Apollo missions also landed astronauts on the Moon, the last, Apollo 17, in December 1972. In these six spaceflights, twelve people walked on the Moon.
Apollo ran from 1961 to 1972, with the first crewed flight in 1968. It encountered a major setback in 1967 when an Apollo 1 cabin fire killed the entire crew during a prelaunch test. After the first successful landing, sufficient flight hardware remained for nine follow-on landings with a plan for extended lunar geological and astrophysical exploration. Budget cuts forced the cancellation of three of these. Five of the remaining six missions achieved successful landings, but the Apollo 13 landing was prevented by an oxygen tank explosion in transit to the Moon, which destroyed the service module's capability to provide electrical power, crippling the CSM's propulsion and life support systems. The crew returned to Earth safely by using the lunar module as a "lifeboat" for these functions. Apollo used Saturn family rockets as launch vehicles, which were also used for an Apollo Applications Program, which consisted of Skylab, a space station that supported three crewed missions in 1973–74, and Apollo–Soyuz, a joint US-Soviet Union Earth-orbit mission in 1975.
Apollo set several major human spaceflight milestones. It stands alone in sending crewed missions beyond low Earth orbit. Apollo 8 was the first crewed spacecraft to orbit another celestial body, and Apollo 11 was the first crewed spacecraft to land humans on one.
Overall the Apollo program returned of lunar rocks and soil to Earth, greatly contributing to the understanding of the Moon's composition and geological history. The program laid the foundation for NASA's subsequent human spaceflight capability, and funded construction of its Johnson Space Center and Kennedy Space Center. Apollo also spurred advances in many areas of technology incidental to rocketry and human spaceflight, including avionics, telecommunications, and computers.
The Apollo program was conceived during the Eisenhower administration in early 1960, as a follow-up to Project Mercury. While the Mercury capsule could support only one astronaut on a limited Earth orbital mission, Apollo would carry three. Possible missions included ferrying crews to a space station, circumlunar flights, and eventual crewed lunar landings.
The program was named after Apollo, the Greek god of light, music, and the Sun, by NASA manager Abe Silverstein, who later said, "I was naming the spacecraft like I'd name my baby." Silverstein chose the name at home one evening, early in 1960, because he felt "Apollo riding his chariot across the Sun was appropriate to the grand scale of the proposed program."
In July 1960, NASA Deputy Administrator Hugh L. Dryden announced the Apollo program to industry representatives at a series of Space Task Group conferences. Preliminary specifications were laid out for a spacecraft with a "mission module" cabin separate from the "command module" (piloting and reentry cabin), and a "propulsion and equipment module". On August 30, a feasibility study competition was announced, and on October 25, three study contracts were awarded to General Dynamics/Convair, General Electric, and the Glenn L. Martin Company. Meanwhile, NASA performed its own in-house spacecraft design studies led by Maxime Faget, to serve as a gauge to judge and monitor the three industry designs.
In November 1960, John F. Kennedy was elected president after a campaign that promised American superiority over the Soviet Union in the fields of space exploration and missile defense. Up to the election of 1960, Kennedy had been speaking out against the "missile gap" that he and many other senators felt had developed between the Soviet Union and the United States due to the inaction of President Eisenhower. Beyond military power, Kennedy used aerospace technology as a symbol of national prestige, pledging to make the US not "first but, first and, first if, but first period". Despite Kennedy's rhetoric, he did not immediately come to a decision on the status of the Apollo program once he became president. He knew little about the technical details of the space program, and was put off by the massive financial commitment required by a crewed Moon landing. When Kennedy's newly appointed NASA Administrator James E. Webb requested a 30 percent budget increase for his agency, Kennedy supported an acceleration of NASA's large booster program but deferred a decision on the broader issue.
On April 12, 1961, Soviet cosmonaut Yuri Gagarin became the first person to fly in space, reinforcing American fears about being left behind in a technological competition with the Soviet Union. At a meeting of the US House Committee on Science and Astronautics one day after Gagarin's flight, many congressmen pledged their support for a crash program aimed at ensuring that America would catch up. Kennedy was circumspect in his response to the news, refusing to make a commitment on America's response to the Soviets.
On April 20, Kennedy sent a memo to Vice President Lyndon B. Johnson, asking Johnson to look into the status of America's space program, and into programs that could offer NASA the opportunity to catch up. Johnson responded approximately one week later, concluding that "we are neither making maximum effort nor achieving results necessary if this country is to reach a position of leadership." His memo concluded that a crewed Moon landing was far enough in the future that it was likely the United States would achieve it first.
On May 25, 1961, twenty days after the first US crewed spaceflight "Freedom 7", Kennedy proposed the crewed Moon landing in a "Special Message to the Congress on Urgent National Needs":
At the time of Kennedy's proposal, only one American had flown in space—less than a month earlier—and NASA had not yet sent an astronaut into orbit. Even some NASA employees doubted whether Kennedy's ambitious goal could be met. By 1963, Kennedy even came close to agreeing to a joint US-USSR Moon mission, to eliminate duplication of effort.
With the clear goal of a crewed landing replacing the more nebulous goals of space stations and circumlunar flights, NASA decided that, in order to make progress quickly, it would discard the feasibility study designs of Convair, GE, and Martin, and proceed with Faget's command and service module design. The mission module was determined to be useful only as an extra room, and therefore unnecessary. They used Faget's design as the specification for another competition for spacecraft procurement bids in October 1961. On November 28, 1961, it was announced that North American Aviation had won the contract, although its bid was not rated as good as Martin's. Webb, Dryden and Robert Seamans chose it in preference due to North American's longer association with NASA and its predecessor.
Landing humans on the Moon by the end of 1969 required the most sudden burst of technological creativity, and the largest commitment of resources ($25 billion; $ in dollars) ever made by any nation in peacetime. At its peak, the Apollo program employed 400,000 people and required the support of over 20,000 industrial firms and universities.
On July 1, 1960, NASA established the Marshall Space Flight Center (MSFC) in Huntsville, Alabama. MSFC designed the heavy lift-class Saturn launch vehicles, which would be required for Apollo.
It became clear that managing the Apollo program would exceed the capabilities of Robert R. Gilruth's Space Task Group, which had been directing the nation's crewed space program from NASA's Langley Research Center. So Gilruth was given authority to grow his organization into a new NASA center, the Manned Spacecraft Center (MSC). A site was chosen in Houston, Texas, on land donated by Rice University, and Administrator Webb announced the conversion on September 19, 1961. It was also clear NASA would soon outgrow its practice of controlling missions from its Cape Canaveral Air Force Station launch facilities in Florida, so a new Mission Control Center would be included in the MSC.
In September 1962, by which time two Project Mercury astronauts had orbited the Earth, Gilruth had moved his organization to rented space in Houston, and construction of the MSC facility was under way, Kennedy visited Rice to reiterate his challenge in a famous speech:
The MSC was completed in September 1963. It was renamed by the US Congress in honor of Lyndon Johnson soon after his death in 1973.
It also became clear that Apollo would outgrow the Canaveral launch facilities in Florida. The two newest launch complexes were already being built for the Saturn I and IB rockets at the northernmost end: LC-34 and LC-37. But an even bigger facility would be needed for the mammoth rocket required for the crewed lunar mission, so land acquisition was started in July 1961 for a Launch Operations Center (LOC) immediately north of Canaveral at Merritt Island. The design, development and construction of the center was conducted by Kurt H. Debus, a member of Dr. Wernher von Braun's original V-2 rocket engineering team. Debus was named the LOC's first Director. Construction began in November 1962. Upon Kennedy's death, President Johnson issued an executive order on November 29, 1963, to rename the LOC and Cape Canaveral in honor of Kennedy.
The LOC included Launch Complex 39, a Launch Control Center, and a Vertical Assembly Building (VAB) in which the space vehicle (launch vehicle and spacecraft) would be assembled on a mobile launcher platform and then moved by a crawler-transporter to one of several launch pads. Although at least three pads were planned, only two, designated AandB, were completed in October 1965. The LOC also included an Operations and Checkout Building (OCB) to which Gemini and Apollo spacecraft were initially received prior to being mated to their launch vehicles. The Apollo spacecraft could be tested in two vacuum chambers capable of simulating atmospheric pressure at altitudes up to , which is nearly a vacuum.
Administrator Webb realized that in order to keep Apollo costs under control, he had to develop greater project management skills in his organization, so he recruited Dr. George E. Mueller for a high management job. Mueller accepted, on the condition that he have a say in NASA reorganization necessary to effectively administer Apollo. Webb then worked with Associate Administrator (later Deputy Administrator) Seamans to reorganize the Office of Manned Space Flight (OMSF). On July 23, 1963, Webb announced Mueller's appointment as Deputy Associate Administrator for Manned Space Flight, to replace then Associate Administrator D. Brainerd Holmes on his retirement effective September 1. Under Webb's reorganization, the directors of the Manned Spacecraft Center (Gilruth), Marshall Space Flight Center (von Braun), and the Launch Operations Center (Debus) reported to Mueller.
Based on his industry experience on Air Force missile projects, Mueller realized some skilled managers could be found among high-ranking officers in the United States Air Force, so he got Webb's permission to recruit General Samuel C. Phillips, who gained a reputation for his effective management of the Minuteman program, as OMSF program controller. Phillips' superior officer Bernard A. Schriever agreed to loan Phillips to NASA, along with a staff of officers under him, on the condition that Phillips be made Apollo Program Director. Mueller agreed, and Phillips managed Apollo from January 1964, until it achieved the first human landing in July 1969, after which he returned to Air Force duty.
Once Kennedy had defined a goal, the Apollo mission planners were faced with the challenge of designing a spacecraft that could meet it while minimizing risk to human life, cost, and demands on technology and astronaut skill. Four possible mission modes were considered:
In early 1961, direct ascent was generally the mission mode in favor at NASA. Many engineers feared that rendezvous and docking, maneuvers which had not been attempted in Earth orbit, would be nearly impossible in lunar orbit. LOR advocates including John Houbolt at Langley Research Center emphasized the important weight reductions that were offered by the LOR approach. Throughout 1960 and 1961, Houbolt campaigned for the recognition of LOR as a viable and practical option. Bypassing the NASA hierarchy, he sent a series of memos and reports on the issue to Associate Administrator Robert Seamans; while acknowledging that he spoke "somewhat as a voice in the wilderness", Houbolt pleaded that LOR should not be discounted in studies of the question.
Seamans' establishment of an ad hoc committee headed by his special technical assistant Nicholas E. Golovin in July 1961, to recommend a launch vehicle to be used in the Apollo program, represented a turning point in NASA's mission mode decision. This committee recognized that the chosen mode was an important part of the launch vehicle choice, and recommended in favor of a hybrid EOR-LOR mode. Its consideration of LOR—as well as Houbolt's ceaseless work—played an important role in publicizing the workability of the approach. In late 1961 and early 1962, members of the Manned Spacecraft Center began to come around to support LOR, including the newly hired deputy director of the Office of Manned Space Flight, Joseph Shea, who became a champion of LOR. The engineers at Marshall Space Flight Center (MSFC), which had much to lose from the decision, took longer to become convinced of its merits, but their conversion was announced by Wernher von Braun at a briefing on June 7, 1962.
But even after NASA reached internal agreement, it was far from smooth sailing. Kennedy's science advisor Jerome Wiesner, who had expressed his opposition to human spaceflight to Kennedy before the President took office, and had opposed the decision to land people on the Moon, hired Golovin, who had left NASA, to chair his own "Space Vehicle Panel", ostensibly to monitor, but actually to second-guess NASA's decisions on the Saturn V launch vehicle and LOR by forcing Shea, Seamans, and even Webb to defend themselves, delaying its formal announcement to the press on July 11, 1962, and forcing Webb to still hedge the decision as "tentative".
Wiesner kept up the pressure, even making the disagreement public during a two-day September visit by the President to Marshall Space Flight Center. Wiesner blurted out "No, that's no good" in front of the press, during a presentation by von Braun. Webb jumped in and defended von Braun, until Kennedy ended the squabble by stating that the matter was "still subject to final review". Webb held firm and issued a request for proposal to candidate Lunar Excursion Module (LEM) contractors. Wiesner finally relented, unwilling to settle the dispute once and for all in Kennedy's office, because of the President's involvement with the October Cuban Missile Crisis, and fear of Kennedy's support for Webb. NASA announced the selection of Grumman as the LEM contractor in November 1962.
Space historian James Hansen concludes that:
The LOR method had the advantage of allowing the lander spacecraft to be used as a "lifeboat" in the event of a failure of the command ship. Some documents prove this theory was discussed before and after the method was chosen. In 1964 an MSC study concluded, "The LM [as lifeboat]... was finally dropped, because no single reasonable CSM failure could be identified that would prohibit use of the SPS." Ironically, just such a failure happened on Apollo 13 when an oxygen tank explosion left the CSM without electrical power. The lunar module provided propulsion, electrical power and life support to get the crew home safely.
Faget's preliminary Apollo design employed a cone-shaped command module, supported by one of several service modules providing propulsion and electrical power, sized appropriately for the space station, cislunar, and lunar landing missions. Once Kennedy's Moon landing goal became official, detailed design began of a command and service module (CSM) in which the crew would spend the entire direct-ascent mission and lift off from the lunar surface for the return trip, after being soft-landed by a larger landing propulsion module. The final choice of lunar orbit rendezvous changed the CSM's role to the translunar ferry used to transport the crew, along with a new spacecraft, the Lunar Excursion Module (LEM, later shortened to LM (Lunar Module) but still pronounced ) which would take two individuals to the lunar surface and return them to the CSM.
The command module (CM) was the conical crew cabin, designed to carry three astronauts from launch to lunar orbit and back to an Earth ocean landing. It was the only component of the Apollo spacecraft to survive without major configuration changes as the program evolved from the early Apollo study designs. Its exterior was covered with an ablative heat shield, and had its own reaction control system (RCS) engines to control its attitude and steer its atmospheric entry path. Parachutes were carried to slow its descent to splashdown. The module was tall, in diameter, and weighed approximately .
A cylindrical service module (SM) supported the command module, with a service propulsion engine and an RCS with propellants, and a fuel cell power generation system with liquid hydrogen and liquid oxygen reactants. A high-gain S-band antenna was used for long-distance communications on the lunar flights. On the extended lunar missions, an orbital scientific instrument package was carried. The service module was discarded just before reentry. The module was long and in diameter. The initial lunar flight version weighed approximately fully fueled, while a later version designed to carry a lunar orbit scientific instrument package weighed just over .
North American Aviation won the contract to build the CSM, and also the second stage of the Saturn V launch vehicle for NASA. Because the CSM design was started early before the selection of lunar orbit rendezvous, the service propulsion engine was sized to lift the CSM off the Moon, and thus was oversized to about twice the thrust required for translunar flight. Also, there was no provision for docking with the lunar module. A 1964 program definition study concluded that the initial design should be continued as Block I which would be used for early testing, while Block II, the actual lunar spacecraft, would incorporate the docking equipment and take advantage of the lessons learned in Block I development.
The Apollo Lunar Module (LM) was designed to descend from lunar orbit to land two astronauts on the Moon and take them back to orbit to rendezvous with the command module. Not designed to fly through the Earth's atmosphere or return to Earth, its fuselage was designed totally without aerodynamic considerations and was of an extremely lightweight construction. It consisted of separate descent and ascent stages, each with its own engine. The descent stage contained storage for the descent propellant, surface stay consumables, and surface exploration equipment. The ascent stage contained the crew cabin, ascent propellant, and a reaction control system. The initial LM model weighed approximately , and allowed surface stays up to around 34 hours. An extended lunar module weighed over , and allowed surface stays of more than three days. The contract for design and construction of the lunar module was awarded to Grumman Aircraft Engineering Corporation, and the project was overseen by Thomas J. Kelly.
Before the Apollo program began, Wernher von Braun and his team of rocket engineers had started work on plans for very large launch vehicles, the Saturn series, and the even larger Nova series. In the midst of these plans, von Braun was transferred from the Army to NASA and was made Director of the Marshall Space Flight Center. The initial direct ascent plan to send the three-person Apollo command and service module directly to the lunar surface, on top of a large descent rocket stage, would require a Nova-class launcher, with a lunar payload capability of over . The June 11, 1962, decision to use lunar orbit rendezvous enabled the Saturn V to replace the Nova, and the MSFC proceeded to develop the Saturn rocket family for Apollo.
Since Apollo, like Mercury, used more than one launch vehicle for space missions, NASA used spacecraft-launch vehicle combination series numbers: AS-10x for Saturn I, AS-20x for Saturn IB, and AS-50x for Saturn V (compare Mercury-Redstone 3, Mercury-Atlas 6) to designate and plan all missions, rather than numbering them sequentially as in Project Gemini. This was changed by the time human flights began.
Since Apollo, like Mercury, would require a launch escape system (LES) in case of a launch failure, a relatively small rocket was required for qualification flight testing of this system. A rocket bigger than the Little Joe used by Mercury would be required, so the Little Joe II was built by General Dynamics/Convair. After an August 1963 qualification test flight, four LES test flights (A-001 through 004) were made at the White Sands Missile Range between May 1964 and January 1966.
Saturn I, the first US heavy lift launch vehicle, was initially planned to launch partially equipped CSMs in low Earth orbit tests. The S-I first stage burned RP-1 with liquid oxygen (LOX) oxidizer in eight clustered Rocketdyne H-1 engines, to produce of thrust. The S-IV second stage used six liquid hydrogen-fueled Pratt & Whitney RL-10 engines with of thrust. The S-V third stage flew inactively on Saturn I four times.
The first four Saturn I test flights were launched from LC-34, with only the first stage live, carrying dummy upper stages filled with water. The first flight with a live S-IV was launched from LC-37. This was followed by five launches of boilerplate CSMs (designated AS-101 through AS-105) into orbit in 1964 and 1965. The last three of these further supported the Apollo program by also carrying Pegasus satellites, which verified the safety of the translunar environment by measuring the frequency and severity of micrometeorite impacts.
In September 1962, NASA planned to launch four crewed CSM flights on the Saturn I from late 1965 through 1966, concurrent with Project Gemini. The payload capacity would have severely limited the systems which could be included, so the decision was made in October 1963 to use the uprated Saturn IB for all crewed Earth orbital flights.
The Saturn IB was an upgraded version of the Saturn I. The S-IB first stage increased the thrust to by uprating the H-1 engine. The second stage replaced the S-IV with the S-IVB-200, powered by a single J-2 engine burning liquid hydrogen fuel with LOX, to produce of thrust. A restartable version of the S-IVB was used as the third stage of the Saturn V. The Saturn IB could send over into low Earth orbit, sufficient for a partially fueled CSM or the LM. Saturn IB launch vehicles and flights were designated with an AS-200 series number, "AS" indicating "Apollo Saturn" and the "2" indicating the second member of the Saturn rocket family.
Saturn V launch vehicles and flights were designated with an AS-500 series number, "AS" indicating "Apollo Saturn" and the "5" indicating Saturn V. The three-stage Saturn V was designed to send a fully fueled CSM and LM to the Moon. It was in diameter and stood tall with its lunar payload. Its capability grew to for the later advanced lunar landings. The S-IC first stage burned RP-1/LOX for a rated thrust of , which was upgraded to . The second and third stages burned liquid hydrogen, and the third stage was a modified version of the S-IVB, with thrust increased to and capability to restart the engine for translunar injection after reaching a parking orbit.
NASA's director of flight crew operations during the Apollo program was Donald K. "Deke" Slayton, one of the original Mercury Seven astronauts who was medically grounded in September 1962 due to a heart murmur. Slayton was responsible for making all Gemini and Apollo crew assignments.
Thirty-two astronauts were assigned to fly missions in the Apollo program. Twenty-four of these left Earth's orbit and flew around the Moon between December 1968 and December 1972 (three of them twice). Half of the 24 walked on the Moon's surface, though none of them returned to it after landing once. One of the moonwalkers was a trained geologist. Of the 32, Gus Grissom, Ed White, and Roger Chaffee were killed during a ground test in preparation for the Apollo 1 mission.
The Apollo astronauts were chosen from the Project Mercury and Gemini veterans, plus from two later astronaut groups. All missions were commanded by Gemini or Mercury veterans. Crews on all development flights (except the Earth orbit CSM development flights) through the first two landings on Apollo 11 and Apollo 12, included at least two (sometimes three) Gemini veterans. Dr. Harrison Schmitt, a geologist, was the first NASA scientist astronaut to fly in space, and landed on the Moon on the last mission, Apollo 17. Schmitt participated in the lunar geology training of all of the Apollo landing crews.
NASA awarded all 32 of these astronauts its highest honor, the Distinguished Service Medal, given for "distinguished service, ability, or courage", and personal "contribution representing substantial progress to the NASA mission". The medals were awarded posthumously to Grissom, White, and Chaffee in 1969, then to the crews of all missions from Apollo 8 onward. The crew that flew the first Earth orbital test mission Apollo 7, Walter M. Schirra, Donn Eisele, and Walter Cunningham, were awarded the lesser NASA Exceptional Service Medal, because of discipline problems with the flight director's orders during their flight. The NASA Administrator in October, 2008, decided to award them the Distinguished Service Medals, by this time posthumously to Schirra and Eisele.
The first lunar landing mission was planned to proceed as follows:
Two Block I CSMs were launched from LC-34 on suborbital flights in 1966 with the Saturn IB. The first, AS-201 launched on February 26, reached an altitude of and splashed down downrange in the Atlantic Ocean. The second, AS-202 on August 25, reached altitude and was recovered downrange in the Pacific Ocean. These flights validated the service module engine and the command module heat shield.
A third Saturn IB test, AS-203 launched from pad 37, went into orbit to support design of the S-IVB upper stage restart capability needed for the Saturn V. It carried a nose cone instead of the Apollo spacecraft, and its payload was the unburned liquid hydrogen fuel, the behavior of which engineers measured with temperature and pressure sensors, and a TV camera. This flight occurred on July 5, before AS-202, which was delayed because of problems getting the Apollo spacecraft ready for flight.
Two crewed orbital Block I CSM missions were planned: AS-204 and AS-205. The Block I crew positions were titled Command Pilot, Senior Pilot, and Pilot. The Senior Pilot would assume navigation duties, while the Pilot would function as a systems engineer. The astronauts would wear a modified version of the Gemini spacesuit.
After an uncrewed LM test flight AS-206, a crew would fly the first Block II CSM and LM in a dual mission known as AS-207/208, or AS-278 (each spacecraft would be launched on a separate Saturn IB). The Block II crew positions were titled Commander, Command Module Pilot, and Lunar Module Pilot. The astronauts would begin wearing a new Apollo A6L spacesuit, designed to accommodate lunar extravehicular activity (EVA). The traditional visor helmet was replaced with a clear "fishbowl" type for greater visibility, and the lunar surface EVA suit would include a water-cooled undergarment.
Deke Slayton, the grounded Mercury astronaut who became director of flight crew operations for the Gemini and Apollo programs, selected the first Apollo crew in January 1966, with Grissom as Command Pilot, White as Senior Pilot, and rookie Donn F. Eisele as Pilot. But Eisele dislocated his shoulder twice aboard the KC135 weightlessness training aircraft, and had to undergo surgery on January 27. Slayton replaced him with Chaffee. NASA announced the final crew selection for AS-204 on March 21, 1966, with the backup crew consisting of Gemini veterans James McDivitt and David Scott, with rookie Russell L. "Rusty" Schweickart. Mercury/Gemini veteran Wally Schirra, Eisele, and rookie Walter Cunningham were announced on September 29 as the prime crew for AS-205.
In December 1966, the AS-205 mission was canceled, since the validation of the CSM would be accomplished on the 14-day first flight, and AS-205 would have been devoted to space experiments and contribute no new engineering knowledge about the spacecraft. Its Saturn IB was allocated to the dual mission, now redesignated AS-205/208 or AS-258, planned for August 1967. McDivitt, Scott and Schweickart were promoted to the prime AS-258 crew, and Schirra, Eisele and Cunningham were reassigned as the Apollo1 backup crew.
The spacecraft for the AS-202 and AS-204 missions were delivered by North American Aviation to the Kennedy Space Center with long lists of equipment problems which had to be corrected before flight; these delays caused the launch of AS-202 to slip behind AS-203, and eliminated hopes the first crewed mission might be ready to launch as soon as November 1966, concurrently with the last Gemini mission. Eventually, the planned AS-204 flight date was pushed to February 21, 1967.
North American Aviation was prime contractor not only for the Apollo CSM, but for the SaturnV S-II second stage as well, and delays in this stage pushed the first uncrewed SaturnV flight AS-501 from late 1966 to November 1967. (The initial assembly of AS-501 had to use a dummy spacer spool in place of the stage.)
The problems with North American were severe enough in late 1965 to cause Manned Space Flight Administrator George Mueller to appoint program director Samuel Phillips to head a "tiger team" to investigate North American's problems and identify corrections. Phillips documented his findings in a December 19 letter to NAA president Lee Atwood, with a strongly worded letter by Mueller, and also gave a presentation of the results to Mueller and Deputy Administrator Robert Seamans. Meanwhile, Grumman was also encountering problems with the Lunar Module, eliminating hopes it would be ready for crewed flight in 1967, not long after the first crewed CSM flights.
Grissom, White, and Chaffee decided to name their flight Apollo1 as a motivational focus on the first crewed flight. They trained and conducted tests of their spacecraft at North American, and in the altitude chamber at the Kennedy Space Center. A "plugs-out" test was planned for January, which would simulate a launch countdown on LC-34 with the spacecraft transferring from pad-supplied to internal power. If successful, this would be followed by a more rigorous countdown simulation test closer to the February 21 launch, with both spacecraft and launch vehicle fueled.
The plugs-out test began on the morning of January 27, 1967, and immediately was plagued with problems. First, the crew noticed a strange odor in their spacesuits which delayed the sealing of the hatch. Then, communications problems frustrated the astronauts and forced a hold in the simulated countdown. During this hold, an electrical fire began in the cabin and spread quickly in the high pressure, 100% oxygen atmosphere. Pressure rose high enough from the fire that the cabin inner wall burst, allowing the fire to erupt onto the pad area and frustrating attempts to rescue the crew. The astronauts were asphyxiated before the hatch could be opened.
NASA immediately convened an accident review board, overseen by both houses of Congress. While the determination of responsibility for the accident was complex, the review board concluded that "deficiencies existed in command module design, workmanship and quality control". At the insistence of NASA Administrator Webb, North American removed Harrison Storms as command module program manager. Webb also reassigned Apollo Spacecraft Program Office (ASPO) Manager Joseph Francis Shea, replacing him with George Low.
To remedy the causes of the fire, changes were made in the Block II spacecraft and operational procedures, the most important of which were use of a nitrogen/oxygen mixture instead of pure oxygen before and during launch, and removal of flammable cabin and space suit materials. The Block II design already called for replacement of the Block I plug-type hatch cover with a quick-release, outward opening door. NASA discontinued the crewed Block I program, using the BlockI spacecraft only for uncrewed SaturnV flights. Crew members would also exclusively wear modified, fire-resistant A7L Block II space suits, and would be designated by the Block II titles, regardless of whether a LM was present on the flight or not.
On April 24, 1967, Mueller published an official Apollo mission numbering scheme, using sequential numbers for all flights, crewed or uncrewed. The sequence would start with Apollo 4 to cover the first three uncrewed flights while retiring the Apollo1 designation to honor the crew, per their widows' wishes.
In September 1967, Mueller approved a sequence of mission types which had to be successfully accomplished in order to achieve the crewed lunar landing. Each step had to be successfully accomplished before the next ones could be performed, and it was unknown how many tries of each mission would be necessary; therefore letters were used instead of numbers. The A missions were uncrewed Saturn V validation; B was uncrewed LM validation using the Saturn IB; C was crewed CSM Earth orbit validation using the Saturn IB; D was the first crewed CSM/LM flight (this replaced AS-258, using a single Saturn V launch); E would be a higher Earth orbit CSM/LM flight; F would be the first lunar mission, testing the LM in lunar orbit but without landing (a "dress rehearsal"); and G would be the first crewed landing. The list of types covered follow-on lunar exploration to include H lunar landings, I for lunar orbital survey missions, and J for extended-stay lunar landings.
The delay in the CSM caused by the fire enabled NASA to catch up on human-rating the LM and SaturnV. Apollo4 (AS-501) was the first uncrewed flight of the SaturnV, carrying a BlockI CSM on November 9, 1967. The capability of the command module's heat shield to survive a trans-lunar reentry was demonstrated by using the service module engine to ram it into the atmosphere at higher than the usual Earth-orbital reentry speed.
Apollo 5 (AS-204) was the first uncrewed test flight of the LM in Earth orbit, launched from pad 37 on January 22, 1968, by the Saturn IB that would have been used for Apollo 1. The LM engines were successfully test-fired and restarted, despite a computer programming error which cut short the first descent stage firing. The ascent engine was fired in abort mode, known as a "fire-in-the-hole" test, where it was lit simultaneously with jettison of the descent stage. Although Grumman wanted a second uncrewed test, George Low decided the next LM flight would be crewed.
This was followed on April 4, 1968, by Apollo 6 (AS-502) which carried a CSM and a LM Test Article as ballast. The intent of this mission was to achieve trans-lunar injection, followed closely by a simulated direct-return abort, using the service module engine to achieve another high-speed reentry. The Saturn V experienced pogo oscillation, a problem caused by non-steady engine combustion, which damaged fuel lines in the second and third stages. Two S-II engines shut down prematurely, but the remaining engines were able to compensate. The damage to the third stage engine was more severe, preventing it from restarting for trans-lunar injection. Mission controllers were able to use the service module engine to essentially repeat the flight profile of Apollo 4. Based on the good performance of Apollo6 and identification of satisfactory fixes to the Apollo6 problems, NASA declared the SaturnV ready to fly crew, canceling a third uncrewed test.
Apollo 7, launched from LC-34 on October 11, 1968, was the Cmission, crewed by Schirra, Eisele, and Cunningham. It was an 11-day Earth-orbital flight which tested the CSM systems.
Apollo 8 was planned to be the D mission in December 1968, crewed by McDivitt, Scott and Schweickart, launched on a SaturnV instead of two Saturn IBs. In the summer it had become clear that the LM would not be ready in time. Rather than waste the Saturn V on another simple Earth-orbiting mission, ASPO Manager George Low suggested the bold step of sending Apollo8 to orbit the Moon instead, deferring the Dmission to the next mission in March 1969, and eliminating the E mission. This would keep the program on track. The Soviet Union had sent two tortoises, mealworms, wine flies, and other lifeforms around the Moon on September 15, 1968, aboard Zond 5, and it was believed they might soon repeat the feat with human cosmonauts. The decision was not announced publicly until successful completion of Apollo 7. Gemini veterans Frank Borman and Jim Lovell, and rookie William Anders captured the world's attention by making ten lunar orbits in 20 hours, transmitting television pictures of the lunar surface on Christmas Eve, and returning safely to Earth.
The following March, LM flight, rendezvous and docking were successfully demonstrated in Earth orbit on Apollo 9, and Schweickart tested the full lunar EVA suit with its portable life support system (PLSS) outside the LM. The F mission was successfully carried out on Apollo 10 in May 1969 by Gemini veterans Thomas P. Stafford, John Young and Eugene Cernan. Stafford and Cernan took the LM to within of the lunar surface.
The G mission was achieved on Apollo 11 in July 1969 by an all-Gemini veteran crew consisting of Neil Armstrong, Michael Collins and Buzz Aldrin. Armstrong and Aldrin performed the first landing at the Sea of Tranquility at 20:17:40 UTC on July 20, 1969. They spent a total of 21 hours, 36 minutes on the surface, and spent 2hours, 31 minutes outside the spacecraft, walking on the surface, taking photographs, collecting material samples, and deploying automated scientific instruments, while continuously sending black-and-white television back to Earth. The astronauts returned safely on July 24.
In November 1969, Gemini veteran Charles "Pete" Conrad and rookie Alan L. Bean made a precision landing on Apollo 12 within walking distance of the Surveyor 3 uncrewed lunar probe, which had landed in April 1967 on the Ocean of Storms. The command module pilot was Gemini veteran Richard F. Gordon Jr. Conrad and Bean carried the first lunar surface color television camera, but it was damaged when accidentally pointed into the Sun. They made two EVAs totaling 7hours and 45 minutes. On one, they walked to the Surveyor, photographed it, and removed some parts which they returned to Earth.
The success of the first two landings allowed the remaining missions to be crewed with a single veteran as commander, with two rookies. Apollo 13 launched Lovell, Jack Swigert, and Fred Haise in April 1970, headed for the Fra Mauro formation. But two days out, a liquid oxygen tank exploded, disabling the service module and forcing the crew to use the LM as a "lifeboat" to return to Earth. Another NASA review board was convened to determine the cause, which turned out to be a combination of damage of the tank in the factory, and a subcontractor not making a tank component according to updated design specifications. Apollo was grounded again, for the remainder of 1970 while the oxygen tank was redesigned and an extra one was added.
The contracted batch of 15 Saturn Vs was enough for lunar landing missions through Apollo 20. NASA publicized a preliminary list of eight more planned landing sites, with plans to increase the mass of the CSM and LM for the last five missions, along with the payload capacity of the Saturn V. These final missions would combine the I and J types in the 1967 list, allowing the CMP to operate a package of lunar orbital sensors and cameras while his companions were on the surface, and allowing them to stay on the Moon for over three days. These missions would also carry the Lunar Roving Vehicle (LRV) increasing the exploration area and allowing televised liftoff of the LM. Also, the Block II spacesuit was revised for the extended missions to allow greater flexibility and visibility for driving the LRV.
About the time of the first landing in 1969, it was decided to use an existing Saturn V to launch the Skylab orbital laboratory pre-built on the ground, replacing the original plan to construct it in orbit from several Saturn IB launches; this eliminated Apollo 20. NASA's yearly budget also began to shrink in light of the successful landing, and NASA also had to make funds available for the development of the upcoming Space Shuttle. By 1971, the decision was made to also cancel missions 18 and 19. The two unused Saturn Vs became museum exhibits at the John F. Kennedy Space Center on Merritt Island, Florida, George C. Marshall Space Center in Huntsville, Alabama, Michoud Assembly Facility in New Orleans, Louisiana, and Lyndon B. Johnson Space Center in Houston, Texas.
The cutbacks forced mission planners to reassess the original planned landing sites in order to achieve the most effective geological sample and data collection from the remaining four missions. Apollo 15 had been planned to be the last of the H series missions, but since there would be only two subsequent missions left, it was changed to the first of three J missions.
Apollo 13's Fra Mauro mission was reassigned to Apollo 14, commanded in February 1971 by Mercury veteran Alan Shepard, with Stuart Roosa and Edgar Mitchell. This time the mission was successful. Shepard and Mitchell spent 33 hours and 31 minutes on the surface, and completed two EVAs totalling 9hours 24 minutes, which was a record for the longest EVA by a lunar crew at the time.
In August 1971, just after conclusion of the Apollo 15 mission, President Richard Nixon proposed canceling the two remaining lunar landing missions, Apollo 16 and 17. Office of Management and Budget Deputy Director Caspar Weinberger was opposed to this, and persuaded Nixon to keep the remaining missions.
Apollo 15 was launched on July 26, 1971, with David Scott, Alfred Worden and James Irwin. Scott and Irwin landed on July 30 near Hadley Rille, and spent just under two days, 19 hours on the surface. In over 18 hours of EVA, they collected about of lunar material.
Apollo 16 landed in the Descartes Highlands on April 20, 1972. The crew was commanded by John Young, with Ken Mattingly and Charles Duke. Young and Duke spent just under three days on the surface, with a total of over 20 hours EVA.
Apollo 17 was the last of the Apollo program, landing in the Taurus–Littrow region in December 1972. Eugene Cernan commanded Ronald E. Evans and NASA's first scientist-astronaut, geologist Dr. Harrison H. Schmitt. Schmitt was originally scheduled for Apollo 18, but the lunar geological community lobbied for his inclusion on the final lunar landing. Cernan and Schmitt stayed on the surface for just over three days and spent just over 23 hours of total EVA.
Source: "Apollo by the Numbers: A Statistical Reference" (Orloff 2004)
The Apollo program returned over of lunar rocks and soil to the Lunar Receiving Laboratory in Houston. Today, 75% of the samples are stored at the Lunar Sample Laboratory Facility built in 1979.
The rocks collected from the Moon are extremely old compared to rocks found on Earth, as measured by radiometric dating techniques. They range in age from about 3.2 billion years for the basaltic samples derived from the lunar maria, to about 4.6 billion years for samples derived from the highlands crust. As such, they represent samples from a very early period in the development of the Solar System, that are largely absent on Earth. One important rock found during the Apollo Program is dubbed the Genesis Rock, retrieved by astronauts David Scott and James Irwin during the Apollo 15 mission. This anorthosite rock is composed almost exclusively of the calcium-rich feldspar mineral anorthite, and is believed to be representative of the highland crust. A geochemical component called KREEP was discovered by Apollo 12, which has no known terrestrial counterpart. KREEP and the anorthositic samples have been used to infer that the outer portion of the Moon was once completely molten (see lunar magma ocean).
Almost all the rocks show evidence of impact process effects. Many samples appear to be pitted with micrometeoroid impact craters, which is never seen on Earth rocks, due to the thick atmosphere. Many show signs of being subjected to high-pressure shock waves that are generated during impact events. Some of the returned samples are of "impact melt" (materials melted near an impact crater.) All samples returned from the Moon are highly brecciated as a result of being subjected to multiple impact events.
Analysis of the composition of the lunar samples supports the giant impact hypothesis, that the Moon was created through impact of a large astronomical body with the Earth.
Apollo cost $25.4 billion (or approximately $ in dollars when adjusted for inflation via the GDP deflator index).
Of this amount, $20.2 billion ($ adjusted) was spent on the design, development, and production of the Saturn family of launch vehicles, the Apollo spacecraft, space suits, scientific experiments, and mission operations. The cost of constructing and operating Apollo-related ground facilities, such as the NASA human spaceflight centers and the global tracking and data acquisition network, added an additional $5.2 billion ($ adjusted).
The amount grows to $28 billion ($ adjusted) if the costs for related projects such as Project Gemini and the robotic Ranger, Surveyor, and Lunar Orbiter programs are included.
NASA's official cost breakdown, as reported to Congress in the Spring of 1973, is as follows:
Accurate estimates of human spaceflight costs were difficult in the early 1960s, as the capability was new and management experience was lacking. Preliminary cost analysis by NASA estimated $7 billion - $12 billion for a crewed lunar landing effort. NASA Administrator James Webb increased this estimate to $20 billion before reporting it to Vice President Johnson in April 1961.
Project Apollo was a massive undertaking, representing the largest research and development project in peacetime. At its peak, it employed over 400,000 employees and contractors around the country and accounted for more than half of NASA's total spending in the 1960s. It proved unsustainable.
After the first Moon landing, public and political interest waned, including that of President Nixon, who wanted to rein in federal spending. NASA's budget could not sustain Apollo missions which cost, on average, $445 million ($ adjusted) each while simultaneously developing the Space Shuttle. The final fiscal year of Apollo funding was 1973.
Looking beyond the crewed lunar landings, NASA investigated several post-lunar applications for Apollo hardware. The Apollo Extension Series ("Apollo X") proposed up to 30 flights to Earth orbit, using the space in the Spacecraft Lunar Module Adapter (SLA) to house a small orbital laboratory (workshop). Astronauts would continue to use the CSM as a ferry to the station. This study was followed by design of a larger orbital workshop to be built in orbit from an empty S-IVB Saturn upper stage and grew into the Apollo Applications Program (AAP). The workshop was to be supplemented by the Apollo Telescope Mount, which could be attached to the ascent stage of the lunar module via a rack. The most ambitious plan called for using an empty S-IVB as an interplanetary spacecraft for a Venus fly-by mission.
The S-IVB orbital workshop was the only one of these plans to make it off the drawing board. Dubbed Skylab, it was assembled on the ground rather than in space, and launched in 1973 using the two lower stages of a Saturn V. It was equipped with an Apollo Telescope Mount. Skylab's last crew departed the station on February 8, 1974, and the station itself re-entered the atmosphere in 1979.
The Apollo–Soyuz program also used Apollo hardware for the first joint nation spaceflight, paving the way for future cooperation with other nations in the Space Shuttle and International Space Station programs.
In 2008, Japan Aerospace Exploration Agency's SELENE probe observed evidence of the halo surrounding the Apollo 15 Lunar Module blast crater while orbiting above the lunar surface.
Beginning in 2009, NASA's robotic Lunar Reconnaissance Orbiter, while orbiting above the Moon, photographed the remnants of the Apollo program left on the lunar surface, and each site where crewed Apollo flights landed. All of the U.S. flags left on the Moon during the Apollo missions were found to still be standing, with the exception of the one left during the Apollo 11 mission, which was blown over during that mission's lift-off from the lunar surface and return to the mission Command Module in lunar orbit; the degree to which these flags retain their original colors remains unknown.
In a November 16, 2009, editorial, "The New York Times" opined:
The Apollo program has been called the greatest technological achievement in human history. Apollo stimulated many areas of technology, leading to over 1,800 spinoff products as of 2015. The flight computer design used in both the lunar and command modules was, along with the Polaris and Minuteman missile systems, the driving force behind early research into integrated circuits (ICs). By 1963, Apollo was using 60 percent of the United States' production of ICs. The crucial difference between the requirements of Apollo and the missile programs was Apollo's much greater need for reliability. While the Navy and Air Force could work around reliability problems by deploying more missiles, the political and financial cost of failure of an Apollo mission was unacceptably high.
Technologies and techniques required for Apollo were developed by Project Gemini. The Apollo project was enabled by NASA's adoption of new advances in semiconductor electronic technology, including metal-oxide-semiconductor field-effect transistors (MOSFETs) in the Interplanetary Monitoring Platform (IMP) and silicon integrated circuit chips in the Apollo Guidance Computer (AGC).
The crew of Apollo 8 sent the first live televised pictures of the Earth and the Moon back to Earth, and read from the creation story in the Book of Genesis, on Christmas Eve 1968. An estimated one-quarter of the population of the world saw—either live or delayed—the Christmas Eve transmission during the ninth orbit of the Moon, and an estimated one-fifth of the population of the world watched the live transmission of the Apollo 11 moonwalk.
The Apollo program also affected environmental activism in the 1970s due to photos taken by the astronauts. The most well known include "Earthrise", taken by William Anders on Apollo 8, and "The Blue Marble", taken by the Apollo 17 astronauts. "The Blue Marble" was released during a surge in environmentalism, and became a symbol of the environmental movement as a depiction of Earth's frailty, vulnerability, and isolation amid the vast expanse of space.
According to "The Economist", Apollo succeeded in accomplishing President Kennedy's goal of taking on the Soviet Union in the Space Race by accomplishing a singular and significant achievement, to demonstrate the superiority of the free-market system. The publication noted the irony that in order to achieve the goal, the program required the organization of tremendous public resources within a vast, centralized government bureaucracy.
Prior to Apollo 11's 40th anniversary in 2009, NASA searched for the original videotapes of the mission's live televised moonwalk. After an exhaustive three-year search, it was concluded that the tapes had probably been erased and reused. A new digitally remastered version of the best available broadcast television footage was released instead.
Numerous documentary films cover the Apollo program and the Space Race, including:
The Apollo program, or certain missions, have been dramatized in "Apollo 13" (1995), "Apollo 11" (1996), "From the Earth to the Moon" (1998), "The Dish" (2000), "Space Race" (2005), "Moonshot" (2009), and "First Man" (2018).
The Apollo program has been the focus of several works of fiction, including:

</doc>
<doc id="1466" url="https://en.wikipedia.org/wiki?curid=1466" title="Assault">
Assault

An assault is the act of inflicting physical harm or unwanted physical contact upon a person or, in some specific legal definitions, a threat or attempt to commit such an action. It is both a crime and a tort and, therefore, may result in criminal prosecution, civil liability, or both. Generally, the common law definition is the same in criminal and tort law.
Traditionally, common law legal systems had separate definitions for assault and battery. When this distinction is observed, battery refers to the actual bodily contact, whereas assault refers to a credible threat or attempt to cause battery. Some jurisdictions combined the two offences into assault and battery, which then became widely referred to as "assault". The result is that in many of these jurisdictions, assault has taken on a definition that is more in line with the traditional definition of battery. The legal systems of civil law and Scots law have never distinguished assault from battery.
Legal systems generally acknowledge that assaults can vary greatly in severity. In the United States, an assault can be charged as either a misdemeanor or a felony. In England and Wales and Australia, it can be charged as either common assault, assault occasioning actual bodily harm (ABH) or grievous bodily harm (GBH). Canada also has a three-tier system: assault, assault causing bodily harm and aggravated assault. Separate charges typically exist for sexual assaults, affray and assaulting a police officer. Assault may overlap with an attempted crime; for example an assault may be charged as an attempted murder if it was done with intent to kill.
In jurisdictions that make a distinction between the two, assault usually accompanies battery if the assailant both threatens to make unwanted contact and then carries through with this threat. See common assault. The elements of battery are that it is a volitional act, done for the purpose of causing a harmful or offensive contact with another person or under circumstances that make such contact substantially certain to occur, and which causes such contact.
Aggravated assault is, in some jurisdictions, a stronger form of assault, usually using a deadly weapon. A person has committed an aggravated assault when that person attempts to:
Aggravated assault can also be charged in cases of attempted harm against police officers or other public servants.
Although the range and precise application of defenses varies between jurisdictions, the following represents a list of the defenses that may apply to all levels of assault:
Exceptions exist to cover unsolicited physical contact which amount to normal social behavior known as de minimis harm. Assault can also be considered in cases involving the spitting on, or unwanted exposure of bodily fluids to others.
Consent may be a complete or partial defense to assault. In some jurisdictions, most notably England, it is not a defense where the degree of injury is severe, as long as there is no legally recognized good reason for the assault. This can have important consequences when dealing with issues such as consensual sadomasochistic sexual activity, the most notable case being the Operation Spanner case. Legally recognized good reasons for consent include surgery, activities within the rules of a game (mixed martial arts, wrestling, boxing, or contact sports), bodily adornment ("R v Wilson" [1996] Crim LR 573), or horseplay ("R v Jones" [1987] Crim LR 123). However, any activity outside the rules of the game is not legally recognized as a defense of consent. In Scottish law, consent is not a defense for assault.
Police officers and court officials have a general power to use force for the purpose of performing an arrest or generally carrying out their official duties. Thus, a court officer taking possession of goods under a court order may use force if reasonably necessary.
In some jurisdictions such as Singapore, judicial corporal punishment is part of the legal system. The officers who administer the punishment have immunity from prosecution for assault.
In the United States, the United Kingdom, Australia and Canada, corporal punishment administered to children by their parent or legal guardian is not legally considered to be assault unless it is deemed to be excessive or unreasonable. What constitutes "reasonable" varies in both statutory law and case law. Unreasonable physical punishment may be charged as assault or under a separate statute for child abuse.
Many countries, including some US states, also permit the use of corporal punishment for children in school. In English law, s. 58 Children Act 2004 limits the availability of the lawful correction defense to common assault under s. 39 Criminal Justice Act 1988.
This may or may not involve self-defense in that, using a reasonable degree of force to prevent another from committing a crime could involve preventing an assault, but it could be preventing a crime not involving the use of personal violence.
Some jurisdictions allow force to be used in defense of property, to prevent damage either in its own right, or under one or both of the preceding classes of defense in that a threat or attempt to damage property might be considered a crime (in English law, under s5 Criminal Damage Act 1971 it may be argued that the defendant has a "lawful excuse" to damage property during the defense and a defense under s3 Criminal Law Act 1967) subject to the need to deter vigilantes and excessive self-help. Furthermore, some jurisdictions, such as Ohio, allow residents in their homes to use force when ejecting an intruder. The resident merely needs to assert to the court that they felt threatened by the intruder's presence.
This defense is not universal: in New Zealand (for example) homeowners have been convicted of assault for attacking burglars.
Assault is an offence under s. 265 of the Canadian Criminal Code. There is a wide range of the types of assault that can occur. Generally, an assault occurs when a person directly or indirectly applies force intentionally to another person without their consent. It can also occur when a person attempts to apply such force, or threatens to do so, without the consent of the other person. An injury need not occur for an assault to be committed, but the force used in the assault must be offensive in nature with an intention to apply force. It can be an assault to "tap", "pinch", "push", or direct another such minor action toward another, but an accidental application of force is not an assault.
The potential punishment for an assault in Canada varies depending on the manner in which the charge proceeds through the court system and the type of assault that is committed. The Criminal Code defines assault as a dual offence (indictable or summary offence). Police officers can arrest someone without a warrant for an assault if it is in the public's interest to do so notwithstanding S.495(2)(d) of the Code. This public interest is usually satisfied by preventing a continuation or repetition of the offence on the same victim.
Some variations on the ordinary crime of assault include:
An individual cannot consent to an assault with a weapon, assault causing bodily harm, aggravated assault, or any sexual assault. Consent will also be vitiated if two people consent to fight but serious bodily harm is intended and caused (R v Paice; R v Jobidon). A person cannot consent to serious bodily harm.
The Indian Penal Code covers the punishments and types of assault in Chapter 16, sections 351 through 358.
The Code further explains that "mere words do not amount to an assault. But the words which a person uses may give to their gestures or preparation such a meaning as may make those gestures or preparations amount to an assault". Assault is in Indian criminal law an attempt to use criminal force (with criminal force being described in s.350). The attempt itself has been made an offence in India, as in other states.
The Criminal Code Act (chapter 29 of Part V; sections 351 to 365) creates a number of offences of assault. Assault is defined by section 252 of that Act. Assault is a misdemeanor punishable by one year imprisonment; assault with "intent to have carnal knowledge of him or her" or who indecently assaults another, or who commits other more-serious variants of assault (as defined in the Act) are guilty of a felony, and longer prison terms are provided for.
Marshall Islands
The offence of assault is created by section 113 of the Criminal Code. A person is guilty of this offence if they unlawfully offer or attempt, with force or violence, to strike, beat, wound, or do bodily harm to, another.
Section 2 of the Non-Fatal Offences against the Person Act 1997 creates the offence of assault, and section 3 of that Act creates the offence of assault causing harm.
South African law does not draw the distinction between assault and battery. "Assault" is a common law crime defined as "unlawfully and intentionally applying force to the person of another, or inspiring a belief in that other that force is immediately to be applied to him". The law also recognises the crime of "assault with intent to cause grievous bodily harm", where grievous bodily harm is defined as "harm which in itself is such as seriously to interfere with health". The common law crime of "indecent assault" was repealed by the Criminal Law (Sexual Offences and Related Matters) Amendment Act, 2007, and replaced by a statutory crime of "sexual assault".
Abolished offences:
English law provides for two offences of assault: common assault and battery. Assault (or common assault) is committed if one intentionally or recklessly causes another person to apprehend immediate and unlawful personal violence. "Violence" in this context means any unlawful touching, though there is some debate over whether the touching must also be hostile. The terms "assault" and "common assault" often encompass the separate offence of battery, even in statutory settings such as s 40(3)(a) of the Criminal Justice Act 1988.
A common assault is an assault that lacks any of the aggravating features which Parliament has deemed serious enough to deserve a higher penalty. Section 39 of the Criminal Justice Act 1988 provides that common assault, like battery, is triable only in the magistrates' court in England and Wales (unless it is linked to a more serious offence, which is triable in the Crown Court). Additionally, if a defendant has been charged on an indictment with assault occasioning actual bodily harm (ABH), or racially/religiously aggravated assault, then a jury in the Crown Court may acquit the defendant of the more serious offence, but still convict of common assault if it finds common assault has been committed.
An assault which is aggravated by the scale of the injuries inflicted may be charged as offences causing "actual bodily harm" (ABH) or, in the severest cases, "grievous bodily harm" (GBH).
Other aggravated assault charges refer to assaults carried out against a specific target or with a specific intent:
In Scots Law, assault is defined as an "attack upon the person of another". There is no distinction made in Scotland between assault and battery (which is not a term used in Scots law), although, as in England and Wales, assault can be occasioned without a "physical" attack on another's person, as demonstrated in "Atkinson v. HM Advocate" wherein the accused was found guilty of assaulting a shop assistant by simply jumping over a counter wearing a ski mask. The court said:
Scottish law also provides for a more serious charge of aggravated assault on the basis of such factors as severity of injury, the use of a weapon, or "Hamesucken" (to assault a person in their own home). The "mens rea" for assault is simply "evil intent", although this has been held to mean no more than that assault "cannot be committed accidentally or recklessly or negligently" as upheld in "Lord Advocate's Reference No 2 of 1992" where it was found that a "hold-up" in a shop justified as a joke would still constitute an offence.
It is a separate offence to assault on a constable in the execution of their duty, under Section 90, Police and Fire Reform (Scotland) Act 2012 (previously Section 41 of the Police (Scotland) Act 1967) which provides that it is an offence for a person to, amongst other things, assault a constable in the execution of their duty or a person assisting a constable in the execution of their duty.
Several offences of assault exist in Northern Ireland. The Offences against the Person Act 1861 creates the offences of:
The Criminal Justice (Miscellaneous Provisions) Act (Northern Ireland) 1968 creates the offences of:
That Act formerly created the offence of 'Assault on a constable in the execution of his duty'. under section 7(1)(a), but that section has been superseded by section 66(1) of the Police (Northern Ireland) Act 1998 (c.32) which now provides that it is an offence for a person to, amongst other things, assault a constable in the execution of his duty, or a person assisting a constable in the execution of his duty.
The term 'assault', when used in legislation, commonly refers to both common assault and battery, even though the two offences remain distinct. Common assault involves intentionally or recklessly causing a person to apprehend the imminent infliction of unlawful force, whilst battery refers to the actual infliction of force.
Each state has legislation relating to the act of assault, and offences against the act that constitute assault are heard in the Magistrates Court of that state or indictable offences are heard in a District or Supreme Court of that State. The legislation that defines assault of each state outline what the elements are that make up the assault, where the assault is sectioned in legislation or criminal codes, and the penalties that apply for the offence of assault.
In New South Wales, the Crimes Act 1900 defines a range of assault offences deemed more serious than common assault and which attract heavier penalties. These include:
In the United States, assault may be defined as an attempt to commit a battery. However, the crime of assault can encompass acts in which no battery is intended, but the defendant's act nonetheless creates reasonable fear in others that a battery will occur.
Four elements were required at common law:
As the criminal law evolved, element one was weakened in most jurisdictions so that a reasonable fear of bodily injury would suffice. These four elements were eventually codified in most states.
The crime of assault generally requires that both the perpetrator and the victim of an assault be a natural person. Thus, unless the attack is directed by a person, an animal attack does not constitute an assault. However, the Unborn Victims of Violence Act of 2004 treats a fetus as a separate person for the purposes of assault and other violent crimes, under certain limited circumstances. See H.R. 1997/P.L. 108-212.
Possible examples of defenses, mitigating circumstances, or failures of proof that may be raised in response to an assault charge include:
Laws on assault vary by state. Since each state has its own criminal laws, there is no universal assault law. Acts classified as assault in one state may be classified as battery, menacing, intimidation, reckless endangerment, etc. in another state. Assault is often subdivided into two categories, simple assault and aggravated assault.
Modern American statutes may define assault as including:
In some states, consent is a complete defense to assault. In other jurisdictions, mutual consent is an incomplete defense to an assault charge such that an assault charge is prosecuted as a less significant offense such as a "petty misdemeanor".
States vary on whether it is possible to commit an "attempted assault" since it can be considered a double inchoate offense.
In Kansas the law on assault states:
In New York State, assault (as defined in the New York State Penal Code Article 120) requires an actual injury. Other states define this as battery; there is no crime of battery in New York. However, in New York if a person threatens another person with imminent injury without engaging in physical contact, that is called "menacing". A person who engages in that behavior is guilty of aggravated harassment in the second degree (a Class A misdemeanor; punishable with up to one year incarceration, probation for an extended time, and a permanent criminal record) when they threaten to cause physical harm to another person, and guilty of aggravated harassment in the first degree (a Class E felony) if they have a previous conviction for the same offense. New York also has specific laws against hazing, when such threats are made as requirement to join an organization.
North Dakota law states:
In Tennessee assault is defined as follows:
Assault in Ancient Greece was normally termed hubris. Contrary to modern usage, the term did not have the extended connotation of overweening pride, self-confidence or arrogance, often resulting in fatal retribution. In Ancient Greece, "hubris" referred to actions which, intentionally or not, shamed and humiliated the victim, and frequently the perpetrator as well. It was most evident in the public and private actions of the powerful and rich.
Violations of the law against hubris included, what would today be termed, assault and battery; sexual crimes ranging from forcible rape of women or children to consensual but improper activities; or the theft of public or sacred property. Two well-known cases are found in the speeches of Demosthenes, a prominent statesman and orator in ancient Greece. These two examples occurred when first, Meidias punched Demosthenes in the face in the theater (Against Meidias), and second when (in Against Konon) a defendant allegedly assaulted a man and crowed over the victim.
Hubris, though not specifically defined, was a legal term and was considered a crime in classical Athens. It was also considered the greatest sin of the ancient Greek world. That was so because it not only was proof of excessive pride, but also resulted in violent acts by or to those involved. The category of acts constituting hubris for the ancient Greeks apparently broadened from the original specific reference to mutilation of a corpse, or a humiliation of a defeated foe, or irreverent, "outrageous treatment", in general.
The meaning was eventually further generalized in its modern English usage to apply to any outrageous act or exhibition of pride or disregard for basic moral laws. Such an act may be referred to as an "act of hubris", or the person committing the act may be said to be hubristic. Atë, Greek for 'ruin, folly, delusion', is the action performed by the hero, usually because of their hubris, or great pride, that leads to their death or downfall.
Crucial to this definition are the ancient Greek concepts of honor (timē) and shame. The concept of timē included not only the exaltation of the one receiving honor, but also the shaming of the one overcome by the act of hubris. This concept of honor is akin to a zero-sum game. Rush Rehm simplifies this definition to the contemporary concept of "insolence, contempt, and excessive violence".

</doc>
<doc id="1478" url="https://en.wikipedia.org/wiki?curid=1478" title="Álfheimr">
Álfheimr

In Norse cosmology, Alfheim (, "Land Of The Elves" or "Elfland"), also called Ljosalfheim ("Ljósálf[a]heimr", "home of the light-elves"), is home of the Light Elves.
Álfheim as an abode of the Elves is mentioned only twice in Old Norse texts.
The eddic poem "Grímnismál" describes twelve divine dwellings beginning in stanza 5 with:
Ýdalir call they     the place where Ull
A hall for himself hath set;
And Álfheim the gods     to Frey once gave
As a tooth-gift in ancient times.
A tooth-gift was a gift given to an infant on the cutting of the first tooth.
In the 12th century eddic prose "Gylfaginning", Snorri Sturluson relates it as the first of a series of abodes in heaven:
That which is called Álfheim is one, where dwell the peoples called "ljósálfar" [Light Elves]; but the "dökkálfar" [Dark Elves] dwell down in the earth, and they are unlike in appearance, but by far more unlike in nature. The Light-elves are fairer to look upon than the sun, but the Dark-elves are blacker than pitch.
The account later, in speaking of a hall in the Highest Heaven called Gimlé that shall survive when heaven and earth have died, explains:
It is said that another heaven is to the southward and upward of this one, and it is called Andlang ["Andlangr" 'Endlong'] but the third heaven is yet above that, and it is called Vídbláin ["Vídbláinn" 'Wide-blue'] and in that heaven we think this abode is. But we believe that none but Light-Elves inhabit these mansions now.
It is not indicated whether these heavens are identical to Álfheim or distinct. Some texts read Vindbláin ("Vindbláinn" 'Wind-blue') instead of Vídbláin.
Modern commentators speculate (or sometimes state as fact) that Álfheim was one of the nine worlds ("heima") mentioned in stanza 2 of the eddic poem "Völuspá".

</doc>
<doc id="1482" url="https://en.wikipedia.org/wiki?curid=1482" title="Ask and Embla">
Ask and Embla

In Norse mythology, Ask and Embla (from )—male and female respectively—were the first two humans, created by the gods. The pair are attested in both the "Poetic Edda", compiled in the 13th century from earlier traditional sources, and the "Prose Edda", written in the 13th century by Snorri Sturluson. In both sources, three gods, one of whom is Odin, find Ask and Embla and bestow upon them various corporeal and spiritual gifts. A number of theories have been proposed to explain the two figures, and there are occasional references to them in popular culture.
Old Norse literally means "ash tree" but the etymology of "embla" is uncertain, and two possibilities of the meaning of "embla" are generally proposed. The first meaning, "elm tree", is problematic, and is reached by deriving "*Elm-la" from "*Almilōn" and subsequently to ("elm"). The second suggestion is "vine", which is reached through "*Ambilō", which may be related to the Greek term (), itself meaning "vine, liana". The latter etymology has resulted in a number of theories.
According to Benjamin Thorpe "Grimm says the word embla, emla, signifies a busy woman, from amr, ambr, aml, ambl, assiduous labour; the same relation as Meshia and Meshiane, the ancient Persian names of the first man and woman, who were also formed from trees."
In stanza 17 of the "Poetic Edda" poem "Völuspá", the seeress reciting the poem states that Hœnir, Lóðurr and Odin once found Ask and Embla on land. The seeress says that the two were capable of very little, lacking in "ørlög" and says that they were given three gifts by the three gods:
The meaning of these gifts has been a matter of scholarly disagreement and translations therefore vary.
According to chapter 9 of the "Prose Edda" book "Gylfaginning", the three brothers Vili, Vé, and Odin, are the creators of the first man and woman. The brothers were once walking along a beach and found two trees there. They took the wood and from it created the first human beings; Ask and Embla. One of the three gave them the breath of life, the second gave them movement and intelligence, and the third gave them shape, speech, hearing and sight. Further, the three gods gave them clothing and names. Ask and Embla go on to become the progenitors of all humanity and were given a home within the walls of Midgard.
A Proto-Indo-European basis has been theorized for the duo based on the etymology of "embla" meaning "vine." In Indo-European societies, an analogy is derived from the drilling of fire and sexual intercourse. Vines were used as a flammable wood, where they were placed beneath a drill made of harder wood, resulting in fire. Further evidence of ritual making of fire in Scandinavia has been theorized from a depiction on a stone plate on a Bronze Age grave in Kivik, Scania, Sweden.
Jaan Puhvel comments that "ancient myths teem with trite 'first couples' of the type of Adam and his by-product Eve. In Indo-European tradition, these range from the Vedic Yama and Yamī and the Iranian Mašya and Mašyānag to the Icelandic Askr and Embla, with trees or rocks as preferred raw material, and dragon's teeth or other bony substance occasionally thrown in for good measure".
In his study of the comparative evidence for an origin of mankind from trees in Indo-European society, Anders Hultgård observes that "myths of the origin of mankind from trees or wood seem to be particularly connected with ancient Europe and Indo-Europe and Indo-European-speaking peoples of Asia Minor and Iran. By contrast the cultures of the Near East show almost exclusively the type of anthropogonic stories that derive man's origin from clay, earth or blood by means of a divine creation act".
Two wooden figures—the Braak Bog Figures—of "more than human height" were unearthed from a peat bog at Braak in Schleswig, Germany. The figures depict a nude male and a nude female. Hilda Ellis Davidson comments that these figures may represent a "Lord and Lady" of the Vanir, a group of Norse gods, and that "another memory of [these wooden deities] may survive in the tradition of the creation of Ask and Embla, the man and woman who founded the human race, created by the gods from trees on the seashore".
A figure named Æsc (Old English "ash tree") appears as the son of Hengest in the Anglo-Saxon genealogy for the kings of Kent. This has resulted in a number of theories that the figures may have had an earlier basis in pre-Norse Germanic mythology.
Connections have been proposed between Ask and Embla and the Vandal kings Assi and Ambri, attested in Paul the Deacon's 7th century AD work "Origo Gentis Langobardorum". There, the two ask the god Godan (Odin) for victory. The name "Ambri", like Embla, likely derives from "*Ambilō".
A stanza preceding the account of the creation of Ask and Embla in "Völuspá" provides a catalog of dwarfs, and stanza 10 has been considered as describing the creation of human forms from the earth. This may potentially mean that dwarfs formed humans, and that the three gods gave them life. Carolyne Larrington theorizes that humans are metaphorically designated as trees in Old Norse works (examples include "trees of jewellery" for women and "trees of battle" for men) due to the origin of humankind stemming from trees; Ask and Embla.
Ask and Embla have been the subject of a number of references and artistic depictions. 
A sculpture depicting the two, created by Stig Blomberg in 1948, stands in Sölvesborg in southern Sweden. 
Ask and Embla are depicted on two of the sixteen wooden panels by Dagfin Werenskiold on Oslo City Hall.

</doc>
<doc id="1484" url="https://en.wikipedia.org/wiki?curid=1484" title="Alabama River">
Alabama River

The Alabama River, in the U.S. state of Alabama, is formed by the Tallapoosa and Coosa rivers, which unite about north of Montgomery, near the town of Wetumpka.
The river flows west to Selma, then southwest until, about from Mobile, it unites with the Tombigbee, forming the Mobile and Tensaw rivers, which discharge into Mobile Bay.
The run of the Alabama is highly meandering. Its width varies from , and its depth from . Its length as measured by the United States Geological Survey is , and by steamboat measurement, .
The river crosses the richest agricultural and timber districts of the state. Railways connect it with the mineral regions of north-central Alabama.
After the Coosa and Tallapoosa rivers, the principal tributary of the Alabama is the Cahaba River, which is about long and joins the Alabama River about below Selma. The Alabama River's main tributary, the Coosa River, crosses the mineral region of Alabama and is navigable for light-draft boats from Rome, Georgia, to about above Wetumpka (about below Rome and below Greensport), and from Wetumpka to its junction with the Tallapoosa. The channel of the river has been considerably improved by the federal government.
The navigation of the Tallapoosa River – which has its source in Paulding County, Georgia, and is about long – is prevented by shoals and a fall at Tallassee, a few miles north of its junction with the Coosa. The Alabama is navigable throughout the year.
The river played an important role in the growth of the economy in the region during the 19th century as a source of transportation of goods. The river is still used for transportation of farming produce; however, it is not as important as it once was due to the construction of roads and railways.
Documented by Europeans first in 1701, the Alabama, Coosa, and Tallapoosa rivers were central to the homeland of the Creek Indians before their removal by United States forces to the Indian Territory in the 1830s.
The Edmund Pettus Bridge crosses the Alabama River near Selma. The bridge was the site of the famous marches for voting rights in 1965; the first became known as "Bloody Sunday" because the state and county police beat protesters after they crossed out of the city.
The Alabama River has three lock and dams between Montgomery and the Mobile River. The Robert F. Henry Lock & Dam is located at river mile 236.2, the Millers Ferry Lock & Dam is located at river mile 133.0, and the Claiborne Lock & Dam is located at river mile 72.5.

</doc>
<doc id="1485" url="https://en.wikipedia.org/wiki?curid=1485" title="Alain de Lille">
Alain de Lille

Alain de Lille (Alan of Lille) (Latin: "Alanus ab Insulis"; 11281202/03) was a French theologian and poet. He was born in Lille, some time before 1128. His exact date of death remains unclear as well, with most research pointing toward it being between 14 April 1202, and 5 April 1203.
Little is known of his life. Alain entered the schools no earlier than the late 1140s; first attending the school at Paris, and then at Chartres. He probably studied under masters such as Peter Abelard, Gilbert of Poitiers, and Thierry of Chartres. This is known through the writings of John of Salisbury, who is thought to have been a contemporary student of Alain of Lille. His earliest writings were probably written in the 1150s, and probably in Paris. Alain spent many years as a professor of Theology at the University of Paris and he attended the Lateran Council in 1179. Though the only accounts of his lectures seem to show a sort of eccentric style and approach, he was said to have been good friends with many other masters at the school in Paris, and taught there, as well as some time in southern France, into his old age. He afterwards inhabited Montpellier (he is sometimes called "Alanus de Montepessulano"), lived for a time outside the walls of any cloister, and finally retired to Cîteaux, where he died in 1202.
He had a very widespread reputation during his lifetime, and his knowledge caused him to be called "Doctor Universalis". Many of Alain's writings are unable to be exactly dated, and the circumstances and details surrounding his writing are often unknown as well. However, it does seem clear that his first notable work, "Summa Quoniam Homines", was completed somewhere between 1155 and 1165, with the most conclusive date being 1160, and was probably developed through his lectures at the school in Paris. Among his very numerous works two poems entitle him to a distinguished place in the Latin literature of the Middle Ages; one of these, the "De planctu naturae", is an ingenious satire on the vices of humanity. He created the allegory of grammatical "conjugation" which was to have its successors throughout the Middle Ages. The "Anticlaudianus", a treatise on morals as allegory, the form of which recalls the pamphlet of Claudian against Rufinus, is agreeably versified and relatively pure in its latinity.
As a theologian Alain de Lille shared in the mystic reaction of the second half of the 12th century against the scholastic philosophy. His mysticism, however, is far from being as absolute as that of the Victorines. In the "Anticlaudianus" he sums up as follows: Reason, guided by prudence, can unaided discover most of the truths of the physical order; for the apprehension of religious truths it must trust to faith. This rule is completed in his treatise, "Ars catholicae fidei", as follows: Theology itself may be demonstrated by reason. Alain even ventures an immediate application of this principle, and tries to prove geometrically the dogmas defined in the Creed. This bold attempt is entirely factitious and verbal, and it is only his employment of various terms not generally used in such a connection (axiom, theorem, corollary, etc.) that gives his treatise its apparent originality.
Alan's philosophy was a sort of mixture of Aristotelian logic and Neoplatonic philosophy. The Platonist seemed to outweigh the Aristotelian in Alan, but he felt strongly that the divine is all intelligibility and argued this notion through much Aristotelian logic combined with Pythagorean mathematics.
One of Alain's most notable works was one he modeled after Boethius’ "Consolation of Philosophy", to which he gave the title "De Planctu Naturae", or "The Plaint of Nature", and which was most likely written in the late 1160s. In this work, Alan uses prose and verse to illustrate the way in which nature defines its own position as inferior to that of God. He also attempts to illustrate the way in which humanity, through sexual perversion and specifically homosexuality, has defiled itself from nature and God. In "Anticlaudianus", another of his notable works, Alan uses a poetical dialogue to illustrate the way in which nature comes to the realization of her failure in producing the perfect man. She has only the ability to create a soulless body, and thus she is "persuaded to undertake the journey to heaven to ask for a soul," and "the Seven Liberal Arts produce a chariot for her... the Five Senses are the horses". The "Anticlaudianus" was translated into French and German in the following century, and toward 1280 was re-worked into a musical anthology by Adam de la Bassée. One of Alan's most popular and widely distributed works is his manual on preaching, "Ars Praedicandi", or "The Art of Preaching". This work shows how Alan saw theological education as being a fundamental preliminary step in preaching and strove to give clergyman a manuscript to be "used as a practical manual" when it came to the formation of sermons and art of preaching.
Alain wrote three very large theological textbooks, one being his first work, "Summa Quoniam Homines". Another of his theological textbooks that strove to be more minute in its focus, is his "De Fide Catholica", dated somewhere between 1185 and 1200, Alan sets out to refute heretical views, specifically that of the Waldensians and Cathars. In his third theological textbook, "Regulae Caelestis Iuris", he presents a set of what seems to be theological rules; this was typical of the followers of Gilbert of Poitiers, of which Alan could be associated. Other than these theological textbooks, and the aforementioned works of the mixture of prose and poetry, Alan of Lille had numerous other works on numerous subjects, primarily including Speculative Theology, Theoretical Moral Theology, Practical Moral Theology, and various collections of poems.
Alain de Lille has often been confounded with other persons named Alain, in particular with another Alanus (Alain, bishop of Auxerre), Alan, abbot of Tewkesbury, Alain de Podio, etc. Certain facts of their lives have been attributed to him, as well as some of their works: thus the "Life of St Bernard" should be ascribed to Alain of Auxerre and the "Commentary upon Merlin" to Alan of Tewkesbury. Alan of Lille was not the author of a "Memoriale rerum difficilium", published under his name, nor of "Moralium dogma philosophorum", nor of the satirical "Apocalypse of Golias" once attributed to him; and it is exceedingly doubtful whether the "Dicta Alani de lapide philosophico" really issued from his pen. On the other hand, it now seems practically demonstrated that Alain de Lille was the author of the "Ars catholicae fidei" and the treatise "Contra haereticos".
In his sermons on capital sins, Alain argued that sodomy and homicide are the most serious sins, since they call forth the wrath of God, which led to the destruction of Sodom and Gomorrah. His chief work on penance, the "Liber poenitenitalis" dedicated to Henry de Sully, exercised great influence on the many manuals of penance produced as a result of the Fourth Lateran Council. Alain's identification of the sins against nature included bestiality, masturbation, oral and anal intercourse, incest, adultery and rape. In addition to his battle against moral decay, Alan wrote a work against Islam, Judaism and Christian heretics dedicated to William VIII of Montpellier.
Attribution:

</doc>
<doc id="1486" url="https://en.wikipedia.org/wiki?curid=1486" title="Alemanni">
Alemanni

The Alemanni (also "Alamanni"; "Suebi" "Swabians") were a confederation of Germanic tribes on the Upper Rhine River. First mentioned by Cassius Dio in the context of the campaign of Caracalla of 213, the Alemanni captured the in 260, and later expanded into present-day Alsace, and northern Switzerland, leading to the establishment of the Old High German language in those regions, by the eighth century named "Alamannia".
In 496, the Alemanni were conquered by Frankish leader Clovis and incorporated into his dominions. Mentioned as still pagan allies of the Christian Franks, the Alemanni were gradually Christianized during the seventh century. The is a record of their customary law during this period. Until the eighth century, Frankish suzerainty over Alemannia was mostly nominal. After an uprising by Theudebald, Duke of Alamannia, though, Carloman executed the Alamannic nobility and installed Frankish dukes. 
During the later and weaker years of the Carolingian Empire, the Alemannic counts became almost independent, and a struggle for supremacy took place between them and the Bishopric of Constance. The chief family in Alamannia was that of the counts of , who were sometimes called margraves, and one of whom, Burchard II, established the Duchy of Swabia, which was recognized by Henry the Fowler in 919 and became a stem duchy of the Holy Roman Empire.
The area settled by the Alemanni corresponds roughly to the area where Alemannic German dialects remain spoken, including German Swabia and Baden, French Alsace, German-speaking Switzerland, Liechtenstein and Austrian Vorarlberg. 
The French language name of Germany, , is derived from their name, from Old French "aleman(t)", from French loaned into a number of other languages, including Middle English which commonly used the term "Almains" for Germans. Likewise, the Arabic name for Germany is المانيا (Almania), the Spanish is Alemania, the Portuguese is Alemanha, Welsh is Yr Almaen and Persian is (Alman).
According to Gaius Asinius Quadratus (quoted in the mid-sixth century by Byzantine historian Agathias), the name "Alamanni" (Ἀλαμανοι) means "all men". It indicates that they were a conglomeration drawn from various Germanic tribes. The Romans and the Greeks called them as such mentioned. This derivation was accepted by Edward Gibbon, in his "Decline and Fall of the Roman Empire" and by the anonymous contributor of notes assembled from the papers of Nicolas Fréret, published in 1753.
This etymology has remained the standard derivation of the name.
An alternative suggestion proposes derivation from "*alah" "sanctuary".
Walafrid Strabo in the 9th century remarked, in discussing the people of Switzerland and the surrounding regions, that only foreigners called them the Alemanni, but that they gave themselves the name of "Suebi".
The Suebi are given the alternative name of "Ziuwari" (as "Cyuuari") in an Old High German gloss, interpreted by Jacob Grimm as "Martem colentes" ("worshippers of Mars").
The Alemanni were first mentioned by Cassius Dio describing the campaign of Caracalla in 213. At that time, they apparently dwelt in the basin of the Main, to the south of the Chatti.
Cassius Dio portrays the Alemanni as victims of this treacherous emperor. They had asked for his help, according to Dio, but instead he colonized their country, changed their place names, and executed their warriors under a pretext of coming to their aid. When he became ill, the Alemanni claimed to have put a hex on him. Caracalla, it was claimed, tried to counter this influence by invoking his ancestral spirits.
In retribution, Caracalla then led the Legio II "Traiana Fortis" against the Alemanni, who lost and were pacified for a time. The legion was as a result honored with the name "Germanica." The fourth-century fictional Historia Augusta, "Life of Antoninus Caracalla", relates (10.5) that Caracalla then assumed the name "Alemannicus," at which Helvius Pertinax jested that he should really be called "Geticus Maximus," because in the year before he had murdered his brother, Geta.
Through much of his short reign, Caracalla was known for unpredictable and arbitrary operations launched by surprise after a pretext of peace negotiations. If he had any reasons of state for such actions, they remained unknown to his contemporaries. Whether or not the Alemanni had been previously neutral, they were certainly further influenced by Caracalla to become thereafter notoriously implacable enemies of Rome.
This mutually antagonistic relationship is perhaps the reason why the Roman writers persisted in calling the Alemanni ”barbari," meaning "savages." The archaeology, however, shows that they were largely Romanized, lived in Roman-style houses and used Roman artifacts, the Alemannic women having adopted the Roman fashion of the "tunica" even earlier than the men.
Most of the Alemanni were probably at the time, in fact, resident in or close to the borders of Germania Superior. Although Dio is the earliest writer to mention them, Ammianus Marcellinus used the name to refer to Germans on the Limes Germanicus in the time of Trajan's governorship of the province shortly after it was formed, around 98-99 AD. At that time, the entire frontier was being fortified for the first time. Trees from the earliest fortifications found in Germania Inferior are dated by dendrochronology to 99-100 AD.
Ammianus relates (xvii.1.11) that much later the Emperor Julian undertook a punitive expedition against the Alemanni, who by then were in Alsace, and crossed the Main (Latin "Menus"), entering the forest, where the trails were blocked by felled trees. As winter was upon them, they reoccupied a
"fortification which was founded on the soil of the Alemanni that Trajan wished to be called with his own name".
In this context, the use of Alemanni is possibly an anachronism, but it reveals that Ammianus believed they were the same people, which is consistent with the location of the Alemanni of Caracalla's campaigns.
"Germania" by Tacitus (AD 90) in Chapter 42 states that the Hermunduri were a tribe certainly located in the region that later became Thuringia. Tacitus states that they traded with Rhaetia, which in Ptolemy is located across the Danube from Germania Superior, suggesting that the Alemanni originally in part derived from the Hermunduri.
However, no Hermunduri appear in Ptolemy, though after the time of Ptolemy, the Hermunduri joined with the Marcomanni in the wars of 166–180 against the empire. 
Tacitus says that the source of the Elbe is among the Hermunduri, somewhat to the east of the upper Main. He places them also between the Naristi (Varisti), whose location was at the very edge of the Black Forest, and the Marcomanni and Quadi. Moreover, the Hermunduri were broken in the Marcomannic Wars and made a separate peace with Rome. 
The Alemanni thus were probably not primarily the Hermunduri, although some elements of them may have been present.
Before the mention of Alemanni in the time of Caracalla, one would search in vain for Alemanni in the moderately detailed geography of southern Germany in Claudius Ptolemy, written in Greek in the mid-second century; at that time, the people who later used that name likely were known by other designations.
Nevertheless, some conclusions can be drawn from Ptolemy. Germania Superior is easily identified. Following up the Rhine one comes to a town, Mattiacum, which must be at the border of the Roman Germany (vicinity of Wiesbaden). Upstream from it and between the Rhine and Abnoba (in the Black Forest) are the Ingriones, Intuergi, Vangiones, Caritni and Vispi, some of whom were there since the days of the early empire or before. On the other side of the northern Black Forest were the Chatti about where Hesse is today, on the lower Main.
Historic Swabia was eventually replaced by today's Baden-Württemberg, but it had been the most significant territory of mediaeval Alamannia, comprising all Germania Superior and territory east to Bavaria. It did not include the upper Main, but that is where Caracalla campaigned. Moreover, the territory of Germania Superior was not originally included among the Alemanni's possessions.
However, if one looks for the peoples in the region from the upper Main in the north, south to the Danube and east to the Czech Republic where the Quadi and Marcomanni were located, Ptolemy does not give any tribes. The Tubanti are just south of the Chatti and at the other end of what was then the Black Forest, the Varisti, whose location is known. One possible reason for this distribution is that the population preferred not to live in the forest except in troubled times. The region between the forest and the Danube, though, included about a dozen settlements, or "cantons".
Ptolemy's view of Germans in the region indicates that the tribal structure had lost its grip in the Black Forest region and was replaced by a canton structure. The tribes stayed in the Roman province, perhaps because the Romans offered stability. Also, Caracalla perhaps felt more comfortable about campaigning in the upper Main because he was not declaring war on any specific historic tribe, such as the Chatti or Cherusci, against whom Rome had suffered grievous losses. By Caracalla's time, the name Alemanni was being used by cantons themselves banding together for purposes of supporting a citizen army (the "war bands").
The term Suebi has a double meaning in the sources. On the one hand Tacitus' "Germania" tells us (Chapters 38, 39) that they occupy more than half of Germany, use a distinctive hair style, and are spiritually centered on the Semnones. On the other hand, the Suebi of the upper Danube are described as though they were a tribe.
The solution to the puzzle as well as explaining the historical circumstances leading to the choice of the Agri Decumates as a defensive point and the concentration of Germans there are probably to be found in the German attack on the Gallic fortified town of Vesontio in 58 BC. The upper Rhine and Danube appear to form a funnel pointing straight at Vesontio.
Julius Caesar in "Gallic Wars" tells us (1.51) that Ariovistus had gathered an army from a wide region of Germany, but especially the Harudes, Marcomanni, Triboci, Vangiones, Nemetes and Sedusii. The Suebi were being invited to join. They lived in 100 cantons (4.1) from which 1000 young men per year were chosen for military service, a citizen-army by our standards and by comparison with the Roman professional army.
Ariovistus had become involved in an invasion of Gaul, which the German wished to settle. Intending to take the strategic town of Vesontio, he concentrated his forces on the Rhine near Lake Constance, and when the Suebi arrived, he crossed. The Gauls had called to Rome for military aid. Caesar occupied the town first and defeated the Germans before its walls, slaughtering most of the German army as it tried to flee across the river (1.36ff). He did not pursue the retreating remnants, leaving what was left of the German army and their dependents intact on the other side of the Rhine.
The Gauls were ambivalent in their policies toward the Romans. In 53 BC the Treveri broke their alliance and attempted to break free of Rome. Caesar foresaw that they would now attempt to ally themselves with the Germans. He crossed the Rhine to forestall that event, a successful strategy. Remembering their expensive defeat at the Battle of Vesontio, the Germans withdrew to the Black Forest, concentrating there a mixed population dominated by Suebi. As they had left their tribal homes behind, they probably took over all the former Celtic cantons along the Danube.
The Alemanni were continually engaged in conflicts with the Roman Empire in the 3rd and 4th centuries. They launched a major invasion of Gaul and northern Italy in 268, when the Romans were forced to denude much of their German frontier of troops in response to a massive invasion of the Goths from the east. Their raids throughout the three parts of Gaul were traumatic: Gregory of Tours (died ca 594) mentions their destructive force at the time of Valerian and Gallienus (253–260), when the Alemanni assembled under their "king", whom he calls Chrocus, who "by the advice, it is said, of his wicked mother, and overran the whole of the Gauls, and destroyed from their foundations all the temples which had been built in ancient times. And coming to Clermont he set on fire, overthrew and destroyed that shrine which they call "Vasso Galatae" in the Gallic tongue," martyring many Christians ("Historia Francorum" Book I.32–34). Thus 6th-century Gallo-Romans of Gregory's class, surrounded by the ruins of Roman temples and public buildings, attributed the destruction they saw to the plundering raids of the Alemanni.
In the early summer of 268, the Emperor Gallienus halted their advance into Italy, but then had to deal with the Goths. When the Gothic campaign ended in Roman victory at the Battle of Naissus in September, Gallienus' successor Claudius Gothicus turned north to deal with the Alemanni, who were swarming over all Italy north of the Po River.
After efforts to secure a peaceful withdrawal failed, Claudius forced the Alemanni to battle at the Battle of Lake Benacus in November. The Alemanni were routed, forced back into Germany, and did not threaten Roman territory for many years afterwards.
Their most famous battle against Rome took place in Argentoratum (Strasbourg), in 357, where they were defeated by Julian, later Emperor of Rome, and their king Chnodomarius was taken prisoner to Rome.
On January 2, 366, the Alemanni yet again crossed the frozen Rhine in large numbers, to invade the Gallic provinces, this time being defeated by Valentinian (see Battle of Solicinium). In the great mixed invasion of 406, the Alemanni appear to have crossed the Rhine river a final time, conquering and then settling what is today Alsace and a large part of the Swiss Plateau. The crossing is described in Wallace Breem's historical novel "Eagle in the Snow". The Chronicle of Fredegar gives the account. At "Alba Augusta" (Alba-la-Romaine) the devastation was so complete, that the Christian bishop retired to Viviers, but in Gregory's account at Mende in Lozère, also deep in the heart of Gaul, bishop Privatus was forced to sacrifice to idols in the very cave where he was later venerated. It is thought this detail may be a generic literary ploy to epitomize the horrors of barbarian violence.
The kingdom of Alamannia between Strasbourg and Augsburg lasted until 496, when the Alemanni were conquered by Clovis I at the Battle of Tolbiac. The war of Clovis with the Alemanni forms the setting for the conversion of Clovis, briefly treated by Gregory of Tours. (Book II.31) Subsequently, the Alemanni formed part of the Frankish dominions and were governed by a Frankish duke.
In 746, Carloman ended an uprising by summarily executing all Alemannic nobility at the blood court at Cannstatt, and for the following century, Alemannia was ruled by Frankish dukes. Following the treaty of Verdun of 843, Alemannia became a province of the eastern kingdom of Louis the German, the precursor of the Holy Roman Empire. The duchy persisted until 1268.
The German spoken today over the range of the former Alemanni is termed Alemannic German, and is recognised among the subgroups of the High German languages. Alemannic runic inscriptions such as those on the Pforzen buckle are among the earliest testimonies of Old High German.
The High German consonant shift is thought to have originated around the 5th century either in Alemannia or among the Lombards; before that the dialect spoken by Alemannic tribes was little different from that of other West Germanic peoples.
"Alemannia" lost its distinct jurisdictional identity when Charles Martel absorbed it into the Frankish empire, early in the 8th century. Today, "Alemannic" is a linguistic term, referring to Alemannic German, encompassing the dialects of the southern two thirds of Baden-Württemberg (German State), in western Bavaria (German State), in Vorarlberg (Austrian State), Swiss German in Switzerland and the Alsatian language of the Alsace (France).
The Alemanni established a series of territorially defined "pagi" (cantons) on the east bank of the Rhine. The exact number and extent of these "pagi" is unclear and probably changed over time.
"Pagi", usually pairs of "pagi" combined, formed kingdoms ("regna") which, it is generally believed, were permanent and hereditary. Ammianus describes Alemanni rulers with various terms: "reges excelsiores ante alios" ("paramount kings"), "reges proximi" ("neighbouring kings"), "reguli" ("petty kings") and "regales" ("princes"). This may be a formal hierarchy, or they may be vague, overlapping terms, or a combination of both. In 357, there appear to have been two paramount kings (Chnodomar and Westralp) who probably acted as presidents of the confederation and seven other kings ("reges"). Their territories were small and mostly strung along the Rhine (although a few were in the hinterland). It is possible that the "reguli" were the rulers of the two "pagi" in each kingdom. Underneath the royal class were the nobles (called "optimates" by the Romans) and warriors (called "armati" by the Romans). The warriors consisted of professional warbands and levies of free men. Each nobleman could raise an average of c. 50 warriors.
The Christianization of the Alemanni took place during Merovingian times (6th to 8th centuries). We know that in the 6th century, the Alemanni were predominantly pagan, and in the 8th century, they were predominantly Christian. The intervening 7th century was a period of genuine syncretism during which Christian symbolism and doctrine gradually grew in influence.
Some scholars have speculated that members of the Alemannic elite such as king Gibuld due to Visigothic influence may have been converted to Arianism even in the later 5th century.
In the mid-6th century, the Byzantine historian Agathias records, in the context of the wars of the Goths and Franks against Byzantium, that the Alemanni fighting among the troops of Frankish king Theudebald were like the Franks in all respects except religion, since
He also spoke of the particular ruthlessness of the Alemanni in destroying Christian sanctuaries and plundering churches while the genuine Franks were respectful towards those sanctuaries. Agathias expresses his hope that the Alemanni would assume better manners through prolonged contact with the Franks, which is by all appearances, in a manner of speaking, what eventually happened.
Apostles of the Alemanni were Columbanus and his disciple Saint Gall. Jonas of Bobbio records that Columbanus was active in Bregenz, where he disrupted a beer sacrifice to Wodan. Despite these activities, for some time, the Alemanni seem to have continued their pagan cult activities, with only superficial or syncretistic Christian elements. In particular, there is no change in burial practice, and tumulus warrior graves continued to be erected throughout Merovingian times. Syncretism of traditional Germanic animal-style with Christian symbolism is also present in artwork, but Christian symbolism becomes more and more prevalent during the 7th century. Unlike the later Christianization of the Saxons and of the Slavs, the Alemanni seem to have adopted Christianity gradually, and voluntarily, spread in emulation of the Merovingian elite.
From c. the 520s to the 620s, there was a surge of Alemannic Elder Futhark inscriptions. About 70 specimens have survived, roughly half of them on fibulae, others on belt buckles (see Pforzen buckle, Bülach fibula) and other jewelry and weapon parts. Use of runes subsides with the advance of Christianity.
The Nordendorf fibula (early 7th century) clearly records pagan theonyms, "logaþorewodanwigiþonar " read as "Wodan and Donar are magicians/sorcerers", but this may be interpreted as either a pagan invocation of the powers of these deities, or a Christian protective charm against them.
A runic inscription on a fibula found at Bad Ems reflects Christian pious sentiment (and is also explicitly marked with a Christian cross), reading "god fura dih deofile ᛭" ("God for/before you, Theophilus!", or alternatively "God before you, Devil!"). Dated to between AD 660 and 690, it marks the end of the native Alemannic tradition of runic literacy. Bad Ems is in Rhineland-Palatinate, on the northwestern boundary of Alemannic settlement, where Frankish influence would have been strongest.
The establishment of the bishopric of Konstanz cannot be dated exactly and was possibly undertaken by Columbanus himself (before 612). In any case, it existed by 635, when Gunzo appointed John of Grab bishop. Constance was a missionary bishopric in newly converted lands, and did not look back on late Roman church history unlike the Raetian bishopric of Chur (established 451) and Basel (an episcopal seat from 740, and which continued the line of Bishops of Augusta Raurica, see Bishop of Basel). The establishment of the church as an institution recognized by worldly rulers is also visible in legal history. In the early 7th century "Pactus Alamannorum" hardly ever mentions the special privileges of the church, while Lantfrid's "Lex Alamannorum" of 720 has an entire chapter reserved for ecclesial matters alone.
A genetic study published in "Science Advances" in September 2018 examined the remains of eight individuals buried at a 7th century Alemannic graveyard in Niederstotzingen, Germany. This is the richest and most complete Alemannic graveyard ever found. The highest ranking individual at the graveyard was a male with Frankish grave goods. Four males were found to be closely related to him. They were all cariers of types of the paternal haplogroup R1b1a2a1a1c2b2b. A sixth male was a carrier of the paternal haplogroup R1b1a2a1a1c2b2b1a1 and the maternal haplogroup U5a1a1. Along with the five closely related individuals, he displayed close genetic links to northern and eastern Europe, particularly Lithuania and Iceland. Two individuals buried at the cemetery were found to be genetically different from both the others and each other, displaying genetic links to Southern Europe, particularly northern Spain. Along with the sixth male, they might have been adoptees.

</doc>
<doc id="1488" url="https://en.wikipedia.org/wiki?curid=1488" title="NYSE American">
NYSE American

NYSE American, formerly known as the American Stock Exchange (AMEX), and more recently as NYSE MKT, is an American stock exchange situated in New York City. AMEX was previously a mutual organization, owned by its members. Until 1953, it was known as the New York Curb Exchange.
NYSE Euronext acquired AMEX on October 1, 2008, with AMEX integrated with the Alternext European small-cap exchange and renamed the NYSE Alternext U.S. In March 2009, NYSE Alternext U.S. was changed to NYSE Amex Equities. On May 10, 2012, NYSE Amex Equities changed its name to NYSE MKT LLC.
Following the SEC approval of competing stock exchange IEX in 2016, NYSE MKT rebranded as NYSE American and introduced a 350-microsecond delay in trading, referred to as a "speed bump", which is also present on the IEX.
The exchange grew out of the loosely organized curb market of curbstone brokers on Broad Street in Manhattan. Efforts to organize and standardize the market started early in the 20th century under Emanuel S. Mendels and Carl H. Pforzheimer. The curb brokers had been kicked out of the Mills Building front by 1907, and had moved to the pavement outside the Blair Building where cabbies lined up. There they were given a "little domain of asphalt" fenced off by the police on Broad Street between Exchange Place and Beaver Street. As of 1907, the curb market operated starting at 10 AM, each day except Sundays, until a gong at 3 PM. Orders for the purchase and sale of securities were shouted down from the windows of nearby brokerages, with the execution of the sale then shouted back up to the brokerage. 
As of 1907, E. S. Mendels gave the brokers rules "by right of seniority", but the curb brokers intentionally avoided organizing. According to the "Times", this came from a general belief that if a curb exchange was organized, the exchange authorities would force members to sell their other exchange memberships. However, in 1908 the New York Curb Market Agency was established, which developed appropriate trading rules for curbstone brokers, organized by Mendels. The informal Curb Association formed in 1910 to weed out undesirables. The curb exchange was for years at odds with the New York Stock Exchange (NYSE), or "Big Board", operating several buildings away. Explained the "New York Times" in 1910, the Big Board looked at the curb as "a trading place for 'cats and dogs.'" On April 1, 1910, however, when the NYSE abolished its unlisted department, the NYSE stocks "made homeless by the abolition" were "refused domicile" by the curb brokers on Broad Street until they had complied with the "Curb list" of requirements. In 1911, Mendels and his advisers drew up a constitution and formed the New York Curb Market Association, which can be considered the first formal constitution of American Stock Exchange.
In 1920, journalist Edwin C. Hill wrote that the curb exchange on lower Broad Street was a "roaring, swirling whirlpool" that "tears control of a gold-mine from an unlucky operator, and pauses to auction a puppy-dog. It is like nothing else under the astonished sky that is its only roof." After a group of Curb brokers formed a real estate company to design a building, Starrett & Van Vleck designed the new exchange building on Greenwich Street in Lower Manhattan between Thames and Rector, at 86 Trinity Place. It opened in 1921, and the curbstone brokers moved indoors on June 27, 1921. In 1929, the New York Curb Market changed its name to the New York Curb Exchange. The Curb Exchange soon became the leading international stock market, and according to historian Robert Sobel, "had more individual foreign issues on its list than [...] all other American securities markets combined."
Edward Reid McCormick was the first president of the New York Curb Market Association and is credited with moving the market indoors. George Rea was approached about the position of president of the New York Curb Exchange in 1939. He was unanimously elected as the first paid president in the history of the Curb Exchange. He was paid $25,000 per year (equivalent to $ today) and held the position for three years before offering his resignation in 1942. He left the position having "done such a good job that there is virtually no need for a full-time successor."
In 1953 the Curb Exchange was renamed the American Stock Exchange. The exchange was shaken by a scandal in 1961, and in 1962 began a reorganization. Its reputation recently damaged by charges of mismanagement, in 1962 the American Stock Exchange named Edwin Etherington its president. Writes CNN, he and executive vice president Paul Kolton were "tapped in 1962 to clean up and reinvigorate the scandal-plagued American Stock Exchange." At AMEX for five years, he was credited with improving opportunities for minorities and women. In 1971, Johnson Products Company became the first African American-owned company to be listed on the American Stock Exchange.
As of 1971, it was the second largest stock exchange in the United States. Paul Kolton succeeded Ralph S. Saul as AMEX president on June 17, 1971, making him the first person to be selected from within the exchange to serve as its leader, succeeding Ralph S. Saul, who announced his resignation in March 1971. In November 1972, Kolton was named as the exchange's first chief executive officer and its first salaried top executive. As chairman, Kolton oversaw the introduction of options trading. Kolton opposed the idea of a merger with the New York Stock Exchange while he headed the exchange saying that "two independent, viable exchanges are much more likely to be responsive to new pressures and public needs than a single institution". Kolton announced in July 1977 that he would be leaving his position at the American Exchange in November of that year.
In 1977, Thomas Peterffy purchased a seat on the American Stock Exchange and played a role in developing Interactive Brokers, an electronic trading platform. Peterffy created a major stir among traders by introducing handheld computers onto the trading floor in the early 1980s.
As of 2003, AMEX was the only U.S. stock market to permit the transmission of buy and sell orders through hand signals.
In October 2008 NYSE Euronext completed acquisition of the AMEX for $260 million in stock. Before the closing of the acquisition, NYSE Euronext announced that the AMEX would be integrated with the Alternext European small-cap exchange and renamed the NYSE Alternext U.S. The American Stock Exchange merged with the New York Stock Exchange (NYSE Euronext) on October 1, 2008. Post merger, the Amex equities business was branded "NYSE Alternext US". As part of the re-branding exercise, NYSE Alternext US was re-branded as NYSE Amex Equities. On December 1, 2008, the Curb Exchange building at 86 Trinity Place was closed, and the Amex Equities trading floor was moved to the NYSE Trading floor at 11 Wall Street. 90 years after its 1921 opening, the old New York Curb Market building was empty but remained standing. In March 2009, NYSE Alternext U.S. was changed to NYSE Amex Equities. On May 10, 2012, NYSE Amex Equities changed its name to NYSE MKT LLC.
In June 2016, a competing stock exchange IEX (which operated with a 350-microsecond delay in trading), gained approval from the SEC, despite lobbying protests by the NYSE and other exchanges and trading firms. 
On July 24, 2017, the NYSE renamed NYSE MKT to NYSE American, and announced plans to introduce its own 350-microsecond "speed bump" in trading on the small and mid-cap company exchange.

</doc>
<doc id="1490" url="https://en.wikipedia.org/wiki?curid=1490" title="August 17">
August 17


</doc>
<doc id="1491" url="https://en.wikipedia.org/wiki?curid=1491" title="August 12">
August 12

It is the peak of the Perseid meteor shower. It is also known as the "Glorious Twelfth" in the United Kingdom, as it marks the traditional start of the grouse shooting season.

</doc>
<doc id="1494" url="https://en.wikipedia.org/wiki?curid=1494" title="Alfred Russel Wallace">
Alfred Russel Wallace

Alfred Russel Wallace (8 January 18237 November 1913) was a British naturalist, explorer, geographer, anthropologist, biologist and illustrator. He is best known for independently conceiving the theory of evolution through natural selection; his paper on the subject was jointly published with some of Charles Darwin's writings in 1858." "This prompted Darwin to publish "On the Origin of Species".
Like Darwin, Wallace did extensive fieldwork; first in the Amazon River basin, and then in the Malay Archipelago, where he identified the faunal divide now termed the Wallace Line, which separates the Indonesian archipelago into two distinct parts: a western portion in which the animals are largely of Asian origin, and an eastern portion where the fauna reflect Australasia.
He was considered the 19th century's leading expert on the geographical distribution of animal species and is sometimes called the "father of biogeography". Wallace was one of the leading evolutionary thinkers of the 19th century and made many other contributions to the development of evolutionary theory besides being co-discoverer of natural selection. These included the concepts of warning colouration in animals, and reinforcement (sometimes known as the Wallace effect), a hypothesis on how natural selection could contribute to speciation by encouraging the development of barriers against hybridisation. Wallace's 1904 book "Man's Place in the Universe" was the first serious attempt by a biologist to evaluate the likelihood of life on other planets. He was also one of the first scientists to write a serious exploration of the subject of whether there was life on Mars.
Wallace was strongly attracted to unconventional ideas (such as evolution). His advocacy of spiritualism and his belief in a non-material origin for the higher mental faculties of humans strained his relationship with some members of the scientific establishment.
Aside from scientific work, he was a social activist who was critical of what he considered to be an unjust social and economic system (capitalism) in 19th-century Britain. His interest in natural history resulted in his being one of the first prominent scientists to raise concerns over the environmental impact of human activity. He was also a prolific author who wrote on both scientific and social issues; his account of his adventures and observations during his explorations in Singapore, Indonesia and Malaysia, "The Malay Archipelago", was both popular and highly regarded. Since its publication in 1869, it has never been out of print.
Wallace had financial difficulties throughout much of his life. His Amazon and Far Eastern trips were supported by the sale of specimens he collected and, after he lost most of the considerable money he made from those sales in unsuccessful investments, he had to support himself mostly from the publications he produced. Unlike some of his contemporaries in the British scientific community, such as Darwin and Charles Lyell, he had no family wealth to fall back on, and he was unsuccessful in finding a long-term salaried position, receiving no regular income until he was awarded a small government pension, through Darwin's efforts, in 1881.
Alfred Wallace was born in the Welsh village of Llanbadoc, near Usk, Monmouthshire. He was the eighth of nine children of Thomas Vere Wallace and Mary Anne Greenell. Mary Anne was English; Thomas Wallace was probably of Scottish ancestry. His family, like many Wallaces, claimed a connection to William Wallace, a leader of Scottish forces during the Wars of Scottish Independence in the 13th century. Thomas Wallace graduated in law but never practised law. He owned some income-generating property, but bad investments and failed business ventures resulted in a steady deterioration of the family's financial position. His mother was from a middle-class English family from Hertford, north of London. When Wallace was five years old, his family moved to Hertford. There he attended Hertford Grammar School until financial difficulties forced his family to withdraw him in 1836 when he was aged 14.
Wallace then moved to London to board with his older brother John, a 19-year-old apprentice builder. This was a stopgap measure until William, his oldest brother, was ready to take him on as an apprentice surveyor. While in London, Alfred attended lectures and read books at the London Mechanics Institute (current Birkbeck, University of London). Here he was exposed to the radical political ideas of the Welsh social reformer Robert Owen and of Thomas Paine. He left London in 1837 to live with William and work as his apprentice for six years.
At the end of 1839, they moved to Kington, Hereford, near the Welsh border, before eventually settling at Neath in Glamorgan in Wales. Between 1840 and 1843, Wallace did land surveying work in the countryside of the west of England and Wales. By the end of 1843, William's business had declined due to difficult economic conditions, and Wallace, at the age of 20, left in January.
One result of Wallace's early travels is a modern controversy about his nationality. Since Wallace was born in Monmouthshire, some sources have considered him to be Welsh. However, some historians have questioned this because neither of his parents was Welsh, his family only briefly lived in Monmouthshire, the Welsh people Wallace knew in his childhood considered him to be English, and because Wallace himself consistently referred to himself as English rather than Welsh (even when writing about his time in Wales). One Wallace scholar has stated that the most reasonable interpretation is therefore that he was an Englishman born in Wales.
After a brief period of unemployment, he was hired as a master at the Collegiate School in Leicester to teach drawing, mapmaking, and surveying. Wallace spent many hours at the library in Leicester: he read "An Essay on the Principle of Population" by Thomas Robert Malthus, and one evening he met the entomologist Henry Bates. Bates was 19 years old, and in 1843 he had published a paper on beetles in the journal "Zoologist". He befriended Wallace and started him collecting insects. His brother William died in March 1845, and Wallace left his teaching position to assume control of his brother's firm in Neath, but his brother John and he were unable to make the business work. After a few months, Wallace found work as a civil engineer for a nearby firm that was working on a survey for a proposed railway in the Vale of Neath.
Wallace's work on the survey involved spending a lot of time outdoors in the countryside, allowing him to indulge his new passion for collecting insects. Wallace persuaded his brother John to join him in starting another architecture and civil engineering firm, which carried out a number of projects, including the design of a building for the Neath Mechanics' Institute, founded in 1843. William Jevons, the founder of that institute, was impressed by Wallace and persuaded him to give lectures there on science and engineering. In the autumn of 1846, John and he purchased a cottage near Neath, where they lived with their mother and sister Fanny (his father had died in 1843).
During this period, he read avidly, exchanging letters with Bates about Robert Chambers' anonymously published evolutionary treatise "Vestiges of the Natural History of Creation", Charles Darwin's "The Voyage of the Beagle", and Charles Lyell's "Principles of Geology".
Inspired by the chronicles of earlier and contemporary travelling naturalists, including Alexander von Humboldt, Ida Laura Pfeiffer, Charles Darwin and especially William Henry Edwards, Wallace decided that he too wanted to travel abroad as a naturalist. In 1848, Wallace and Henry Bates left for Brazil aboard the "Mischief". Their intention was to collect insects and other animal specimens in the Amazon Rainforest for their private collections, selling the duplicates to museums and collectors back in Britain in order to fund the trip. Wallace also hoped to gather evidence of the transmutation of species.
Wallace and Bates spent most of their first year collecting near Belém, then explored inland separately, occasionally meeting to discuss their findings. In 1849, they were briefly joined by another young explorer, botanist Richard Spruce, along with Wallace's younger brother Herbert. Herbert left soon thereafter (dying two years later from yellow fever), but Spruce, like Bates, would spend over ten years collecting in South America.
Wallace continued charting the Rio Negro for four years, collecting specimens and making notes on the peoples and languages he encountered as well as the geography, flora, and fauna. On 12 July 1852, Wallace embarked for the UK on the brig "Helen". After 25 days at sea, the ship's cargo caught fire and the crew was forced to abandon ship. All of the specimens Wallace had on the ship, mostly collected during the last, and most interesting, two years of his trip, were lost. He managed to save a few notes and pencil sketches and little else.
Wallace and the crew spent ten days in an open boat before being picked up by the brig "Jordeson", which was sailing from Cuba to London. The "Jordeson"'s provisions were strained by the unexpected passengers, but after a difficult passage on very short rations the ship finally reached its destination on 1 October 1852.
After his return to the UK, Wallace spent 18 months in London living on the insurance payment for his lost collection and selling a few specimens that had been shipped back to Britain prior to his starting his exploration of the Rio Negro until the Indian town of Jativa on Orinoco River basin and as far west as Micúru (Mitú) on the Vaupés River. He was deeply impressed by the grandeur of the virgin forest, by the variety and beauty of the butterflies and birds, and by his first encounter with Indians on the Uaupés River area, an experience he never forgot. During this period, despite having lost almost all of the notes from his South American expedition, he wrote six academic papers (which included "On the Monkeys of the Amazon") and two books; "Palm Trees of the Amazon and Their Uses" and "Travels on the Amazon". He also made connections with a number of other British naturalists.
From 1854 to 1862, age 31 to 39, Wallace travelled through the Malay Archipelago or East Indies (now Singapore, Malaysia and Indonesia), to collect specimens for sale and to study natural history. A set of 80 bird skeletons he collected in Indonesia and associated documentation can be found in the Cambridge University Museum of Zoology. Wallace had as many as a hundred assistants who collected on his behalf. Among these, his most trusted assistant was a Malay by the name of Ali who later called himself Ali Wallace. While Wallace collected insects, many of the bird specimens were collected by his assistants including around 5000 collected and prepared by Ali. Wallace's observations of the marked zoological differences across a narrow strait in the archipelago led to his proposing the zoogeographical boundary now known as the Wallace line.
Wallace collected more than 125,000 specimens in the Malay Archipelago (more than 83,000 beetles alone). Several thousand of them represented species new to science. One of his better-known species descriptions during this trip is that of the gliding tree frog "Rhacophorus nigropalmatus", known as Wallace's flying frog. While he was exploring the archipelago, he refined his thoughts about evolution and had his famous insight on natural selection. In 1858 he sent an article outlining his theory to Darwin; it was published, along with a description of Darwin's own theory, in the same year.
Accounts of his studies and adventures there were eventually published in 1869 as "The Malay Archipelago", which became one of the most popular books of scientific exploration of the 19th century, and has never been out of print. It was praised by scientists such as Darwin (to whom the book was dedicated), and Charles Lyell, and by non-scientists such as the novelist Joseph Conrad, who called it his "favorite bedside companion" and used it as source of information for several of his novels, especially "Lord Jim".
In 1862, Wallace returned to England, where he moved in with his sister Fanny Sims and her husband Thomas. While recovering from his travels, Wallace organised his collections and gave numerous lectures about his adventures and discoveries to scientific societies such as the Zoological Society of London. Later that year, he visited Darwin at Down House, and became friendly with both Charles Lyell and Herbert Spencer. During the 1860s, Wallace wrote papers and gave lectures defending natural selection. He also corresponded with Darwin about a variety of topics, including sexual selection, warning colouration, and the possible effect of natural selection on hybridisation and the divergence of species. In 1865, he began investigating spiritualism.
After a year of courtship, Wallace became engaged in 1864 to a young woman whom, in his autobiography, he would only identify as Miss L. Miss L. was the daughter of Lewis Leslie who played chess with Wallace. However, to Wallace's great dismay, she broke off the engagement. In 1866, Wallace married Annie Mitten. Wallace had been introduced to Mitten through the botanist Richard Spruce, who had befriended Wallace in Brazil and who was also a good friend of Annie Mitten's father, William Mitten, an expert on mosses. In 1872, Wallace built the Dell, a house of concrete, on land he leased in Grays in Essex, where he lived until 1876. The Wallaces had three children: Herbert (1867–1874), Violet (1869–1945), and William (1871–1951).
In the late 1860s and 1870s, Wallace was very concerned about the financial security of his family. While he was in the Malay Archipelago, the sale of specimens had brought in a considerable amount of money, which had been carefully invested by the agent who sold the specimens for Wallace. However, on his return to the UK, Wallace made a series of bad investments in railways and mines that squandered most of the money, and he found himself badly in need of the proceeds from the publication of "The Malay Archipelago".
Despite assistance from his friends, he was never able to secure a permanent salaried position such as a curatorship in a museum. To remain financially solvent, Wallace worked grading government examinations, wrote 25 papers for publication between 1872 and 1876 for various modest sums, and was paid by Lyell and Darwin to help edit some of their own works.
In 1876, Wallace needed a £500 advance from the publisher of "The Geographical Distribution of Animals" to avoid having to sell some of his personal property. Darwin was very aware of Wallace's financial difficulties and lobbied long and hard to get Wallace awarded a government pension for his lifetime contributions to science. When the £200 annual pension was awarded in 1881, it helped to stabilise Wallace's financial position by supplementing the income from his writings.
John Stuart Mill was impressed by remarks criticising English society that Wallace had included in "The Malay Archipelago". Mill asked him to join the general committee of his Land Tenure Reform Association, but the association dissolved after Mill's death in 1873. Wallace had written only a handful of articles on political and social issues between 1873 and 1879 when, at the age of 56, he entered the debates over trade policy and land reform in earnest. He believed that rural land should be owned by the state and leased to people who would make whatever use of it that would benefit the largest number of people, thus breaking the often-abused power of wealthy landowners in British society.
In 1881, Wallace was elected as the first president of the newly formed Land Nationalisation Society. In the next year, he published a book, "Land Nationalisation; Its Necessity and Its Aims", on the subject. He criticised the UK's free trade policies for the negative impact they had on working-class people. In 1889, Wallace read "Looking Backward" by Edward Bellamy and declared himself a socialist, despite his earlier foray as a speculative investor. After reading "Progress and Poverty", the best selling book by the progressive land reformist Henry George, Wallace described it as "Undoubtedly the most remarkable and important book of the present century."
Wallace opposed eugenics, an idea supported by other prominent 19th-century evolutionary thinkers, on the grounds that contemporary society was too corrupt and unjust to allow any reasonable determination of who was fit or unfit. In the 1890 article "Human Selection" he wrote, "Those who succeed in the race for wealth are by no means the best or the most intelligent ..." In 1898, Wallace wrote a paper advocating a pure paper money system, not backed by silver or gold, which impressed the economist Irving Fisher so much that he dedicated his 1920 book "Stabilizing the Dollar" to Wallace.
Wallace wrote on other social and political topics including his support for women's suffrage, and repeatedly on the dangers and wastefulness of militarism. In an essay published in 1899 Wallace called for popular opinion to be rallied against warfare by showing people: "...that all modern wars are dynastic; that they are caused by the ambition, the interests, the jealousies, and the insatiable greed of power of their rulers, or of the great mercantile and financial classes which have power and influence over their rulers; and that the results of war are never good for the people, who yet bear all its burthens". In a letter published by the Daily Mail in 1909, with aviation in its infancy, he advocated an international treaty to ban the military use of aircraft, arguing against the idea "...that this new horror is "inevitable," and that all we can do is to be sure and be in the front rank of the aerial assassins—for surely no other term can so fitly describe the dropping of, say, ten thousand bombs at midnight into an enemy's capital from an invisible flight of airships."
In 1898, Wallace published a book entitled "The Wonderful Century: Its Successes and Its Failures" about developments in the 19th century. The first part of the book covered the major scientific and technical advances of the century; the second part covered what Wallace considered to be its social failures including: the destruction and waste of wars and arms races, the rise of the urban poor and the dangerous conditions in which they lived and worked, a harsh criminal justice system that failed to reform criminals, abuses in a mental health system based on privately owned sanatoriums, the environmental damage caused by capitalism, and the evils of European colonialism. Wallace continued his social activism for the rest of his life, publishing the book "The Revolt of Democracy" just weeks before his death.
Wallace continued his scientific work in parallel with his social commentary. In 1880, he published "Island Life" as a sequel to "The Geographic Distribution of Animals". In November 1886, Wallace began a ten-month trip to the United States to give a series of popular lectures. Most of the lectures were on Darwinism (evolution through natural selection), but he also gave speeches on biogeography, spiritualism, and socio-economic reform. During the trip, he was reunited with his brother John who had emigrated to California years before. He also spent a week in Colorado, with the American botanist Alice Eastwood as his guide, exploring the flora of the Rocky Mountains and gathering evidence that would lead him to a theory on how glaciation might explain certain commonalities between the mountain flora of Europe, Asia and North America, which he published in 1891 in the paper "English and American Flowers". He met many other prominent American naturalists and viewed their collections. His 1889 book "Darwinism" used information he collected on his American trip and information he had compiled for the lectures.
On 7 November 1913, Wallace died at home in the country house he called Old Orchard, which he had built a decade earlier. He was 90 years old. His death was widely reported in the press. "The New York Times" called him "the last of the giants belonging to that wonderful group of intellectuals that included, among others, Darwin, Huxley, Spencer, Lyell, and Owen, whose daring investigations revolutionised and evolutionised the thought of the century." Another commentator in the same edition said: "No apology need be made for the few literary or scientific follies of the author of that great book on the 'Malay Archipelago'."
Some of Wallace's friends suggested that he be buried in Westminster Abbey, but his wife followed his wishes and had him buried in the small cemetery at Broadstone, Dorset. Several prominent British scientists formed a committee to have a medallion of Wallace placed in Westminster Abbey near where Darwin had been buried. The medallion was unveiled on 1 November 1915.
Unlike Darwin, Wallace began his career as a travelling naturalist already believing in the transmutation of species. The concept had been advocated by Jean-Baptiste Lamarck, Geoffroy Saint-Hilaire, Erasmus Darwin, and Robert Grant, among others. It was widely discussed, but not generally accepted by leading naturalists, and was considered to have radical, even revolutionary connotations.
Prominent anatomists and geologists such as Georges Cuvier, Richard Owen, Adam Sedgwick, and Charles Lyell attacked it vigorously. It has been suggested that Wallace accepted the idea of the transmutation of species in part because he was always inclined to favour radical ideas in politics, religion and science, and because he was unusually open to marginal, even fringe, ideas in science.
He was also profoundly influenced by Robert Chambers' work, "Vestiges of the Natural History of Creation", a highly controversial work of popular science published anonymously in 1844 that advocated an evolutionary origin for the solar system, the earth, and living things. Wallace wrote to Henry Bates in 1845:
In 1847, he wrote to Bates:
Wallace deliberately planned some of his fieldwork to test the hypothesis that under an evolutionary scenario closely related species should inhabit neighbouring territories. During his work in the Amazon basin, he came to realise that geographical barriers—such as the Amazon and its major tributaries—often separated the ranges of closely allied species, and he included these observations in his 1853 paper "On the Monkeys of the Amazon". Near the end of the paper he asks the question, "Are very closely allied species ever separated by a wide interval of country?"
In February 1855, while working in Sarawak on the island of Borneo, Wallace wrote "On the Law which has Regulated the Introduction of New Species", a paper which was published in the "Annals and Magazine of Natural History" in September 1855. In this paper, he discussed observations regarding the geographic and geologic distribution of both living and fossil species, what would become known as biogeography. His conclusion that "Every species has come into existence coincident both in space and time with a closely allied species" has come to be known as the "Sarawak Law". Wallace thus answered the question he had posed in his earlier paper on the monkeys of the Amazon river basin. Although it contained no mention of any possible mechanisms for evolution, this paper foreshadowed the momentous paper he would write three years later.
The paper shook Charles Lyell's belief that species were immutable. Although his friend Charles Darwin had written to him in 1842 expressing support for transmutation, Lyell had continued to be strongly opposed to the idea. Around the start of 1856, he told Darwin about Wallace's paper, as did Edward Blyth who thought it "Good! Upon the whole! ... Wallace has, I think put the matter well; and according to his theory the various domestic races of animals have been fairly developed into "species"." Despite this hint, Darwin mistook Wallace's conclusion for the progressive creationism of the time and wrote that it was "nothing very new ... Uses my simile of tree [but] it seems all creation with him." Lyell was more impressed and opened a notebook on species, in which he grappled with the consequences, particularly for human ancestry. Darwin had already shown his theory to their mutual friend Joseph Hooker and now, for the first time, he spelt out the full details of natural selection to Lyell. Although Lyell could not agree, he urged Darwin to publish to establish priority. Darwin demurred at first, then began writing up a "species sketch" of his continuing work in May 1856.
By February 1858, Wallace had been convinced by his biogeographical research in the Malay Archipelago that evolution was real. He later wrote in his autobiography:
According to his autobiography, it was while he was in bed with a fever that Wallace thought about Malthus's idea of positive checks on human population and had the idea of natural selection. His autobiography says that he was on the island of Ternate at the time; but historians have said that based on his journal he was on the island of Gilolo. From 1858 to 1861, he rented a house on Ternate from the Dutchman Maarten Dirk van Renesse van Duivenbode, which he used as a base for expeditions to other islands such as Gilolo.
Wallace describes how he discovered natural selection as follows:
Wallace had once briefly met Darwin, and was one of the correspondents whose observations Darwin used to support his own theories. Although Wallace's first letter to Darwin has been lost, Wallace carefully kept the letters he received. In the first letter, dated 1 May 1857, Darwin commented that Wallace's letter of 10 October which he had recently received, as well as Wallace's paper "On the Law which has regulated the Introduction of New Species" of 1855, showed that they thought alike, with similar conclusions, and said that he was preparing his own work for publication in about two years time. The second letter, dated 22 December 1857, said how glad he was that Wallace was theorising about distribution, adding that "without speculation there is no good and original observation" but commented that "I believe I go much further than you". Wallace believed this and sent Darwin his February 1858 essay, "On the Tendency of Varieties to Depart Indefinitely From the Original Type", asking Darwin to review it and pass it to Charles Lyell if he thought it worthwhile. Although Wallace had sent several articles for journal publication during his travels through the Malay archipelago, the Ternate essay was in a private letter. Darwin received the essay on 18 June 1858. Although the essay did not use Darwin's term "natural selection", it did outline the mechanics of an evolutionary divergence of species from similar ones due to environmental pressures. In this sense, it was very similar to the theory that Darwin had worked on for 20 years, but had yet to publish. Darwin sent the manuscript to Charles Lyell with a letter saying "he could not have made a better short abstract! Even his terms now stand as heads of my chapters ... he does not say he wishes me to publish, but I shall, of course, at once write and offer to send to any journal." Distraught about the illness of his baby son, Darwin put the problem to Charles Lyell and Joseph Hooker, who decided to publish the essay in a joint presentation together with unpublished writings which highlighted Darwin's priority. Wallace's essay was presented to the Linnean Society of London on 1 July 1858, along with excerpts from an essay which Darwin had disclosed privately to Hooker in 1847 and a letter Darwin had written to Asa Gray in 1857.
Communication with Wallace in the far-off Malay Archipelago involved months of delay, so he was not part of this rapid publication. Wallace accepted the arrangement after the fact, happy that he had been included at all, and never expressed bitterness in public or in private. Darwin's social and scientific status was far greater than Wallace's, and it was unlikely that, without Darwin, Wallace's views on evolution would have been taken seriously. Lyell and Hooker's arrangement relegated Wallace to the position of co-discoverer, and he was not the social equal of Darwin or the other prominent British natural scientists. However, the joint reading of their papers on natural selection associated Wallace with the more famous Darwin. This, combined with Darwin's (as well as Hooker's and Lyell's) advocacy on his behalf, would give Wallace greater access to the highest levels of the scientific community. The reaction to the reading was muted, with the president of the Linnean Society remarking in May 1859 that the year had not been marked by any striking discoveries; but, with Darwin's publication of "On the Origin of Species" later in 1859, its significance became apparent. When Wallace returned to the UK, he met Darwin. Although some of Wallace's iconoclastic opinions in the ensuing years would test Darwin's patience, they remained on friendly terms for the rest of Darwin's life.
Over the years, a few people have questioned this version of events. In the early 1980s, two books, one written by Arnold Brackman and another by John Langdon Brooks, even suggested not only that there had been a conspiracy to rob Wallace of his proper credit, but that Darwin had actually stolen a key idea from Wallace to finish his own theory. These claims have been examined in detail by a number of scholars who have not found them convincing. Shipping schedules show that, contrary to these accusations, Wallace's letter could not have been delivered earlier than the date shown in Darwin's letter to Lyell.
After Wallace returned to England in 1862, he became one of the staunchest defenders of Darwin's "On the Origin of Species". In one incident in 1863 that particularly pleased Darwin, Wallace published the short paper "Remarks on the Rev. S. Haughton's Paper on the Bee's Cell, And on the Origin of Species" to rebut a paper by a professor of geology at the University of Dublin that had sharply criticised Darwin's comments in the "Origin" on how hexagonal honey bee cells could have evolved through natural selection.
An even longer defence was a 1867 article in the "Quarterly Journal of Science" called "Creation by Law". It reviewed the book "The Reign of Law" by George Campbell, the 8th Duke of Argyll which aimed to refute natural selection.
After an 1870 meeting of the British Science Association, Wallace wrote to Darwin complaining that there were "no opponents left who know anything of natural history, so that there are none of the good discussions we used to have."
Historians of science have noted that, while Darwin considered the ideas in Wallace's paper to be essentially the same as his own, there were differences. Darwin emphasised competition between individuals of the same species to survive and reproduce, whereas Wallace emphasised environmental pressures on varieties and species forcing them to become adapted to their local conditions, leading populations in different locations to diverge. Some historians, notably Peter J. Bowler, have suggested the possibility that in the paper he mailed to Darwin, Wallace did not discus selection of individual variations but group selection. However, Malcolm Kottler showed that Wallace was indeed discussing individual variations.
Others have noted that another difference was that Wallace appeared to have envisioned natural selection as a kind of feedback mechanism keeping species and varieties adapted to their environment (now called 'stabilizing", as opposed to 'directional' selection). They point to a largely overlooked passage of Wallace's famous 1858 paper:
The cybernetician and anthropologist Gregory Bateson observed in the 1970s that, although writing it only as an example, Wallace had "probably said the most powerful thing that'd been said in the 19th Century". Bateson revisited the topic in his 1979 book "Mind and Nature: A Necessary Unity", and other scholars have continued to explore the connection between natural selection and systems theory.
Warning coloration was one of a number of contributions by Wallace in the area of the evolution of animal coloration and in particular protective coloration. It was also a lifelong disagreement with Darwin about the importance of sexual selection.
In 1867, Darwin wrote to Wallace about a problem in explaining how some caterpillars could have evolved conspicuous colour schemes. Darwin had come to believe that many conspicuous animal colour schemes were due to sexual selection. However, this could not apply to caterpillars. Wallace responded that he and Henry Bates had observed that many of the most spectacular butterflies had a peculiar odour and taste, and that he had been told by John Jenner Weir that birds would not eat a certain kind of common white moth because they found it unpalatable. "Now, as the white moth is as conspicuous at dusk as a coloured caterpillar in the daylight", it seemed likely that the conspicuous colours served as a warning to predators and thus could have evolved through natural selection. Darwin was impressed by the idea. At a later meeting of the Entomological Society, Wallace asked for any evidence anyone might have on the topic. In 1869, Weir published data from experiments and observations involving brightly coloured caterpillars that supported Wallace's idea.
Wallace attributed less importance than Darwin to sexual selection. In his 1878 book "Tropical Nature and Other Essays", he wrote extensively about the coloration of animals and plants and proposed alternative explanations for a number of cases Darwin had attributed to sexual selection. He revisited the topic at length in his 1889 book "Darwinism". In 1890, he wrote a critical review in "Nature" of his friend Edward Bagnall Poulton's "The Colours of Animals" which supported Darwin on sexual selection, attacking especially Poulton's claims on the "aesthetic preferences of the insect world".
In 1889, Wallace wrote the book "Darwinism", which explained and defended natural selection. In it, he proposed the hypothesis that natural selection could drive the reproductive isolation of two varieties by encouraging the development of barriers against hybridisation. Thus it might contribute to the development of new species. He suggested the following scenario: When two populations of a species had diverged beyond a certain point, each adapted to particular conditions, hybrid offspring would be less adapted than either parent form and so natural selection would tend to eliminate the hybrids. Furthermore, under such conditions, natural selection would favour the development of barriers to hybridisation, as individuals that avoided hybrid matings would tend to have more fit offspring, and thus contribute to the reproductive isolation of the two incipient species.
This idea came to be known as the Wallace effect, later referred to as reinforcement. Wallace had suggested to Darwin that natural selection could play a role in preventing hybridisation in private correspondence as early as 1868, but had not worked it out to this level of detail. It continues to be a topic of research in evolutionary biology today, with both computer simulation and empirical results supporting its validity.
In 1864, Wallace published a paper, "The Origin of Human Races and the Antiquity of Man Deduced from the Theory of 'Natural Selection'", applying the theory to humankind. Darwin had not yet publicly addressed the subject, although Thomas Huxley had in "Evidence as to Man's Place in Nature". He explained the apparent stability of the human stock by pointing to the vast gap in cranial capacities between humans and the great apes. Unlike some other Darwinists, including Darwin himself, he did not "regard modern primitives as almost filling the gap between man and ape".
He saw the evolution of humans in two stages: achieving a bipedal posture freeing the hands to carry out the dictates of the brain, and the "recognition of the human brain as a totally new factor in the history of life. Wallace was apparently the first evolutionist to recognize clearly that ... with the emergence of that bodily specialization which constitutes the human brain, bodily specialization itself might be said to be outmoded." For this paper he won Darwin's praise.
Shortly afterwards, Wallace became a spiritualist. At about the same time, he began to maintain that natural selection cannot account for mathematical, artistic, or musical genius, as well as metaphysical musings, and wit and humour. He eventually said that something in "the unseen universe of Spirit" had interceded at least three times in history. The first was the creation of life from inorganic matter. The second was the introduction of consciousness in the higher animals. And the third was the generation of the higher mental faculties in humankind. He also believed that the raison d'être of the universe was the development of the human spirit. These views greatly disturbed Darwin, who argued that spiritual appeals were not necessary and that sexual selection could easily explain apparently non-adaptive mental phenomena.
While some historians have concluded that Wallace's belief that natural selection was insufficient to explain the development of consciousness and the human mind was directly caused by his adoption of spiritualism, other Wallace scholars have disagreed, and some maintain that Wallace never believed natural selection applied to those areas. Reaction to Wallace's ideas on this topic among leading naturalists at the time varied. Charles Lyell endorsed Wallace's views on human evolution rather than Darwin's. Wallace's belief that human consciousness could not be entirely a product of purely material causes was shared by a number of prominent intellectuals in the late 19th and early 20th centuries. However, many, including Huxley, Hooker, and Darwin himself, were critical of Wallace.
As the historian of science Michael Shermer has stated, Wallace's views in this area were at odds with two major tenets of the emerging Darwinian philosophy, which were that evolution was not teleological (purpose driven) and that it was not anthropocentric (human-centred). Much later in his life Wallace returned to these themes, that evolution suggested that the universe might have a purpose and that certain aspects of living organisms might not be explainable in terms of purely materialistic processes, in a 1909 magazine article entitled "The World of Life", which he later expanded into a book of the same name; a work that Shermer said anticipated some ideas about design in nature and directed evolution that would arise from various religious traditions throughout the 20th century.
In many accounts of the development of evolutionary theory, Wallace is mentioned only in passing as simply being the stimulus to the publication of Darwin's own theory. In reality, Wallace developed his own distinct evolutionary views which diverged from Darwin's, and was considered by many (especially Darwin) to be a leading thinker on evolution in his day, whose ideas could not be ignored. One historian of science has pointed out that, through both private correspondence and published works, Darwin and Wallace exchanged knowledge and stimulated each other's ideas and theories over an extended period. Wallace is the most-cited naturalist in Darwin's "Descent of Man", occasionally in strong disagreement.
Both Darwin and Wallace agreed on the importance of natural selection, and some of the factors responsible for it: competition between species and geographical isolation. But Wallace believed that evolution had a purpose ("teleology") in maintaining species' fitness to their environment, whereas Darwin hesitated to attribute any purpose to a random natural process. Scientific discoveries since the 19th century support Darwin's viewpoint, by identifying several additional mechanisms and triggers:
Wallace remained an ardent defender of natural selection for the rest of his life. By the 1880s, evolution was widely accepted in scientific circles, but natural selection less so. In 1889, Wallace published the book "Darwinism" as a response to the scientific critics of natural selection. Of all Wallace's books, it is the most cited by scholarly publications.
In 1872, at the urging of many of his friends, including Darwin, Philip Sclater, and Alfred Newton, Wallace began research for a general review of the geographic distribution of animals. Initial progress was slow, in part because classification systems for many types of animals were in flux. He resumed the work in earnest in 1874 after the publication of a number of new works on classification. Extending the system developed by Sclater for birds—which divided the earth into six separate geographic regions for describing species distribution—to cover mammals, reptiles and insects as well, Wallace created the basis for the zoogeographic regions still in use today. He discussed all of the factors then known to influence the current and past geographic distribution of animals within each geographic region.
These factors included the effects of the appearance and disappearance of land bridges (such as the one currently connecting North America and South America) and the effects of periods of increased glaciation. He provided maps showing factors, such as elevation of mountains, depths of oceans, and the character of regional vegetation, that affected the distribution of animals. He also summarised all the known families and genera of the higher animals and listed their known geographic distributions. The text was organised so that it would be easy for a traveller to learn what animals could be found in a particular location. The resulting two-volume work, "The Geographical Distribution of Animals", was published in 1876 and served as the definitive text on zoogeography for the next 80 years.
The book included evidence from the fossil record to discuss the processes of evolution and migration that had led to the geographical distribution of modern species. For example, he discussed how fossil evidence showed that tapirs had originated in the Northern Hemisphere, migrating between North America and Eurasia and then, much more recently, to South America after which the northern species became extinct, leaving the modern distribution of two isolated groups of tapir species in South America and Southeast Asia. Wallace was very aware of, and interested in, the mass extinction of megafauna in the late Pleistocene. In "The Geographical Distribution of Animals" (1876) he wrote, "We live in a zoologically impoverished world, from which all the hugest, and fiercest, and strangest forms have recently disappeared". He added that he believed the most likely cause for the rapid extinctions was glaciation, but by the time he wrote "World of Life" (1911) he had come to believe those extinctions were "due to man's agency".
In 1880, Wallace published the book "Island Life" as a sequel to "The Geographical Distribution of Animals". It surveyed the distribution of both animal and plant species on islands. Wallace classified islands into oceanic and two types of continental islands.
Oceanic islands, such as the Galapagos and Hawaiian Islands (then called Sandwich Islands) formed in mid-ocean and never part of any large continent. Such islands were characterised by a complete lack of terrestrial mammals and amphibians, and their inhabitants (except migratory birds and species introduced by humans) were typically the result of accidental colonisation and subsequent evolution.
Continental islands were divided into those that were recently separated from a continent (like Britain) and those much less recently (like Madagascar). Wallace discussed how that difference affected flora and fauna. He discussed how isolation affected evolution and how that could result in the preservation of classes of animals, such as the lemurs of Madagascar that were remnants of once widespread continental faunas. He extensively discussed how changes of climate, particularly periods of increased glaciation, may have affected the distribution of flora and fauna on some islands, and the first portion of the book discusses possible causes of these great ice ages. "Island Life" was considered a very important work at the time of its publication. It was discussed extensively in scientific circles both in published reviews and in private correspondence.
Wallace's extensive work in biogeography made him aware of the impact of human activities on the natural world. In "Tropical Nature and Other Essays" (1878), he warned about the dangers of deforestation and soil erosion, especially in tropical climates prone to heavy rainfall. Noting the complex interactions between vegetation and climate, he warned that the extensive clearing of rainforest for coffee cultivation in Ceylon (now called Sri Lanka) and India would adversely impact the climate in those countries and lead to their impoverishment due to soil erosion. In "Island Life", Wallace again mentioned deforestation and invasive species. On the impact of European colonisation on the island of Saint Helena, he wrote:
Wallace's comments on environment grew more urgent later in his career. In "The World of Life" (1911) he wrote:
Wallace's 1904 book "Man's Place in the Universe" was the first serious attempt by a biologist to evaluate the likelihood of life on other planets. He concluded that the Earth was the only planet in the solar system that could possibly support life, mainly because it was the only one in which water could exist in the liquid phase. More controversially he maintained that it was unlikely that other stars in the galaxy could have planets with the necessary properties (the existence of other galaxies not having been proved at the time).
His treatment of Mars in this book was brief, and in 1907, Wallace returned to the subject with a book "Is Mars Habitable?" to criticise the claims made by Percival Lowell that there were Martian canals built by intelligent beings. Wallace did months of research, consulted various experts, and produced his own scientific analysis of the Martian climate and atmospheric conditions. Among other things, Wallace pointed out that spectroscopic analysis had shown no signs of water vapour in the Martian atmosphere, that Lowell's analysis of Mars's climate was seriously flawed and badly overestimated the surface temperature, and that low atmospheric pressure would make liquid water, let alone a planet-girding irrigation system, impossible. Richard Milner comments: "It was the brilliant and eccentric evolutionist Alfred Russel Wallace ... who effectively debunked Lowell's illusionary network of Martian canals." Wallace originally became interested in the topic because his anthropocentric philosophy inclined him to believe that man would likely be unique in the universe.
Wallace also wrote poetic verse, an example being 'A Description of Javita' from his book "Travels on the Amazon".
The poem begins:
'Tis where the streams divide, to swell the floods
Of the two mighty rivers of our globe;
Where gushing brooklets in their narrow beds'
There is an Indian village; all around,
The dark, eternal, boundless forest spreads
Its varied foliage. Stately palm-trees rise
On every side, and numerous trees unknown
Save by strange names uncouth to English ears.
Here I dwelt awhile the one white man
Among perhaps two hundred living souls.
They pass a peaceful and contented life'
I'd be an Indian here, and live content
To fish, and hunt, and paddle my canoe,
And see my children grow, like young wild fawns,
In health of body and in peace of mind,
Rich without wealth, and happy without gold !
The poem is referenced and partially recited in the BBC television series 'The Ascent of Man'.
In a letter to his brother-in-law in 1861, Wallace wrote:
Wallace was an enthusiast of phrenology. Early in his career, he experimented with hypnosis, then known as mesmerism. He used some of his students in Leicester as subjects, with considerable success. When he began his experiments with mesmerism, the topic was very controversial and early experimenters, such as John Elliotson, had been harshly criticised by the medical and scientific establishment. Wallace drew a connection between his experiences with mesmerism and his later investigations into spiritualism. In 1893, he wrote:
Wallace began investigating spiritualism in the summer of 1865, possibly at the urging of his older sister Fanny Sims, who had been involved with it for some time. After reviewing the literature on the topic and attempting to test the phenomena he witnessed at séances, he came to accept that the belief was connected to a natural reality. For the rest of his life, he remained convinced that at least some séance phenomena were genuine, no matter how many accusations of fraud sceptics made or how much evidence of trickery was produced. Historians and biographers have disagreed about which factors most influenced his adoption of spiritualism. It has been suggested by one biographer that the emotional shock he had received a few months earlier, when his first fiancée broke their engagement, contributed to his receptiveness to spiritualism. Other scholars have preferred to emphasise instead Wallace's desire to find rational and scientific explanations for all phenomena, both material and non-material, of the natural world and of human society.
Spiritualism appealed to many educated Victorians who no longer found traditional religious doctrine, such as that of the Church of England, acceptable yet were unsatisfied with the completely materialistic and mechanical view of the world that was increasingly emerging from 19th-century science. However, several scholars who have researched Wallace's views in depth have emphasised that, for him, spiritualism was a matter of science and philosophy rather than religious belief. Among other prominent 19th-century intellectuals involved with spiritualism were the social reformer Robert Owen, who was one of Wallace's early idols, the physicists William Crookes and Lord Rayleigh, the mathematician Augustus De Morgan, and the Scottish publisher Robert Chambers.
During the 1860s the stage magician John Nevil Maskelyne exposed the trickery of the Davenport brothers. Wallace was unable to accept that he had replicated their feats utilizing natural methods, and stated that Maskelyne possessed supernatural powers. However, in one of his writings Wallace dismissed Maskelyne, referring to a lecture exposing his tricks.
In 1874, Wallace visited the spirit photographer Frederick Hudson. A photograph of him with his deceased mother was produced and Wallace declared the photograph genuine, declaring "even if he had by some means obtained possession of all the photographs ever taken of my mother, they would not have been of the slightest use to him in the manufacture of these pictures. I see no escape from the conclusion that some spiritual being, acquainted with my mother's various aspects during life, produced these recognisable impressions on the plate." However, Hudson's photographs had previously been exposed as fraudulent in 1872.
Wallace's very public advocacy of spiritualism and his repeated defence of spiritualist mediums against allegations of fraud in the 1870s damaged his scientific reputation. In 1875 Wallace published the evidence he believed proved his position in his book "On Miracles and Modern Spiritualism" which is a compilation of essays he wrote over a period of time. In his chapter entitled 'Modern Spiritualism: Evidence of Men of Science', Wallace refers to "three men of the highest eminence in their respective departments" who were Professor De Morgan, Professor Hare and Judge Edmonds who all investigated spiritualist phenomena. However, Wallace himself is only quoting their results and was not present at any of their investigations. His vehement defence of spiritualism strained his relationships with previously friendly scientists such as Henry Bates, Thomas Huxley, and even Darwin, who felt he was overly credulous. Evidence of this can be seen in Wallace's letters dated 22 November and 1 December 1866, to Thomas Huxley asking him if he would be interested in getting involved in scientific spiritualist investigations which Huxley, politely but emphatically, declined on the basis that he had neither the time nor the inclination. Others, such as the physiologist William Benjamin Carpenter and zoologist E. Ray Lankester became openly and publicly hostile to Wallace over the issue. Wallace and other scientists who defended spiritualism, notably William Crookes, were subject to much criticism from the press, with "The Lancet" as the leading English medical journal of the time being particularly harsh. The controversy affected the public perception of Wallace's work for the rest of his career. When, in 1879, Darwin first tried to rally support among naturalists to get a civil pension awarded to Wallace, Joseph Hooker responded:
Hooker eventually relented and agreed to support the pension request.
In 1870, a flat-Earth proponent named John Hampden offered a £500 wager (equivalent to about £ in present-day terms) in a magazine advertisement to anyone who could demonstrate a convex curvature in a body of water such as a river, canal, or lake. Wallace, intrigued by the challenge and short of money at the time, designed an experiment in which he set up two objects along a six-mile (10 km) stretch of canal. Both objects were at the same height above the water, and he mounted a telescope on a bridge at the same height above the water as well. When seen through the telescope, one object appeared higher than the other, showing the curvature of the earth.
The judge for the wager, the editor of "Field" magazine, declared Wallace the winner, but Hampden refused to accept the result. He sued Wallace and launched a campaign, which persisted for several years, of writing letters to various publications and to organisations of which Wallace was a member denouncing him as a swindler and a thief. Wallace won multiple libel suits against Hampden, but the resulting litigation cost Wallace more than the amount of the wager, and the controversy frustrated him for years.
In the early 1880s, Wallace was drawn into the debate over mandatory smallpox vaccination. Wallace originally saw the issue as a matter of personal liberty; but, after studying some of the statistics provided by anti-vaccination activists, he began to question the efficacy of vaccination. At the time, the germ theory of disease was very new and far from universally accepted. Moreover, no one knew enough about the human immune system to understand why vaccination worked. When Wallace did some research, he discovered instances where supporters of vaccination had used questionable, in a few cases completely phony, statistics to support their arguments. Always suspicious of authority, Wallace suspected that physicians had a vested interest in promoting vaccination, and became convinced that reductions in the incidence of smallpox that had been attributed to vaccination were, in fact, due to better hygiene and improvements in public sanitation.
Another factor in Wallace's thinking was his belief that, because of the action of natural selection, organisms were in a state of balance with their environment, and that everything in nature, even disease-causing organisms, served a useful purpose in the natural order of things; he feared vaccination might upset that natural balance with unfortunate results. Wallace and other anti-vaccinationists pointed out that vaccination, which at the time was often done in a sloppy and unsanitary manner, could be dangerous.
In 1890, Wallace gave evidence before a Royal Commission investigating the controversy. When the commission examined the material he had submitted to support his testimony, they found errors, including some questionable statistics. "The Lancet" averred that Wallace and the other anti-vaccination activists were being selective in their choice of statistics, ignoring large quantities of data inconsistent with their position. The commission found that smallpox vaccination was effective and should remain compulsory, though they did recommend some changes in procedures to improve safety, and that the penalties for people who refused to comply be made less severe. Years later, in 1898, Wallace wrote a pamphlet, "Vaccination a Delusion; Its Penal Enforcement a Crime", attacking the commission's findings. It, in turn, was attacked by "The Lancet", which stated that it contained many of the same errors as his evidence given to the commission.
As a result of his writing, at the time of his death Wallace had been for many years a well-known figure both as a scientist and as a social activist. He was often sought out by journalists and others for his views on a variety of topics. He received honorary doctorates and a number of professional honours, such the Royal Society's Royal Medal and Darwin Medal in 1868 and 1890, respectively, and the Order of Merit in 1908. Above all, his role as the co-discoverer of natural selection and his work on zoogeography marked him out as an exceptional figure.
He was undoubtedly one of the greatest natural history explorers of the 19th century. Despite this, his fame faded quickly after his death. For a long time, he was treated as a relatively obscure figure in the history of science. A number of reasons have been suggested for this lack of attention, including his modesty, his willingness to champion unpopular causes without regard for his own reputation, and the discomfort of much of the scientific community with some of his unconventional ideas.
Recently, he has become a less obscure figure with the publication of several book-length biographies on him, as well as anthologies of his writings. In 2007 a literary critic for "New Yorker" magazine observed that five such biographies and two such anthologies had been published since 2000. There has also been a web page created that is dedicated to Wallace scholarship.
In a 2010 book, the environmentalist Tim Flannery claimed that Wallace was 'the first modern scientist to comprehend how essential cooperation is to our survival,' and suggested that Wallace's understanding of natural selection and his later work on the atmosphere be seen as a forerunner to modern ecological thinking.
The Natural History Museum, London, co-ordinated commemorative events for the Wallace centenary worldwide in the 'Wallace100' project in 2013. On 24 January, his portrait was unveiled in the Main Hall of the museum by Bill Bailey, a fervent admirer. On the BBC Two programme "Bill Bailey's Jungle Hero", first broadcast on 21 April 2013, Bailey revealed how Wallace cracked evolution by revisiting places where Wallace discovered exotic species. Episode one featured orangutans and flying frogs in Bailey's journey through Borneo. Episode two featured birds of paradise. On 7 November 2013, the 100th anniversary of Wallace's death, Sir David Attenborough unveiled a statue of Wallace at the museum. The statue was donated by the A. R. Wallace Memorial Fund, and was sculpted by Anthony Smith. It depicts Wallace as a young man, collecting in the jungle. November 2013 also marked the debut of "The Animated Life of A. R. Wallace", a paper-puppet animation film dedicated to Wallace's centennial.
Wallace was a prolific author. In 2002, a historian of science published a quantitative analysis of Wallace's publications. He found that Wallace had published 22 full-length books and at least 747 shorter pieces, 508 of which were scientific papers (191 of them published in "Nature"). He further broke down the 747 short pieces by their primary subjects as follows. 29% were on biogeography and natural history, 27% were on evolutionary theory, 25% were social commentary, 12% were on Anthropology, and 7% were on spiritualism and phrenology. An online bibliography of Wallace's writings has more than 750 entries. 
A more comprehensive list of Wallace's publications that are available online, as well as a full bibliography of all of Wallace's writings, has been compiled by the historian Charles H. Smith at The Alfred Russel Wallace Page.

</doc>
<doc id="1495" url="https://en.wikipedia.org/wiki?curid=1495" title="Australian Labor Party">
Australian Labor Party

The Australian Labor Party (ALP), also simply known as Labor and historically spelt Labour, is a major centre-left political party in Australia. The party has been in opposition at the federal level since the 2013 federal election. The party is a federal party with branches in each state and territory. Labor is in government in the states of Victoria, Queensland and Western Australia and also in the Australian Capital Territory and the Northern Territory. The party competes against the Liberal/National Coalition for political office at the federal, state and sometimes local levels. It is the oldest political party in Australia.
The ALP was not founded as a federal party until after the first sitting of the Australian Parliament in 1901. Nevertheless, it is regarded as descended from labour parties founded in the various Australian colonies by the emerging labour movement in Australia, formally beginning in 1891. Colonial labour parties contested seats from 1891, and federal seats following Federation at the 1901 federal election. The ALP formed the world's first labour party government as well as the world's first social democratic government at a national level. Labor was the first party in Australia to win a majority in either house of the Australian Parliament, at the 1910 federal election. At federal and state/colony level, the Australian Labor Party predates, among others, both the British Labour Party and the New Zealand Labour Party in party formation, government, and policy implementation. Internationally, the ALP is a member of the Progressive Alliance network of social-democratic parties, having previously been a member of the Socialist International.
In standard Australian English, the word "labour" is spelled with a "u". However, the political party uses the spelling "Labor", without a "u". There was originally no standardised spelling of the party's name, with "Labor" and "Labour" both in common usage. According to Ross McMullin, who wrote an official history of the Labor Party, the title page of the proceedings of Federal Conference used the spelling "Labor" in 1902, "Labour" in 1905 and 1908, and then "Labor" from 1912 onwards. In 1908, James Catts put forward a motion at Federal Conference that "the name of the party be the Australian Labour Party", which was carried by 22 votes to two. A separate motion recommending state branches to adopt the name was defeated. There was no uniformity of party names until 1918, when Federal Conference resolved that state branches should adopt the name "Australian Labor Party" – now spelled without a "u". Each state branch had previously used a different name, due to their different origins. 
Despite the ALP officially adopting the spelling without a "u", it took decades for the official spelling to achieve widespread acceptance. According to McMullin, "the way the spelling of 'Labor Party' was consolidated had more to do with the chap who ended up being in charge of printing the federal conference report than any other reason". Some sources have attributed the official choice of "Labor" to influence from King O'Malley, who was born in the United States and was reputedly an advocate of spelling reform; the spelling without a "u" is the standard form in American English. It has been suggested that the adoption of the spelling without a "u" "signified one of the ALP's earliest attempts at modernisation", and served the purpose of differentiating the party from the Australian labour movement as a whole and distinguishing it from other British Empire labour parties. The decision to include the word "Australian" in the party's name – rather than just "Labour Party" as in the United Kingdom – has been attributed to "the greater importance of nationalism for the founders of the colonial parties".
The Australian Labor Party has its origins in the Labour parties founded in the 1890s in the Australian colonies prior to federation. Labor tradition ascribes the founding of Queensland Labour to a meeting of striking pastoral workers under a ghost gum tree (the "Tree of Knowledge") in Barcaldine, Queensland in 1891. The Balmain, New South Wales branch of the party claims to be the oldest in Australia. Labour as a parliamentary party dates from 1891 in New South Wales and South Australia, 1893 in Queensland, and later in the other colonies.
The first election contested by Labour candidates was the 1891 New South Wales election, when Labour candidates (then called the Labor Electoral League of New South Wales) won 35 of 141 seats. The major parties were the Protectionist and Free Trade parties and Labour held the balance of power. It offered parliamentary support in exchange for policy concessions. The United Labor Party (ULP) of South Australia was founded in 1891, and three candidates were that year elected to the South Australian Legislative Council. The first successful South Australian House of Assembly candidate was John McPherson at the 1892 East Adelaide by-election. Richard Hooper however was elected as an Independent Labor candidate at the 1891 Wallaroo by-election, while he was the first "labor" member of the House of Assembly he was not a member of the newly formed ULP.
At the 1893 South Australian elections the ULP was immediately elevated to balance of power status with 10 of 54 lower house seats. The liberal government of Charles Kingston was formed with the support of the ULP, ousting the conservative government of John Downer. So successful, less than a decade later at the 1905 state election, Thomas Price formed the world's first stable Labor government. John Verran led Labor to form the state's first of many majority governments at the 1910 state election.
In 1899, Anderson Dawson formed a minority Labour government in Queensland, the first in the world, which lasted one week while the conservatives regrouped after a split.
The colonial Labour parties and the trade unions were mixed in their support for the Federation of Australia. Some Labour representatives argued against the proposed constitution, claiming that the Senate as proposed was too powerful, similar to the anti-reformist colonial upper houses and the British House of Lords. They feared that federation would further entrench the power of the conservative forces. However, the first Labour leader and Prime Minister Chris Watson was a supporter of federation.
Historian Celia Hamilton, examining New South Wales, argues for the central role of Irish Catholics. Before 1890, they opposed Henry Parkes, the main Liberal leader, and of free trade, seeing them both as the ideals of Protestant Englishmen who represented landholding and large business interests. In the strike of 1890 the leading Catholic, Sydney's Archbishop Patrick Francis Moran was sympathetic toward unions, but Catholic newspapers were negative. After 1900, says Hamilton, Irish Catholics were drawn to the Labour Party because its stress on equality and social welfare fitted with their status as manual labourers and small farmers. In the 1910 elections Labour gained in the more Catholic areas and the representation of Catholics increased in Labour's parliamentary ranks.
The federal parliament in 1901 was contested by each state Labour Party. In total, they won 14 of the 75 seats in the House of Representatives, collectively holding the balance of power, and the Labour members now met as the Federal Parliamentary Labour Party (informally known as the caucus) on 8 May 1901 at Parliament House, Melbourne, the meeting place of the first federal Parliament. The caucus decided to support the incumbent Protectionist Party in minority government, while the Free Trade Party formed the opposition. It was some years before there was any significant structure or organisation at a national level. Labour under Chris Watson doubled its vote at the 1903 federal election and continued to hold the balance of power. In April 1904, however, Watson and Alfred Deakin fell out over the issue of extending the scope of industrial relations laws concerning the Conciliation and Arbitration Bill to cover state public servants, the fallout causing Deakin to resign. Free Trade leader George Reid declined to take office, which saw Watson become the first Labour Prime Minister of Australia, and the world's first Labour head of government at a national level (Anderson Dawson had led a short-lived Labour government in Queensland in December 1899), though his was a minority government that lasted only four months. He was aged only 37, and is still the youngest Prime Minister in Australia's history.
George Reid of the Free Trade Party adopted a strategy of trying to reorient the party system along Labour vs. non-Labour lines prior to the 1906 federal election and renamed his Free Trade Party to the Anti-Socialist Party. Reid envisaged a spectrum running from socialist to anti-socialist, with the Protectionist Party in the middle. This attempt struck a chord with politicians who were steeped in the Westminster tradition and regarded a two-party system as very much the norm.
Although Watson further strengthened Labour's position in 1906, he stepped down from the leadership the following year, to be succeeded by Andrew Fisher who formed a minority government lasting seven months from late 1908 to mid 1909. At the 1910 federal election, Fisher led Labor to victory, forming Australia's first elected federal majority government, Australia's first elected Senate majority, the world's first Labour Party majority government at a national level, and after the 1904 Chris Watson minority government the world's second Labour Party government at a national level. It was the first time a Labour Party had controlled any house of a legislature, and the first time the party controlled both houses of a bicameral legislature. The state branches were also successful, except in Victoria, where the strength of Deakinite liberalism inhibited the party's growth. The state branches formed their first majority governments in New South Wales and South Australia in 1910, Western Australia in 1911, Queensland in 1915 and Tasmania in 1925. Such success eluded equivalent social democratic and labour parties in other countries for many years.
Analysis of the early NSW Labor caucus reveals "a band of unhappy amateurs", made up of blue collar workers, a squatter, a doctor, and even a mine owner, indicating that the idea that only the socialist working class formed Labor is untrue. In addition, many members from the working class supported the liberal notion of free trade between the colonies; in the first grouping of state MPs, 17 of the 35 were free-traders.
In the aftermath of World War I and the Russian Revolution of 1917, support for socialism grew in trade union ranks, and at the 1921 All-Australian Trades Union Congress a resolution was passed calling for "the socialisation of industry, production, distribution and exchange." The 1922 Labor Party National Conference adopted a similarly worded "socialist objective," which remained official policy for many years. The resolution was immediately qualified, however, by the "Blackburn amendment," which said that "socialisation" was desirable only when was necessary to "eliminate exploitation and other anti-social features." In practice the socialist objective was a dead letter. Only once has a federal Labor government attempted to nationalise any industry (Ben Chifley's bank nationalisation of 1947), and that was held by the High Court to be unconstitutional. The commitment to nationalisation was dropped by Gough Whitlam, and Bob Hawke's government carried out many free market reforms including the floating of the dollar and privatisation of state enterprises such as Qantas airways and the Commonwealth Bank.
The Labor Party is commonly described as a social democratic party, and its constitution stipulates that it is a democratic socialist party. The party was created by, and has always been influenced by, the trade unions, and in practice its policy at any given time has usually been the policy of the broader labour movement. Thus at the first federal election 1901 Labor's platform called for a White Australia policy, a citizen army and compulsory arbitration of industrial disputes. Labor has at various times supported high tariffs and low tariffs, conscription and pacifism, White Australia and multiculturalism, nationalisation and privatisation, isolationism and internationalism.
Historically, Labor and its affiliated unions were strong defenders of the White Australia policy, which banned all non-European migration to Australia. This policy was partly motivated by 19th century theories about "racial purity" and by fears of economic competition from low-wage overseas workers which was shared by the vast majority of Australians and all major political parties. In practice the Labor party opposed all migration, on the grounds that immigrants competed with Australian workers and drove down wages, until after World War II, when the Chifley Government launched a major immigration program. The party's opposition to non-European immigration did not change until after the retirement of Arthur Calwell as leader in 1967. Subsequently, Labor has become an advocate of multiculturalism, although some of its trade union base and some of its members continue to oppose high immigration levels.
The Curtin and Chifley governments governed Australia through the latter half of the Second World War and initial stages of transition to peace. Labor leader John Curtin became prime minister in October 1941 when two independents crossed the floor of Parliament. Labor, led by Curtin, then led Australia through the years of the Pacific War. In December 1941, Curtin announced that "Australia looks to America, free of any pangs as to our traditional links or kinship with the United Kingdom", thus helping to establish the Australian-American alliance (later formalised as ANZUS by the Menzies Government). Remembered as a strong war time leader and for a landslide win at the 1943 federal election, Curtin died in office just prior to the end of the war and was succeeded by Ben Chifley. Chifley Labor won the 1946 federal election and oversaw Australia's initial transition to a peacetime economy.
Labor was defeated at the 1949 federal election. At the conference of the New South Wales Labor Party in June 1949, Chifley sought to define the labour movement as follows:
To a large extent, Chifley saw centralisation of the economy as the means to achieve such ambitions. With an increasingly uncertain economic outlook, after his attempt to nationalise the banks and a strike by the Communist-dominated Miners' Federation, Chifley lost office in 1949 to Robert Menzies' Liberal-National Coalition. Labor commenced a 23-year period in opposition. The party was primarily led during this time by H. V. Evatt and Arthur Calwell. 
Various ideological beliefs were factionalised under reforms to the ALP under Gough Whitlam, resulting in what is now known as the Socialist Left who tend to favour a more interventionist economic policy and more socially progressive ideals, and Labor Right, the now dominant faction that tends to be more economically liberal and focus to a lesser extent on social issues. The Whitlam Labor government, marking a break with Labor's socialist tradition, pursued social-democratic policies rather than democratic socialist policies. In contrast to earlier Labor leaders, Whitlam also cut tariffs by 25 percent. Whitlam led the Federal Labor Party back to office at the 1972 and 1974 federal elections, and passed a large amount of legislation. The Whitlam Government lost office following the 1975 Australian constitutional crisis and dismissal by Governor-General John Kerr after the Coalition blocked supply in the Senate after a series of political scandals, and was defeated at the 1975 federal election. Whitlam remains the only Prime Minister to have his commission terminated in that manner. Whitlam also lost the 1977 federal election and subsequently resigned as leader.
Bill Hayden succeeded Whitlam as leader in the 1980 federal election the party managed to gain more seats however they still lost. In 1983, Bob Hawke became leader of the party after Hayden resigned to avoid a leadership spill.
Bob Hawke led Labor back to office at the 1983 federal election and the party won 4 elections under Hawke. In December 1991 Paul Keating defeated Bob Hawke in a leadership spill. The Party then won the 1993 federal election. The Hawke–Keating Government was in power for 13 years with 5 terms until defeated by John Howard at the 1996 federal election. This was the longest period the party was in Government.
Kim Beazley led the party to the 1998 federal election, winning 51 percent of the two-party-preferred vote but falling short on seats, and lost ground at the 2001 federal election. Mark Latham led Labor to the 2004 federal election but lost further ground. Beazley replaced Latham in 2005. Beazley in turn was challenged by Kevin Rudd.
Rudd went on to defeat John Howard at the 2007 federal election with 52.7 percent of the two-party vote. The Rudd Government ended prior to the 2010 federal election with the replacement of Rudd as leader of the Party by deputy leader Julia Gillard. The Gillard Government was commissioned to govern in a hung parliament following the election with a one-seat parliamentary majority and 50.12 percent of the two-party vote. The Gillard government lasted until 2013 when Gillard lost a leadership spill with Rudd becoming leader once again. The party subsequently lost the 2013 federal election.
After the 2013 election, Rudd resigned as leader and Bill Shorten became leader of the party. The party narrowly lost the 2016 federal election however it gained 14 seats and was 7 seats away from majority Government. It remained in opposition after the 2019 federal election despite having been ahead in opinion polls for 2 years. The party lost some of the seats it had gained at the previous election. After the 2019 election, Shorten stood down as leader. Anthony Albanese was elected as leader unopposed.
Between the 2007 federal election and the 2008 Western Australian state election, Labor was in government nationally and in all eight state and territory legislatures. This was the first time any single party or any coalition had achieved this since the ACT and the NT gained self-government. Labor narrowly lost government in Western Australia at the 2008 state election and Victoria at the 2010 state election. These losses were further compounded by landslide defeats in New South Wales in 2011, Queensland in 2012, the Northern Territory in 2012, Federally in 2013 and Tasmania in 2014. Labor secured a good result in the Australian Capital Territory in 2012 and, despite losing its majority, the party retained government in South Australia in 2014.
However, most of these reversals proved only temporary with Labor returning to government in Victoria in 2014 and in Queensland in 2015 after spending only one term in opposition in both states. Furthermore, after winning the 2014 Fisher by-election by nine votes from a 7.3 percent swing, the Labor government in South Australia went from minority to majority government. Labor won landslide victories in the 2016 Northern Territory election, the 2017 Western Australian election and the 2018 Victorian state election. However, Labor lost the 2018 South Australian state election after 16 years in government. Despite favourable polling, the party also did not return to government in the 2019 New South Wales state election or the 2019 federal election. The latter has been considered a historic upset due to Labor's consistent and significant polling lead; the result has been likened to the Coalition's loss in the 1993 federal election, with 2019 retrospectively referred to as "unloseable election".
The policy of the Australian Labor Party is contained in its National Platform, which is approved by delegates to Labor's National Conference, held every three years. According to the Labor Party's website, "The Platform is the result of a rigorous and constructive process of consultation, spanning the nation and including the cooperation and input of state and territory policy committees, local branches, unions, state and territory governments, and individual Party members. The Platform provides the policy foundation from which we can continue to work towards the election of a federal Labor Government."
The platform gives a general indication of the policy direction which a future Labor government would follow, but does not commit the party to specific policies. It maintains that "Labor's traditional values will remain a constant on which all Australians can rely." While making it clear that Labor is fully committed to a market economy, it says that: "Labor believes in a strong role for national government – the one institution all Australians truly own and control through our right to vote." Labor "will not allow the benefits of change to be concentrated in fewer and fewer hands, or located only in privileged communities. The benefits must be shared by all Australians and all our regions." The platform and Labor "believe that all people are created equal in their entitlement to dignity and respect, and should have an equal chance to achieve their potential." For Labor, "government has a critical role in ensuring fairness by: ensuring equal opportunity; removing unjustifiable discrimination; and achieving a more equitable distribution of wealth, income and status." Further sections of the platform stress Labor's support for equality and human rights, labour rights and democracy.
In practice, the platform provides only general policy guidelines to Labor's federal, state and territory parliamentary leaderships. The policy Labor takes into an election campaign is determined by the Cabinet (if the party is in office) or the Shadow Cabinet (if it is in opposition), in consultation with key interest groups within the party, and is contained in the parliamentary Leader's policy speech delivered during the election campaign. When Labor is in office, the policies it implements are determined by the Cabinet, subject to the platform. Generally, it is accepted that while the platform binds Labor governments, how and when it is implemented remains the prerogative of the parliamentary caucus. It is now rare for the platform to conflict with government policy, as the content of the platform is usually developed in close collaboration with the party's parliamentary leadership as well as the factions. However, where there is a direct contradiction with the platform, Labor governments have sought to change the platform as a prerequisite for a change in policy. For example, privatisation legislation under the Hawke government occurred only after holding a special national conference to debate changing the platform.
The Australian Labor Party National Executive is the party's chief administrative authority, subject only to Labor's national conference. The executive is responsible for organising the triennial national conference; carrying out the decisions of the conference; interpreting the national constitution, the national platform and decisions of the national conference; and directing federal members.
The party holds a national conference every three years, which consists of delegates representing the state and territory branches (many coming from affiliated trade unions, although there is no formal requirement for unions to be represented at the national conference). The national conference decides the party's platform, elects the national executive and appoints office-bearers such as the national secretary, who also serves as national campaign director during elections. The current national secretary is Paul Erickson. The most recent national conference was the 48th conference held in December 2018.
The head office of the ALP, the national secretariat, is managed by the national secretary. It plays a dual role of administration and a national campaign strategy. It acts as a permanent secretariat to the national executive by managing and assisting in all administrative affairs of the party. As the national secretary also serves as national campaign director during elections, it is also responsible for the national campaign strategy and organisation.
The elected members of the Labor party in both houses of the national Parliament meet as the Federal Parliamentary Labor Party, also known as the Australian Labor Party Caucus (see also caucus). Besides discussing parliamentary business and tactics, the Caucus also is involved in the election of the federal parliamentary leaders.
Until 2013, the parliamentary leaders were elected by the Caucus from among its members. The leader has historically been a member of the House of Representatives. Since October 2013, a ballot of both the Caucus and by the Labor Party's rank-and-file members determined the party leader and the deputy leader. When the Labor Party is in government, the party leader is the Prime Minister and the deputy leader is the Deputy Prime Minister. If a Labor prime minister resigns or dies in office, the deputy leader acts as prime minister and party leader until a successor is elected. The deputy prime minister also acts as prime minister when the prime minister is on leave or out of the country. Members of the Ministry are also chosen by Caucus, though the leader may allocate portfolios to the ministers.
Anthony Albanese is the leader of the federal Labor party, serving since 30 May 2019. The deputy leader is Richard Marles, also serving since 30 May 2019.
The Australian Labor Party is a federal party, consisting of eight branches from each state and territory. While the National Executive is responsible for national campaign strategy, each state and territory are an autonomous branch and are responsible for campaigning in their own jurisdictions for federal, state and local elections. State and territory branches consist of both individual members and affiliated trade unions, who between them decide the party's policies, elect its governing bodies and choose its candidates for public office.
Members join a state branch and pay a membership fee, which is graduated according to income. The majority of trade unions in Australia are affiliated to the party at a state level. Union affiliation is direct and not through the Australian Council of Trade Unions. Affiliated unions pay an affiliation fee based on the size of their membership. Union affiliation fees make up a large part of the party's income. Another source of funds for the party are political donations and public funding.
Members are generally expected to attend at least one meeting of their local branch each year, although there are differences in the rules from state to state. In practice only a dedicated minority regularly attend meetings. Many members are only active during election campaigns.
The members and unions elect delegates to state and territory conferences (usually held annually, although more frequent conferences are often held). These conferences decide policy, and elect state or territory executives, a state or territory president (an honorary position usually held for a one-year term), and a state or territory secretary (a full-time professional position). However, ACT Labor directly elects its president. The larger branches also have full-time assistant secretaries and organisers. In the past the ratio of conference delegates coming from the branches and affiliated unions has varied from state to state, however under recent national reforms at least 50% of delegates at all state and territory conferences must be elected by branches.
In some states it also contests local government elections or endorses local candidates. In others it does not, preferring to allow its members to run as non-endorsed candidates. The process of choosing candidates is called preselection. Candidates are preselected by different methods in the various states and territories. In some they are chosen by ballots of all party members, in others by panels or committees elected by the state conference, in still others by a combination of these two.
The state and territory Labor branches are the following:
Country Labor is a subsection of the ALP, and is used as a designation by candidates contesting elections in rural areas. The Country Labor Party is registered as a separate party in New South Wales, and is also registered with the Australian Electoral Commission (AEC) for federal elections. It does not have the same status in other states and, consequently, that designation cannot be used on the ballot paper.
The creation of a separation designation for rural candidates was first suggested at the June 1999 ALP state conference in New South Wales. In May 2000, following Labor's success at the 2000 Benalla by-election in Victoria, Kim Beazley announced that the ALP intended to register a separate "Country Labor Party" with the AEC; this occurred in October 2000. The Country Labor designation is most frequently used in New South Wales. According to the ALP's financial statements for the 2015–16 financial year, NSW Country Labor had around 2,600 members (around 17 percent of the party total), but almost no assets. It recorded a severe funding shortfall at the 2015 New South Wales election, and had to rely on a $1.68-million loan from the party proper to remain solvent. It had been initially assumed that the party proper could provide the money from its own resources, but the NSW Electoral Commission ruled that this was impermissible because the parties were registered separately. Instead the party proper had to loan Country Labor the required funds at a commercial interest rate.
Australian Young Labor is the youth wing of the Australian Labor Party, where all members under age 26 are automatically members. It is the peak youth body within the ALP. Former presidents of AYL have included former NSW Premier Bob Carr, Federal Manager of Opposition Business Tony Burke, former Special Minister of State Senator John Faulkner, former Australian Workers Union National Secretary, current Member for Maribyrnong and former Federal Labor Leader Bill Shorten as well as dozens of State Ministers and MPs. The current National President is Jason Byrne from South Australia.
The Australian Labor Party is beginning to formally recognise single interest groups within the party. The national platform currently encourages state branches to formally establish these groups known as policy action caucuses. Examples of such groups include the Labor Environment Action Network, Rainbow Labor, and Labor for Refugees. The Tasmanian Branch of the Australian Labor Party recently gave these groups voting and speaking rights at their state conference.
Labor's constitution has long stated: "The Australian Labor Party is a democratic socialist party and has the objective of the democratic socialisation of industry, production, distribution and exchange, to the extent necessary to eliminate exploitation and other anti-social features in these fields". This "socialist objective" was introduced in 1921, but was later qualified by two further objectives: "maintenance of and support for a competitive non-monopolistic private sector" and "the right to own private property". Labor governments have not attempted the "democratic socialisation" of any industry since the 1940s, when the Chifley Government failed to nationalise the private banks, and in fact have privatised several industries such as aviation and banking. Labor's current National Platform describes the party as "a modern social democratic party".
The Labor Party has always had a left wing and a right wing, but since the 1970s it has been organised into formal factions, to which party members may belong and often pay an additional membership fee. The two largest factions are Labor Right and Labor Left. Labor Right generally supports free-market policies and the US alliance and tends to be conservative on some social issues. The Labor Left favours more state intervention in the economy, is generally less enthusiastic about the US alliance and is often more liberal on social issues. The national factions are themselves divided into sub-factions, primarily state-based such as Centre Unity in New South Wales and Labor Forum in Queensland.
Some trade unions are affiliated with the Labor Party and are also factionally aligned. The largest unions supporting the right faction are the Australian Workers' Union (AWU), the Shop, Distributive and Allied Employees' Association (SDA) and the Transport Workers Union (TWU). Important unions supporting the left include the Australian Manufacturing Workers Union (AMWU), United Workers Union, the Construction, Forestry, Maritime, Mining and Energy Union (CFMMEU) and the Community and Public Sector Union (CPSU).
Preselections are usually conducted along factional lines, although sometimes a non-factional candidate will be given preferential treatment (this happened with Cheryl Kernot in 1998 and again with Peter Garrett in 2004). Deals between the factions to divide up the safe seats between them often take place. Preselections, particularly for safe Labor seats, can sometimes be strongly contested. A particularly fierce preselection sometimes gives rise to accusations of branch stacking (signing up large numbers of nominal party members to vote in preselection ballots), personation, multiple voting and, on occasions, fraudulent electoral enrolment. Trade unions were in the past accused of giving inflated membership figures to increase their influence over preselections, but party rules changes have stamped out this practice. Preselection results are sometimes challenged, and the National Executive is sometimes called on to arbitrate these disputes.
For the 2015–2016 financial year, the top ten disclosed donors to the ALP were the Health Services Union NSW ($389,000), Village Roadshow ($257,000), Electrical Trades Union of Australia ($171,000), National Automotive Leasing and Salary Packaging Association ($153,000), Westfield Corporation ($150,000), Randazzo C&G Developments ($120,000), Macquarie Telecom ($113,000), Woodside Energy ($110,000), ANZ Bank ($100,000) and Ying Zhou ($100,000).
The Labor Party also receives undisclosed funding through several methods, such as "associated entities". John Curtin House, Industry 2020, IR21 and the Happy Wanderers Club are entities which have been used to funnel donations to the Labor Party without disclosing the source.
A 2019 report found that the Labor Party received $33,000 from pro-gun groups during the 2011–2018 periods, threatening to undermine Australian gun control laws. However, the Coalition received over $82,000 in donations from pro-gun groups, almost doubling Labor's pro-gun donors.

</doc>
<doc id="1496" url="https://en.wikipedia.org/wiki?curid=1496" title="August 18">
August 18


</doc>
<doc id="1497" url="https://en.wikipedia.org/wiki?curid=1497" title="August 19">
August 19


</doc>
<doc id="1499" url="https://en.wikipedia.org/wiki?curid=1499" title="August 21">
August 21


</doc>
<doc id="1500" url="https://en.wikipedia.org/wiki?curid=1500" title="Dodo (Alice's Adventures in Wonderland)">
Dodo (Alice's Adventures in Wonderland)

The Dodo is a fictional character appearing in Chapters 2 and 3 of the 1865 book "Alice's Adventures in Wonderland" by Lewis Carroll (Charles Lutwidge Dodgson). The Dodo is a caricature of the author. A popular but unsubstantiated belief is that Dodgson chose the particular animal to represent himself because of his stammer, and thus would accidentally introduce himself as "Do-do-dodgson".
Historically, the Dodo was a non-flying bird that lived on the island of Mauritius, east of Madagascar in the Indian Ocean. It became extinct in the mid 17th century during the colonisation of the island by the Dutch.
In this passage Lewis Carroll incorporated references to the original boating expedition of 4 July 1862 during which Alice's Adventures were first told, with Alice as herself, and the others represented by birds: the Lory was Lorina Liddell, the Eaglet was Edith Liddell, the Dodo was Dodgson, and the Duck was Rev. Robinson Duckworth. In order to get dry after a swim, the Dodo proposes that everyone run a Caucus race – where the participants run in patterns of any shape, starting and leaving off whenever they like, so that everyone wins. At the end of the race, Alice distributes comfits from her pocket to all as prizes. However this leaves no prize for herself. The Dodo inquires what else she has in her pocket. As she has only a thimble, the Dodo requests it from her and then awards it to Alice as her prize. The Caucus Race, as depicted by Carroll, is a satire on the political caucus system, mocking its lack of clarity and decisiveness.
In the Disney film, the Dodo plays a much greater role in the story. He is merged with the character of Pat the Gardener, which leads to him sometimes being nicknamed Pat the Dodo, but this name is never mentioned in the film. The Dodo is also the leader of the caucus race. He has the appearance and personality of a sea captain. The Dodo is voiced by Bill Thompson and animated by Milt Kahl.
Dodo is first seen as Alice is floating on the sea in a bottle. Dodo is seen singing, but when Alice asks him for help, he does not notice her. On shore, Dodo is seen on a rock, organizing a caucus race. This race involves running around until one gets dry, but the attempts are hampered by incoming waves.
Dodo is later summoned by the White Rabbit, when the rabbit believes a monster, actually Alice having magically grown to a giant size, is inside his home. Dodo brings Bill the Lizard, and attempts to get him to go down the chimney. Bill refuses at first, but Dodo is able to convince him otherwise. However, the soot causes Alice to sneeze, sending Bill high up into the sky. Dodo then decides to burn the house down, much to the chagrin of the White Rabbit. He begins gathering wood, such as the furniture, for this purpose. However, Alice is soon able to return to a smaller size and exit the house.
The White Rabbit soon leaves, while Dodo asks for matches, not realizing that the situation has been resolved. He then asks Alice for a match, but when she doesn't have any, Dodo complains about the lack of cooperation and uses his pipe to light the fire.
The Dodo later appears briefly at the end of the film, conducting another Caucus Race.
In Tim Burton's adaptation of Alice in Wonderland, the Dodo's appearance retains the subtle apparent nature from John Tenniel's illustration. He bears a down of brilliant blue and wears a blue coat and white spats along with glasses and a cane. He is one of Alice's good-willed advisers, taking first note of her abilities as the true Alice. He is also one of the oldest inhabitants. His name is Uilleam, and he is portrayed by Michael Gough. He goes with the White Rabbit, Tweedledee and Tweedledum, and Dormouse to take Alice to Caterpillar to decide whether Alice is the real one. He is later captured by the Red Queen's forces. When Alice came to the Red Queen's castle, he was seen at the Red Queen's castle yard as a caddy for the Queen's croquet game. After the Red Queen orders the release of the Jubjub bird to kill all her subjects from rebelling, he is then seen briefly running from it when the Tweedles went to hide from it and escaped but was snatched by the Jubjub and was never seen again throughout the film.
His name may be based on a lecture on William the Conqueror from Chapter Three of the original novel. The character is voiced by Michael Gough in his final feature film role before his death in 2011. Gough came out of retirement to appear in the film but the character only speaks three lines, so Gough managed to record in one day.
In the anime and manga series "Pandora Hearts" Dodo is the chain of Rufus Barma one of the four dukedoms.

</doc>
<doc id="1501" url="https://en.wikipedia.org/wiki?curid=1501" title="Lory (disambiguation)">
Lory (disambiguation)

A Lory is a small to medium-sized arboreal parrot.
Lory may also refer to:

</doc>
<doc id="1504" url="https://en.wikipedia.org/wiki?curid=1504" title="Albert">
Albert

Albert may refer to:

</doc>
<doc id="1505" url="https://en.wikipedia.org/wiki?curid=1505" title="Albert I">
Albert I

Albert I may refer to:

</doc>
<doc id="1506" url="https://en.wikipedia.org/wiki?curid=1506" title="Albert II">
Albert II

Albert II may refer to:

</doc>
